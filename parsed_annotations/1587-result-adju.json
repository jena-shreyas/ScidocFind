[{"paper_id": "1587", "title": "Get out the vote: Determining support or opposition from Congressional floor-debate transcripts", "background_label": "We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation.", "method_label": "To address this problem, we exploit the fact that these speeches occur as part of a discussion; this allows us to use sources of information regarding relationships between discourse segments, such as whether a given utterance indicates agreement with the opinion expressed by another.", "result_label": "We find that the incorporation of such information yields substantial improvements over classifying speeches in isolation.", "abstract": "We investigate whether one can determine from the transcripts of U.S. Congressional floor debates whether the speeches represent support of or opposition to proposed legislation. To address this problem, we exploit the fact that these speeches occur as part of a discussion; this allows us to use sources of information regarding relationships between discourse segments, such as whether a given utterance indicates agreement with the opinion expressed by another. We find that the incorporation of such information yields substantial improvements over classifying speeches in isolation."}, {"paper_id": "195348911", "adju_relevance": 3, "title": "Learning alignments from legislative discourse", "method_label": "To perform this study, we use a corpus of bill discussion transcripts provided by Digital Democracy1. We then apply proven learning methods in the field of natural language processing to predict alignment scores between each member of the California state legislature and a select set of state-recognized organizations. Our methods surpass established baselines, achieving up to 78% accuracy when predicting these same scores using discourse features.", "abstract": " To perform this study, we use a corpus of bill discussion transcripts provided by Digital Democracy1. To perform this study, we use a corpus of bill discussion transcripts provided by Digital Democracy1. We then apply proven learning methods in the field of natural language processing to predict alignment scores between each member of the California state legislature and a select set of state-recognized organizations. To perform this study, we use a corpus of bill discussion transcripts provided by Digital Democracy1. We then apply proven learning methods in the field of natural language processing to predict alignment scores between each member of the California state legislature and a select set of state-recognized organizations. Our methods surpass established baselines, achieving up to 78% accuracy when predicting these same scores using discourse features."}, {"paper_id": "6361438", "adju_relevance": 3, "title": "Mining newsgroups using networks arising from social behavior", "background_label": "Recent advances in information retrieval over hyperlinked corpora have convincingly demonstrated that links carry less noisy information than text.", "abstract": "Recent advances in information retrieval over hyperlinked corpora have convincingly demonstrated that links carry less noisy information than text."}, {"paper_id": "17312927", "adju_relevance": 3, "title": "Stance Classification using Dialogic Properties of Persuasion", "background_label": "AbstractPublic debate functions as a forum for both expressing and forming opinions, an important aspect of public life.", "abstract": "AbstractPublic debate functions as a forum for both expressing and forming opinions, an important aspect of public life."}, {"paper_id": "18151048", "adju_relevance": 3, "title": "Support or Oppose? Classifying Positions in Online Debates from Reply Activities and Opinion Expressions", "method_label": "An online debate is a forum where each user post an opinion on a particular topic while other users state their positions by posting their remarks within the debate. The supporting or opposing remarks are made by directly replying to the opinion, or indirectly to other remarks (to express local agreement or disagreement), which makes the task of identifying users' general positions difficult. A prior study has shown that a linkbased method, which completely ignores the content of the remarks, can achieve higher accuracy for the identification task than methods based solely on the contents of the remarks.", "result_label": "In this paper, we show that utilizing the textual content of the remarks into the link-based method can yield higher accuracy in the identification task.", "abstract": " An online debate is a forum where each user post an opinion on a particular topic while other users state their positions by posting their remarks within the debate. An online debate is a forum where each user post an opinion on a particular topic while other users state their positions by posting their remarks within the debate. The supporting or opposing remarks are made by directly replying to the opinion, or indirectly to other remarks (to express local agreement or disagreement), which makes the task of identifying users' general positions difficult. An online debate is a forum where each user post an opinion on a particular topic while other users state their positions by posting their remarks within the debate. The supporting or opposing remarks are made by directly replying to the opinion, or indirectly to other remarks (to express local agreement or disagreement), which makes the task of identifying users' general positions difficult. A prior study has shown that a linkbased method, which completely ignores the content of the remarks, can achieve higher accuracy for the identification task than methods based solely on the contents of the remarks. In this paper, we show that utilizing the textual content of the remarks into the link-based method can yield higher accuracy in the identification task."}, {"paper_id": "6819967", "adju_relevance": 3, "title": "How can you say such things?!?: Recognizing Disagreement in Informal Political Argument", "background_label": "AbstractThe recent proliferation of political and social forums has given rise to a wealth of freely accessible naturalistic arguments. People can \"talk\" to anyone they want, at any time, in any location, about any topic.", "method_label": "Here we use a Mechanical Turk annotated corpus of forum discussions as a gold standard for the recognition of disagreement in online ideological forums. We analyze the utility of meta-post features, contextual features, dependency features and word-based features for signaling the disagreement relation.", "result_label": "We show that using contextual and dialogic features we can achieve accuracies up to 68% as compared to a unigram baseline of 63%.", "abstract": "AbstractThe recent proliferation of political and social forums has given rise to a wealth of freely accessible naturalistic arguments. AbstractThe recent proliferation of political and social forums has given rise to a wealth of freely accessible naturalistic arguments. People can \"talk\" to anyone they want, at any time, in any location, about any topic. Here we use a Mechanical Turk annotated corpus of forum discussions as a gold standard for the recognition of disagreement in online ideological forums. Here we use a Mechanical Turk annotated corpus of forum discussions as a gold standard for the recognition of disagreement in online ideological forums. We analyze the utility of meta-post features, contextual features, dependency features and word-based features for signaling the disagreement relation. We show that using contextual and dialogic features we can achieve accuracies up to 68% as compared to a unigram baseline of 63%."}, {"paper_id": "1589010", "adju_relevance": 2, "title": "Collective Content Selection for Concept-to-Text Generation", "background_label": "A content selection component determines which information should be conveyed in the output of a natural language generation system.", "method_label": "We present an efficient method for automatically learning content selection rules from a corpus and its related database. Our modeling framework treats content selection as a collective classification problem, thus allowing us to capture contextual dependencies between input items.", "result_label": "Experiments in a sports domain demonstrate that this approach achieves a substantial improvement over context-agnostic methods.", "abstract": "A content selection component determines which information should be conveyed in the output of a natural language generation system. We present an efficient method for automatically learning content selection rules from a corpus and its related database. We present an efficient method for automatically learning content selection rules from a corpus and its related database. Our modeling framework treats content selection as a collective classification problem, thus allowing us to capture contextual dependencies between input items. Experiments in a sports domain demonstrate that this approach achieves a substantial improvement over context-agnostic methods."}, {"paper_id": "6817372", "adju_relevance": 2, "title": "A Problem For RST: The Need For Multi-Level Discourse Analysis", "background_label": "Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Moreover, RST suggests that the information conveyed in a discourse over and above what is conveyed in its component clauses can be derived from the rhetorical relation-based structure of the discourse. A large number of natural language generation systems rely on the rhetorical relations defined in RST to impose structure on multi-sentential text (Hovy 1991; Knott 1991; Moore and Paris 1989; Rosner and Stede 1992). In addition, many descriptive studies of discourse have employed RST (Fox 1987; Linden, Cumming, and Martin 1992; Matthiessen and Thompson 1988). However, recent work by Moore and Paris (1992) noted that RST cannot be used as the sole means of controlling discourse structure in an interactive dialogue system, because RST representations provide insufficient information to support the generation of appropriate responses to \"follow-up questions.\"", "abstract": "Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Moreover, RST suggests that the information conveyed in a discourse over and above what is conveyed in its component clauses can be derived from the rhetorical relation-based structure of the discourse. Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Moreover, RST suggests that the information conveyed in a discourse over and above what is conveyed in its component clauses can be derived from the rhetorical relation-based structure of the discourse. A large number of natural language generation systems rely on the rhetorical relations defined in RST to impose structure on multi-sentential text (Hovy 1991; Knott 1991; Moore and Paris 1989; Rosner and Stede 1992). Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Moreover, RST suggests that the information conveyed in a discourse over and above what is conveyed in its component clauses can be derived from the rhetorical relation-based structure of the discourse. A large number of natural language generation systems rely on the rhetorical relations defined in RST to impose structure on multi-sentential text (Hovy 1991; Knott 1991; Moore and Paris 1989; Rosner and Stede 1992). In addition, many descriptive studies of discourse have employed RST (Fox 1987; Linden, Cumming, and Martin 1992; Matthiessen and Thompson 1988). Rhetorical Structure Theory (RST) (Mann and Thompson 1987), argues that in most coherent discourse, consecutive discourse elements are related by a small set of rhetorical relations. Moreover, RST suggests that the information conveyed in a discourse over and above what is conveyed in its component clauses can be derived from the rhetorical relation-based structure of the discourse. A large number of natural language generation systems rely on the rhetorical relations defined in RST to impose structure on multi-sentential text (Hovy 1991; Knott 1991; Moore and Paris 1989; Rosner and Stede 1992). In addition, many descriptive studies of discourse have employed RST (Fox 1987; Linden, Cumming, and Martin 1992; Matthiessen and Thompson 1988). However, recent work by Moore and Paris (1992) noted that RST cannot be used as the sole means of controlling discourse structure in an interactive dialogue system, because RST representations provide insufficient information to support the generation of appropriate responses to \"follow-up questions.\""}, {"paper_id": "115228776", "adju_relevance": 2, "title": "The Theory and Practice of Discourse Parsing and Summarization", "background_label": "From the Publisher:  Until now, most discourse researchers have assumed that full semantic understanding is necessary to derive the discourse structure of texts. This book documents the first serious attempt to construct automatically and use nonsemantic computational structures for text summarization.", "method_label": "Daniel Marcu develops a semantics-free theoretical framework that is both general enough to be applicable to naturally occurring texts and concise enough to facilitate an algorithmic approach to discourse analysis. He presents and evaluates two discourse parsing methods: one uses manually written rules that reflect common patterns of usage of cue phrases such as \"however\" and \"in addition to\"; the other uses rules that are learned automatically from a corpus of discourse structures. By means of a psycholinguistic experiment, Marcu demonstrates how a discourse-based summarizer identifies the most important parts of texts at levels of performance that are close to those of humans.", "result_label": "Marcu also discusses how the automatic derivation of discourse structures may be used to improve the performance of current natural language generation, machine translation, summarization, question answering, and information retrieval systems.", "abstract": "From the Publisher:  Until now, most discourse researchers have assumed that full semantic understanding is necessary to derive the discourse structure of texts. From the Publisher:  Until now, most discourse researchers have assumed that full semantic understanding is necessary to derive the discourse structure of texts. This book documents the first serious attempt to construct automatically and use nonsemantic computational structures for text summarization. Daniel Marcu develops a semantics-free theoretical framework that is both general enough to be applicable to naturally occurring texts and concise enough to facilitate an algorithmic approach to discourse analysis. Daniel Marcu develops a semantics-free theoretical framework that is both general enough to be applicable to naturally occurring texts and concise enough to facilitate an algorithmic approach to discourse analysis. He presents and evaluates two discourse parsing methods: one uses manually written rules that reflect common patterns of usage of cue phrases such as \"however\" and \"in addition to\"; the other uses rules that are learned automatically from a corpus of discourse structures. Daniel Marcu develops a semantics-free theoretical framework that is both general enough to be applicable to naturally occurring texts and concise enough to facilitate an algorithmic approach to discourse analysis. He presents and evaluates two discourse parsing methods: one uses manually written rules that reflect common patterns of usage of cue phrases such as \"however\" and \"in addition to\"; the other uses rules that are learned automatically from a corpus of discourse structures. By means of a psycholinguistic experiment, Marcu demonstrates how a discourse-based summarizer identifies the most important parts of texts at levels of performance that are close to those of humans. Marcu also discusses how the automatic derivation of discourse structures may be used to improve the performance of current natural language generation, machine translation, summarization, question answering, and information retrieval systems."}, {"paper_id": "1469556", "adju_relevance": 2, "title": "Mining the peanut gallery: opinion extraction and semantic classification of product reviews", "background_label": "The web contains a wealth of product reviews, but sifting through them is a daunting task. Ideally, an opinion mining tool would process a set of search results for a given item, generating a list of product attributes (quality, features, etc.)", "abstract": "The web contains a wealth of product reviews, but sifting through them is a daunting task. The web contains a wealth of product reviews, but sifting through them is a daunting task. Ideally, an opinion mining tool would process a set of search results for a given item, generating a list of product attributes (quality, features, etc.)"}, {"paper_id": "11611132", "adju_relevance": 2, "title": "Collective Classification of Congressional Floor-Debate Transcripts", "background_label": "AbstractThis paper explores approaches to sentiment classification of U.S. Congressional floordebate transcripts.", "method_label": "Collective classification techniques are used to take advantage of the informal citation structure present in the debates. We use a range of methods based on local and global formulations and introduce novel approaches for incorporating the outputs of machine learners into collective classification algorithms.", "result_label": "Our experimental evaluation shows that the mean-field algorithm obtains the best results for the task, significantly outperforming the benchmark technique.", "abstract": "AbstractThis paper explores approaches to sentiment classification of U.S. Congressional floordebate transcripts. Collective classification techniques are used to take advantage of the informal citation structure present in the debates. Collective classification techniques are used to take advantage of the informal citation structure present in the debates. We use a range of methods based on local and global formulations and introduce novel approaches for incorporating the outputs of machine learners into collective classification algorithms. Our experimental evaluation shows that the mean-field algorithm obtains the best results for the task, significantly outperforming the benchmark technique."}, {"paper_id": "12092327", "adju_relevance": 2, "title": "Unveiling the Political Agenda of the European Parliament Plenary: A Topical Analysis", "background_label": "This study analyzes political interactions in the European Parliament (EP) by considering how the political agenda of the plenary sessions has evolved over time and the manner in which Members of the European Parliament (MEPs) have reacted to external and internal stimuli when making Parliamentary speeches. It does so by considering the context in which speeches are made, and the content of those speeches.", "method_label": "To detect latent themes in legislative speeches over time, speech content is analyzed using a new dynamic topic modeling method, based on two layers of matrix factorization. This method is applied to a new corpus of all English language legislative speeches in the EP plenary from the period 1999-2014.", "result_label": "Our findings suggest that the political agenda of the EP has evolved significantly over time, is impacted upon by the committee structure of the Parliament, and reacts to exogenous events such as EU Treaty referenda and the emergence of the Euro-crisis have a significant impact on what is being discussed in Parliament.", "abstract": "This study analyzes political interactions in the European Parliament (EP) by considering how the political agenda of the plenary sessions has evolved over time and the manner in which Members of the European Parliament (MEPs) have reacted to external and internal stimuli when making Parliamentary speeches. This study analyzes political interactions in the European Parliament (EP) by considering how the political agenda of the plenary sessions has evolved over time and the manner in which Members of the European Parliament (MEPs) have reacted to external and internal stimuli when making Parliamentary speeches. It does so by considering the context in which speeches are made, and the content of those speeches. To detect latent themes in legislative speeches over time, speech content is analyzed using a new dynamic topic modeling method, based on two layers of matrix factorization. To detect latent themes in legislative speeches over time, speech content is analyzed using a new dynamic topic modeling method, based on two layers of matrix factorization. This method is applied to a new corpus of all English language legislative speeches in the EP plenary from the period 1999-2014. Our findings suggest that the political agenda of the EP has evolved significantly over time, is impacted upon by the committee structure of the Parliament, and reacts to exogenous events such as EU Treaty referenda and the emergence of the Euro-crisis have a significant impact on what is being discussed in Parliament."}, {"paper_id": "2909452", "adju_relevance": 2, "title": "On the collective classification of email \"speech acts\"", "background_label": "We consider classification of email messages as to whether or not they contain certain \"email acts\", such as a request or a commitment. We show that exploiting the sequential correlation among email messages in the same thread can improve email-act classification.", "method_label": "More specifically, we describe a new text-classification algorithm based on a dependency-network based collective classification method, in which the local classifiers are maximum entropy models based on words and certain relational features.", "result_label": "We show that statistically significant improvements over a bag-of-words baseline classifier can be obtained for some, but not all, email-act classes. Performance improvements obtained by collective classification appears to be consistent across many email acts suggested by prior speech-act theory.", "abstract": "We consider classification of email messages as to whether or not they contain certain \"email acts\", such as a request or a commitment. We consider classification of email messages as to whether or not they contain certain \"email acts\", such as a request or a commitment. We show that exploiting the sequential correlation among email messages in the same thread can improve email-act classification. More specifically, we describe a new text-classification algorithm based on a dependency-network based collective classification method, in which the local classifiers are maximum entropy models based on words and certain relational features. We show that statistically significant improvements over a bag-of-words baseline classifier can be obtained for some, but not all, email-act classes. We show that statistically significant improvements over a bag-of-words baseline classifier can be obtained for some, but not all, email-act classes. Performance improvements obtained by collective classification appears to be consistent across many email acts suggested by prior speech-act theory."}, {"paper_id": "26117576", "adju_relevance": 2, "title": "Detecting Policy Preferences and Dynamics in the UN General Debate with Neural Word Embeddings", "background_label": "Foreign policy analysis has been struggling to find ways to measure policy preferences and paradigm shifts in international political systems.", "abstract": "Foreign policy analysis has been struggling to find ways to measure policy preferences and paradigm shifts in international political systems."}, {"paper_id": "2282762", "adju_relevance": 2, "title": "Discriminative Probabilistic Models for Relational Data", "background_label": "In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent. For example, in hypertext classification, the labels of linked pages are highly correlated. A standard approach is to classify each entity independently, ignoring the correlations between them.", "method_label": "Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models. Second, undirected models are well suited for discriminative training, where we optimize the conditional likelihood of the labels given the features, which generally improves classification accuracy. We show how to train these models effectively, and how to use approximate probabilistic inference over the learned model for collective classification of multiple related entities.", "result_label": "We provide experimental results on a webpage classification task, showing that accuracy can be significantly improved by modeling relational dependencies.", "abstract": "In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent. In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent. For example, in hypertext classification, the labels of linked pages are highly correlated. In many supervised learning tasks, the entities to be labeled are related to each other in complex ways and their labels are not independent. For example, in hypertext classification, the labels of linked pages are highly correlated. A standard approach is to classify each entity independently, ignoring the correlations between them. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models. Second, undirected models are well suited for discriminative training, where we optimize the conditional likelihood of the labels given the features, which generally improves classification accuracy. Recently, Probabilistic Relational Models, a relational version of Bayesian networks, were used to define a joint probabilistic model for a collection of related entities. In this paper, we present an alternative framework that builds on (conditional) Markov networks and addresses two limitations of the previous approach. First, undirected models do not impose the acyclicity constraint that hinders representation of many important relational dependencies in directed models. Second, undirected models are well suited for discriminative training, where we optimize the conditional likelihood of the labels given the features, which generally improves classification accuracy. We show how to train these models effectively, and how to use approximate probabilistic inference over the learned model for collective classification of multiple related entities. We provide experimental results on a webpage classification task, showing that accuracy can be significantly improved by modeling relational dependencies."}, {"paper_id": "2246744", "adju_relevance": 2, "title": "Using Multiple Sources of Agreement Information for Sentiment Classification of Political Transcripts", "background_label": "AbstractSentiment classifiers attempt to determine whether a document expresses a generally positive or negative sentiment about its topic. Previous work has shown that overall performance can be improved by combining per-document classifications with information about agreement between documents.", "abstract": "AbstractSentiment classifiers attempt to determine whether a document expresses a generally positive or negative sentiment about its topic. AbstractSentiment classifiers attempt to determine whether a document expresses a generally positive or negative sentiment about its topic. Previous work has shown that overall performance can be improved by combining per-document classifications with information about agreement between documents."}, {"paper_id": "927208", "adju_relevance": 2, "title": "Recognizing Stances in Ideological On-Line Debates", "background_label": "AbstractThis work explores the utility of sentiment and arguing opinions for classifying stances in ideological debates.", "abstract": "AbstractThis work explores the utility of sentiment and arguing opinions for classifying stances in ideological debates."}, {"paper_id": "713490", "adju_relevance": 2, "title": "Identifying Agreement and Disagreement in Conversational Speech: Use of Bayesian Networks to Model Pragmatic Dependencies", "background_label": "We describe a statistical approach for modeling agreements and disagreements in conversational interaction.", "method_label": "Our approach first identifies adjacency pairs using maximum entropy ranking based on a set of lexical, durational, and structural features that look both forward and backward in the discourse. We then classify utterances as agreement or disagreement using these adjacency pairs and features that represent various pragmatic influences of previous agreement or disagreement on the current utterance.", "result_label": "Our approach achieves 86.9% accuracy, a 4.9% increase over previous work.", "abstract": "We describe a statistical approach for modeling agreements and disagreements in conversational interaction. Our approach first identifies adjacency pairs using maximum entropy ranking based on a set of lexical, durational, and structural features that look both forward and backward in the discourse. Our approach first identifies adjacency pairs using maximum entropy ranking based on a set of lexical, durational, and structural features that look both forward and backward in the discourse. We then classify utterances as agreement or disagreement using these adjacency pairs and features that represent various pragmatic influences of previous agreement or disagreement on the current utterance. Our approach achieves 86.9% accuracy, a 4.9% increase over previous work."}, {"paper_id": "55140408", "adju_relevance": 2, "title": "Measuring Political Positions from Legislative Speech", "background_label": "Existing approaches to measuring political disagreement from text data perform poorly except when applied to narrowly selected texts discussing the same issues and written in the same style. We demonstrate the first viable approach for estimating legislator-specific scores from the entire speech corpus of a legislature, while also producing extensive information about the evolution of speech polarization and politically loaded language.", "method_label": "In the Irish Dail, we show that the dominant dimension of speech variation is government\u2013opposition, with ministers more extreme on this dimension than backbenchers, and a second dimension distinguishing between the establishment and anti-establishment opposition parties.", "result_label": "In the U. S. Senate, we estimate a dimension that has moderate within-party correlations with scales based on roll-call votes and campaign donation patterns; however, we observe greater overlap across parties in speech positions than roll-call positions and partisan polarization in speeches varies more clearly in response to major political events.", "abstract": "Existing approaches to measuring political disagreement from text data perform poorly except when applied to narrowly selected texts discussing the same issues and written in the same style. Existing approaches to measuring political disagreement from text data perform poorly except when applied to narrowly selected texts discussing the same issues and written in the same style. We demonstrate the first viable approach for estimating legislator-specific scores from the entire speech corpus of a legislature, while also producing extensive information about the evolution of speech polarization and politically loaded language. In the Irish Dail, we show that the dominant dimension of speech variation is government\u2013opposition, with ministers more extreme on this dimension than backbenchers, and a second dimension distinguishing between the establishment and anti-establishment opposition parties. In the U. S. Senate, we estimate a dimension that has moderate within-party correlations with scales based on roll-call votes and campaign donation patterns; however, we observe greater overlap across parties in speech positions than roll-call positions and partisan polarization in speeches varies more clearly in response to major political events."}, {"paper_id": "484335", "adju_relevance": 1, "title": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews", "background_label": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs.", "method_label": "A phrase has a positive semantic orientation when it has good associations (e.g.,\"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g.,\"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word\"excellent\"minus the mutual information between the given phrase and the word\"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive.", "result_label": "The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.", "abstract": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down). The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs. A phrase has a positive semantic orientation when it has good associations (e.g.,\"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g.,\"very cavalier\"). A phrase has a positive semantic orientation when it has good associations (e.g.,\"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g.,\"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word\"excellent\"minus the mutual information between the given phrase and the word\"poor\". A phrase has a positive semantic orientation when it has good associations (e.g.,\"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g.,\"very cavalier\"). In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word\"excellent\"minus the mutual information between the given phrase and the word\"poor\". A review is classified as recommended if the average semantic orientation of its phrases is positive. The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations). The accuracy ranges from 84% for automobile reviews to 66% for movie reviews."}, {"paper_id": "7105713", "adju_relevance": 1, "title": "Thumbs up? Sentiment Classification using Machine Learning Techniques", "background_label": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines.", "method_label": "However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization.", "result_label": "We conclude by examining factors that make the sentiment classification problem more challenging.", "abstract": "We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging."}, {"paper_id": "12254186", "adju_relevance": 1, "title": "QUOTUS: The Structure of Political Media Coverage as Revealed by Quoting Patterns", "background_label": "Given the extremely large pool of events and stories available, media outlets need to focus on a subset of issues and aspects to convey to their audience. Outlets are often accused of exhibiting a systematic bias in this selection process, with different outlets portraying different versions of reality. However, in the absence of objective measures and empirical evidence, the direction and extent of systematicity remains widely disputed.", "abstract": "Given the extremely large pool of events and stories available, media outlets need to focus on a subset of issues and aspects to convey to their audience. Given the extremely large pool of events and stories available, media outlets need to focus on a subset of issues and aspects to convey to their audience. Outlets are often accused of exhibiting a systematic bias in this selection process, with different outlets portraying different versions of reality. Given the extremely large pool of events and stories available, media outlets need to focus on a subset of issues and aspects to convey to their audience. Outlets are often accused of exhibiting a systematic bias in this selection process, with different outlets portraying different versions of reality. However, in the absence of objective measures and empirical evidence, the direction and extent of systematicity remains widely disputed."}, {"paper_id": "52802182", "adju_relevance": 1, "title": "Dialogue Act Modeling for Automatic Tagging and Recognition of Conversational Speech", "background_label": "We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as Statement, Question, Backchannel, Agreement, Disagreement, and Apology.", "method_label": "Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech.", "result_label": "We achieved good dialogue act labeling accuracy (65% based on errorful, automatically recognized words and prosody, and 71% based on word transcripts, compared to a chance baseline accuracy of 35% and human accuracy of 84%) and a small reduction in word recognition error.", "abstract": "We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as Statement, Question, Backchannel, Agreement, Disagreement, and Apology. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech. We achieved good dialogue act labeling accuracy (65% based on errorful, automatically recognized words and prosody, and 71% based on word transcripts, compared to a chance baseline accuracy of 35% and human accuracy of 84%) and a small reduction in word recognition error."}, {"paper_id": "96457939", "adju_relevance": 1, "title": "Lobbyists before the U.S. Supreme Court Investigating the Influence of Amicus Curiae Briefs", "background_label": "Despite the fact that amicus curiae participation is the most common method of interest group activity in the judicial arena, there is little consensus as to whether this means of participation influences the decision making of the U.S. Supreme Court.", "abstract": "Despite the fact that amicus curiae participation is the most common method of interest group activity in the judicial arena, there is little consensus as to whether this means of participation influences the decision making of the U.S. Supreme Court."}, {"paper_id": "2436153", "adju_relevance": 1, "title": "Argumentation Mining in Parliamentary Discourse", "background_label": "We examine whether using frame choices in forum statements can help us identify framing strategies in parliamentary discourse.", "method_label": "In this analysis, we show how features based on embedding representations can improve the discovery of various frames in argumentative political speech.", "result_label": "Given the complex nature of the parliamentary discourse, the initial results that are presented here are promising. We further present a manually annotated corpus for frame recognition in parliamentary discourse.", "abstract": " We examine whether using frame choices in forum statements can help us identify framing strategies in parliamentary discourse. In this analysis, we show how features based on embedding representations can improve the discovery of various frames in argumentative political speech. Given the complex nature of the parliamentary discourse, the initial results that are presented here are promising. Given the complex nature of the parliamentary discourse, the initial results that are presented here are promising. We further present a manually annotated corpus for frame recognition in parliamentary discourse."}, {"paper_id": "2795175", "adju_relevance": 1, "title": "Seeing Stars When There Aren\u2019t Many Stars: Graph-Based Semi-Supervised Learning For Sentiment Categorization", "background_label": "We present a graph-based semi-supervised learning algorithm to address the sentiment analysis task of rating inference. Given a set of documents (e.g., movie reviews) and accompanying ratings (e.g., \"4 stars\"), the task calls for inferring numerical ratings for unlabeled documents based on the perceived sentiment expressed by their text. In particular, we are interested in the situation where labeled data is scarce.", "method_label": "We place this task in the semi-supervised setting and demonstrate that considering unlabeled reviews in the learning process can improve rating-inference performance. We do so by creating a graph on both labeled and unlabeled data to encode certain assumptions for this task. We then solve an optimization problem to obtain a smooth rating function over the whole graph.", "result_label": "When only limited labeled data is available, this method achieves significantly better predictive accuracy over other methods that ignore the unlabeled examples during training.", "abstract": "We present a graph-based semi-supervised learning algorithm to address the sentiment analysis task of rating inference. We present a graph-based semi-supervised learning algorithm to address the sentiment analysis task of rating inference. Given a set of documents (e.g., movie reviews) and accompanying ratings (e.g., \"4 stars\"), the task calls for inferring numerical ratings for unlabeled documents based on the perceived sentiment expressed by their text. We present a graph-based semi-supervised learning algorithm to address the sentiment analysis task of rating inference. Given a set of documents (e.g., movie reviews) and accompanying ratings (e.g., \"4 stars\"), the task calls for inferring numerical ratings for unlabeled documents based on the perceived sentiment expressed by their text. In particular, we are interested in the situation where labeled data is scarce. We place this task in the semi-supervised setting and demonstrate that considering unlabeled reviews in the learning process can improve rating-inference performance. We place this task in the semi-supervised setting and demonstrate that considering unlabeled reviews in the learning process can improve rating-inference performance. We do so by creating a graph on both labeled and unlabeled data to encode certain assumptions for this task. We place this task in the semi-supervised setting and demonstrate that considering unlabeled reviews in the learning process can improve rating-inference performance. We do so by creating a graph on both labeled and unlabeled data to encode certain assumptions for this task. We then solve an optimization problem to obtain a smooth rating function over the whole graph. When only limited labeled data is available, this method achieves significantly better predictive accuracy over other methods that ignore the unlabeled examples during training."}, {"paper_id": "144521843", "adju_relevance": 1, "title": "Perceived Support for One's Opinions and Willingness to Speak Out: A Meta-Analysis of Survey Studies on the 'Spiral of Silence'", "background_label": "The authors report a meta-analysis of survey studies examining the relationship between people's perceptions of support for their opinions and their willingness to express those opinions.", "result_label": "Evidence from the analysis indicates the presence of a very small but statistically significant, relationship between the degree to which a person believes others hold similar opinions and the willingness to express those opinions. Moderator analyses did not reveal significant moderators of this relationship, although the observed correlations were statistically heterogeneous, suggesting at least one undiscovered moderator", "abstract": "The authors report a meta-analysis of survey studies examining the relationship between people's perceptions of support for their opinions and their willingness to express those opinions. Evidence from the analysis indicates the presence of a very small but statistically significant, relationship between the degree to which a person believes others hold similar opinions and the willingness to express those opinions. Evidence from the analysis indicates the presence of a very small but statistically significant, relationship between the degree to which a person believes others hold similar opinions and the willingness to express those opinions. Moderator analyses did not reveal significant moderators of this relationship, although the observed correlations were statistically heterogeneous, suggesting at least one undiscovered moderator"}, {"paper_id": "52058704", "adju_relevance": 1, "title": "Analysis of Speeches in Indian Parliamentary Debates", "background_label": "With the increasing usage of the internet, more and more data is being digitized including parliamentary debates but they are in an unstructured format. There is a need to convert them into a structured format for linguistic analysis. Much work has been done on parliamentary data such as Hansard, American congressional floor-debate data on various aspects but less on pragmatics.", "method_label": "In this paper, we provide a dataset for the synopsis of Indian parliamentary debates and perform stance classification of speeches i.e identifying if the speaker is supporting the bill/issue or against it. We also analyze the intention of the speeches beyond mere sentences i.e pragmatics in the parliament. Based on thorough manual analysis of the debates, we developed an annotation scheme of 4 mutually exclusive categories to analyze the purpose of the speeches: to find out ISSUES, to BLAME, to APPRECIATE and for CALL FOR ACTION. We have annotated the dataset provided, with these 4 categories and conducted preliminary experiments for automatic detection of the categories.", "result_label": "Our automated classification approach gave us promising results.", "abstract": "With the increasing usage of the internet, more and more data is being digitized including parliamentary debates but they are in an unstructured format. With the increasing usage of the internet, more and more data is being digitized including parliamentary debates but they are in an unstructured format. There is a need to convert them into a structured format for linguistic analysis. With the increasing usage of the internet, more and more data is being digitized including parliamentary debates but they are in an unstructured format. There is a need to convert them into a structured format for linguistic analysis. Much work has been done on parliamentary data such as Hansard, American congressional floor-debate data on various aspects but less on pragmatics. In this paper, we provide a dataset for the synopsis of Indian parliamentary debates and perform stance classification of speeches i.e identifying if the speaker is supporting the bill/issue or against it. In this paper, we provide a dataset for the synopsis of Indian parliamentary debates and perform stance classification of speeches i.e identifying if the speaker is supporting the bill/issue or against it. We also analyze the intention of the speeches beyond mere sentences i.e pragmatics in the parliament. In this paper, we provide a dataset for the synopsis of Indian parliamentary debates and perform stance classification of speeches i.e identifying if the speaker is supporting the bill/issue or against it. We also analyze the intention of the speeches beyond mere sentences i.e pragmatics in the parliament. Based on thorough manual analysis of the debates, we developed an annotation scheme of 4 mutually exclusive categories to analyze the purpose of the speeches: to find out ISSUES, to BLAME, to APPRECIATE and for CALL FOR ACTION. In this paper, we provide a dataset for the synopsis of Indian parliamentary debates and perform stance classification of speeches i.e identifying if the speaker is supporting the bill/issue or against it. We also analyze the intention of the speeches beyond mere sentences i.e pragmatics in the parliament. Based on thorough manual analysis of the debates, we developed an annotation scheme of 4 mutually exclusive categories to analyze the purpose of the speeches: to find out ISSUES, to BLAME, to APPRECIATE and for CALL FOR ACTION. We have annotated the dataset provided, with these 4 categories and conducted preliminary experiments for automatic detection of the categories. Our automated classification approach gave us promising results."}, {"paper_id": "62217505", "adju_relevance": 1, "title": "Elements of a computational model for multi-party discourse: The turn-taking behavior of Supreme Court justices", "background_label": "This work explores computational models of multi-party discourse, using transcripts from U.S. Supreme Court oral arguments. The turn-taking behavior of participants is treated as a supervised sequence-labeling problem and modeled using first- and second-order conditional random fields (CRFs).", "method_label": "We specifically explore the hypothesis that discourse markers and personal references provide important features in such models.", "result_label": "Results from a sequence prediction experiment demonstrate that incorporating these two types of features yields significant improvements in accuracy. Our experiments are couched in the broader context of developing tools to support legal scholarship, although we see other natural language processing applications as well.", "abstract": "This work explores computational models of multi-party discourse, using transcripts from U.S. Supreme Court oral arguments. This work explores computational models of multi-party discourse, using transcripts from U.S. Supreme Court oral arguments. The turn-taking behavior of participants is treated as a supervised sequence-labeling problem and modeled using first- and second-order conditional random fields (CRFs). We specifically explore the hypothesis that discourse markers and personal references provide important features in such models. Results from a sequence prediction experiment demonstrate that incorporating these two types of features yields significant improvements in accuracy. Results from a sequence prediction experiment demonstrate that incorporating these two types of features yields significant improvements in accuracy. Our experiments are couched in the broader context of developing tools to support legal scholarship, although we see other natural language processing applications as well."}, {"paper_id": "5035109", "adju_relevance": 1, "title": "A Predictive Model for Notional Anaphora in English", "background_label": "Notional anaphors are pronouns which disagree with their antecedents' grammatical categories for notional reasons, such as plural to singular agreement in: 'the government ... they'. Since such cases are rare and conflict with evidence from strictly agreeing cases ('the government ... it'), they present a substantial challenge to both coreference resolution and referring expression generation.", "method_label": "Using the OntoNotes corpus, this paper takes an ensemble approach to predicting English notional anaphora in context on the basis of the largest empirical data to date.", "result_label": "In addition to state of the art prediction accuracy, the results suggest that theoretical approaches positing a plural construal at the antecedent's utterance are insufficient, and that circumstances at the anaphor's utterance location, as well as global factors such as genre, have a strong effect on the choice of referring expression.", "abstract": "Notional anaphors are pronouns which disagree with their antecedents' grammatical categories for notional reasons, such as plural to singular agreement in: 'the government ... they'. Notional anaphors are pronouns which disagree with their antecedents' grammatical categories for notional reasons, such as plural to singular agreement in: 'the government ... they'. Since such cases are rare and conflict with evidence from strictly agreeing cases ('the government ... it'), they present a substantial challenge to both coreference resolution and referring expression generation. Using the OntoNotes corpus, this paper takes an ensemble approach to predicting English notional anaphora in context on the basis of the largest empirical data to date. In addition to state of the art prediction accuracy, the results suggest that theoretical approaches positing a plural construal at the antecedent's utterance are insufficient, and that circumstances at the anaphor's utterance location, as well as global factors such as genre, have a strong effect on the choice of referring expression."}, {"paper_id": "3545253", "adju_relevance": 1, "title": "\"You are no Jack Kennedy\": On Media Selection of Highlights from Presidential Debates", "background_label": "Political speeches and debates play an important role in shaping the images of politicians, and the public often relies on media outlets to select bits of political communication from a large pool of utterances. It is an important research question to understand what factors impact this selection process.", "abstract": "Political speeches and debates play an important role in shaping the images of politicians, and the public often relies on media outlets to select bits of political communication from a large pool of utterances. Political speeches and debates play an important role in shaping the images of politicians, and the public often relies on media outlets to select bits of political communication from a large pool of utterances. It is an important research question to understand what factors impact this selection process."}, {"paper_id": "11312524", "adju_relevance": 1, "title": "Learning associative Markov networks", "background_label": "Markov networks are extensively used to model complex sequential, spatial, and relational interactions in fields as diverse as image processing, natural language analysis, and bioinformatics. However, inference and learning in general Markov networks is intractable.", "abstract": "Markov networks are extensively used to model complex sequential, spatial, and relational interactions in fields as diverse as image processing, natural language analysis, and bioinformatics. Markov networks are extensively used to model complex sequential, spatial, and relational interactions in fields as diverse as image processing, natural language analysis, and bioinformatics. However, inference and learning in general Markov networks is intractable."}, {"paper_id": "3264224", "adju_relevance": 1, "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales", "background_label": "We address the rating-inference problem, wherein rather than simply decide whether a review is\"thumbs up\"or\"thumbs down\", as in previous sentiment analysis work, one must determine an author's evaluation with respect to a multi-point scale (e.g., one to five\"stars\").", "method_label": "This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example,\"three stars\"is intuitively closer to\"four stars\"than to\"one star\". We first evaluate human performance at the task. Then, we apply a meta-algorithm, based on a metric labeling formulation of the problem, that alters a given n-ary classifier's output in an explicit attempt to ensure that similar items receive similar labels.", "result_label": "We show that the meta-algorithm can provide significant improvements over both multi-class and regression versions of SVMs when we employ a novel similarity measure appropriate to the problem.", "abstract": "We address the rating-inference problem, wherein rather than simply decide whether a review is\"thumbs up\"or\"thumbs down\", as in previous sentiment analysis work, one must determine an author's evaluation with respect to a multi-point scale (e.g., one to five\"stars\"). This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example,\"three stars\"is intuitively closer to\"four stars\"than to\"one star\". This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example,\"three stars\"is intuitively closer to\"four stars\"than to\"one star\". We first evaluate human performance at the task. This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example,\"three stars\"is intuitively closer to\"four stars\"than to\"one star\". We first evaluate human performance at the task. Then, we apply a meta-algorithm, based on a metric labeling formulation of the problem, that alters a given n-ary classifier's output in an explicit attempt to ensure that similar items receive similar labels. We show that the meta-algorithm can provide significant improvements over both multi-class and regression versions of SVMs when we employ a novel similarity measure appropriate to the problem."}, {"paper_id": "142582489", "adju_relevance": 1, "title": "Turn-Taking and Affirmative Cue Words in TaskOriented Dialogue", "background_label": "As interactive voice response systems spread at a rapid pace, providing an increasingly more complex functionality, it is becoming clear that the challenges of such systems are not solely associated to their synthesis and recognition capabilities. Rather, issues such as the coordination of turn exchanges between system and user, or the correct generation and understanding of words that may convey multiple meanings, appear to play an important role in system usability.", "abstract": "As interactive voice response systems spread at a rapid pace, providing an increasingly more complex functionality, it is becoming clear that the challenges of such systems are not solely associated to their synthesis and recognition capabilities. As interactive voice response systems spread at a rapid pace, providing an increasingly more complex functionality, it is becoming clear that the challenges of such systems are not solely associated to their synthesis and recognition capabilities. Rather, issues such as the coordination of turn exchanges between system and user, or the correct generation and understanding of words that may convey multiple meanings, appear to play an important role in system usability."}, {"paper_id": "140292583", "adju_relevance": 1, "title": "Abductive Interpretation And Reinterpretation Of Natural Language Utterances", "background_label": "To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. If a listener hears something that seems inconsistent, he may reinterpret an earlier utterance and respond to it anew. Otherwise, he assumes that the conversation is proceeding smoothly. In sociological accounts provided by Ethnomethodology, discourse interactions and the resolution of misunderstandings are normal activities guided by social conventions. The approach extends intentional accounts by using expectations deriving from social conventions in order to guide interpretation. As a result, it avoids the unconstrained inference of goals that has plagued many models of discourse.", "method_label": "Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. To model the repair of misunderstandings, this thesis combines both intentional and social accounts of discourse, unifying theories of speech act production, interpretation, and repair. A unified theory has been developed by using default reasoning to generate utterances and using abduction to characterize interpretation and repair. The account has been expressed as a logical theory within the Prioritized Theorist Framework. The theory includes relations on linguistic acts and the Gricean attitudes that they express. It also contains an axiomatization of speakers' knowledge for generating socially appropriate utterances and for detecting and repairing misunderstandings.", "result_label": "In intentional accounts, speakers use their beliefs, goals, and expectations to decide what to say; when they interpret an utterance, speakers identify goals that might account for it. The generality of the approach is demonstrated by re-enacting real conversations using the theorem-proving capabilities of Prioritized Theorist.", "abstract": "To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. If a listener hears something that seems inconsistent, he may reinterpret an earlier utterance and respond to it anew. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. If a listener hears something that seems inconsistent, he may reinterpret an earlier utterance and respond to it anew. Otherwise, he assumes that the conversation is proceeding smoothly. Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. To model the repair of misunderstandings, this thesis combines both intentional and social accounts of discourse, unifying theories of speech act production, interpretation, and repair. In intentional accounts, speakers use their beliefs, goals, and expectations to decide what to say; when they interpret an utterance, speakers identify goals that might account for it. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. If a listener hears something that seems inconsistent, he may reinterpret an earlier utterance and respond to it anew. Otherwise, he assumes that the conversation is proceeding smoothly. In sociological accounts provided by Ethnomethodology, discourse interactions and the resolution of misunderstandings are normal activities guided by social conventions. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. If a listener hears something that seems inconsistent, he may reinterpret an earlier utterance and respond to it anew. Otherwise, he assumes that the conversation is proceeding smoothly. In sociological accounts provided by Ethnomethodology, discourse interactions and the resolution of misunderstandings are normal activities guided by social conventions. The approach extends intentional accounts by using expectations deriving from social conventions in order to guide interpretation. To decide how to respond to an utterance, a speaker must interpret what others have said and why they have said it. Speakers rely on their expectations to decide whether they have understood each other. Misunderstandings occur when speakers differ in their beliefs about what has been said or why. If a listener hears something that seems inconsistent, he may reinterpret an earlier utterance and respond to it anew. Otherwise, he assumes that the conversation is proceeding smoothly. In sociological accounts provided by Ethnomethodology, discourse interactions and the resolution of misunderstandings are normal activities guided by social conventions. The approach extends intentional accounts by using expectations deriving from social conventions in order to guide interpretation. As a result, it avoids the unconstrained inference of goals that has plagued many models of discourse. Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. To model the repair of misunderstandings, this thesis combines both intentional and social accounts of discourse, unifying theories of speech act production, interpretation, and repair. A unified theory has been developed by using default reasoning to generate utterances and using abduction to characterize interpretation and repair. Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. To model the repair of misunderstandings, this thesis combines both intentional and social accounts of discourse, unifying theories of speech act production, interpretation, and repair. A unified theory has been developed by using default reasoning to generate utterances and using abduction to characterize interpretation and repair. The account has been expressed as a logical theory within the Prioritized Theorist Framework. Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. To model the repair of misunderstandings, this thesis combines both intentional and social accounts of discourse, unifying theories of speech act production, interpretation, and repair. A unified theory has been developed by using default reasoning to generate utterances and using abduction to characterize interpretation and repair. The account has been expressed as a logical theory within the Prioritized Theorist Framework. The theory includes relations on linguistic acts and the Gricean attitudes that they express. Recognizing an inconsistency as a misunderstanding and generating a new reply together accomplish what is known as a fourth-position repair. To model the repair of misunderstandings, this thesis combines both intentional and social accounts of discourse, unifying theories of speech act production, interpretation, and repair. A unified theory has been developed by using default reasoning to generate utterances and using abduction to characterize interpretation and repair. The account has been expressed as a logical theory within the Prioritized Theorist Framework. The theory includes relations on linguistic acts and the Gricean attitudes that they express. It also contains an axiomatization of speakers' knowledge for generating socially appropriate utterances and for detecting and repairing misunderstandings. In intentional accounts, speakers use their beliefs, goals, and expectations to decide what to say; when they interpret an utterance, speakers identify goals that might account for it. The generality of the approach is demonstrated by re-enacting real conversations using the theorem-proving capabilities of Prioritized Theorist."}, {"paper_id": "1840697", "adju_relevance": 1, "title": "Detection Of Agreement vs. Disagreement In Meetings: Training With Unlabeled Data", "background_label": "To support summarization of automatically transcribed meetings, we introduce a classifier to recognize agreement or disagreement utterances, utilizing both word-based and prosodic cues.", "method_label": "We show that hand-labeling efforts can be minimized by using unsupervised training on a large unlabeled data set combined with supervised training on a small amount of data.", "result_label": "For ASR transcripts with over 45% WER, the system recovers nearly 80% of agree/disagree utterances with a confusion rate of only 3%.", "abstract": "To support summarization of automatically transcribed meetings, we introduce a classifier to recognize agreement or disagreement utterances, utilizing both word-based and prosodic cues. We show that hand-labeling efforts can be minimized by using unsupervised training on a large unlabeled data set combined with supervised training on a small amount of data. For ASR transcripts with over 45% WER, the system recovers nearly 80% of agree/disagree utterances with a confusion rate of only 3%."}, {"paper_id": "12979200", "adju_relevance": 1, "title": "Automated classification of congressional legislation", "background_label": "For social science researchers, content analysis and classification of United States Congressional legislative activities have been time consuming and costly. The Library of Congress THOMAS system provides detailed information about bills and laws, but its classification system, the Legislative Indexing Vocabulary (LIV), is geared toward information retrieval instead of the pattern or historical trend recognition that social scientists value. The same event (a bill) may be coded with many subjects at the same time, with little indication of its primary emphasis.", "abstract": "For social science researchers, content analysis and classification of United States Congressional legislative activities have been time consuming and costly. For social science researchers, content analysis and classification of United States Congressional legislative activities have been time consuming and costly. The Library of Congress THOMAS system provides detailed information about bills and laws, but its classification system, the Legislative Indexing Vocabulary (LIV), is geared toward information retrieval instead of the pattern or historical trend recognition that social scientists value. For social science researchers, content analysis and classification of United States Congressional legislative activities have been time consuming and costly. The Library of Congress THOMAS system provides detailed information about bills and laws, but its classification system, the Legislative Indexing Vocabulary (LIV), is geared toward information retrieval instead of the pattern or historical trend recognition that social scientists value. The same event (a bill) may be coded with many subjects at the same time, with little indication of its primary emphasis."}, {"paper_id": "12917488", "adju_relevance": 1, "title": "Discovering value from community activity on focused question answering sites: a case study of stack overflow", "background_label": "Question answering (Q&A) websites are now large repositories of valuable knowledge. While most Q&A sites were initially aimed at providing useful answers to the question asker, there has been a marked shift towards question answering as a community-driven knowledge creation process whose end product can be of enduring value to a broad audience. As part of this shift, specific expertise and deep knowledge of the subject at hand have become increasingly important, and many Q&A sites employ voting and reputation mechanisms as centerpieces of their design to help users identify the trustworthiness and accuracy of the content.", "method_label": "To better understand this shift in focus from one-off answers to a group knowledge-creation process, we consider a question together with its entire set of corresponding answers as our fundamental unit of analysis, in contrast with the focus on individual question-answer pairs that characterized previous work.", "abstract": "Question answering (Q&A) websites are now large repositories of valuable knowledge. Question answering (Q&A) websites are now large repositories of valuable knowledge. While most Q&A sites were initially aimed at providing useful answers to the question asker, there has been a marked shift towards question answering as a community-driven knowledge creation process whose end product can be of enduring value to a broad audience. Question answering (Q&A) websites are now large repositories of valuable knowledge. While most Q&A sites were initially aimed at providing useful answers to the question asker, there has been a marked shift towards question answering as a community-driven knowledge creation process whose end product can be of enduring value to a broad audience. As part of this shift, specific expertise and deep knowledge of the subject at hand have become increasingly important, and many Q&A sites employ voting and reputation mechanisms as centerpieces of their design to help users identify the trustworthiness and accuracy of the content. To better understand this shift in focus from one-off answers to a group knowledge-creation process, we consider a question together with its entire set of corresponding answers as our fundamental unit of analysis, in contrast with the focus on individual question-answer pairs that characterized previous work."}, {"paper_id": "1973915", "adju_relevance": 1, "title": "Cultural orientation: Classifying subjective documents by cociation analysis", "background_label": "This paper introduces a simple method for estimating cultural orientation, the affiliation of hypertext documents in a polarized field of discourse. Using a probabilistic model based on cocitation information, two experiments are reported.", "method_label": "The first experiment tests the model\u2019s ability to discriminate between leftand right-wing documents about politics. In this context the model is tested on three sets of data, 695 partisan web documents, 162 political weblogs, and 72 non-partisan documents. In the second experiment, the proposed method is used to classify the home pages of musical artists with respect to their mainstream or \u201calternative\u201d appeal.", "result_label": "Accuracy above 90% is obtained from the cocitation model, outperforming lexically based classifiers at statistically significant levels. For musical artists the model is tested on a set of 227 artist home pages, achieving 88 % accuracy.", "abstract": "This paper introduces a simple method for estimating cultural orientation, the affiliation of hypertext documents in a polarized field of discourse. This paper introduces a simple method for estimating cultural orientation, the affiliation of hypertext documents in a polarized field of discourse. Using a probabilistic model based on cocitation information, two experiments are reported. The first experiment tests the model\u2019s ability to discriminate between leftand right-wing documents about politics. The first experiment tests the model\u2019s ability to discriminate between leftand right-wing documents about politics. In this context the model is tested on three sets of data, 695 partisan web documents, 162 political weblogs, and 72 non-partisan documents. Accuracy above 90% is obtained from the cocitation model, outperforming lexically based classifiers at statistically significant levels. The first experiment tests the model\u2019s ability to discriminate between leftand right-wing documents about politics. In this context the model is tested on three sets of data, 695 partisan web documents, 162 political weblogs, and 72 non-partisan documents. In the second experiment, the proposed method is used to classify the home pages of musical artists with respect to their mainstream or \u201calternative\u201d appeal. Accuracy above 90% is obtained from the cocitation model, outperforming lexically based classifiers at statistically significant levels. For musical artists the model is tested on a set of 227 artist home pages, achieving 88 % accuracy."}, {"paper_id": "17908422", "adju_relevance": 1, "title": "Unshared task: (Dis)agreement in online debates", "background_label": "Topic-independent expressions for conveying agreement and disagreement were annotated in a corpus of web forum debates, in order to evaluate a classifier trained to detect these two categories. Among the 175 expressions annotated in the evaluation set, 163 were unique, which shows that there is large variation in expressions used.", "result_label": "This variation might be one of the reasons why the task of automatically detecting the categories was difficult. F-scores of 0.44 and 0.37 were achieved by a classifier trained on 2,000 debate sentences for detecting sentence-level agreement and disagreement.", "abstract": "Topic-independent expressions for conveying agreement and disagreement were annotated in a corpus of web forum debates, in order to evaluate a classifier trained to detect these two categories. Topic-independent expressions for conveying agreement and disagreement were annotated in a corpus of web forum debates, in order to evaluate a classifier trained to detect these two categories. Among the 175 expressions annotated in the evaluation set, 163 were unique, which shows that there is large variation in expressions used. This variation might be one of the reasons why the task of automatically detecting the categories was difficult. This variation might be one of the reasons why the task of automatically detecting the categories was difficult. F-scores of 0.44 and 0.37 were achieved by a classifier trained on 2,000 debate sentences for detecting sentence-level agreement and disagreement."}, {"paper_id": "10274824", "adju_relevance": 1, "title": "Extracting Policy Positions from Political Texts Using Words as Data", "method_label": "We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We \u201cexport\u201d the method to a non-English-language environment, analyzing the policy positions of German parties, including the PDS as it entered the former West German party system. Finally, we extend its application beyond the analysis of party manifestos, to the estimation of political positions from legislative speeches. Our \u201clanguage-blind\u201d word scoring technique successfully replicates published policy estimates without the substantial costs of time and labor that these require.", "result_label": "Furthermore, unlike in any previous method for extracting policy positions from political texts, we provide uncertainty measures for our estimates, allowing analysts to make informed judgments of the extent to which differences between two estimated policy positions can be viewed as significant or merely as products of measurement error.", "abstract": " We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We \u201cexport\u201d the method to a non-English-language environment, analyzing the policy positions of German parties, including the PDS as it entered the former West German party system. We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We \u201cexport\u201d the method to a non-English-language environment, analyzing the policy positions of German parties, including the PDS as it entered the former West German party system. Finally, we extend its application beyond the analysis of party manifestos, to the estimation of political positions from legislative speeches. We compare this approach to previous methods of text analysis and use it to replicate published estimates of the policy positions of political parties in Britain and Ireland, on both economic and social policy dimensions. We \u201cexport\u201d the method to a non-English-language environment, analyzing the policy positions of German parties, including the PDS as it entered the former West German party system. Finally, we extend its application beyond the analysis of party manifestos, to the estimation of political positions from legislative speeches. Our \u201clanguage-blind\u201d word scoring technique successfully replicates published policy estimates without the substantial costs of time and labor that these require. Furthermore, unlike in any previous method for extracting policy positions from political texts, we provide uncertainty measures for our estimates, allowing analysts to make informed judgments of the extent to which differences between two estimated policy positions can be viewed as significant or merely as products of measurement error."}, {"paper_id": "8577096", "adju_relevance": 1, "title": "Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions", "background_label": "Changing someone's opinion is arguably one of the most important challenges of social interaction. The underlying process proves difficult to study: it is hard to know how someone's opinions are formed and whether and how someone's views shift. Fortunately, ChangeMyView, an active community on Reddit, provides a platform where users present their own opinions and reasoning, invite others to contest them, and acknowledge when the ensuing discussions change their original views.", "abstract": "Changing someone's opinion is arguably one of the most important challenges of social interaction. Changing someone's opinion is arguably one of the most important challenges of social interaction. The underlying process proves difficult to study: it is hard to know how someone's opinions are formed and whether and how someone's views shift. Changing someone's opinion is arguably one of the most important challenges of social interaction. The underlying process proves difficult to study: it is hard to know how someone's opinions are formed and whether and how someone's views shift. Fortunately, ChangeMyView, an active community on Reddit, provides a platform where users present their own opinions and reasoning, invite others to contest them, and acknowledge when the ensuing discussions change their original views."}, {"paper_id": "155180937", "adju_relevance": 0, "title": "What does Twitter have to say about ideology", "background_label": "Political debates bearing ideological references exist for long in our society; the last few years though the explosion of the use of the internet and the social media as communication means have boosted the production of ideological texts to unprecedented levels. This creates the need for automated processing of the text if we are interested in understanding the ideological references it contains.", "abstract": "Political debates bearing ideological references exist for long in our society; the last few years though the explosion of the use of the internet and the social media as communication means have boosted the production of ideological texts to unprecedented levels. Political debates bearing ideological references exist for long in our society; the last few years though the explosion of the use of the internet and the social media as communication means have boosted the production of ideological texts to unprecedented levels. This creates the need for automated processing of the text if we are interested in understanding the ideological references it contains."}, {"paper_id": "21790248", "adju_relevance": 0, "title": "Selfie-Takers Prefer Left Cheeks: Converging Evidence from the (Extended) selfiecity Database", "background_label": "According to previous reports, selfie takers in widely different cultural contexts prefer poses showing the left cheek more than the right cheek. This posing bias may be interpreted as evidence for a right-hemispheric specialization for the expression of facial emotions. However, earlier studies analyzed selfie poses as categorized by human raters, which raises methodological issues in relation to the distinction between frontal and three-quarter poses.", "method_label": "Here, we provide converging evidence by analyzing the (extended) selfiecity database which includes automatic assessments of head rotation and of emotional expression.", "result_label": "We confirm a culture- and sex-independent left-cheek bias and report stronger expression of negative emotions in selfies showing the left cheek. These results are generally consistent with a psychobiological account of a left cheek bias in self-portraits but reveal possible unexpected facts concerning the relation between side bias and lateralization of emotional expression.", "abstract": "According to previous reports, selfie takers in widely different cultural contexts prefer poses showing the left cheek more than the right cheek. According to previous reports, selfie takers in widely different cultural contexts prefer poses showing the left cheek more than the right cheek. This posing bias may be interpreted as evidence for a right-hemispheric specialization for the expression of facial emotions. According to previous reports, selfie takers in widely different cultural contexts prefer poses showing the left cheek more than the right cheek. This posing bias may be interpreted as evidence for a right-hemispheric specialization for the expression of facial emotions. However, earlier studies analyzed selfie poses as categorized by human raters, which raises methodological issues in relation to the distinction between frontal and three-quarter poses. Here, we provide converging evidence by analyzing the (extended) selfiecity database which includes automatic assessments of head rotation and of emotional expression. We confirm a culture- and sex-independent left-cheek bias and report stronger expression of negative emotions in selfies showing the left cheek. We confirm a culture- and sex-independent left-cheek bias and report stronger expression of negative emotions in selfies showing the left cheek. These results are generally consistent with a psychobiological account of a left cheek bias in self-portraits but reveal possible unexpected facts concerning the relation between side bias and lateralization of emotional expression."}, {"paper_id": "156027410", "adju_relevance": 0, "title": "All Copying Is Not Created Equal: Examining Supreme Court Opinions\u2019 Borrowed Language", "background_label": "Long ago, Judge Cardozo warned of an \"agglunative\" style of judicial writing where whole sections are cut from other documents and reassembled together in courts' opinions. Critics of this practice label it judicial plagiarism while others in the legal community see this as an acceptable, common practice.", "abstract": "Long ago, Judge Cardozo warned of an \"agglunative\" style of judicial writing where whole sections are cut from other documents and reassembled together in courts' opinions. Long ago, Judge Cardozo warned of an \"agglunative\" style of judicial writing where whole sections are cut from other documents and reassembled together in courts' opinions. Critics of this practice label it judicial plagiarism while others in the legal community see this as an acceptable, common practice."}, {"paper_id": "12147916", "adju_relevance": 0, "title": "Complexity over Uncertainty in Generalized Representational Information Theory (GRIT): A Structure-Sensitive General Theory of Information", "background_label": "Abstract:What is information? Although researchers have used the construct of information liberally to refer to pertinent forms of domain-specific knowledge, relatively few have attempted to generalize and standardize the construct. Shannon and Weaver (1949) offered the best known attempt at a quantitative generalization in terms of the number of discriminable symbols required to communicate the state of an uncertain event.", "abstract": "Abstract:What is information? Abstract:What is information? Although researchers have used the construct of information liberally to refer to pertinent forms of domain-specific knowledge, relatively few have attempted to generalize and standardize the construct. Abstract:What is information? Although researchers have used the construct of information liberally to refer to pertinent forms of domain-specific knowledge, relatively few have attempted to generalize and standardize the construct. Shannon and Weaver (1949) offered the best known attempt at a quantitative generalization in terms of the number of discriminable symbols required to communicate the state of an uncertain event."}, {"paper_id": "12310659", "adju_relevance": 0, "title": "Opposition based computing \u2014 A survey", "background_label": "In algorithms design, one of the important aspects is to consider efficiency. Many algorithm design paradigms are existed and used in order to enhance algorithms' efficiency. Opposition-based Learning (OBL) paradigm was recently introduced as a new way of thinking during the design of algorithms. The concepts of opposition have already been used and applied in several applications. These applications are from different fields, such as optimization algorithms, learning algorithms and fuzzy logic.", "result_label": "The reported results confirm that OBL paradigm was promising to accelerate or to enhance accuracy of soft computing algorithms. In this paper, a survey of existing applications of opposition-based computing is presented.", "abstract": "In algorithms design, one of the important aspects is to consider efficiency. In algorithms design, one of the important aspects is to consider efficiency. Many algorithm design paradigms are existed and used in order to enhance algorithms' efficiency. In algorithms design, one of the important aspects is to consider efficiency. Many algorithm design paradigms are existed and used in order to enhance algorithms' efficiency. Opposition-based Learning (OBL) paradigm was recently introduced as a new way of thinking during the design of algorithms. In algorithms design, one of the important aspects is to consider efficiency. Many algorithm design paradigms are existed and used in order to enhance algorithms' efficiency. Opposition-based Learning (OBL) paradigm was recently introduced as a new way of thinking during the design of algorithms. The concepts of opposition have already been used and applied in several applications. In algorithms design, one of the important aspects is to consider efficiency. Many algorithm design paradigms are existed and used in order to enhance algorithms' efficiency. Opposition-based Learning (OBL) paradigm was recently introduced as a new way of thinking during the design of algorithms. The concepts of opposition have already been used and applied in several applications. These applications are from different fields, such as optimization algorithms, learning algorithms and fuzzy logic. The reported results confirm that OBL paradigm was promising to accelerate or to enhance accuracy of soft computing algorithms. The reported results confirm that OBL paradigm was promising to accelerate or to enhance accuracy of soft computing algorithms. In this paper, a survey of existing applications of opposition-based computing is presented."}, {"paper_id": "4426973", "adju_relevance": 0, "title": "A Recorded Debating Dataset", "background_label": "This paper describes an English audio and textual dataset of debating speeches, a unique resource for the growing research field of computational argumentation and debating technologies.", "method_label": "We detail the process of speech recording by professional debaters, the transcription of the speeches with an Automatic Speech Recognition (ASR) system, their consequent automatic processing to produce a text that is more\"NLP-friendly\", and in parallel -- the manual transcription of the speeches in order to produce gold-standard\"reference\"transcripts. We release 60 speeches on various controversial topics, each in five formats corresponding to the different stages in the production of the data.", "abstract": "This paper describes an English audio and textual dataset of debating speeches, a unique resource for the growing research field of computational argumentation and debating technologies. We detail the process of speech recording by professional debaters, the transcription of the speeches with an Automatic Speech Recognition (ASR) system, their consequent automatic processing to produce a text that is more\"NLP-friendly\", and in parallel -- the manual transcription of the speeches in order to produce gold-standard\"reference\"transcripts. We detail the process of speech recording by professional debaters, the transcription of the speeches with an Automatic Speech Recognition (ASR) system, their consequent automatic processing to produce a text that is more\"NLP-friendly\", and in parallel -- the manual transcription of the speeches in order to produce gold-standard\"reference\"transcripts. We release 60 speeches on various controversial topics, each in five formats corresponding to the different stages in the production of the data."}, {"paper_id": "91183985", "adju_relevance": 0, "title": "Temporal and Aspectual Entailment", "background_label": "Inferences regarding\"Jane's arrival in London\"from predications such as\"Jane is going to London\"or\"Jane has gone to London\"depend on tense and aspect of the predications. Tense determines the temporal location of the predication in the past, present or future of the time of utterance. The aspectual auxiliaries on the other hand specify the internal constituency of the event, i.e. whether the event of\"going to London\"is completed and whether its consequences hold at that time or not. While tense and aspect are among the most important factors for determining natural language inference, there has been very little work to show whether modern NLP models capture these semantic concepts.", "abstract": "Inferences regarding\"Jane's arrival in London\"from predications such as\"Jane is going to London\"or\"Jane has gone to London\"depend on tense and aspect of the predications. Inferences regarding\"Jane's arrival in London\"from predications such as\"Jane is going to London\"or\"Jane has gone to London\"depend on tense and aspect of the predications. Tense determines the temporal location of the predication in the past, present or future of the time of utterance. Inferences regarding\"Jane's arrival in London\"from predications such as\"Jane is going to London\"or\"Jane has gone to London\"depend on tense and aspect of the predications. Tense determines the temporal location of the predication in the past, present or future of the time of utterance. The aspectual auxiliaries on the other hand specify the internal constituency of the event, i.e. Inferences regarding\"Jane's arrival in London\"from predications such as\"Jane is going to London\"or\"Jane has gone to London\"depend on tense and aspect of the predications. Tense determines the temporal location of the predication in the past, present or future of the time of utterance. The aspectual auxiliaries on the other hand specify the internal constituency of the event, i.e. whether the event of\"going to London\"is completed and whether its consequences hold at that time or not. Inferences regarding\"Jane's arrival in London\"from predications such as\"Jane is going to London\"or\"Jane has gone to London\"depend on tense and aspect of the predications. Tense determines the temporal location of the predication in the past, present or future of the time of utterance. The aspectual auxiliaries on the other hand specify the internal constituency of the event, i.e. whether the event of\"going to London\"is completed and whether its consequences hold at that time or not. While tense and aspect are among the most important factors for determining natural language inference, there has been very little work to show whether modern NLP models capture these semantic concepts."}, {"paper_id": "173990964", "adju_relevance": 0, "title": "Mining Data from the Congressional Record", "method_label": "We use Amazon Web Services and the Solr search engine to store and process Congressional record data from 1789 to the present, and then query Solr to find how frequently language related to tax increases and decreases appears. This frequency data is compared to six economic indicators.", "result_label": "Our preliminary results indicate potential relationships between incidence of tax discussion and multiple indicators. We present our data storage and analysis procedures, as well as results from comparisons to all six indicators.", "abstract": " We use Amazon Web Services and the Solr search engine to store and process Congressional record data from 1789 to the present, and then query Solr to find how frequently language related to tax increases and decreases appears. We use Amazon Web Services and the Solr search engine to store and process Congressional record data from 1789 to the present, and then query Solr to find how frequently language related to tax increases and decreases appears. This frequency data is compared to six economic indicators. Our preliminary results indicate potential relationships between incidence of tax discussion and multiple indicators. Our preliminary results indicate potential relationships between incidence of tax discussion and multiple indicators. We present our data storage and analysis procedures, as well as results from comparisons to all six indicators."}, {"paper_id": "146628687", "adju_relevance": 0, "title": "Getting Out the Vote in the Social Media Era: Are Digital Tools Changing the Extent, Nature and Impact of Party Contacting in Elections?", "method_label": "We develop hypotheses regarding the relative effects of online contacting and test them using election study data.", "result_label": "Our findings show that while online contact is generally less frequent than the offline form in both countries, this gap is particularly pronounced in the UK. US campaigns also reach a much wider audience than their UK counterparts. In terms of impact, while offline forms remain most effective in mobilizing turnout, online messages are important for campaign participation, particularly among younger citizens when they are mediated through social networks.", "abstract": " We develop hypotheses regarding the relative effects of online contacting and test them using election study data. Our findings show that while online contact is generally less frequent than the offline form in both countries, this gap is particularly pronounced in the UK. Our findings show that while online contact is generally less frequent than the offline form in both countries, this gap is particularly pronounced in the UK. US campaigns also reach a much wider audience than their UK counterparts. Our findings show that while online contact is generally less frequent than the offline form in both countries, this gap is particularly pronounced in the UK. US campaigns also reach a much wider audience than their UK counterparts. In terms of impact, while offline forms remain most effective in mobilizing turnout, online messages are important for campaign participation, particularly among younger citizens when they are mediated through social networks."}, {"paper_id": "144181398", "adju_relevance": 0, "title": "Republicans and Golf, Democrats and Outkast: Or, Party Political Culture from the Top Down", "background_label": "Do political elite operatives differ by party affiliation?", "abstract": "Do political elite operatives differ by party affiliation?"}, {"paper_id": "118988729", "adju_relevance": 0, "title": "A Microphotonic Astrocomb", "background_label": "One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers.", "method_label": "Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer.", "result_label": "As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research.", "abstract": "One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers. Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer. As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research."}, {"paper_id": "143106655", "adju_relevance": 0, "title": "'We the Peoples': The Global Origins of Constitutional Preambles", "background_label": "We like to think that constitutions are expressions of distinctly national values, speaking for \u201cWe the People.\u201d This is especially true of constitutional preambles, which often recount distinct events from national history and speak to national values. This article challenges this popular view by demonstrating the global influences on constitutional preambles. It does so using a new set of tools in linguistic and textual analysis, applied to a database of most constitutional preambles written since 1789.", "method_label": "Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. We also examine the circumstances in which countries introduce new terms into preambles, showing that countries innovate when neighbors innovate, and that innovations come in global waves. We show that innovation in language is something like punctuated equilibrium within an ecosystem. For long periods of stasis, countries borrow from one another and restrict their language to a set of common terms and phrases. Then, at particular junctures (likely associated with global conflicts), the equilibrium becomes disrupted and a period of innovation ensues. This eventually generates the \u201cnew normal\u201d in terms of the set of language that constitutional drafters use.", "result_label": "The article provides an example of how text analysis can help us understand the ways in which legal texts are interrelated across space and time.", "abstract": "We like to think that constitutions are expressions of distinctly national values, speaking for \u201cWe the People.\u201d This is especially true of constitutional preambles, which often recount distinct events from national history and speak to national values. We like to think that constitutions are expressions of distinctly national values, speaking for \u201cWe the People.\u201d This is especially true of constitutional preambles, which often recount distinct events from national history and speak to national values. This article challenges this popular view by demonstrating the global influences on constitutional preambles. We like to think that constitutions are expressions of distinctly national values, speaking for \u201cWe the People.\u201d This is especially true of constitutional preambles, which often recount distinct events from national history and speak to national values. This article challenges this popular view by demonstrating the global influences on constitutional preambles. It does so using a new set of tools in linguistic and textual analysis, applied to a database of most constitutional preambles written since 1789. Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. We also examine the circumstances in which countries introduce new terms into preambles, showing that countries innovate when neighbors innovate, and that innovations come in global waves. Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. We also examine the circumstances in which countries introduce new terms into preambles, showing that countries innovate when neighbors innovate, and that innovations come in global waves. We show that innovation in language is something like punctuated equilibrium within an ecosystem. Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. We also examine the circumstances in which countries introduce new terms into preambles, showing that countries innovate when neighbors innovate, and that innovations come in global waves. We show that innovation in language is something like punctuated equilibrium within an ecosystem. For long periods of stasis, countries borrow from one another and restrict their language to a set of common terms and phrases. Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. We also examine the circumstances in which countries introduce new terms into preambles, showing that countries innovate when neighbors innovate, and that innovations come in global waves. We show that innovation in language is something like punctuated equilibrium within an ecosystem. For long periods of stasis, countries borrow from one another and restrict their language to a set of common terms and phrases. Then, at particular junctures (likely associated with global conflicts), the equilibrium becomes disrupted and a period of innovation ensues. Arguing that legal language can be analogized to memes or genetic material, we analyze \u201chorizontal\u201d transfer of language across countries and \u201cvertical\u201d transfers within a single country over time. We also examine the circumstances in which countries introduce new terms into preambles, showing that countries innovate when neighbors innovate, and that innovations come in global waves. We show that innovation in language is something like punctuated equilibrium within an ecosystem. For long periods of stasis, countries borrow from one another and restrict their language to a set of common terms and phrases. Then, at particular junctures (likely associated with global conflicts), the equilibrium becomes disrupted and a period of innovation ensues. This eventually generates the \u201cnew normal\u201d in terms of the set of language that constitutional drafters use. The article provides an example of how text analysis can help us understand the ways in which legal texts are interrelated across space and time."}, {"paper_id": "121252897", "adju_relevance": 0, "title": "Information status and noncanonical word order in English", "background_label": "This work provides a comprehensive discourse-functional account of three classes of noncanonical constituent placement in English \u2013 preposing, postposing, and argument reversal \u2013 and shows how their interaction is accounted for in a principled and predictive way. In doing so, it details the variety of ways in which information can be 'given' or 'new' and shows how an understanding of this variety allows us to account for the distribution of these constructions in discourse. Moreover, the authors show that there exist broad and empirically verifiable functional correspondences within classes of syntactically similar constructions.", "method_label": "Relying heavily on corpus data, the authors identify three interacting dimensions along which individual constructions may vary with respect to the pragmatic constraints to which they are sensitive: old vs. new information, relative vs. absolute familiarity, and discourse- vs. hearer-familiarity. They show that preposed position is reserved for information that is linked to the prior discourse by means of a contextually licensed partially-ordered set relationship; postposed position is reserved for information that is 'new' in one of a small number of distinct senses; and argument-reversing constructions require that the information represented by the preverbal constituent be at least as familiar within the discourse as that represented by the postverbal constituent.", "result_label": "Within each of the three classes of constructions, individual constructions vary with respect to whether they are sensitive to familiarity within the discourse or (assumed) familiarity within the hearer's knowledge store. Thus, although the individual constructions in question are subject to distinct constraints, this work provides empirical evidence for the existence of strong correlations between sentence position and information status. The final chapter presents crosslinguistic data showing that these correlations are not limited to English.", "abstract": "This work provides a comprehensive discourse-functional account of three classes of noncanonical constituent placement in English \u2013 preposing, postposing, and argument reversal \u2013 and shows how their interaction is accounted for in a principled and predictive way. This work provides a comprehensive discourse-functional account of three classes of noncanonical constituent placement in English \u2013 preposing, postposing, and argument reversal \u2013 and shows how their interaction is accounted for in a principled and predictive way. In doing so, it details the variety of ways in which information can be 'given' or 'new' and shows how an understanding of this variety allows us to account for the distribution of these constructions in discourse. This work provides a comprehensive discourse-functional account of three classes of noncanonical constituent placement in English \u2013 preposing, postposing, and argument reversal \u2013 and shows how their interaction is accounted for in a principled and predictive way. In doing so, it details the variety of ways in which information can be 'given' or 'new' and shows how an understanding of this variety allows us to account for the distribution of these constructions in discourse. Moreover, the authors show that there exist broad and empirically verifiable functional correspondences within classes of syntactically similar constructions. Relying heavily on corpus data, the authors identify three interacting dimensions along which individual constructions may vary with respect to the pragmatic constraints to which they are sensitive: old vs. new information, relative vs. absolute familiarity, and discourse- vs. hearer-familiarity. Relying heavily on corpus data, the authors identify three interacting dimensions along which individual constructions may vary with respect to the pragmatic constraints to which they are sensitive: old vs. new information, relative vs. absolute familiarity, and discourse- vs. hearer-familiarity. They show that preposed position is reserved for information that is linked to the prior discourse by means of a contextually licensed partially-ordered set relationship; postposed position is reserved for information that is 'new' in one of a small number of distinct senses; and argument-reversing constructions require that the information represented by the preverbal constituent be at least as familiar within the discourse as that represented by the postverbal constituent. Within each of the three classes of constructions, individual constructions vary with respect to whether they are sensitive to familiarity within the discourse or (assumed) familiarity within the hearer's knowledge store. Within each of the three classes of constructions, individual constructions vary with respect to whether they are sensitive to familiarity within the discourse or (assumed) familiarity within the hearer's knowledge store. Thus, although the individual constructions in question are subject to distinct constraints, this work provides empirical evidence for the existence of strong correlations between sentence position and information status. Within each of the three classes of constructions, individual constructions vary with respect to whether they are sensitive to familiarity within the discourse or (assumed) familiarity within the hearer's knowledge store. Thus, although the individual constructions in question are subject to distinct constraints, this work provides empirical evidence for the existence of strong correlations between sentence position and information status. The final chapter presents crosslinguistic data showing that these correlations are not limited to English."}, {"paper_id": "197837335", "adju_relevance": 0, "title": "Roman Republican coinage", "abstract": ""}, {"paper_id": "59593603", "adju_relevance": 0, "title": "A joint text mining-rank size investigation of the rhetoric structures of the US Presidents' speeches", "background_label": "This work presents a text mining context and its use for a deep analysis of the messages delivered by the politicians. Specifically, we deal with an expert systems-based exploration of the rhetoric dynamics of a large collection of US Presidents' speeches, ranging from Washington to Trump. In particular, speeches are viewed as complex expert systems whose structures can be effectively analyzed through rank-size laws.", "abstract": "This work presents a text mining context and its use for a deep analysis of the messages delivered by the politicians. This work presents a text mining context and its use for a deep analysis of the messages delivered by the politicians. Specifically, we deal with an expert systems-based exploration of the rhetoric dynamics of a large collection of US Presidents' speeches, ranging from Washington to Trump. This work presents a text mining context and its use for a deep analysis of the messages delivered by the politicians. Specifically, we deal with an expert systems-based exploration of the rhetoric dynamics of a large collection of US Presidents' speeches, ranging from Washington to Trump. In particular, speeches are viewed as complex expert systems whose structures can be effectively analyzed through rank-size laws."}, {"paper_id": "14439818", "adju_relevance": 0, "title": "Optimizing to Arbitrary NLP Metrics using Ensemble Selection", "background_label": "While there have been many successful applications of machine learning methods to tasks in NLP, learning algorithms are not typically designed to optimize NLP performance metrics.", "abstract": "While there have been many successful applications of machine learning methods to tasks in NLP, learning algorithms are not typically designed to optimize NLP performance metrics."}, {"paper_id": "143237240", "adju_relevance": 0, "title": "WHO'S REPORTING THE PROTESTS?: Converging practices of citizen journalists and two BBC World Service newsrooms, from Iran's election protests to the Arab uprisings", "background_label": "The 2009 protests in Iran and the 2011 Arab uprisings took place in complex and fast evolving media ecologies. The BBC's Persian and Arabic language services, which reach millions, drew heavily on content created by ordinary citizens to cover events.", "abstract": "The 2009 protests in Iran and the 2011 Arab uprisings took place in complex and fast evolving media ecologies. The 2009 protests in Iran and the 2011 Arab uprisings took place in complex and fast evolving media ecologies. The BBC's Persian and Arabic language services, which reach millions, drew heavily on content created by ordinary citizens to cover events."}, {"paper_id": "193019136", "adju_relevance": 0, "title": "\u0413\u0435\u043d\u0434\u0435\u0440\u043d\u044b\u0435 \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0438 \u043f\u0435\u0440\u0435\u0432\u043e\u0434\u0430 \u0440\u043e\u043c\u0430\u043d\u0430 \u0414\u0436\u043e\u0430\u043d \u0420\u043e\u0443\u043b\u0438\u043d\u0433 \u201cHarry Potter and the Philosopher`s Stone\u201d \u043d\u0430 \u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u044f\u0437\u044b\u043a", "background_label": "The paper focuses on exposing gender peculiarities of literary translations of the book \u2018Harry Potter and the Pholosopher\u2019s Stone\u201d that was written by Joan Rowling. The literary translation like no other type of translation gives the translator the opportunity to express their linguistic identity at most. Instinctively a translator in the process of his or her translation uses some language means that are typical for their gender.", "result_label": "Studying gender peculiarities manifestation at different language levels allows developing and describing the connection between thinking and gender, gender and language, which favours the cognition of a person through the prism of the language.", "abstract": "The paper focuses on exposing gender peculiarities of literary translations of the book \u2018Harry Potter and the Pholosopher\u2019s Stone\u201d that was written by Joan Rowling. The paper focuses on exposing gender peculiarities of literary translations of the book \u2018Harry Potter and the Pholosopher\u2019s Stone\u201d that was written by Joan Rowling. The literary translation like no other type of translation gives the translator the opportunity to express their linguistic identity at most. The paper focuses on exposing gender peculiarities of literary translations of the book \u2018Harry Potter and the Pholosopher\u2019s Stone\u201d that was written by Joan Rowling. The literary translation like no other type of translation gives the translator the opportunity to express their linguistic identity at most. Instinctively a translator in the process of his or her translation uses some language means that are typical for their gender. Studying gender peculiarities manifestation at different language levels allows developing and describing the connection between thinking and gender, gender and language, which favours the cognition of a person through the prism of the language."}, {"paper_id": "152903975", "adju_relevance": 0, "title": "The American Congress", "background_label": "The American Congress: modern trends 2. Representation and lawmaking in Congress: the constitutional and historical context 3.", "abstract": " The American Congress: modern trends 2. The American Congress: modern trends 2. Representation and lawmaking in Congress: the constitutional and historical context 3."}, {"paper_id": "23216433", "adju_relevance": 0, "title": "Irrelevant events affect voters' evaluations of government performance.", "background_label": "Does information irrelevant to government performance affect voting behavior? If so, how does this help us understand the mechanisms underlying voters' retrospective assessments of candidates' performance in office? To precisely test for the effects of irrelevant information, we explore the electoral impact of local college football games just before an election, irrelevant events that government has nothing to do with and for which no government response would be expected.", "method_label": "We find that a win in the 10 d before Election Day causes the incumbent to receive an additional 1.61 percentage points of the vote in Senate, gubernatorial, and presidential elections, with the effect being larger for teams with stronger fan support. In addition to conducting placebo tests based on postelection games, we demonstrate these effects by using the betting market's estimate of a team's probability of winning the game before it occurs to isolate the surprise component of game outcomes.", "result_label": "We corroborate these aggregate-level results with a survey that we conducted during the 2009 NCAA men's college basketball tournament, where we find that surprising wins and losses affect presidential approval. An experiment embedded within the survey also indicates that personal well-being may influence voting decisions on a subconscious level. We find that making people more aware of the reasons for their current state of mind reduces the effect that irrelevant events have on their opinions. These findings underscore the subtle power of irrelevant events in shaping important real-world decisions and suggest ways in which decision making can be improved.", "abstract": "Does information irrelevant to government performance affect voting behavior? Does information irrelevant to government performance affect voting behavior? If so, how does this help us understand the mechanisms underlying voters' retrospective assessments of candidates' performance in office? Does information irrelevant to government performance affect voting behavior? If so, how does this help us understand the mechanisms underlying voters' retrospective assessments of candidates' performance in office? To precisely test for the effects of irrelevant information, we explore the electoral impact of local college football games just before an election, irrelevant events that government has nothing to do with and for which no government response would be expected. We find that a win in the 10 d before Election Day causes the incumbent to receive an additional 1.61 percentage points of the vote in Senate, gubernatorial, and presidential elections, with the effect being larger for teams with stronger fan support. We find that a win in the 10 d before Election Day causes the incumbent to receive an additional 1.61 percentage points of the vote in Senate, gubernatorial, and presidential elections, with the effect being larger for teams with stronger fan support. In addition to conducting placebo tests based on postelection games, we demonstrate these effects by using the betting market's estimate of a team's probability of winning the game before it occurs to isolate the surprise component of game outcomes. We corroborate these aggregate-level results with a survey that we conducted during the 2009 NCAA men's college basketball tournament, where we find that surprising wins and losses affect presidential approval. We corroborate these aggregate-level results with a survey that we conducted during the 2009 NCAA men's college basketball tournament, where we find that surprising wins and losses affect presidential approval. An experiment embedded within the survey also indicates that personal well-being may influence voting decisions on a subconscious level. We corroborate these aggregate-level results with a survey that we conducted during the 2009 NCAA men's college basketball tournament, where we find that surprising wins and losses affect presidential approval. An experiment embedded within the survey also indicates that personal well-being may influence voting decisions on a subconscious level. We find that making people more aware of the reasons for their current state of mind reduces the effect that irrelevant events have on their opinions. We corroborate these aggregate-level results with a survey that we conducted during the 2009 NCAA men's college basketball tournament, where we find that surprising wins and losses affect presidential approval. An experiment embedded within the survey also indicates that personal well-being may influence voting decisions on a subconscious level. We find that making people more aware of the reasons for their current state of mind reduces the effect that irrelevant events have on their opinions. These findings underscore the subtle power of irrelevant events in shaping important real-world decisions and suggest ways in which decision making can be improved."}, {"paper_id": "37600461", "adju_relevance": 0, "title": "Does Campaigning on Social Media Make a Difference? Evidence from candidate use of Twitter during the 2015 and 2017 UK Elections", "background_label": "Social media are now a routine part of political campaigns all over the world. However, studies of the impact of campaigning on social platform have thus far been limited to cross-sectional datasets from one election period which are vulnerable to unobserved variable bias. Hence empirical evidence on the effectiveness of political social media activity is thin.", "abstract": "Social media are now a routine part of political campaigns all over the world. Social media are now a routine part of political campaigns all over the world. However, studies of the impact of campaigning on social platform have thus far been limited to cross-sectional datasets from one election period which are vulnerable to unobserved variable bias. Social media are now a routine part of political campaigns all over the world. However, studies of the impact of campaigning on social platform have thus far been limited to cross-sectional datasets from one election period which are vulnerable to unobserved variable bias. Hence empirical evidence on the effectiveness of political social media activity is thin."}, {"paper_id": "2731141", "adju_relevance": 0, "title": "Semi-Supervised Learning Literature Survey", "background_label": "Door lock apparatus in which a door latch mechanism is operated by inner and outer door handles coupled to a latch shaft extending through the latch mechanism.", "method_label": "Handles are coupled to ends of latch shaft by coupling devices enabling door to be locked from the inside to prevent entry from the outside but can still be opened from the inside by normal operation of outside handle. Inside coupling device has limited lost-motion which is used to operate cam device to unlock the door on actuation of inner handles.", "abstract": "Door lock apparatus in which a door latch mechanism is operated by inner and outer door handles coupled to a latch shaft extending through the latch mechanism. Handles are coupled to ends of latch shaft by coupling devices enabling door to be locked from the inside to prevent entry from the outside but can still be opened from the inside by normal operation of outside handle. Handles are coupled to ends of latch shaft by coupling devices enabling door to be locked from the inside to prevent entry from the outside but can still be opened from the inside by normal operation of outside handle. Inside coupling device has limited lost-motion which is used to operate cam device to unlock the door on actuation of inner handles."}, {"paper_id": "61807733", "adju_relevance": 0, "title": "Congressional Vote Analysis Using Signed Networks", "background_label": "In today's era of big data, much can be represented as a network. However, most of the work in traditional network analysis is unable to handle many existing network types, which is due to certain networks having added complexities. For example, signed networks, which have both positive and negative links, have been shown to require dedicated efforts due to the methods designed for typical unsigned networks (those having only positive links) being no longer applicable. One specific type of signed network is that of voting records, such as the Senate and House of Representatives from the U.S. Congress, which form signed bipartite networks between the congresspeople and the bills voted upon. With the current tensions between the two prominent political parties in the U.S., it seems time to ask the question if signed network analysis methods are able to aid in our understanding of the underlying dynamics of the voting habits in the U.S. Congress, since they drive some of the most influential decision making processes in the country.", "result_label": "To this end, in this paper, we conduct a thorough analysis on the behaviors of both current and past U.S. Congress voting datasets uncovering numerous patterns, extending and then investigating the applicability of balance theory in the signed bipartite setting, and then finally leverage our findings to accurately predict the sign of missing links.", "abstract": "In today's era of big data, much can be represented as a network. In today's era of big data, much can be represented as a network. However, most of the work in traditional network analysis is unable to handle many existing network types, which is due to certain networks having added complexities. In today's era of big data, much can be represented as a network. However, most of the work in traditional network analysis is unable to handle many existing network types, which is due to certain networks having added complexities. For example, signed networks, which have both positive and negative links, have been shown to require dedicated efforts due to the methods designed for typical unsigned networks (those having only positive links) being no longer applicable. In today's era of big data, much can be represented as a network. However, most of the work in traditional network analysis is unable to handle many existing network types, which is due to certain networks having added complexities. For example, signed networks, which have both positive and negative links, have been shown to require dedicated efforts due to the methods designed for typical unsigned networks (those having only positive links) being no longer applicable. One specific type of signed network is that of voting records, such as the Senate and House of Representatives from the U.S. Congress, which form signed bipartite networks between the congresspeople and the bills voted upon. In today's era of big data, much can be represented as a network. However, most of the work in traditional network analysis is unable to handle many existing network types, which is due to certain networks having added complexities. For example, signed networks, which have both positive and negative links, have been shown to require dedicated efforts due to the methods designed for typical unsigned networks (those having only positive links) being no longer applicable. One specific type of signed network is that of voting records, such as the Senate and House of Representatives from the U.S. Congress, which form signed bipartite networks between the congresspeople and the bills voted upon. With the current tensions between the two prominent political parties in the U.S., it seems time to ask the question if signed network analysis methods are able to aid in our understanding of the underlying dynamics of the voting habits in the U.S. Congress, since they drive some of the most influential decision making processes in the country. To this end, in this paper, we conduct a thorough analysis on the behaviors of both current and past U.S. Congress voting datasets uncovering numerous patterns, extending and then investigating the applicability of balance theory in the signed bipartite setting, and then finally leverage our findings to accurately predict the sign of missing links."}, {"paper_id": "119425731", "adju_relevance": 0, "title": "Unzerlegbare Darstellungen I", "background_label": "LetK be the structure got by forgetting the composition law of morphisms in a given category. A linear representation ofK is given by a map V associating with any morphism \u03d5: a\u2192e ofK a linear vector space map V(\u03d5): V(a)\u2192V(e).", "method_label": "We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations.", "abstract": "LetK be the structure got by forgetting the composition law of morphisms in a given category. LetK be the structure got by forgetting the composition law of morphisms in a given category. A linear representation ofK is given by a map V associating with any morphism \u03d5: a\u2192e ofK a linear vector space map V(\u03d5): V(a)\u2192V(e). We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations."}, {"paper_id": "8270358", "adju_relevance": 0, "title": "Lexical Influences on the Perception of Sarcasm", "background_label": "Speakers and listeners make use of a variety of pragmatic factors to produce and identify sarcastic statements. It is also possible that lexical factors play a role, although this possibility has not been investigated previously.", "method_label": "College students were asked to read excerpts from published works that originally contained the phrase said sarcastically, although the word sarcastically was deleted. The participants rated the characters' statements in these excerpts as more likely to be sarcastic than those from similar excerpts that did not originally contain the word sarcastically.", "result_label": "The use of interjections, such as gee or gosh, predicted a significant amount of the variance in the participants' ratings of sarcastic intent. This outcome suggests that sarcastic statements may be more formulaic than previously realized. It also suggests that computer software could be written to recognize such lexical factors, greatly increasing the likelihood that non-literal intent could be correctly interpreted by such programs, even if they are unable to identify the pragmatic components of nonliteral language.", "abstract": "Speakers and listeners make use of a variety of pragmatic factors to produce and identify sarcastic statements. Speakers and listeners make use of a variety of pragmatic factors to produce and identify sarcastic statements. It is also possible that lexical factors play a role, although this possibility has not been investigated previously. College students were asked to read excerpts from published works that originally contained the phrase said sarcastically, although the word sarcastically was deleted. College students were asked to read excerpts from published works that originally contained the phrase said sarcastically, although the word sarcastically was deleted. The participants rated the characters' statements in these excerpts as more likely to be sarcastic than those from similar excerpts that did not originally contain the word sarcastically. The use of interjections, such as gee or gosh, predicted a significant amount of the variance in the participants' ratings of sarcastic intent. The use of interjections, such as gee or gosh, predicted a significant amount of the variance in the participants' ratings of sarcastic intent. This outcome suggests that sarcastic statements may be more formulaic than previously realized. The use of interjections, such as gee or gosh, predicted a significant amount of the variance in the participants' ratings of sarcastic intent. This outcome suggests that sarcastic statements may be more formulaic than previously realized. It also suggests that computer software could be written to recognize such lexical factors, greatly increasing the likelihood that non-literal intent could be correctly interpreted by such programs, even if they are unable to identify the pragmatic components of nonliteral language."}, {"paper_id": "143086807", "adju_relevance": 0, "title": "Deliberative democracy or agonistic pluralism", "background_label": "Abstract: This article examines the current debate about the nature of democracy and discusses the main theses of the approach called 'deliberative democracy' in its two main versions, the one put forward by John Rawls, and the other one put forwardby Jurgen Habermas. While agreeing with them as regards to the need to develop a more of democracy than the one offered by the 'aggregative' model, I submit that they do not provide an adequate understanding of the main task of democracy. No doubt, by stating that democracy cannot be reduced to a question of procedures to mediate among conflicting interests, deliberative democrats defend a conception of democracy that presents a richer conception of politics. But, albeit in a different way thanthe view they criticize, their vision is also a rationalist one which leaves aside the crucial role played by 'passions' and collective forms of identifications in the field of politics. Moreover, in their attempt to reconcile the liberal tradition with the democratic one, deliberative democrats tend to erase the tension that exist between liberalism and democracy and they are therefore unable to come to terms with the conflictual nature of democratic politics.", "abstract": "Abstract: This article examines the current debate about the nature of democracy and discusses the main theses of the approach called 'deliberative democracy' in its two main versions, the one put forward by John Rawls, and the other one put forwardby Jurgen Habermas. Abstract: This article examines the current debate about the nature of democracy and discusses the main theses of the approach called 'deliberative democracy' in its two main versions, the one put forward by John Rawls, and the other one put forwardby Jurgen Habermas. While agreeing with them as regards to the need to develop a more of democracy than the one offered by the 'aggregative' model, I submit that they do not provide an adequate understanding of the main task of democracy. Abstract: This article examines the current debate about the nature of democracy and discusses the main theses of the approach called 'deliberative democracy' in its two main versions, the one put forward by John Rawls, and the other one put forwardby Jurgen Habermas. While agreeing with them as regards to the need to develop a more of democracy than the one offered by the 'aggregative' model, I submit that they do not provide an adequate understanding of the main task of democracy. No doubt, by stating that democracy cannot be reduced to a question of procedures to mediate among conflicting interests, deliberative democrats defend a conception of democracy that presents a richer conception of politics. Abstract: This article examines the current debate about the nature of democracy and discusses the main theses of the approach called 'deliberative democracy' in its two main versions, the one put forward by John Rawls, and the other one put forwardby Jurgen Habermas. While agreeing with them as regards to the need to develop a more of democracy than the one offered by the 'aggregative' model, I submit that they do not provide an adequate understanding of the main task of democracy. No doubt, by stating that democracy cannot be reduced to a question of procedures to mediate among conflicting interests, deliberative democrats defend a conception of democracy that presents a richer conception of politics. But, albeit in a different way thanthe view they criticize, their vision is also a rationalist one which leaves aside the crucial role played by 'passions' and collective forms of identifications in the field of politics. Abstract: This article examines the current debate about the nature of democracy and discusses the main theses of the approach called 'deliberative democracy' in its two main versions, the one put forward by John Rawls, and the other one put forwardby Jurgen Habermas. While agreeing with them as regards to the need to develop a more of democracy than the one offered by the 'aggregative' model, I submit that they do not provide an adequate understanding of the main task of democracy. No doubt, by stating that democracy cannot be reduced to a question of procedures to mediate among conflicting interests, deliberative democrats defend a conception of democracy that presents a richer conception of politics. But, albeit in a different way thanthe view they criticize, their vision is also a rationalist one which leaves aside the crucial role played by 'passions' and collective forms of identifications in the field of politics. Moreover, in their attempt to reconcile the liberal tradition with the democratic one, deliberative democrats tend to erase the tension that exist between liberalism and democracy and they are therefore unable to come to terms with the conflictual nature of democratic politics."}, {"paper_id": "17178673", "adju_relevance": 0, "title": "Planting colourings silently", "background_label": "Let $k\\geq3$ be a fixed integer and let $Z_k(G)$ be the number of $k$-colourings of the graph $G$. For certain values of the average degree, the random variable $Z_k(G(n,m))$ is known to be concentrated in the sense that $\\frac1n(\\ln Z_k(G(n,m))-\\ln E[Z_k(G(n,m))])$ converges to $0$ in probability [Achlioptas and Coja-Oghlan: FOCS 2008].", "abstract": "Let $k\\geq3$ be a fixed integer and let $Z_k(G)$ be the number of $k$-colourings of the graph $G$. Let $k\\geq3$ be a fixed integer and let $Z_k(G)$ be the number of $k$-colourings of the graph $G$. For certain values of the average degree, the random variable $Z_k(G(n,m))$ is known to be concentrated in the sense that $\\frac1n(\\ln Z_k(G(n,m))-\\ln E[Z_k(G(n,m))])$ converges to $0$ in probability [Achlioptas and Coja-Oghlan: FOCS 2008]."}, {"paper_id": "7675902", "adju_relevance": 0, "title": "Political Speech Generation", "background_label": "In this report we present a system that can generate political speeches for a desired political party. Furthermore, the system allows to specify whether a speech should hold a supportive or opposing opinion.", "method_label": "The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson&Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. Sequences of words are generated based on probabilities obtained from two underlying models: A language model takes care of the grammatical correctness while a topic model aims for textual consistency. Both models were trained on the Convote dataset which contains transcripts from US congressional floor debates. Furthermore, we present a manual and an automated approach to evaluate the quality of generated speeches.", "result_label": "In an experimental evaluation generated speeches have shown very high quality in terms of grammatical correctness and sentence transitions.", "abstract": "In this report we present a system that can generate political speeches for a desired political party. In this report we present a system that can generate political speeches for a desired political party. Furthermore, the system allows to specify whether a speech should hold a supportive or opposing opinion. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson&Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson&Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. Sequences of words are generated based on probabilities obtained from two underlying models: A language model takes care of the grammatical correctness while a topic model aims for textual consistency. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson&Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. Sequences of words are generated based on probabilities obtained from two underlying models: A language model takes care of the grammatical correctness while a topic model aims for textual consistency. Both models were trained on the Convote dataset which contains transcripts from US congressional floor debates. The system relies on a combination of several state-of-the-art NLP methods which are discussed in this report. These include n-grams, Justeson&Katz POS tag filter, recurrent neural networks, and latent Dirichlet allocation. Sequences of words are generated based on probabilities obtained from two underlying models: A language model takes care of the grammatical correctness while a topic model aims for textual consistency. Both models were trained on the Convote dataset which contains transcripts from US congressional floor debates. Furthermore, we present a manual and an automated approach to evaluate the quality of generated speeches. In an experimental evaluation generated speeches have shown very high quality in terms of grammatical correctness and sentence transitions."}, {"paper_id": "144917312", "adju_relevance": 0, "title": "Many-Voiced or Unisono? : An Inquiry into Motives for Attendance and Aesthetic Dispositions of the Audience Attending Classical Concerts", "background_label": "In this article, I analyse empirically whether the audience attending classical concerts can be subdivided into three segments - following the lead of Howard Becker's Art Worlds (1984).", "abstract": "In this article, I analyse empirically whether the audience attending classical concerts can be subdivided into three segments - following the lead of Howard Becker's Art Worlds (1984)."}, {"paper_id": "16266534", "adju_relevance": 0, "title": "Direction-Based Text Interpretation as an Information Access Refinement", "background_label": "A Text-Based Intelligent System should provide more in-depth information about the contents of its corpus than does a standard information retrieval system, while at the same time avoiding the complexity and resource-consuming behavior of detailed text understanders.", "method_label": "Instead of focusing on discovering documents that pertain to some topic of interest to the user, an approach is introduced based on the criterion of directionality (e.g., Is the agent in favor of, neutral, or opposed to the event?). A method is described for coercing sentence meanings into a metaphoric model such that the only semantic interpretation needed in order to determine the directionality of a sentence is done with respect to the model. This interpretation method is designed to be an integrated component of a hybrid information access system.", "abstract": "A Text-Based Intelligent System should provide more in-depth information about the contents of its corpus than does a standard information retrieval system, while at the same time avoiding the complexity and resource-consuming behavior of detailed text understanders. Instead of focusing on discovering documents that pertain to some topic of interest to the user, an approach is introduced based on the criterion of directionality (e.g., Is the agent in favor of, neutral, or opposed to the event?). Instead of focusing on discovering documents that pertain to some topic of interest to the user, an approach is introduced based on the criterion of directionality (e.g., Is the agent in favor of, neutral, or opposed to the event?). A method is described for coercing sentence meanings into a metaphoric model such that the only semantic interpretation needed in order to determine the directionality of a sentence is done with respect to the model. Instead of focusing on discovering documents that pertain to some topic of interest to the user, an approach is introduced based on the criterion of directionality (e.g., Is the agent in favor of, neutral, or opposed to the event?). A method is described for coercing sentence meanings into a metaphoric model such that the only semantic interpretation needed in order to determine the directionality of a sentence is done with respect to the model. This interpretation method is designed to be an integrated component of a hybrid information access system."}, {"paper_id": "155063811", "adju_relevance": 0, "title": "Off the Record: Unrecorded Legislative Votes, Selection Bias and Roll-Call Vote Analysis", "background_label": "Scholars often use roll-call votes to study legislative behaviour. However, many legislatures only conclude a minority of decisions by roll call. Thus, if these votes are not a random sample of the universe of votes cast, scholars may be drawing misleading inferences. In fact, theories over why roll-call votes are requested would predict selection bias based on exactly the characteristics of legislative voting that scholars have most heavily studied.", "method_label": "This article demonstrates the character and severity of this sampling problem empirically by examining European Parliament vote data for a whole year.", "result_label": "Given that many legislatures decided only a fraction of their legislation by roll call, these findings have potentially important implications for the general study of legislative behaviour.", "abstract": "Scholars often use roll-call votes to study legislative behaviour. Scholars often use roll-call votes to study legislative behaviour. However, many legislatures only conclude a minority of decisions by roll call. Scholars often use roll-call votes to study legislative behaviour. However, many legislatures only conclude a minority of decisions by roll call. Thus, if these votes are not a random sample of the universe of votes cast, scholars may be drawing misleading inferences. Scholars often use roll-call votes to study legislative behaviour. However, many legislatures only conclude a minority of decisions by roll call. Thus, if these votes are not a random sample of the universe of votes cast, scholars may be drawing misleading inferences. In fact, theories over why roll-call votes are requested would predict selection bias based on exactly the characteristics of legislative voting that scholars have most heavily studied. This article demonstrates the character and severity of this sampling problem empirically by examining European Parliament vote data for a whole year. Given that many legislatures decided only a fraction of their legislation by roll call, these findings have potentially important implications for the general study of legislative behaviour."}, {"paper_id": "20339999", "adju_relevance": 0, "title": "Asking Too Much? The Rhetorical Role of Questions in Political Discourse", "background_label": "Questions play a prominent role in social interactions, performing rhetorical functions that go beyond that of simple informational exchange. The surface form of a question can signal the intention and background of the person asking it, as well as the nature of their relation with the interlocutor. While the informational nature of questions has been extensively examined in the context of question-answering applications, their rhetorical aspects have been largely understudied.", "method_label": "In this work we introduce an unsupervised methodology for extracting surface motifs that recur in questions, and for grouping them according to their latent rhetorical role.", "result_label": "By applying this framework to the setting of question sessions in the UK parliament, we show that the resulting typology encodes key aspects of the political discourse---such as the bifurcation in questioning behavior between government and opposition parties---and reveals new insights into the effects of a legislator's tenure and political career ambitions.", "abstract": "Questions play a prominent role in social interactions, performing rhetorical functions that go beyond that of simple informational exchange. Questions play a prominent role in social interactions, performing rhetorical functions that go beyond that of simple informational exchange. The surface form of a question can signal the intention and background of the person asking it, as well as the nature of their relation with the interlocutor. Questions play a prominent role in social interactions, performing rhetorical functions that go beyond that of simple informational exchange. The surface form of a question can signal the intention and background of the person asking it, as well as the nature of their relation with the interlocutor. While the informational nature of questions has been extensively examined in the context of question-answering applications, their rhetorical aspects have been largely understudied. In this work we introduce an unsupervised methodology for extracting surface motifs that recur in questions, and for grouping them according to their latent rhetorical role. By applying this framework to the setting of question sessions in the UK parliament, we show that the resulting typology encodes key aspects of the political discourse---such as the bifurcation in questioning behavior between government and opposition parties---and reveals new insights into the effects of a legislator's tenure and political career ambitions."}, {"paper_id": "154087903", "adju_relevance": 0, "title": "Get Out the Vote: How to Increase Voter Turnout", "background_label": "Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Unlike authors of other campaign advice books, Donald Green and Alan Gerber root their work firmly in rigorous science. Their recommendations emerge from thorough experiments conducted in real electoral settings, examining the impact and effectiveness of door-to-door canvassing, telephone calls, direct mail, and other campaign tactics. They discover that many GOTV tactics used by campaign managers and political consultants are less effective than is often believed. The authors, relying on rigorous and systematic research, challenge much of the conventional wisdom about what works and what doesn't in the political campaigns. The authors' applied form of political science has won acclaim from scholars and earned the attention of campaign professionals and journalists.", "method_label": "Since 1998 the authors have conducted research in over a dozen states, studying a wide range of federal, state, and municipal elections.", "result_label": "Their book connects theory with practice, informing campaign professionals and local organizers as well as students of electoral politics. This book presents their result for a non-academic audience interested in putting campaign research into practice, and the findings will be surprising to many.", "abstract": "Get Out the Vote! Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Unlike authors of other campaign advice books, Donald Green and Alan Gerber root their work firmly in rigorous science. Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Unlike authors of other campaign advice books, Donald Green and Alan Gerber root their work firmly in rigorous science. Their recommendations emerge from thorough experiments conducted in real electoral settings, examining the impact and effectiveness of door-to-door canvassing, telephone calls, direct mail, and other campaign tactics. Since 1998 the authors have conducted research in over a dozen states, studying a wide range of federal, state, and municipal elections. Their book connects theory with practice, informing campaign professionals and local organizers as well as students of electoral politics. Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Unlike authors of other campaign advice books, Donald Green and Alan Gerber root their work firmly in rigorous science. Their recommendations emerge from thorough experiments conducted in real electoral settings, examining the impact and effectiveness of door-to-door canvassing, telephone calls, direct mail, and other campaign tactics. They discover that many GOTV tactics used by campaign managers and political consultants are less effective than is often believed. Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Unlike authors of other campaign advice books, Donald Green and Alan Gerber root their work firmly in rigorous science. Their recommendations emerge from thorough experiments conducted in real electoral settings, examining the impact and effectiveness of door-to-door canvassing, telephone calls, direct mail, and other campaign tactics. They discover that many GOTV tactics used by campaign managers and political consultants are less effective than is often believed. The authors, relying on rigorous and systematic research, challenge much of the conventional wisdom about what works and what doesn't in the political campaigns. Get Out the Vote! Is a practical guide for anyone trying to mobilize voters or organize at the grass roots. Unlike authors of other campaign advice books, Donald Green and Alan Gerber root their work firmly in rigorous science. Their recommendations emerge from thorough experiments conducted in real electoral settings, examining the impact and effectiveness of door-to-door canvassing, telephone calls, direct mail, and other campaign tactics. They discover that many GOTV tactics used by campaign managers and political consultants are less effective than is often believed. The authors, relying on rigorous and systematic research, challenge much of the conventional wisdom about what works and what doesn't in the political campaigns. The authors' applied form of political science has won acclaim from scholars and earned the attention of campaign professionals and journalists. Their book connects theory with practice, informing campaign professionals and local organizers as well as students of electoral politics. This book presents their result for a non-academic audience interested in putting campaign research into practice, and the findings will be surprising to many."}, {"paper_id": "145770267", "adju_relevance": 0, "title": "Causal connectives in discourse processing: How differences in subjectivity are reflected in eye movements", "background_label": "Causal connectives are often considered to provide crucial information about the discourse structure; they signal a causal relation between two text segments. However, in many languages of the world causal connectives specialise in either subjective or objective causal relations.", "abstract": "Causal connectives are often considered to provide crucial information about the discourse structure; they signal a causal relation between two text segments. Causal connectives are often considered to provide crucial information about the discourse structure; they signal a causal relation between two text segments. However, in many languages of the world causal connectives specialise in either subjective or objective causal relations."}, {"paper_id": "841374", "adju_relevance": 0, "title": "Intense ultrasonic clicks from echolocating toothed whales do not elicit anti\u2013predator responses or debilitate the squid Loligo pealeii", "background_label": "Toothed whales use intense ultrasonic clicks to echolocate prey and it has been hypothesized that they also acoustically debilitate their prey with these intense sound pulses to facilitate capture. Cephalopods are an important food source for toothed whales, and there has probably been an evolutionary selection pressure on cephalopods to develop a mechanism for detecting and evading sound\u2013emitting toothed whale predators. Ultrasonic detection has evolved in some insects to avoid echolocating bats, and it can be hypothesized that cephalopods might have evolved similar ultrasound detection as an anti\u2013predation measure.", "method_label": "We test this hypothesis in the squid Loligo pealeii in a playback experiment using intense echolocation clicks from two squid\u2013eating toothed whale species. Twelve squid were exposed to clicks at two repetition rates (16 and 125 clicks per second) with received sound pressure levels of 199\u2013226 dB re 1 \u03bcPa (pp) mimicking the sound exposure from an echolocating toothed whale as it approaches and captures prey.", "result_label": "We demonstrate that intense ultrasonic clicks do not elicit any detectable anti\u2013predator behaviour in L. pealeii and that clicks with received levels up to 226 dB re 1 \u03bcPa (pp) do not acoustically debilitate this cephalopod species.", "abstract": "Toothed whales use intense ultrasonic clicks to echolocate prey and it has been hypothesized that they also acoustically debilitate their prey with these intense sound pulses to facilitate capture. Toothed whales use intense ultrasonic clicks to echolocate prey and it has been hypothesized that they also acoustically debilitate their prey with these intense sound pulses to facilitate capture. Cephalopods are an important food source for toothed whales, and there has probably been an evolutionary selection pressure on cephalopods to develop a mechanism for detecting and evading sound\u2013emitting toothed whale predators. Toothed whales use intense ultrasonic clicks to echolocate prey and it has been hypothesized that they also acoustically debilitate their prey with these intense sound pulses to facilitate capture. Cephalopods are an important food source for toothed whales, and there has probably been an evolutionary selection pressure on cephalopods to develop a mechanism for detecting and evading sound\u2013emitting toothed whale predators. Ultrasonic detection has evolved in some insects to avoid echolocating bats, and it can be hypothesized that cephalopods might have evolved similar ultrasound detection as an anti\u2013predation measure. We test this hypothesis in the squid Loligo pealeii in a playback experiment using intense echolocation clicks from two squid\u2013eating toothed whale species. We test this hypothesis in the squid Loligo pealeii in a playback experiment using intense echolocation clicks from two squid\u2013eating toothed whale species. Twelve squid were exposed to clicks at two repetition rates (16 and 125 clicks per second) with received sound pressure levels of 199\u2013226 dB re 1 \u03bcPa (pp) mimicking the sound exposure from an echolocating toothed whale as it approaches and captures prey. We demonstrate that intense ultrasonic clicks do not elicit any detectable anti\u2013predator behaviour in L. pealeii and that clicks with received levels up to 226 dB re 1 \u03bcPa (pp) do not acoustically debilitate this cephalopod species."}, {"paper_id": "144522875", "adju_relevance": 0, "title": "Argumentation and the lexical topical fields", "background_label": "Abstract Most of the work which has been done within the framework of the theory of Argumentation Within Language (AWL) was, until recently, centred on what can be called \u2018articulators of argumentation\u2019. This work, which consisted, mainly, in studying the constraints that articulators such as but, nevertheless, therefore, even , or almost, little, a little , impose on the meaning, has concentrated on the fact that the argumentative movements operated in utterances containing those words bear on gradual argumentative rules presented as general and shared by the linguistic community. Those rules, which we call topoi (singular: topos ) appear to belong to the speakers' implicit knowledge and beliefs: from the perspective of the study of articulators, what belongs to the semantic description are the constraints on those topoi, not the topoi themselves. In this paper, we present a way to mark this emergence: we describe the lexical items with argumentative \u2018ingredients\u2019 \u2014 we call those ingredients topical fields \u2014 on the basis of which the topoi used in each utterance containing those lexical items are constructed, according to what the situation requires.", "result_label": "Now, if the semantic description could say nothing about those topoi, the study of the argumentative articulators would strictly belong to pragmatics, since it could be achieved only after those topoi have been determined. We defend here a different position: the argumentative description of articulators belongs to semantics; as a consequence, semantics must mark in a certain way the emergence of the topoi used in utterances, even if those topoi belong to the speakers' knowledge and beliefs. In particular, we evaluate the consequences, from a structuralist point of view, of our account of the grounding of language in the world.", "method_label": "We first reconsider the definition of topos and topical field used in the past; we propose a recursive definition of topical fields, which we then apply to the description of lexicon. We then define an operation which allows the transformation of a chain of topoi into a topos. This definition is used in order to construct the dynamic topoi out of the lexical ones. Finally, we step back and reflect about the relationship between the conception of language which underlies our work and the structuralist program.", "abstract": "Abstract Most of the work which has been done within the framework of the theory of Argumentation Within Language (AWL) was, until recently, centred on what can be called \u2018articulators of argumentation\u2019. Abstract Most of the work which has been done within the framework of the theory of Argumentation Within Language (AWL) was, until recently, centred on what can be called \u2018articulators of argumentation\u2019. This work, which consisted, mainly, in studying the constraints that articulators such as but, nevertheless, therefore, even , or almost, little, a little , impose on the meaning, has concentrated on the fact that the argumentative movements operated in utterances containing those words bear on gradual argumentative rules presented as general and shared by the linguistic community. Abstract Most of the work which has been done within the framework of the theory of Argumentation Within Language (AWL) was, until recently, centred on what can be called \u2018articulators of argumentation\u2019. This work, which consisted, mainly, in studying the constraints that articulators such as but, nevertheless, therefore, even , or almost, little, a little , impose on the meaning, has concentrated on the fact that the argumentative movements operated in utterances containing those words bear on gradual argumentative rules presented as general and shared by the linguistic community. Those rules, which we call topoi (singular: topos ) appear to belong to the speakers' implicit knowledge and beliefs: from the perspective of the study of articulators, what belongs to the semantic description are the constraints on those topoi, not the topoi themselves. Now, if the semantic description could say nothing about those topoi, the study of the argumentative articulators would strictly belong to pragmatics, since it could be achieved only after those topoi have been determined. Now, if the semantic description could say nothing about those topoi, the study of the argumentative articulators would strictly belong to pragmatics, since it could be achieved only after those topoi have been determined. We defend here a different position: the argumentative description of articulators belongs to semantics; as a consequence, semantics must mark in a certain way the emergence of the topoi used in utterances, even if those topoi belong to the speakers' knowledge and beliefs. Abstract Most of the work which has been done within the framework of the theory of Argumentation Within Language (AWL) was, until recently, centred on what can be called \u2018articulators of argumentation\u2019. This work, which consisted, mainly, in studying the constraints that articulators such as but, nevertheless, therefore, even , or almost, little, a little , impose on the meaning, has concentrated on the fact that the argumentative movements operated in utterances containing those words bear on gradual argumentative rules presented as general and shared by the linguistic community. Those rules, which we call topoi (singular: topos ) appear to belong to the speakers' implicit knowledge and beliefs: from the perspective of the study of articulators, what belongs to the semantic description are the constraints on those topoi, not the topoi themselves. In this paper, we present a way to mark this emergence: we describe the lexical items with argumentative \u2018ingredients\u2019 \u2014 we call those ingredients topical fields \u2014 on the basis of which the topoi used in each utterance containing those lexical items are constructed, according to what the situation requires. We first reconsider the definition of topos and topical field used in the past; we propose a recursive definition of topical fields, which we then apply to the description of lexicon. We first reconsider the definition of topos and topical field used in the past; we propose a recursive definition of topical fields, which we then apply to the description of lexicon. We then define an operation which allows the transformation of a chain of topoi into a topos. We first reconsider the definition of topos and topical field used in the past; we propose a recursive definition of topical fields, which we then apply to the description of lexicon. We then define an operation which allows the transformation of a chain of topoi into a topos. This definition is used in order to construct the dynamic topoi out of the lexical ones. We first reconsider the definition of topos and topical field used in the past; we propose a recursive definition of topical fields, which we then apply to the description of lexicon. We then define an operation which allows the transformation of a chain of topoi into a topos. This definition is used in order to construct the dynamic topoi out of the lexical ones. Finally, we step back and reflect about the relationship between the conception of language which underlies our work and the structuralist program. Now, if the semantic description could say nothing about those topoi, the study of the argumentative articulators would strictly belong to pragmatics, since it could be achieved only after those topoi have been determined. We defend here a different position: the argumentative description of articulators belongs to semantics; as a consequence, semantics must mark in a certain way the emergence of the topoi used in utterances, even if those topoi belong to the speakers' knowledge and beliefs. In particular, we evaluate the consequences, from a structuralist point of view, of our account of the grounding of language in the world."}, {"paper_id": "145734678", "adju_relevance": 0, "title": "Presupposition Trigger-A Comparative Analysis of Broadcast News Discourse", "background_label": "Presupposition has long been used as a property of language to mold the audience\u2019s ideology. Using presupposition triggers, surprisingly the author or speaker impinges on readers or listeners\u2019 interpretation of facts and events, establishing either a favorable or unfavorable bias throughout the text. The role of presupposition in mass media\u2019s use of language is of paramount importance in that media writers attempt consciously or unconsciously to influence the audience understanding of news events.", "abstract": "Presupposition has long been used as a property of language to mold the audience\u2019s ideology. Presupposition has long been used as a property of language to mold the audience\u2019s ideology. Using presupposition triggers, surprisingly the author or speaker impinges on readers or listeners\u2019 interpretation of facts and events, establishing either a favorable or unfavorable bias throughout the text. Presupposition has long been used as a property of language to mold the audience\u2019s ideology. Using presupposition triggers, surprisingly the author or speaker impinges on readers or listeners\u2019 interpretation of facts and events, establishing either a favorable or unfavorable bias throughout the text. The role of presupposition in mass media\u2019s use of language is of paramount importance in that media writers attempt consciously or unconsciously to influence the audience understanding of news events."}, {"paper_id": "152125453", "adju_relevance": 0, "title": "What Does 'But' Really Mean? -- Evidence from Managers' Answers to Analysts' Questions During Conference Calls", "background_label": "This study examines investors\u2019 reaction to managers\u2019 use of contrastive words (words that introduce corrective and/or unexpected information) during the question and answer (Q&A) sessions of conference calls. We document evidence that managers\u2019 use of contrastive words is an indicator of the quality of their disclosure. Specifically, we find that the use of contrastive words is positively associated with the extent to which investors react to earnings news.", "result_label": "Our findings indicate that managers use contrastive words to provide more value-relevant information to investors. This suggests that there is variation in the informativeness within the disclosure content. Overall, our results support the conjecture that the informativeness of Q&A sessions comes primarily from its explanatory feature.", "method_label": "Further, we shed light on the underexplored contrarian returns phenomenon and show that the use of contrastive words explains some of the instances in which share price reacts positively to unfavorable earnings news. Finally, we separate disclosure content into two sections: before and after the contrastive word \"but\". We find that disclosure reported after the contrastive word \u201cbut\u201d is more informative than disclosure communicated before.", "abstract": "This study examines investors\u2019 reaction to managers\u2019 use of contrastive words (words that introduce corrective and/or unexpected information) during the question and answer (Q&A) sessions of conference calls. This study examines investors\u2019 reaction to managers\u2019 use of contrastive words (words that introduce corrective and/or unexpected information) during the question and answer (Q&A) sessions of conference calls. We document evidence that managers\u2019 use of contrastive words is an indicator of the quality of their disclosure. This study examines investors\u2019 reaction to managers\u2019 use of contrastive words (words that introduce corrective and/or unexpected information) during the question and answer (Q&A) sessions of conference calls. We document evidence that managers\u2019 use of contrastive words is an indicator of the quality of their disclosure. Specifically, we find that the use of contrastive words is positively associated with the extent to which investors react to earnings news. Our findings indicate that managers use contrastive words to provide more value-relevant information to investors. Further, we shed light on the underexplored contrarian returns phenomenon and show that the use of contrastive words explains some of the instances in which share price reacts positively to unfavorable earnings news. Further, we shed light on the underexplored contrarian returns phenomenon and show that the use of contrastive words explains some of the instances in which share price reacts positively to unfavorable earnings news. Finally, we separate disclosure content into two sections: before and after the contrastive word \"but\". Further, we shed light on the underexplored contrarian returns phenomenon and show that the use of contrastive words explains some of the instances in which share price reacts positively to unfavorable earnings news. Finally, we separate disclosure content into two sections: before and after the contrastive word \"but\". We find that disclosure reported after the contrastive word \u201cbut\u201d is more informative than disclosure communicated before. Our findings indicate that managers use contrastive words to provide more value-relevant information to investors. This suggests that there is variation in the informativeness within the disclosure content. Our findings indicate that managers use contrastive words to provide more value-relevant information to investors. This suggests that there is variation in the informativeness within the disclosure content. Overall, our results support the conjecture that the informativeness of Q&A sessions comes primarily from its explanatory feature."}, {"paper_id": "43448265", "adju_relevance": 0, "title": "\"Stop Kremlin trolls: \" Ideological trolling as calling out, rebuttal, and reactions on online news portal commenting", "background_label": "Mainstream media sources have recently heightened public awareness to a phenomenon known as Russian troll farms. This research thematically analyzes \u201cKremlin troll\u201d use and its variations found in user comments on a leading Lithuanian news portal. The main findings of this study indicate that \u201cKremlin troll\u201d was used in two oppositional themes. The first one reveals accusations of paid commentators as \u201cKremlin trolls.\u201d The second, in contrast, counter-argues \u201cKremlin troll\u201d accusations through rebuttal. Sarcasm and humor, e.g.", "method_label": ", by emergence of self-identification as a \u201cKremlin troll\u201d furthermore downplays the \u201cKremlin troll\u201d accusations and reclaims uncertainty of who is the real troll.", "result_label": "Even if the offensive and defensive tactics might seem rather similar to overall Internet troll tactics found in the previous online research, the unique side of \u201cKremlin troll\u201d use was the emergence of ideological trolling, charged with accusations of some commentators being paid by a foreign government, thus referring to \u201cKremlin trolling\u201d as a form of astroturfing. We conclude that \u201cKremlin troll\u201d in this study exemplifies politically charged ideological trolling, rather than the mere subcultural phenomenon that is prevalent in English-language contexts.", "abstract": "Mainstream media sources have recently heightened public awareness to a phenomenon known as Russian troll farms. Mainstream media sources have recently heightened public awareness to a phenomenon known as Russian troll farms. This research thematically analyzes \u201cKremlin troll\u201d use and its variations found in user comments on a leading Lithuanian news portal. Mainstream media sources have recently heightened public awareness to a phenomenon known as Russian troll farms. This research thematically analyzes \u201cKremlin troll\u201d use and its variations found in user comments on a leading Lithuanian news portal. The main findings of this study indicate that \u201cKremlin troll\u201d was used in two oppositional themes. Mainstream media sources have recently heightened public awareness to a phenomenon known as Russian troll farms. This research thematically analyzes \u201cKremlin troll\u201d use and its variations found in user comments on a leading Lithuanian news portal. The main findings of this study indicate that \u201cKremlin troll\u201d was used in two oppositional themes. The first one reveals accusations of paid commentators as \u201cKremlin trolls.\u201d The second, in contrast, counter-argues \u201cKremlin troll\u201d accusations through rebuttal. Mainstream media sources have recently heightened public awareness to a phenomenon known as Russian troll farms. This research thematically analyzes \u201cKremlin troll\u201d use and its variations found in user comments on a leading Lithuanian news portal. The main findings of this study indicate that \u201cKremlin troll\u201d was used in two oppositional themes. The first one reveals accusations of paid commentators as \u201cKremlin trolls.\u201d The second, in contrast, counter-argues \u201cKremlin troll\u201d accusations through rebuttal. Sarcasm and humor, e.g. , by emergence of self-identification as a \u201cKremlin troll\u201d furthermore downplays the \u201cKremlin troll\u201d accusations and reclaims uncertainty of who is the real troll. Even if the offensive and defensive tactics might seem rather similar to overall Internet troll tactics found in the previous online research, the unique side of \u201cKremlin troll\u201d use was the emergence of ideological trolling, charged with accusations of some commentators being paid by a foreign government, thus referring to \u201cKremlin trolling\u201d as a form of astroturfing. Even if the offensive and defensive tactics might seem rather similar to overall Internet troll tactics found in the previous online research, the unique side of \u201cKremlin troll\u201d use was the emergence of ideological trolling, charged with accusations of some commentators being paid by a foreign government, thus referring to \u201cKremlin trolling\u201d as a form of astroturfing. We conclude that \u201cKremlin troll\u201d in this study exemplifies politically charged ideological trolling, rather than the mere subcultural phenomenon that is prevalent in English-language contexts."}, {"paper_id": "198967887", "adju_relevance": 0, "title": "Towards Effective Rebuttal: Listening Comprehension using Corpus-Wide Claim Mining", "background_label": "Engaging in a live debate requires, among other things, the ability to effectively rebut arguments claimed by your opponent. In particular, this requires identifying these arguments.", "abstract": "Engaging in a live debate requires, among other things, the ability to effectively rebut arguments claimed by your opponent. Engaging in a live debate requires, among other things, the ability to effectively rebut arguments claimed by your opponent. In particular, this requires identifying these arguments."}, {"paper_id": "6227816", "adju_relevance": 0, "title": "Estimation of heterogeneous treatment effects from randomized experiments, with application to the optimal planning of the get-out-the-vote campaign", "background_label": "Although a growing number of political scientists are conducting randomized experiments, many of them only report the average treatment effects and do not systematically explore the variation in treatment effects across subpopulations. This is unfortunate from a scientific point of view because heterogeneous treatment effects can provide additional substantive insights. This current state of affairs is also problematic from a policy makers\u2019 perspective since such studies do not identify subgroups for which treatments are effective.", "method_label": "In this paper, we propose a formal two-step framework that first identifies heterogeneous treatment effects from a randomized experiment and then uses this information to derive an optimal policy about which treatment should be given to whom. Our proposed method avoids the risk of false discoveries that are likely in post hoc subgroup analysis routinely conducted in the discipline.", "result_label": "We discuss our methodology in the context of getout-the-vote randomized field experiments and show how the proposed two-step framework can be applied in real-world settings.", "abstract": "Although a growing number of political scientists are conducting randomized experiments, many of them only report the average treatment effects and do not systematically explore the variation in treatment effects across subpopulations. Although a growing number of political scientists are conducting randomized experiments, many of them only report the average treatment effects and do not systematically explore the variation in treatment effects across subpopulations. This is unfortunate from a scientific point of view because heterogeneous treatment effects can provide additional substantive insights. Although a growing number of political scientists are conducting randomized experiments, many of them only report the average treatment effects and do not systematically explore the variation in treatment effects across subpopulations. This is unfortunate from a scientific point of view because heterogeneous treatment effects can provide additional substantive insights. This current state of affairs is also problematic from a policy makers\u2019 perspective since such studies do not identify subgroups for which treatments are effective. In this paper, we propose a formal two-step framework that first identifies heterogeneous treatment effects from a randomized experiment and then uses this information to derive an optimal policy about which treatment should be given to whom. In this paper, we propose a formal two-step framework that first identifies heterogeneous treatment effects from a randomized experiment and then uses this information to derive an optimal policy about which treatment should be given to whom. Our proposed method avoids the risk of false discoveries that are likely in post hoc subgroup analysis routinely conducted in the discipline. We discuss our methodology in the context of getout-the-vote randomized field experiments and show how the proposed two-step framework can be applied in real-world settings."}, {"paper_id": "82456167", "adju_relevance": 0, "title": "Janeway's Immunobiology", "background_label": "Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Dynamics of Adaptive Immunity 11.", "method_label": "The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. Signaling Through Immune System Receptors 7.", "result_label": "The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8.", "abstract": "Part I An Introduction to Immunobiology and Innate Immunity 1. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. The Generation of Lymphocyte Antigen Receptors 5. The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. Signaling Through Immune System Receptors 7. The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Dynamics of Adaptive Immunity 11."}, {"paper_id": "7580918", "adju_relevance": 0, "title": "Tracking Point of View in Narrative", "background_label": "Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Such passages take a character's ``psychological point of view''. A language understander must determine the current psychological point of view in order to distinguish the beliefs of the characters from the facts of the story, to correctly attribute beliefs and other attitudes to their sources, and to understand the discourse relations among sentences. Tracking the psychological point of view is not a trivial problem, because many sentences are not explicitly marked for point of view, and whether the point of view of a sentence is objective or that of a character (and if the latter, which character it is) often depends on the context in which the sentence appears.", "abstract": "Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Such passages take a character's ``psychological point of view''. Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Such passages take a character's ``psychological point of view''. A language understander must determine the current psychological point of view in order to distinguish the beliefs of the characters from the facts of the story, to correctly attribute beliefs and other attitudes to their sources, and to understand the discourse relations among sentences. Third-person fictional narrative text is composed not only of passages that objectively narrate events, but also of passages that present characters' thoughts, perceptions, and inner states. Such passages take a character's ``psychological point of view''. A language understander must determine the current psychological point of view in order to distinguish the beliefs of the characters from the facts of the story, to correctly attribute beliefs and other attitudes to their sources, and to understand the discourse relations among sentences. Tracking the psychological point of view is not a trivial problem, because many sentences are not explicitly marked for point of view, and whether the point of view of a sentence is objective or that of a character (and if the latter, which character it is) often depends on the context in which the sentence appears."}, {"paper_id": "6071630", "adju_relevance": 0, "title": "Decision-Making Under the Gambler's Fallacy: Evidence from Asylum Judges, Loan Officers, and Baseball Umpires*", "background_label": "We find consistent evidence of negative autocorrelation in decision making that is unrelated to the merits of the cases considered in three separate high-stakes field settings: refugee asylum court decisions, loan application reviews, and Major League Baseball umpire pitch calls. The evidence is most consistent with the law of small numbers and the gambler\u2019s fallacy\u2014people underestimating the likelihood of sequential streaks occurring by chance\u2014leading to negatively autocorrelated decisions that result in errors. The negative autocorrelation is stronger among more moderate and less experienced decision makers, following longer streaks of decisions in one direction, when the current and previous cases share similar characteristics or occur close in time, and when decision makers face weaker incentives for accuracy.", "result_label": "Other explanations for negatively autocorrelated decisions such as quotas, learning, or preferences to treat all parties fairly are less consistent with the evidence, though we cannot completely rule out sequential contrast effects as an alternative explanation.", "abstract": "We find consistent evidence of negative autocorrelation in decision making that is unrelated to the merits of the cases considered in three separate high-stakes field settings: refugee asylum court decisions, loan application reviews, and Major League Baseball umpire pitch calls. We find consistent evidence of negative autocorrelation in decision making that is unrelated to the merits of the cases considered in three separate high-stakes field settings: refugee asylum court decisions, loan application reviews, and Major League Baseball umpire pitch calls. The evidence is most consistent with the law of small numbers and the gambler\u2019s fallacy\u2014people underestimating the likelihood of sequential streaks occurring by chance\u2014leading to negatively autocorrelated decisions that result in errors. We find consistent evidence of negative autocorrelation in decision making that is unrelated to the merits of the cases considered in three separate high-stakes field settings: refugee asylum court decisions, loan application reviews, and Major League Baseball umpire pitch calls. The evidence is most consistent with the law of small numbers and the gambler\u2019s fallacy\u2014people underestimating the likelihood of sequential streaks occurring by chance\u2014leading to negatively autocorrelated decisions that result in errors. The negative autocorrelation is stronger among more moderate and less experienced decision makers, following longer streaks of decisions in one direction, when the current and previous cases share similar characteristics or occur close in time, and when decision makers face weaker incentives for accuracy. Other explanations for negatively autocorrelated decisions such as quotas, learning, or preferences to treat all parties fairly are less consistent with the evidence, though we cannot completely rule out sequential contrast effects as an alternative explanation."}, {"paper_id": "36117198", "adju_relevance": 0, "title": "DeepMind_Commentary", "background_label": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy.", "abstract": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy."}, {"paper_id": "154785269", "adju_relevance": 0, "title": "Look who\u2019s talking: Parliamentary debate in the European Union:", "background_label": "Legislative speeches are an important part of parliamentary activity in the European Parliament (EP). Using a new dataset on EP speeches, this paper offers an explanation for participation in legislative debates. We argue that floor speeches partially serve as a communication tool between members of parliament, their national parties, and their European political groups. EP group dissidents often go on record by taking the floor when there is a conflict between their national party and their European political group.", "result_label": "In this instance, members give speeches for two reasons: to explain their national party's position to other members of their EP political group, and to create a positive record for themselves in the eyes of the national party to serve their own reelection purposes.", "abstract": "Legislative speeches are an important part of parliamentary activity in the European Parliament (EP). Legislative speeches are an important part of parliamentary activity in the European Parliament (EP). Using a new dataset on EP speeches, this paper offers an explanation for participation in legislative debates. Legislative speeches are an important part of parliamentary activity in the European Parliament (EP). Using a new dataset on EP speeches, this paper offers an explanation for participation in legislative debates. We argue that floor speeches partially serve as a communication tool between members of parliament, their national parties, and their European political groups. Legislative speeches are an important part of parliamentary activity in the European Parliament (EP). Using a new dataset on EP speeches, this paper offers an explanation for participation in legislative debates. We argue that floor speeches partially serve as a communication tool between members of parliament, their national parties, and their European political groups. EP group dissidents often go on record by taking the floor when there is a conflict between their national party and their European political group. In this instance, members give speeches for two reasons: to explain their national party's position to other members of their EP political group, and to create a positive record for themselves in the eyes of the national party to serve their own reelection purposes."}, {"paper_id": "9574000", "adju_relevance": 0, "title": "Negotiating Lexical Uncertainty and Speaker Expertise with Disjunction", "background_label": "There is a well-known preference for disjunctions XorY to be construed so that X and Y are semantically disjoint. However, there are two felicitous usage patterns in which the speaker violates this preference in part to convey information about the language itself. First, disjunctions of terms in a one-way semantic inclusion relation, such as boat or canoe, can form part of a speaker strategy to manage lexical uncertainty surrounding the two terms, or block unwanted implicatures that the listener might draw from the general term alone. Second, disjunctions of synonymous terms like wine lover or oenophile can be used to convey denitional information.", "method_label": "We explore both of these uses, relying on corpora to obtain a fuller picture of their motivations and their eects on the listener. In addition, we show how both these uses are predicted by a standard semantics for disjunction and a recursive probabilistic model of communication in which speakers and listeners simultaneously exchange information about the world and about the language they are using. We also use the model to begin to formally characterize the pragmatics of implicature cancelation or blocking.", "abstract": "There is a well-known preference for disjunctions XorY to be construed so that X and Y are semantically disjoint. There is a well-known preference for disjunctions XorY to be construed so that X and Y are semantically disjoint. However, there are two felicitous usage patterns in which the speaker violates this preference in part to convey information about the language itself. There is a well-known preference for disjunctions XorY to be construed so that X and Y are semantically disjoint. However, there are two felicitous usage patterns in which the speaker violates this preference in part to convey information about the language itself. First, disjunctions of terms in a one-way semantic inclusion relation, such as boat or canoe, can form part of a speaker strategy to manage lexical uncertainty surrounding the two terms, or block unwanted implicatures that the listener might draw from the general term alone. There is a well-known preference for disjunctions XorY to be construed so that X and Y are semantically disjoint. However, there are two felicitous usage patterns in which the speaker violates this preference in part to convey information about the language itself. First, disjunctions of terms in a one-way semantic inclusion relation, such as boat or canoe, can form part of a speaker strategy to manage lexical uncertainty surrounding the two terms, or block unwanted implicatures that the listener might draw from the general term alone. Second, disjunctions of synonymous terms like wine lover or oenophile can be used to convey denitional information. We explore both of these uses, relying on corpora to obtain a fuller picture of their motivations and their eects on the listener. We explore both of these uses, relying on corpora to obtain a fuller picture of their motivations and their eects on the listener. In addition, we show how both these uses are predicted by a standard semantics for disjunction and a recursive probabilistic model of communication in which speakers and listeners simultaneously exchange information about the world and about the language they are using. We explore both of these uses, relying on corpora to obtain a fuller picture of their motivations and their eects on the listener. In addition, we show how both these uses are predicted by a standard semantics for disjunction and a recursive probabilistic model of communication in which speakers and listeners simultaneously exchange information about the world and about the language they are using. We also use the model to begin to formally characterize the pragmatics of implicature cancelation or blocking."}, {"paper_id": "153935978", "adju_relevance": 0, "title": "To Vote or Not to Vote: The Merits and Limits of Rational Choice Theory", "background_label": "What makes people vote? In addressing this simple question, Andre Blais examines the factors that increase or decrease turnout at the aggregate, cross-national level and considers what affects people's decision to vote or abstain. In doing so, Blais assesses the merits and limitations of the rational choice model in explaining voter behaviour.", "method_label": "The past few decades have witnessed a rise in the popularity of the rational choice model in accounting for voter turnout, and more recently a groundswell of outspoken opposition to rational choice theory. Blais brings together the opposing theories and literatures, and offers tests of these different viewpoints.", "result_label": "Using new data sets from many countries, Blais concludes that while rational choice is an important tool - even when it doesn't work - its empirical contribution to understanding why people vote is quite limited.", "abstract": "What makes people vote? What makes people vote? In addressing this simple question, Andre Blais examines the factors that increase or decrease turnout at the aggregate, cross-national level and considers what affects people's decision to vote or abstain. What makes people vote? In addressing this simple question, Andre Blais examines the factors that increase or decrease turnout at the aggregate, cross-national level and considers what affects people's decision to vote or abstain. In doing so, Blais assesses the merits and limitations of the rational choice model in explaining voter behaviour. The past few decades have witnessed a rise in the popularity of the rational choice model in accounting for voter turnout, and more recently a groundswell of outspoken opposition to rational choice theory. The past few decades have witnessed a rise in the popularity of the rational choice model in accounting for voter turnout, and more recently a groundswell of outspoken opposition to rational choice theory. Blais brings together the opposing theories and literatures, and offers tests of these different viewpoints. Using new data sets from many countries, Blais concludes that while rational choice is an important tool - even when it doesn't work - its empirical contribution to understanding why people vote is quite limited."}, {"paper_id": "1500891", "adju_relevance": 0, "title": "Summarizing Scientific Articles: Experiments With Relevance And Rhetorical Status", "background_label": "In this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: Material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work.", "method_label": "We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. We present several experiments measuring our judges' agreement on these annotations. We also present an algorithm that, on the basis of the annotated training material, selects content from unseen articles and classifies it into a fixed set of seven rhetorical categories.", "result_label": "The output of this extraction and classification system can be viewed as a single-document summary in its own right; alternatively, it provides starting material for the generation of task-oriented and user-tailored summaries designed to give users an overview of a scientific field.", "abstract": "In this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: Material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work. We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. We present several experiments measuring our judges' agreement on these annotations. We provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. We present several experiments measuring our judges' agreement on these annotations. We also present an algorithm that, on the basis of the annotated training material, selects content from unseen articles and classifies it into a fixed set of seven rhetorical categories. The output of this extraction and classification system can be viewed as a single-document summary in its own right; alternatively, it provides starting material for the generation of task-oriented and user-tailored summaries designed to give users an overview of a scientific field."}, {"paper_id": "154143942", "adju_relevance": 0, "title": "To Find or be Forgotten: Global Tensions on the Right toErasure and Internet Governance", "background_label": "The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The judgment caused concern to transparency and open information advocates in terms of pitting a right to forget against the general right of the public to know. This, as this paper will argue, is a false distinction. The Internet is, and has always been, a regulated space. Nor is the right to free expression, even in its American form, absolute. While there are genuine concerns about how the balance is struck, evolving practice is likely to identify what cases deserve deletion, to those that do not.", "result_label": "The biggest challenge lies in how, and who, tests that balance as to what is removed from the search engines of the Internet. Finding material is important but forgetting may be just as vital to liberties as well.", "abstract": "The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The judgment caused concern to transparency and open information advocates in terms of pitting a right to forget against the general right of the public to know. The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The judgment caused concern to transparency and open information advocates in terms of pitting a right to forget against the general right of the public to know. This, as this paper will argue, is a false distinction. The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The judgment caused concern to transparency and open information advocates in terms of pitting a right to forget against the general right of the public to know. This, as this paper will argue, is a false distinction. The Internet is, and has always been, a regulated space. The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The judgment caused concern to transparency and open information advocates in terms of pitting a right to forget against the general right of the public to know. This, as this paper will argue, is a false distinction. The Internet is, and has always been, a regulated space. Nor is the right to free expression, even in its American form, absolute. The decision of the Court of Justice of the European Union (CJEU) in Google Spain v AEPD and Mario Costeja Gonzalez enshrined the \"right to forget\" in the jurisprudence of the European Union. The judgment caused concern to transparency and open information advocates in terms of pitting a right to forget against the general right of the public to know. This, as this paper will argue, is a false distinction. The Internet is, and has always been, a regulated space. Nor is the right to free expression, even in its American form, absolute. While there are genuine concerns about how the balance is struck, evolving practice is likely to identify what cases deserve deletion, to those that do not. The biggest challenge lies in how, and who, tests that balance as to what is removed from the search engines of the Internet. The biggest challenge lies in how, and who, tests that balance as to what is removed from the search engines of the Internet. Finding material is important but forgetting may be just as vital to liberties as well."}, {"paper_id": "153673590", "adju_relevance": 0, "title": "The voter says no, but nobody listens: causes and consequences of the Eurosceptic vote in the 2014 European elections", "background_label": "ABSTRACTThe 2014 European Parliament elections saw an unprecedented surge of support for Eurosceptic parties.", "abstract": "ABSTRACTThe 2014 European Parliament elections saw an unprecedented surge of support for Eurosceptic parties."}, {"paper_id": "3732838", "adju_relevance": 0, "title": "Separating the Shirkers from the Workers? Making Sure Respondents Pay Attention on Self\u2010Administered Surveys", "background_label": "Good survey and experimental research requires subjects to pay attention to questions and treatments, but many subjects do not.", "abstract": "Good survey and experimental research requires subjects to pay attention to questions and treatments, but many subjects do not."}, {"paper_id": "17247053", "adju_relevance": 0, "title": "Re-placing faith: reconsidering the secular-religious use divide in the United States and Kenya", "background_label": "In this paper, we report on design-oriented fieldwork and design research conducted over a six-month period in urban centers in the United States and Kenya.", "abstract": "In this paper, we report on design-oriented fieldwork and design research conducted over a six-month period in urban centers in the United States and Kenya."}, {"paper_id": "822944", "adju_relevance": 0, "title": "Rooting out the Rumor Culprit from Suspects", "background_label": "Suppose that a rumor originating from a single source among a set of suspects spreads in a network, how to root out this rumor source? With the a priori knowledge of suspect nodes and an observation of infected nodes, we construct a maximum a posteriori (MAP) estimator to identify the rumor source using the susceptible-infected (SI) model.", "method_label": "The a priori suspect set and its associated connectivity bring about new ingredients to the problem, and thus we propose to use local rumor center, a generalized concept based on rumor centrality, to identify the source from suspects. For regular tree-type networks of node degree {\\delta}, we characterize Pc(n), the correct detection probability of the estimator upon observing n infected nodes, in both the finite and asymptotic regimes. First, when every infected node is a suspect, Pc(n) asymptotically grows from 0.25 to 0.307 with {\\delta} from 3 to infinity, a result first established in Shah and Zaman (2011, 2012) via a different approach; and it monotonically decreases with n and increases with {\\delta}. Second, when the suspects form a connected subgraph of the network, Pc(n) asymptotically significantly exceeds the a priori probability if {\\delta}>2, and reliable detection is achieved as {\\delta} becomes large; furthermore, it monotonically decreases with n and increases with {\\delta}.", "result_label": "Third, when there are only two suspects, Pc(n) is asymptotically at least 0.75 if {\\delta}>2; and it increases with the distance between the two suspects. Fourth, when there are multiple suspects, among all possible connection patterns, that they form a connected subgraph of the network achieves the smallest detection probability. Our analysis leverages ideas from the Polya's urn model in probability theory and sheds insight into the behavior of the rumor spreading process not only in the asymptotic regime but also for the general finite-n regime.", "abstract": "Suppose that a rumor originating from a single source among a set of suspects spreads in a network, how to root out this rumor source? Suppose that a rumor originating from a single source among a set of suspects spreads in a network, how to root out this rumor source? With the a priori knowledge of suspect nodes and an observation of infected nodes, we construct a maximum a posteriori (MAP) estimator to identify the rumor source using the susceptible-infected (SI) model. The a priori suspect set and its associated connectivity bring about new ingredients to the problem, and thus we propose to use local rumor center, a generalized concept based on rumor centrality, to identify the source from suspects. The a priori suspect set and its associated connectivity bring about new ingredients to the problem, and thus we propose to use local rumor center, a generalized concept based on rumor centrality, to identify the source from suspects. For regular tree-type networks of node degree {\\delta}, we characterize Pc(n), the correct detection probability of the estimator upon observing n infected nodes, in both the finite and asymptotic regimes. The a priori suspect set and its associated connectivity bring about new ingredients to the problem, and thus we propose to use local rumor center, a generalized concept based on rumor centrality, to identify the source from suspects. For regular tree-type networks of node degree {\\delta}, we characterize Pc(n), the correct detection probability of the estimator upon observing n infected nodes, in both the finite and asymptotic regimes. First, when every infected node is a suspect, Pc(n) asymptotically grows from 0.25 to 0.307 with {\\delta} from 3 to infinity, a result first established in Shah and Zaman (2011, 2012) via a different approach; and it monotonically decreases with n and increases with {\\delta}. The a priori suspect set and its associated connectivity bring about new ingredients to the problem, and thus we propose to use local rumor center, a generalized concept based on rumor centrality, to identify the source from suspects. For regular tree-type networks of node degree {\\delta}, we characterize Pc(n), the correct detection probability of the estimator upon observing n infected nodes, in both the finite and asymptotic regimes. First, when every infected node is a suspect, Pc(n) asymptotically grows from 0.25 to 0.307 with {\\delta} from 3 to infinity, a result first established in Shah and Zaman (2011, 2012) via a different approach; and it monotonically decreases with n and increases with {\\delta}. Second, when the suspects form a connected subgraph of the network, Pc(n) asymptotically significantly exceeds the a priori probability if {\\delta}>2, and reliable detection is achieved as {\\delta} becomes large; furthermore, it monotonically decreases with n and increases with {\\delta}. Third, when there are only two suspects, Pc(n) is asymptotically at least 0.75 if {\\delta}>2; and it increases with the distance between the two suspects. Third, when there are only two suspects, Pc(n) is asymptotically at least 0.75 if {\\delta}>2; and it increases with the distance between the two suspects. Fourth, when there are multiple suspects, among all possible connection patterns, that they form a connected subgraph of the network achieves the smallest detection probability. Third, when there are only two suspects, Pc(n) is asymptotically at least 0.75 if {\\delta}>2; and it increases with the distance between the two suspects. Fourth, when there are multiple suspects, among all possible connection patterns, that they form a connected subgraph of the network achieves the smallest detection probability. Our analysis leverages ideas from the Polya's urn model in probability theory and sheds insight into the behavior of the rumor spreading process not only in the asymptotic regime but also for the general finite-n regime."}, {"paper_id": "5551792", "adju_relevance": 0, "title": "Multidimensional text analysis for eRulemaking", "background_label": "To support rule-writers, we are developing techniques to automatically analyze large number of public comments on proposed regulations.", "method_label": "A document is analyzed in various ways including argument structure, topics, and opinions. The individual results are integrated into a unified output.", "result_label": "The experiments reported here were performed on comments submitted to the Environmental Protection Agency in response to their proposed rule for mercury regulation.", "abstract": "To support rule-writers, we are developing techniques to automatically analyze large number of public comments on proposed regulations. A document is analyzed in various ways including argument structure, topics, and opinions. A document is analyzed in various ways including argument structure, topics, and opinions. The individual results are integrated into a unified output. The experiments reported here were performed on comments submitted to the Environmental Protection Agency in response to their proposed rule for mercury regulation."}, {"paper_id": "152361897", "adju_relevance": 0, "title": "PATTERNS OF CONGRESSIONAL VOTING", "background_label": "Congressional roll call voting has been highly structured for most of U.S. history. The structure is revealed by a dynamic, spatial analysis of the entire roll call voting record from 1789 to 1985. The space is characterized by a predominant major dimension with, at times, a significant, but less important second dimension. In the modern era, spatial positions are very stable. This stability is such that, under certain conditions, short run forecasting of roll call votes is possible.", "result_label": "Since the end of World War II, changes in congressional voting patterns have occurred almost entirely through the process of replacement of retiring or defeated legislators with new members. Politically, selection is far more important than adaptation.", "abstract": "Congressional roll call voting has been highly structured for most of U.S. history. Congressional roll call voting has been highly structured for most of U.S. history. The structure is revealed by a dynamic, spatial analysis of the entire roll call voting record from 1789 to 1985. Congressional roll call voting has been highly structured for most of U.S. history. The structure is revealed by a dynamic, spatial analysis of the entire roll call voting record from 1789 to 1985. The space is characterized by a predominant major dimension with, at times, a significant, but less important second dimension. Congressional roll call voting has been highly structured for most of U.S. history. The structure is revealed by a dynamic, spatial analysis of the entire roll call voting record from 1789 to 1985. The space is characterized by a predominant major dimension with, at times, a significant, but less important second dimension. In the modern era, spatial positions are very stable. Congressional roll call voting has been highly structured for most of U.S. history. The structure is revealed by a dynamic, spatial analysis of the entire roll call voting record from 1789 to 1985. The space is characterized by a predominant major dimension with, at times, a significant, but less important second dimension. In the modern era, spatial positions are very stable. This stability is such that, under certain conditions, short run forecasting of roll call votes is possible. Since the end of World War II, changes in congressional voting patterns have occurred almost entirely through the process of replacement of retiring or defeated legislators with new members. Since the end of World War II, changes in congressional voting patterns have occurred almost entirely through the process of replacement of retiring or defeated legislators with new members. Politically, selection is far more important than adaptation."}, {"paper_id": "12981628", "adju_relevance": 0, "title": "WITP Classifying Party Affiliation from Political Speech", "method_label": "We then examine these party classifiers' person-dependency and time-dependency.", "result_label": "We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. The classifiers trained on 2005 House speeches performed better on Senate speeches from recent years than on older ones, which indicates the classifiers' time-dependency. This dependency may be caused by changes in the issue agenda or the ideological composition of Congress.", "abstract": " We then examine these party classifiers' person-dependency and time-dependency. We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. The classifiers trained on 2005 House speeches performed better on Senate speeches from recent years than on older ones, which indicates the classifiers' time-dependency. We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. The classifiers trained on 2005 House speeches performed better on Senate speeches from recent years than on older ones, which indicates the classifiers' time-dependency. This dependency may be caused by changes in the issue agenda or the ideological composition of Congress."}, {"paper_id": "388", "adju_relevance": 0, "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts", "background_label": "Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as\"thumbs up\"or\"thumbs down\".", "method_label": "To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints.", "abstract": "Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as\"thumbs up\"or\"thumbs down\". To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints."}, {"paper_id": "202660874", "adju_relevance": 0, "title": "What matters, context or sentiment?: Analysing the influence of news in U.S. elections using Natural Language Processing", "background_label": "A key question in the analysis of collective social behaviour is related to know if and how mass media can influence public opinion.", "abstract": "A key question in the analysis of collective social behaviour is related to know if and how mass media can influence public opinion."}, {"paper_id": "144510790", "adju_relevance": 0, "title": "Ideational and pragmatic markers of discourse structure", "background_label": "Abstract This paper presents an integrative approach to the study of discourse coherence which follows the observation of Buhler (1934) and others that language use always involves both the representation of propositional content and the expression of attitudes and intentions. Consideration of only one of these functions is shown to be insufficient for an adequate account of discourse coherence. Coherence is regarded as arising from semantic relations between the ideas states and pragmatic relations between the actions performed in speaking or writing.", "method_label": "Empirical evidence for this view is provided by the use of pragmatic and ideational structuring devices in film descriptions. Speakers who were describing a film to a friend used more markers of pragmatic structure than those whose listener was a stranger. At the same time, they were less explicit in indicating the ideational structure of their discourse.", "result_label": "This trade-off between pragmatic and ideational structuring occurred not only in dialogues (two-way auditory channel where the friends gave more feedback, but also in monologues (one-way channel), where the two conditions differed only in the speaker's knowledge that the listener was a friend or a stranger.", "abstract": "Abstract This paper presents an integrative approach to the study of discourse coherence which follows the observation of Buhler (1934) and others that language use always involves both the representation of propositional content and the expression of attitudes and intentions. Abstract This paper presents an integrative approach to the study of discourse coherence which follows the observation of Buhler (1934) and others that language use always involves both the representation of propositional content and the expression of attitudes and intentions. Consideration of only one of these functions is shown to be insufficient for an adequate account of discourse coherence. Abstract This paper presents an integrative approach to the study of discourse coherence which follows the observation of Buhler (1934) and others that language use always involves both the representation of propositional content and the expression of attitudes and intentions. Consideration of only one of these functions is shown to be insufficient for an adequate account of discourse coherence. Coherence is regarded as arising from semantic relations between the ideas states and pragmatic relations between the actions performed in speaking or writing. Empirical evidence for this view is provided by the use of pragmatic and ideational structuring devices in film descriptions. Empirical evidence for this view is provided by the use of pragmatic and ideational structuring devices in film descriptions. Speakers who were describing a film to a friend used more markers of pragmatic structure than those whose listener was a stranger. Empirical evidence for this view is provided by the use of pragmatic and ideational structuring devices in film descriptions. Speakers who were describing a film to a friend used more markers of pragmatic structure than those whose listener was a stranger. At the same time, they were less explicit in indicating the ideational structure of their discourse. This trade-off between pragmatic and ideational structuring occurred not only in dialogues (two-way auditory channel where the friends gave more feedback, but also in monologues (one-way channel), where the two conditions differed only in the speaker's knowledge that the listener was a friend or a stranger."}, {"paper_id": "4722714", "adju_relevance": 0, "title": "Opposition Based ElectromagnetismLike for Global Optimization", "background_label": "Electromagnetismlike Optimization (EMO) is a global optimization algorithm, particularly well suited to solve problems featuring nonlinear and multimodal cost functions. EMO employs searcher agents that emulate a population of charged particles which interact to each other according to electromagnetisms laws of attraction and repulsion. However, EMO usually requires a large number of iterations for a local search procedure; any reduction or cancelling over such number, critically perturb other issues such as convergence, exploration, population diversity and accuracy.", "method_label": "This paper presents an enhanced EMO algorithm called OBEMO, which employs the Opposition-Based Learning (OBL) approach to accelerate the global convergence speed. OBL is a machine intelligence strategy which considers the current candidate solution and its opposite value at the same time, achieving a faster exploration of the search space. The proposed OBEMO method significantly reduces the required computational effort yet avoiding any detriment to the good search capabilities of the original EMO algorithm.", "result_label": "Experiments are conducted over a comprehensive set of benchmark functions, showing that OBEMO obtains promising performance for most of the discussed test problems.", "abstract": "Electromagnetismlike Optimization (EMO) is a global optimization algorithm, particularly well suited to solve problems featuring nonlinear and multimodal cost functions. Electromagnetismlike Optimization (EMO) is a global optimization algorithm, particularly well suited to solve problems featuring nonlinear and multimodal cost functions. EMO employs searcher agents that emulate a population of charged particles which interact to each other according to electromagnetisms laws of attraction and repulsion. Electromagnetismlike Optimization (EMO) is a global optimization algorithm, particularly well suited to solve problems featuring nonlinear and multimodal cost functions. EMO employs searcher agents that emulate a population of charged particles which interact to each other according to electromagnetisms laws of attraction and repulsion. However, EMO usually requires a large number of iterations for a local search procedure; any reduction or cancelling over such number, critically perturb other issues such as convergence, exploration, population diversity and accuracy. This paper presents an enhanced EMO algorithm called OBEMO, which employs the Opposition-Based Learning (OBL) approach to accelerate the global convergence speed. This paper presents an enhanced EMO algorithm called OBEMO, which employs the Opposition-Based Learning (OBL) approach to accelerate the global convergence speed. OBL is a machine intelligence strategy which considers the current candidate solution and its opposite value at the same time, achieving a faster exploration of the search space. This paper presents an enhanced EMO algorithm called OBEMO, which employs the Opposition-Based Learning (OBL) approach to accelerate the global convergence speed. OBL is a machine intelligence strategy which considers the current candidate solution and its opposite value at the same time, achieving a faster exploration of the search space. The proposed OBEMO method significantly reduces the required computational effort yet avoiding any detriment to the good search capabilities of the original EMO algorithm. Experiments are conducted over a comprehensive set of benchmark functions, showing that OBEMO obtains promising performance for most of the discussed test problems."}, {"paper_id": "154639895", "adju_relevance": 0, "title": "Who Takes the Parliamentary Floor? The Role of Gender in Speech-making in the Swedish Riksdag:", "background_label": "Legislative speeches are an important instrument for parties and members of parliament (MPs) to signal their positions and priorities. This raises the question of who speaks when.", "abstract": "Legislative speeches are an important instrument for parties and members of parliament (MPs) to signal their positions and priorities. Legislative speeches are an important instrument for parties and members of parliament (MPs) to signal their positions and priorities. This raises the question of who speaks when."}, {"paper_id": "144941034", "adju_relevance": 0, "title": "A novel experimental paradigm for distinguishing between what is said and what is implicated", "background_label": "That there is a theoretical distinction between context-dependent and context-independent aspects of utterance interpretation has become a standard assumption in current theories of meaning; however, how and where to draw this distinction has been the subject of considerable debate.", "abstract": "That there is a theoretical distinction between context-dependent and context-independent aspects of utterance interpretation has become a standard assumption in current theories of meaning; however, how and where to draw this distinction has been the subject of considerable debate."}, {"paper_id": "59606304", "adju_relevance": 0, "title": "Assessing Partisan Traits of News Text Attributions", "background_label": "On the topic of journalistic integrity, the current state of accurate, impartial news reporting has garnered much debate in context to the 2016 US Presidential Election. In pursuit of computational evaluation of news text, the statements (attributions) ascribed by media outlets to sources provide a common category of evidence on which to operate.", "method_label": "In this paper, we develop an approach to compare partisan traits of news text attributions and apply it to characterize differences in statements ascribed to candidate, Hilary Clinton, and incumbent President, Donald Trump. In doing so, we present a model trained on over 600 in-house annotated attributions to identify each candidate with accuracy>88%.", "result_label": "Finally, we discuss insights from its performance for future research.", "abstract": "On the topic of journalistic integrity, the current state of accurate, impartial news reporting has garnered much debate in context to the 2016 US Presidential Election. On the topic of journalistic integrity, the current state of accurate, impartial news reporting has garnered much debate in context to the 2016 US Presidential Election. In pursuit of computational evaluation of news text, the statements (attributions) ascribed by media outlets to sources provide a common category of evidence on which to operate. In this paper, we develop an approach to compare partisan traits of news text attributions and apply it to characterize differences in statements ascribed to candidate, Hilary Clinton, and incumbent President, Donald Trump. In this paper, we develop an approach to compare partisan traits of news text attributions and apply it to characterize differences in statements ascribed to candidate, Hilary Clinton, and incumbent President, Donald Trump. In doing so, we present a model trained on over 600 in-house annotated attributions to identify each candidate with accuracy>88%. Finally, we discuss insights from its performance for future research."}, {"paper_id": "149203063", "adju_relevance": 0, "title": "\u2018Lyin' Ted\u2019, \u2018Crooked Hillary\u2019, and \u2018Deceptive Donald\u2019: Language of Lies in the 2016 US Presidential Debates", "background_label": "Summary  Language in the high-stakes 2016 US presidential primary campaign was contentious, filled with name-calling, personal attacks, and insults. Language in debates served at least three political functions: for image making, to imagine potential realities currently not in practice, and to disavow facts. In past research, the reality monitoring (RM) framework has discriminated accurately between truthful and deceptive accounts (~70% classification). Truthful accounts show greater sensory, time and space, and affective information, with little evidence of cognitive operations.", "method_label": "An RM algorithm was used with Linguistic Inquiry and Word Count software to code candidates' language.", "result_label": "RM scores were significantly higher in fact-checked truth statements than in lies, and debate language in the 2016 primaries was as deceptive as fact-checked lies.", "abstract": "Summary  Language in the high-stakes 2016 US presidential primary campaign was contentious, filled with name-calling, personal attacks, and insults. Summary  Language in the high-stakes 2016 US presidential primary campaign was contentious, filled with name-calling, personal attacks, and insults. Language in debates served at least three political functions: for image making, to imagine potential realities currently not in practice, and to disavow facts. Summary  Language in the high-stakes 2016 US presidential primary campaign was contentious, filled with name-calling, personal attacks, and insults. Language in debates served at least three political functions: for image making, to imagine potential realities currently not in practice, and to disavow facts. In past research, the reality monitoring (RM) framework has discriminated accurately between truthful and deceptive accounts (~70% classification). Summary  Language in the high-stakes 2016 US presidential primary campaign was contentious, filled with name-calling, personal attacks, and insults. Language in debates served at least three political functions: for image making, to imagine potential realities currently not in practice, and to disavow facts. In past research, the reality monitoring (RM) framework has discriminated accurately between truthful and deceptive accounts (~70% classification). Truthful accounts show greater sensory, time and space, and affective information, with little evidence of cognitive operations. An RM algorithm was used with Linguistic Inquiry and Word Count software to code candidates' language. RM scores were significantly higher in fact-checked truth statements than in lies, and debate language in the 2016 primaries was as deceptive as fact-checked lies."}, {"paper_id": "51778818", "adju_relevance": 0, "title": "Advancing E-Government at the Grassroots: Tortoise or Hare?", "background_label": "American grassroots governments have rushed to join the e-government revolution. Although there is a growing body of e-government literature, little of it is empirical.", "method_label": "Using data from two nationwide surveys, we conduct a longitudinal examination of local government adoption of e-government, Web site sophistication, the perceived impacts of e-government, and barriers to the adoption and sophistication of e-government. We also discuss correlates of e-government adoption and sophistication with selected institutional factors.", "result_label": "We find that e-government adoption at the grassroots is progressing rapidly (if measured solely by deployment of Web sites). However, the movement toward integrated and transactional e-government is progressing much more slowly. Continuing research, particularly longitudinal study, is needed to monitor the evolution of e-government among U.S. local governments, especially to keep pace with the practice and to ascertain the actual impacts of e-government.", "abstract": "American grassroots governments have rushed to join the e-government revolution. American grassroots governments have rushed to join the e-government revolution. Although there is a growing body of e-government literature, little of it is empirical. Using data from two nationwide surveys, we conduct a longitudinal examination of local government adoption of e-government, Web site sophistication, the perceived impacts of e-government, and barriers to the adoption and sophistication of e-government. Using data from two nationwide surveys, we conduct a longitudinal examination of local government adoption of e-government, Web site sophistication, the perceived impacts of e-government, and barriers to the adoption and sophistication of e-government. We also discuss correlates of e-government adoption and sophistication with selected institutional factors. We find that e-government adoption at the grassroots is progressing rapidly (if measured solely by deployment of Web sites). We find that e-government adoption at the grassroots is progressing rapidly (if measured solely by deployment of Web sites). However, the movement toward integrated and transactional e-government is progressing much more slowly. We find that e-government adoption at the grassroots is progressing rapidly (if measured solely by deployment of Web sites). However, the movement toward integrated and transactional e-government is progressing much more slowly. Continuing research, particularly longitudinal study, is needed to monitor the evolution of e-government among U.S. local governments, especially to keep pace with the practice and to ascertain the actual impacts of e-government."}]