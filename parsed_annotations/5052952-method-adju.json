[{"paper_id": "5052952", "title": "Veracity Computing from Lexical Cues and Perceived Certainty Trends", "background_label": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data.", "method_label": "Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources.", "result_label": "Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false.", "abstract": "We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false."}, {"paper_id": "17025981", "adju_relevance": 2, "title": "Detect Rumors Using Time Series of Social Context Information on Microblogging Websites", "background_label": "Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Most of existing work for rumor detection focuses on modeling features related to microblog contents, users and propagation patterns, but ignore the importance of the variation of these social context features during the message propagation over time.", "method_label": "In this study, we propose a novel approach to capture the temporal characteristics of these features based on the time series of rumor's lifecycle, for which time series modeling technique is applied to incorporate various social context information.", "result_label": "Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-art rumor detection approaches by large margins. Moreover, our model demonstrates strong performance on detecting rumors at early stage after their initial broadcast.", "abstract": "Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Automatically identifying rumors from online social media especially microblogging websites is an important research issue. Most of existing work for rumor detection focuses on modeling features related to microblog contents, users and propagation patterns, but ignore the importance of the variation of these social context features during the message propagation over time. In this study, we propose a novel approach to capture the temporal characteristics of these features based on the time series of rumor's lifecycle, for which time series modeling technique is applied to incorporate various social context information. Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-art rumor detection approaches by large margins. Our experiments using the events in two microblog datasets confirm that the method outperforms state-of-the-art rumor detection approaches by large margins. Moreover, our model demonstrates strong performance on detecting rumors at early stage after their initial broadcast."}, {"paper_id": "27134425", "adju_relevance": 2, "title": "A Temporal Attentional Model for Rumor Stance Classification", "background_label": "Rumor stance classification is the task of determining the stance towards a rumor in text. This is the first step in effective rumor tracking on social media which is an increasingly important task.", "abstract": "Rumor stance classification is the task of determining the stance towards a rumor in text. Rumor stance classification is the task of determining the stance towards a rumor in text. This is the first step in effective rumor tracking on social media which is an increasingly important task."}, {"paper_id": "14124213", "adju_relevance": 1, "title": "Rumor has it: Identifying Misinformation in Microblogs", "background_label": "AbstractA rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority.", "method_label": "In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP).", "result_label": "Finally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations.", "abstract": "AbstractA rumor is commonly defined as a statement whose true value is unverifiable. AbstractA rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. AbstractA rumor is commonly defined as a statement whose true value is unverifiable. Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people. Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors. Moreover, we show how these features are also effective in identifying disinformers, users who endorse a rumor and further help it to spread. We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP). Finally, we believe that our dataset is the first large-scale dataset on rumor detection. Finally, we believe that our dataset is the first large-scale dataset on rumor detection. It can open new dimensions in analyzing online misinformation and other aspects of microblog conversations."}, {"paper_id": "3821227", "adju_relevance": 1, "title": "Rumor Gauge: Predicting the Veracity of Rumors on Twitter", "background_label": "The spread of malicious or accidental misinformation in social media, especially in time-sensitive situations, such as real-world emergencies, can have harmful effects on individuals and society. In this work, we developed models for automated verification of rumors (unverified information) that propagate through Twitter.", "method_label": "To predict the veracity of rumors, we identified salient features of rumors by examining three aspects of information spread: linguistic style used to express rumors, characteristics of people involved in propagating information, and network propagation dynamics. The predicted veracity of a time series of these features extracted from a rumor (a collection of tweets) is generated using Hidden Markov Models. The verification algorithm was trained and tested on 209 rumors representing 938,806 tweets collected from real-world events, including the 2013 Boston Marathon bombings, the 2014 Ferguson unrest, and the 2014 Ebola epidemic, and many other rumors about various real-world events reported on popular websites that document public rumors.", "result_label": "The algorithm was able to correctly predict the veracity of 75% of the rumors faster than any other public source, including journalists and law enforcement officials. The ability to track rumors and predict their outcomes may have practical applications for news consumers, financial markets, journalists, and emergency services, and more generally to help minimize the impact of false information on Twitter.", "abstract": "The spread of malicious or accidental misinformation in social media, especially in time-sensitive situations, such as real-world emergencies, can have harmful effects on individuals and society. The spread of malicious or accidental misinformation in social media, especially in time-sensitive situations, such as real-world emergencies, can have harmful effects on individuals and society. In this work, we developed models for automated verification of rumors (unverified information) that propagate through Twitter. To predict the veracity of rumors, we identified salient features of rumors by examining three aspects of information spread: linguistic style used to express rumors, characteristics of people involved in propagating information, and network propagation dynamics. To predict the veracity of rumors, we identified salient features of rumors by examining three aspects of information spread: linguistic style used to express rumors, characteristics of people involved in propagating information, and network propagation dynamics. The predicted veracity of a time series of these features extracted from a rumor (a collection of tweets) is generated using Hidden Markov Models. To predict the veracity of rumors, we identified salient features of rumors by examining three aspects of information spread: linguistic style used to express rumors, characteristics of people involved in propagating information, and network propagation dynamics. The predicted veracity of a time series of these features extracted from a rumor (a collection of tweets) is generated using Hidden Markov Models. The verification algorithm was trained and tested on 209 rumors representing 938,806 tweets collected from real-world events, including the 2013 Boston Marathon bombings, the 2014 Ferguson unrest, and the 2014 Ebola epidemic, and many other rumors about various real-world events reported on popular websites that document public rumors. The algorithm was able to correctly predict the veracity of 75% of the rumors faster than any other public source, including journalists and law enforcement officials. The algorithm was able to correctly predict the veracity of 75% of the rumors faster than any other public source, including journalists and law enforcement officials. The ability to track rumors and predict their outcomes may have practical applications for news consumers, financial markets, journalists, and emergency services, and more generally to help minimize the impact of false information on Twitter."}, {"paper_id": "1434196", "adju_relevance": 1, "title": "Emergent: a novel data-set for stance classification", "background_label": "We present Emergent, a novel data-set derived from a digital journalism project for rumour debunking. The data-set contains 300 rumoured claims and 2,595 associated news articles, collected and labelled by journalists with an estimation of their veracity (true, false or unverified).", "method_label": "Each associated article is summarized into a headline and labelled to indicate whether its stance is for, against, or observing the claim, where observing indicates that the article merely repeats the claim. Thus, Emergent provides a real-world data source for a variety of natural language processing tasks in the context of fact-checking. Further to presenting the dataset, we address the task of determining the article headline stance with respect to the claim. For this purpose we use a logistic regression classifier and develop features that examine the headline and its agreement with the claim.", "result_label": "The accuracy achieved was 73% which is 26% higher than the one achieved by the Excitement Open Platform (Magnini et al., 2014).", "abstract": "We present Emergent, a novel data-set derived from a digital journalism project for rumour debunking. We present Emergent, a novel data-set derived from a digital journalism project for rumour debunking. The data-set contains 300 rumoured claims and 2,595 associated news articles, collected and labelled by journalists with an estimation of their veracity (true, false or unverified). Each associated article is summarized into a headline and labelled to indicate whether its stance is for, against, or observing the claim, where observing indicates that the article merely repeats the claim. Each associated article is summarized into a headline and labelled to indicate whether its stance is for, against, or observing the claim, where observing indicates that the article merely repeats the claim. Thus, Emergent provides a real-world data source for a variety of natural language processing tasks in the context of fact-checking. Each associated article is summarized into a headline and labelled to indicate whether its stance is for, against, or observing the claim, where observing indicates that the article merely repeats the claim. Thus, Emergent provides a real-world data source for a variety of natural language processing tasks in the context of fact-checking. Further to presenting the dataset, we address the task of determining the article headline stance with respect to the claim. Each associated article is summarized into a headline and labelled to indicate whether its stance is for, against, or observing the claim, where observing indicates that the article merely repeats the claim. Thus, Emergent provides a real-world data source for a variety of natural language processing tasks in the context of fact-checking. Further to presenting the dataset, we address the task of determining the article headline stance with respect to the claim. For this purpose we use a logistic regression classifier and develop features that examine the headline and its agreement with the claim. The accuracy achieved was 73% which is 26% higher than the one achieved by the Excitement Open Platform (Magnini et al., 2014)."}, {"paper_id": "16263275", "adju_relevance": 1, "title": "Predicting webpage credibility using linguistic features", "background_label": "The article focuses on predicting trustworthiness from textual content of webpages. The recent work Olteanu et al.", "abstract": "The article focuses on predicting trustworthiness from textual content of webpages. The article focuses on predicting trustworthiness from textual content of webpages. The recent work Olteanu et al."}, {"paper_id": "9109277", "adju_relevance": 1, "title": "On Early-stage Debunking Rumors on Twitter: Leveraging the Wisdom of Weak Learners", "background_label": "Recently a lot of progress has been made in rumor modeling and rumor detection for micro-blogging streams. However, existing automated methods do not perform very well for early rumor detection, which is crucial in many settings, e.g., in crisis situations. One reason for this is that aggregated rumor features such as propagation features, which work well on the long run, are - due to their accumulating characteristic - not very helpful in the early phase of a rumor.", "method_label": "In this work, we present an approach for early rumor detection, which leverages Convolutional Neural Networks for learning the hidden representations of individual rumor-related tweets to gain insights on the credibility of each tweets. We then aggregate the predictions from the very beginning of a rumor to obtain the overall event credits (so-called wisdom), and finally combine it with a time series based rumor classification model.", "result_label": "Our extensive experiments show a clearly improved classification performance within the critical very first hours of a rumor. For a better understanding, we also conduct an extensive feature evaluation that emphasized on the early stage and shows that the low-level credibility has best predictability at all phases of the rumor lifetime.", "abstract": "Recently a lot of progress has been made in rumor modeling and rumor detection for micro-blogging streams. Recently a lot of progress has been made in rumor modeling and rumor detection for micro-blogging streams. However, existing automated methods do not perform very well for early rumor detection, which is crucial in many settings, e.g., in crisis situations. Recently a lot of progress has been made in rumor modeling and rumor detection for micro-blogging streams. However, existing automated methods do not perform very well for early rumor detection, which is crucial in many settings, e.g., in crisis situations. One reason for this is that aggregated rumor features such as propagation features, which work well on the long run, are - due to their accumulating characteristic - not very helpful in the early phase of a rumor. In this work, we present an approach for early rumor detection, which leverages Convolutional Neural Networks for learning the hidden representations of individual rumor-related tweets to gain insights on the credibility of each tweets. In this work, we present an approach for early rumor detection, which leverages Convolutional Neural Networks for learning the hidden representations of individual rumor-related tweets to gain insights on the credibility of each tweets. We then aggregate the predictions from the very beginning of a rumor to obtain the overall event credits (so-called wisdom), and finally combine it with a time series based rumor classification model. Our extensive experiments show a clearly improved classification performance within the critical very first hours of a rumor. Our extensive experiments show a clearly improved classification performance within the critical very first hours of a rumor. For a better understanding, we also conduct an extensive feature evaluation that emphasized on the early stage and shows that the low-level credibility has best predictability at all phases of the rumor lifetime."}, {"paper_id": "2683954", "adju_relevance": 1, "title": "A Compositional Interpretation of Biomedical Event Factuality", "method_label": "We propose a compositional method to assess the factuality of biomedical events extracted from the literature. The composition procedure relies on the notion of semantic embedding and a fine-grained classification of extrapropositional phenomena, including modality and valence shifting, and a dictionary based on this classification. The event factuality is computed as a product of the extra-propositional operators that have scope over the event. We evaluate our approach on the GENIA event corpus enriched with certainty level and polarity annotations.", "result_label": "The results indicate that our approach is effective in identifying the certainty level component of factuality and is less successful in recognizing the other element, negative polarity.", "abstract": "We propose a compositional method to assess the factuality of biomedical events extracted from the literature. We propose a compositional method to assess the factuality of biomedical events extracted from the literature. The composition procedure relies on the notion of semantic embedding and a fine-grained classification of extrapropositional phenomena, including modality and valence shifting, and a dictionary based on this classification. We propose a compositional method to assess the factuality of biomedical events extracted from the literature. The composition procedure relies on the notion of semantic embedding and a fine-grained classification of extrapropositional phenomena, including modality and valence shifting, and a dictionary based on this classification. The event factuality is computed as a product of the extra-propositional operators that have scope over the event. We propose a compositional method to assess the factuality of biomedical events extracted from the literature. The composition procedure relies on the notion of semantic embedding and a fine-grained classification of extrapropositional phenomena, including modality and valence shifting, and a dictionary based on this classification. The event factuality is computed as a product of the extra-propositional operators that have scope over the event. We evaluate our approach on the GENIA event corpus enriched with certainty level and polarity annotations. The results indicate that our approach is effective in identifying the certainty level component of factuality and is less successful in recognizing the other element, negative polarity."}, {"paper_id": "12954317", "adju_relevance": 1, "title": "Language-Independent Sentiment Analysis Using Subjectivity and Positional Information", "background_label": "AbstractWe describe a novel language-independent approach to the task of determining the polarity, positive or negative, of the author's opinion on a specific topic in natural language text.", "method_label": "In particular, weights are assigned to attributes, individual words or word bi-grams, based on their position and on their likelihood of being subjective. The subjectivity of each attribute is estimated in a two-step process, where first the probability of being subjective is calculated for each sentence containing the attribute, and then these probabilities are used to alter the attribute's weights for polarity classification.", "result_label": "The evaluation results on a standard dataset of movie reviews shows 89.85% classification accuracy, which rivals the best previously published results for this dataset for systems that use no additional linguistic information nor external resources.", "abstract": "AbstractWe describe a novel language-independent approach to the task of determining the polarity, positive or negative, of the author's opinion on a specific topic in natural language text. In particular, weights are assigned to attributes, individual words or word bi-grams, based on their position and on their likelihood of being subjective. In particular, weights are assigned to attributes, individual words or word bi-grams, based on their position and on their likelihood of being subjective. The subjectivity of each attribute is estimated in a two-step process, where first the probability of being subjective is calculated for each sentence containing the attribute, and then these probabilities are used to alter the attribute's weights for polarity classification. The evaluation results on a standard dataset of movie reviews shows 89.85% classification accuracy, which rivals the best previously published results for this dataset for systems that use no additional linguistic information nor external resources."}, {"paper_id": "18989838", "adju_relevance": 1, "title": "Using Gaussian Processes for Rumour Stance Classification in Social Media", "background_label": "Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Interestingly, one can mine multiple reactions expressed by social media users in those situations, exploring their stance towards rumours, ultimately enabling the flagging of highly disputed rumours as being potentially false.", "method_label": "In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a rumourous conversation as either supporting, denying or questioning the rumour. Using a classifier based on Gaussian Processes, and exploring its effectiveness on two datasets with very different characteristics and varying distributions of stances, we show that our approach consistently outperforms competitive baseline classifiers.", "result_label": "Our classifier is especially effective in estimating the distribution of different types of stance associated with a given rumour, which we set forth as a desired characteristic for a rumour-tracking system that will warn both ordinary users of Twitter and professional news practitioners when a rumour is being rebutted.", "abstract": "Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Interestingly, one can mine multiple reactions expressed by social media users in those situations, exploring their stance towards rumours, ultimately enabling the flagging of highly disputed rumours as being potentially false. In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a rumourous conversation as either supporting, denying or questioning the rumour. In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a rumourous conversation as either supporting, denying or questioning the rumour. Using a classifier based on Gaussian Processes, and exploring its effectiveness on two datasets with very different characteristics and varying distributions of stances, we show that our approach consistently outperforms competitive baseline classifiers. Our classifier is especially effective in estimating the distribution of different types of stance associated with a given rumour, which we set forth as a desired characteristic for a rumour-tracking system that will warn both ordinary users of Twitter and professional news practitioners when a rumour is being rebutted."}, {"paper_id": "4196207", "adju_relevance": 1, "title": "Hawkes Processes for Continuous Time Sequence Classification: an Application to Rumour Stance Classification in Twitter", "background_label": "Classification of temporal textual data sequences is a common task in various domains such as social media and the Web.", "abstract": "Classification of temporal textual data sequences is a common task in various domains such as social media and the Web."}, {"paper_id": "13811096", "adju_relevance": 1, "title": "Detect Rumor and Stance Jointly by Neural Multi-task Learning", "background_label": "ABSTRACTIn recent years, an unhealthy phenomenon characterized as the massive spread of fake news or unverified information (i.e., rumors) has become increasingly a daunting issue in human society. The rumors commonly originate from social media outlets, primarily microblogging platforms, being viral afterwards by the wild, willful propagation via a large number of participants. It is observed that rumorous posts often trigger versatile, mostly controversial stances among participating users. Thus, determining the stances on the posts in question can be pertinent to the successful detection of rumors, and vice versa. Existing studies, however, mainly regard rumor detection and stance classification as separate tasks.", "method_label": "In this paper, we argue that they should be treated as a joint, collaborative effort, considering the strong connections between the veracity of claim and the stances expressed in responsive posts.Enlightened by the multi-task learning scheme, we propose a joint framework that unifies the two highly pertinent tasks, i.e., rumor detection and stance classification. Based on deep neural networks, we train both tasks jointly using weight sharing to extract the common and task-invariant features while each task can still learn its task-specific features.", "result_label": "Extensive experiments on real-world datasets gathered from Twitter and news portals demonstrate that our proposed framework improves both rumor detection and stance classification tasks consistently with the help of the strong intertask connections, achieving much better performance than stateof-the-art methods.", "abstract": "ABSTRACTIn recent years, an unhealthy phenomenon characterized as the massive spread of fake news or unverified information (i.e., rumors) has become increasingly a daunting issue in human society. ABSTRACTIn recent years, an unhealthy phenomenon characterized as the massive spread of fake news or unverified information (i.e., rumors) has become increasingly a daunting issue in human society. The rumors commonly originate from social media outlets, primarily microblogging platforms, being viral afterwards by the wild, willful propagation via a large number of participants. ABSTRACTIn recent years, an unhealthy phenomenon characterized as the massive spread of fake news or unverified information (i.e., rumors) has become increasingly a daunting issue in human society. The rumors commonly originate from social media outlets, primarily microblogging platforms, being viral afterwards by the wild, willful propagation via a large number of participants. It is observed that rumorous posts often trigger versatile, mostly controversial stances among participating users. ABSTRACTIn recent years, an unhealthy phenomenon characterized as the massive spread of fake news or unverified information (i.e., rumors) has become increasingly a daunting issue in human society. The rumors commonly originate from social media outlets, primarily microblogging platforms, being viral afterwards by the wild, willful propagation via a large number of participants. It is observed that rumorous posts often trigger versatile, mostly controversial stances among participating users. Thus, determining the stances on the posts in question can be pertinent to the successful detection of rumors, and vice versa. ABSTRACTIn recent years, an unhealthy phenomenon characterized as the massive spread of fake news or unverified information (i.e., rumors) has become increasingly a daunting issue in human society. The rumors commonly originate from social media outlets, primarily microblogging platforms, being viral afterwards by the wild, willful propagation via a large number of participants. It is observed that rumorous posts often trigger versatile, mostly controversial stances among participating users. Thus, determining the stances on the posts in question can be pertinent to the successful detection of rumors, and vice versa. Existing studies, however, mainly regard rumor detection and stance classification as separate tasks. In this paper, we argue that they should be treated as a joint, collaborative effort, considering the strong connections between the veracity of claim and the stances expressed in responsive posts.Enlightened by the multi-task learning scheme, we propose a joint framework that unifies the two highly pertinent tasks, i.e., rumor detection and stance classification. In this paper, we argue that they should be treated as a joint, collaborative effort, considering the strong connections between the veracity of claim and the stances expressed in responsive posts.Enlightened by the multi-task learning scheme, we propose a joint framework that unifies the two highly pertinent tasks, i.e., rumor detection and stance classification. Based on deep neural networks, we train both tasks jointly using weight sharing to extract the common and task-invariant features while each task can still learn its task-specific features. Extensive experiments on real-world datasets gathered from Twitter and news portals demonstrate that our proposed framework improves both rumor detection and stance classification tasks consistently with the help of the strong intertask connections, achieving much better performance than stateof-the-art methods."}, {"paper_id": "59842973", "adju_relevance": 0, "title": "How is Your Mood When Writing Sexist tweets? Detecting the Emotion Type and Intensity of Emotion Using Natural Language Processing Techniques", "background_label": "Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Categorizing sexism as either benevolent or hostile sexism is so broad that it easily ignores the other categories of sexism on social media.", "method_label": "Sharifirad S and Matwin S 2018 proposed a well-defined category of sexism including indirect harassment, information threat, sexual harassment and physical harassment, inspired from social science for the purpose of natural language processing techniques.", "abstract": "Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Categorizing sexism as either benevolent or hostile sexism is so broad that it easily ignores the other categories of sexism on social media. Sharifirad S and Matwin S 2018 proposed a well-defined category of sexism including indirect harassment, information threat, sexual harassment and physical harassment, inspired from social science for the purpose of natural language processing techniques."}, {"paper_id": "141685124", "adju_relevance": 0, "title": "Ferreting Facts or Fashioning Fallacies? Factors in Rumor Accuracy", "background_label": "In some situations, rumors come to reflect reality quite well and in others they become fantastic. Why?", "abstract": "In some situations, rumors come to reflect reality quite well and in others they become fantastic. In some situations, rumors come to reflect reality quite well and in others they become fantastic. Why?"}, {"paper_id": "17246987", "adju_relevance": 0, "title": "Is this word borrowed? An automatic approach to quantify the likeliness of borrowing in social media", "background_label": "Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Use of a foreign word in a language; however, does not necessarily mean that the speaker is code-switching because often languages borrow lexical items from other languages. If a word is borrowed, it becomes a part of the lexicon of a language; whereas, during code-switching, the speaker is aware that the conversation involves foreign words or phrases. Identifying whether a foreign word used by a bilingual speaker is due to borrowing or code-switching is a fundamental importance to theories of multilingualism, and an essential prerequisite towards the development of language and speech technologies for multilingual communities.", "method_label": "In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. We first propose context based clustering method to sample a set of candidate words from the social media data.Next, we propose three novel and similar metrics based on the usage of these words by the users in different tweets; these metrics were used to score and rank the candidate words indicating their borrowed likeliness. We compare these rankings with a ground truth ranking constructed through a human judgment experiment. The Spearman's rank correlation between the two rankings (nearly 0.62 for all the three metric variants) is more than double the value (0.26) of the most competitive existing baseline reported in the literature.", "result_label": "Some other striking observations are, (i) the correlation is higher for the ground truth data elicited from the younger participants (age less than 30) than that from the older participants, and (ii )those participants who use mixed-language for tweeting the least, provide the best signals of borrowing.", "abstract": "Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Use of a foreign word in a language; however, does not necessarily mean that the speaker is code-switching because often languages borrow lexical items from other languages. Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Use of a foreign word in a language; however, does not necessarily mean that the speaker is code-switching because often languages borrow lexical items from other languages. If a word is borrowed, it becomes a part of the lexicon of a language; whereas, during code-switching, the speaker is aware that the conversation involves foreign words or phrases. Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Use of a foreign word in a language; however, does not necessarily mean that the speaker is code-switching because often languages borrow lexical items from other languages. If a word is borrowed, it becomes a part of the lexicon of a language; whereas, during code-switching, the speaker is aware that the conversation involves foreign words or phrases. Identifying whether a foreign word used by a bilingual speaker is due to borrowing or code-switching is a fundamental importance to theories of multilingualism, and an essential prerequisite towards the development of language and speech technologies for multilingual communities. In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. We first propose context based clustering method to sample a set of candidate words from the social media data.Next, we propose three novel and similar metrics based on the usage of these words by the users in different tweets; these metrics were used to score and rank the candidate words indicating their borrowed likeliness. In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. We first propose context based clustering method to sample a set of candidate words from the social media data.Next, we propose three novel and similar metrics based on the usage of these words by the users in different tweets; these metrics were used to score and rank the candidate words indicating their borrowed likeliness. We compare these rankings with a ground truth ranking constructed through a human judgment experiment. In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. We first propose context based clustering method to sample a set of candidate words from the social media data.Next, we propose three novel and similar metrics based on the usage of these words by the users in different tweets; these metrics were used to score and rank the candidate words indicating their borrowed likeliness. We compare these rankings with a ground truth ranking constructed through a human judgment experiment. The Spearman's rank correlation between the two rankings (nearly 0.62 for all the three metric variants) is more than double the value (0.26) of the most competitive existing baseline reported in the literature. Some other striking observations are, (i) the correlation is higher for the ground truth data elicited from the younger participants (age less than 30) than that from the older participants, and (ii )those participants who use mixed-language for tweeting the least, provide the best signals of borrowing."}, {"paper_id": "15782106", "adju_relevance": 0, "title": "Scalable Rumor Source Detection under Independent Cascade Model in Online Social Networks", "abstract": ""}, {"paper_id": "35888392", "adju_relevance": 0, "title": "The Influence of Individual, Contextual, and Social Factors on Perceived Behavioral Control of Information Technology: A Field Theory Approach", "background_label": "Organizations are increasingly concerned about ensuring that workers have sufficient sense of control over the information technology (IT) that they use. However, we know little about the antecedents of the end user's perceived behavioral control (PBC) with respect to IT.", "abstract": "Organizations are increasingly concerned about ensuring that workers have sufficient sense of control over the information technology (IT) that they use. Organizations are increasingly concerned about ensuring that workers have sufficient sense of control over the information technology (IT) that they use. However, we know little about the antecedents of the end user's perceived behavioral control (PBC) with respect to IT."}, {"paper_id": "196038978", "adju_relevance": 0, "title": "Effects of Word Class and Text Position in Sentiment-based News Classification", "background_label": "Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. happy, sad, angry, amused etc. Unlike other review texts that contain more explicit words which can be interpreted directly for sentiment classification, news texts mostly report facts and figures. This resulted in needs to identify whether contents of news can be exploited for classification or otherwise. Two criteria, i.e. text Part of Speech and text position, which could possible influence the training of the classifier are studied.", "result_label": "Hence, in this work, a study is conducted to analyze and determine the relevant key parts of news contents that can be to be used for sentiment-based classification. The results for sentiment-based category has recorded F score of 0.422 whereas for polarity-based category has recorded F score of 0.837.", "method_label": "Evaluations are conducted on the collection of 250 English news texts labelled with sentiments from sentiment voting system.", "abstract": "Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. happy, sad, angry, amused etc. Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. happy, sad, angry, amused etc. Unlike other review texts that contain more explicit words which can be interpreted directly for sentiment classification, news texts mostly report facts and figures. Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. happy, sad, angry, amused etc. Unlike other review texts that contain more explicit words which can be interpreted directly for sentiment classification, news texts mostly report facts and figures. This resulted in needs to identify whether contents of news can be exploited for classification or otherwise. Hence, in this work, a study is conducted to analyze and determine the relevant key parts of news contents that can be to be used for sentiment-based classification. Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. happy, sad, angry, amused etc. Unlike other review texts that contain more explicit words which can be interpreted directly for sentiment classification, news texts mostly report facts and figures. This resulted in needs to identify whether contents of news can be exploited for classification or otherwise. Two criteria, i.e. Abstract In news domain, sentiments captured in the form of sentiment labels (emoticon) give a quick feedback of reactions towards the contents of the news. As these reactions are valuable indicators for social and political well beings, we are motivated to automate the classification of news texts based on these indicators, e.g. happy, sad, angry, amused etc. Unlike other review texts that contain more explicit words which can be interpreted directly for sentiment classification, news texts mostly report facts and figures. This resulted in needs to identify whether contents of news can be exploited for classification or otherwise. Two criteria, i.e. text Part of Speech and text position, which could possible influence the training of the classifier are studied. Evaluations are conducted on the collection of 250 English news texts labelled with sentiments from sentiment voting system. Hence, in this work, a study is conducted to analyze and determine the relevant key parts of news contents that can be to be used for sentiment-based classification. The results for sentiment-based category has recorded F score of 0.422 whereas for polarity-based category has recorded F score of 0.837."}, {"paper_id": "15037304", "adju_relevance": 0, "title": "Emerging Rumor Identification for Social Media with Hot Topic Detection", "background_label": "A rumor is commonly defined as a statement whose true value is unverifiable. As rumor can spread misinformation around people, causing social problems such as panic, and the rapid growth of online social media has made it possible for rumors to spread more quickly, it is important to automatically identify rumors for social media.", "method_label": "Existing methods on rumor detection always concentrate on telling rumor from truth with handcrafted regular expressions, dealing with out of date rumor related message. To solve this problem, we introduce a novel hot topic detection method combining bursty term identification and multi-dimension sentence modeling to automatically detect emerging hot topics for rumor identification. We conduct a comprehensive set of experiments on two data sets from real-world social media.", "result_label": "Experiment results show that our emerging rumor identification for social media with hot topic detection work well both in news data set and twitter data set, and combining the hot topic detection with the rumor detection is possible to finish real-time rumor identification. We believe our method to automatically detect rumor will open new dimensions in analyzing online misinformation and other aspects of social media mining.", "abstract": "A rumor is commonly defined as a statement whose true value is unverifiable. A rumor is commonly defined as a statement whose true value is unverifiable. As rumor can spread misinformation around people, causing social problems such as panic, and the rapid growth of online social media has made it possible for rumors to spread more quickly, it is important to automatically identify rumors for social media. Existing methods on rumor detection always concentrate on telling rumor from truth with handcrafted regular expressions, dealing with out of date rumor related message. Existing methods on rumor detection always concentrate on telling rumor from truth with handcrafted regular expressions, dealing with out of date rumor related message. To solve this problem, we introduce a novel hot topic detection method combining bursty term identification and multi-dimension sentence modeling to automatically detect emerging hot topics for rumor identification. Existing methods on rumor detection always concentrate on telling rumor from truth with handcrafted regular expressions, dealing with out of date rumor related message. To solve this problem, we introduce a novel hot topic detection method combining bursty term identification and multi-dimension sentence modeling to automatically detect emerging hot topics for rumor identification. We conduct a comprehensive set of experiments on two data sets from real-world social media. Experiment results show that our emerging rumor identification for social media with hot topic detection work well both in news data set and twitter data set, and combining the hot topic detection with the rumor detection is possible to finish real-time rumor identification. Experiment results show that our emerging rumor identification for social media with hot topic detection work well both in news data set and twitter data set, and combining the hot topic detection with the rumor detection is possible to finish real-time rumor identification. We believe our method to automatically detect rumor will open new dimensions in analyzing online misinformation and other aspects of social media mining."}, {"paper_id": "14696084", "adju_relevance": 0, "title": "Certainty categorization model", "background_label": "We present a theoretical framework and preliminary results for manual categorization of explicit certainty information in 32 English newspaper articles. The explicit certainty markers were identified and categorized according to the four hypothesized dimensions \u2013 perspective, focus, timeline, and level of certainty.", "method_label": "One hundred twenty one sentences from sample news stories contained a significantly lower frequency of markers per sentence (M=0.46, SD =0.04) than 564 sentences from sample editorials (M=0.6, SD =0.23), p= 0.0056, two-tailed heteroscedastic t-test. Within each dimension, editorials had most numerous markers per sentence in high level of certainty, writer\u2019s point of view, and future and present timeline (0.33, 0.43, 0.24, and 0.22, respectively); news stories \u2013 in high and moderate levels, directly involved third party\u2019s point of view, and past timeline (0.19, 0.20, 0.24, and 0.20, respectively).", "result_label": "These patterns have practical implications for automation. Further analysis of editorials showed that out of 72 combinations possible under the hypothesized model, the high level of certainty from writer\u2019s perspective expressed abstractly in the present and future time, and expressed factually in the future were very common. Twenty two combinations never occurred; and 35 had \u2264 8 occurrences. This narrows the focus for future linguistic analysis of explicit certainty markers.", "abstract": "We present a theoretical framework and preliminary results for manual categorization of explicit certainty information in 32 English newspaper articles. We present a theoretical framework and preliminary results for manual categorization of explicit certainty information in 32 English newspaper articles. The explicit certainty markers were identified and categorized according to the four hypothesized dimensions \u2013 perspective, focus, timeline, and level of certainty. One hundred twenty one sentences from sample news stories contained a significantly lower frequency of markers per sentence (M=0.46, SD =0.04) than 564 sentences from sample editorials (M=0.6, SD =0.23), p= 0.0056, two-tailed heteroscedastic t-test. One hundred twenty one sentences from sample news stories contained a significantly lower frequency of markers per sentence (M=0.46, SD =0.04) than 564 sentences from sample editorials (M=0.6, SD =0.23), p= 0.0056, two-tailed heteroscedastic t-test. Within each dimension, editorials had most numerous markers per sentence in high level of certainty, writer\u2019s point of view, and future and present timeline (0.33, 0.43, 0.24, and 0.22, respectively); news stories \u2013 in high and moderate levels, directly involved third party\u2019s point of view, and past timeline (0.19, 0.20, 0.24, and 0.20, respectively). These patterns have practical implications for automation. These patterns have practical implications for automation. Further analysis of editorials showed that out of 72 combinations possible under the hypothesized model, the high level of certainty from writer\u2019s perspective expressed abstractly in the present and future time, and expressed factually in the future were very common. These patterns have practical implications for automation. Further analysis of editorials showed that out of 72 combinations possible under the hypothesized model, the high level of certainty from writer\u2019s perspective expressed abstractly in the present and future time, and expressed factually in the future were very common. Twenty two combinations never occurred; and 35 had \u2264 8 occurrences. These patterns have practical implications for automation. Further analysis of editorials showed that out of 72 combinations possible under the hypothesized model, the high level of certainty from writer\u2019s perspective expressed abstractly in the present and future time, and expressed factually in the future were very common. Twenty two combinations never occurred; and 35 had \u2264 8 occurrences. This narrows the focus for future linguistic analysis of explicit certainty markers."}, {"paper_id": "119425731", "adju_relevance": 0, "title": "Unzerlegbare Darstellungen I", "background_label": "LetK be the structure got by forgetting the composition law of morphisms in a given category. A linear representation ofK is given by a map V associating with any morphism \u03d5: a\u2192e ofK a linear vector space map V(\u03d5): V(a)\u2192V(e).", "method_label": "We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations.", "abstract": "LetK be the structure got by forgetting the composition law of morphisms in a given category. LetK be the structure got by forgetting the composition law of morphisms in a given category. A linear representation ofK is given by a map V associating with any morphism \u03d5: a\u2192e ofK a linear vector space map V(\u03d5): V(a)\u2192V(e). We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations."}, {"paper_id": "19203748", "adju_relevance": 0, "title": "The role of beliefs in lexical alignment: Evidence from dialogs with humans and computers", "background_label": "Five experiments examined the extent to which speakers' alignment (i.e., convergence) on words in dialog is mediated by beliefs about their interlocutor.", "method_label": "To do this, we told participants that they were interacting with another person or a computer in a task in which they alternated between selecting pictures that matched their 'partner's' descriptions and naming pictures themselves (though in reality all responses were scripted).", "result_label": "In both text- and speech-based dialog, participants tended to repeat their partner's choice of referring expression. However, they showed a stronger tendency to align with 'computer' than with 'human' partners, and with computers that were presented as less capable than with computers that were presented as more capable. The tendency to align therefore appears to be mediated by beliefs, with the relevant beliefs relating to an interlocutor's perceived communicative capacity.", "abstract": "Five experiments examined the extent to which speakers' alignment (i.e., convergence) on words in dialog is mediated by beliefs about their interlocutor. To do this, we told participants that they were interacting with another person or a computer in a task in which they alternated between selecting pictures that matched their 'partner's' descriptions and naming pictures themselves (though in reality all responses were scripted). In both text- and speech-based dialog, participants tended to repeat their partner's choice of referring expression. In both text- and speech-based dialog, participants tended to repeat their partner's choice of referring expression. However, they showed a stronger tendency to align with 'computer' than with 'human' partners, and with computers that were presented as less capable than with computers that were presented as more capable. In both text- and speech-based dialog, participants tended to repeat their partner's choice of referring expression. However, they showed a stronger tendency to align with 'computer' than with 'human' partners, and with computers that were presented as less capable than with computers that were presented as more capable. The tendency to align therefore appears to be mediated by beliefs, with the relevant beliefs relating to an interlocutor's perceived communicative capacity."}, {"paper_id": "144546721", "adju_relevance": 0, "title": "Online Visual Merchandising (VMD) Cues and Consumer Pleasure and Arousal: Purchasing versus Browsing Situation", "method_label": "A random sample of 1634 female college students participated in an experiment in the context of online apparel shopping.", "result_label": "The results of the study revealed a significant effect for high task relevant cues on pleasure and arousal under high situational involvement (purchasing situation). In addition, a significant effect for low task relevant cues on pleasure and arousal under low situational involvement (browsing situation) was found. Pleasure and arousal induced by various online VMD cues were positively related to consumer satisfaction, purchase intention, and approach behavior. The findings of the study emphasize a significant role of VMD cues on apparel Web sites, influencing pleasure and arousal, which in turn increase consumer satisfaction, purchase intention, and approach behavior. The study also provides an important implication for online apparel retailers developing Web sites that may attract both online browsers and purchasers.", "abstract": " A random sample of 1634 female college students participated in an experiment in the context of online apparel shopping. The results of the study revealed a significant effect for high task relevant cues on pleasure and arousal under high situational involvement (purchasing situation). The results of the study revealed a significant effect for high task relevant cues on pleasure and arousal under high situational involvement (purchasing situation). In addition, a significant effect for low task relevant cues on pleasure and arousal under low situational involvement (browsing situation) was found. The results of the study revealed a significant effect for high task relevant cues on pleasure and arousal under high situational involvement (purchasing situation). In addition, a significant effect for low task relevant cues on pleasure and arousal under low situational involvement (browsing situation) was found. Pleasure and arousal induced by various online VMD cues were positively related to consumer satisfaction, purchase intention, and approach behavior. The results of the study revealed a significant effect for high task relevant cues on pleasure and arousal under high situational involvement (purchasing situation). In addition, a significant effect for low task relevant cues on pleasure and arousal under low situational involvement (browsing situation) was found. Pleasure and arousal induced by various online VMD cues were positively related to consumer satisfaction, purchase intention, and approach behavior. The findings of the study emphasize a significant role of VMD cues on apparel Web sites, influencing pleasure and arousal, which in turn increase consumer satisfaction, purchase intention, and approach behavior. The results of the study revealed a significant effect for high task relevant cues on pleasure and arousal under high situational involvement (purchasing situation). In addition, a significant effect for low task relevant cues on pleasure and arousal under low situational involvement (browsing situation) was found. Pleasure and arousal induced by various online VMD cues were positively related to consumer satisfaction, purchase intention, and approach behavior. The findings of the study emphasize a significant role of VMD cues on apparel Web sites, influencing pleasure and arousal, which in turn increase consumer satisfaction, purchase intention, and approach behavior. The study also provides an important implication for online apparel retailers developing Web sites that may attract both online browsers and purchasers."}, {"paper_id": "13996268", "adju_relevance": 0, "title": "A Twitter Hashtag Recommendation Model that Accommodates for Temporal Clustering Effects", "background_label": "Hashtags in social medial platforms such as Twitter are important for accessing related messages as well as for tracking and detecting events.", "abstract": "Hashtags in social medial platforms such as Twitter are important for accessing related messages as well as for tracking and detecting events."}, {"paper_id": "2837736", "adju_relevance": 0, "title": "SentiWordNet: A High-Coverage Lexical Resource for Opinion Mining", "background_label": "Opinion mining (OM) is a recent subdiscipline at the crossroads of information retrieval and computational linguistics which is concerned not with the topic a document is about, but with the opinions it expresses. OM has a rich set of applications, ranging from tracking users\u2019 opinions about products or about political candidates as expressed in online forums, to customer relationship management.", "abstract": "Opinion mining (OM) is a recent subdiscipline at the crossroads of information retrieval and computational linguistics which is concerned not with the topic a document is about, but with the opinions it expresses. Opinion mining (OM) is a recent subdiscipline at the crossroads of information retrieval and computational linguistics which is concerned not with the topic a document is about, but with the opinions it expresses. OM has a rich set of applications, ranging from tracking users\u2019 opinions about products or about political candidates as expressed in online forums, to customer relationship management."}, {"paper_id": "82456167", "adju_relevance": 0, "title": "Janeway's Immunobiology", "background_label": "Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Dynamics of Adaptive Immunity 11.", "method_label": "The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. Signaling Through Immune System Receptors 7.", "result_label": "The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8.", "abstract": "Part I An Introduction to Immunobiology and Innate Immunity 1. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. The Generation of Lymphocyte Antigen Receptors 5. The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. Signaling Through Immune System Receptors 7. The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Dynamics of Adaptive Immunity 11."}, {"paper_id": "143437682", "adju_relevance": 0, "title": "Reading the riots on Twitter: methodological innovation for the analysis of big data", "background_label": "For social scientists, the widespread adoption of social media presents both an opportunity and a challenge. Data that can shed light on people\u2019s habits, opinions and behaviour is available now on a scale never seen before, but this also means that it is impossible to analyse using conventional methodologies and tools.", "abstract": "For social scientists, the widespread adoption of social media presents both an opportunity and a challenge. For social scientists, the widespread adoption of social media presents both an opportunity and a challenge. Data that can shed light on people\u2019s habits, opinions and behaviour is available now on a scale never seen before, but this also means that it is impossible to analyse using conventional methodologies and tools."}, {"paper_id": "197654021", "adju_relevance": 0, "title": "Behavioral Markers and Recognizability of the Smile of Enjoyment", "background_label": "Ekman and Friesen (1982) predicted that smiles that express enjoyment would be marked by smoother zygomatic major actions of more consistent duration than the zygomatic major actions of nonenjoyment smiles.", "method_label": "Study 1 measured the duration and smoothness of smiles shown by female subjects in response to positive emotion films while alone and in a social interaction. Enjoyment smiles in both situations were of more consistent duration and smoother than nonenjoyment smiles.", "result_label": "In Study 2 observers who were shown videotapes of enjoyment and nonenjoyment smiles were able to accurately identify enjoyment smiles at rates greater than chance; moreover, accuracy was positively related to increase salience of orbicularis oculi action", "abstract": "Ekman and Friesen (1982) predicted that smiles that express enjoyment would be marked by smoother zygomatic major actions of more consistent duration than the zygomatic major actions of nonenjoyment smiles. Study 1 measured the duration and smoothness of smiles shown by female subjects in response to positive emotion films while alone and in a social interaction. Study 1 measured the duration and smoothness of smiles shown by female subjects in response to positive emotion films while alone and in a social interaction. Enjoyment smiles in both situations were of more consistent duration and smoother than nonenjoyment smiles. In Study 2 observers who were shown videotapes of enjoyment and nonenjoyment smiles were able to accurately identify enjoyment smiles at rates greater than chance; moreover, accuracy was positively related to increase salience of orbicularis oculi action"}, {"paper_id": "145697234", "adju_relevance": 0, "title": "A THEORY OF RUMOR TRANSMISSION", "background_label": "A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. The individual may find himself/herself in 1 of 3 orientations or situations in relation to a rumor: the rumor may cause the individual to take a critical set an uncritical set or a transmission set toward it. Except for the natural redundancy of language past experiments on rumor transmission do not have redundancies. In a face-to-face conversation a person hears a rumor and asks for a clarification of message or source if he/she does not understand it. In a situation where a rumor is a topic of conversation and speculation interaction produces a modified \"Gestalt\" at every discussion of the rumor. There is another type of redundancy besides that brought about by the normal community setting the individual would probably hear the rumor more than once.", "method_label": "If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If an individual takes an uncritical set it means that he/she is unable to use \"critical ability\" to test the truth of the rumor he/she hears. Implicit in the discussion of single and multiple interactions is the idea of 2 different kinds of rumor patterns. In the 1st type the chain the rumor moves from person to person in a serial manner in a series of single interactions. In the 2nd type the network many people hear the rumor from more than 1 source. 2 group level variables operate to promote or retard the spreading or repeating of rumors: the structure of the group or public through which the rumor is spreading and the involvement or interest the group has in the topic.", "result_label": "If the individual takes the transmission set usually found in laboratory experiments his/her critical ability is irrelevant. The empirical evidence suggests that where individuals have critical ability and interact with more than 1 person the rumor will become more precise with each transmission it will have its false elements stripped away and it will become more accurate because of cross checking with knowledgeable sources.", "abstract": "A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. The individual may find himself/herself in 1 of 3 orientations or situations in relation to a rumor: the rumor may cause the individual to take a critical set an uncritical set or a transmission set toward it. If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If an individual takes an uncritical set it means that he/she is unable to use \"critical ability\" to test the truth of the rumor he/she hears. If the individual takes the transmission set usually found in laboratory experiments his/her critical ability is irrelevant. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. The individual may find himself/herself in 1 of 3 orientations or situations in relation to a rumor: the rumor may cause the individual to take a critical set an uncritical set or a transmission set toward it. Except for the natural redundancy of language past experiments on rumor transmission do not have redundancies. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. The individual may find himself/herself in 1 of 3 orientations or situations in relation to a rumor: the rumor may cause the individual to take a critical set an uncritical set or a transmission set toward it. Except for the natural redundancy of language past experiments on rumor transmission do not have redundancies. In a face-to-face conversation a person hears a rumor and asks for a clarification of message or source if he/she does not understand it. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. The individual may find himself/herself in 1 of 3 orientations or situations in relation to a rumor: the rumor may cause the individual to take a critical set an uncritical set or a transmission set toward it. Except for the natural redundancy of language past experiments on rumor transmission do not have redundancies. In a face-to-face conversation a person hears a rumor and asks for a clarification of message or source if he/she does not understand it. In a situation where a rumor is a topic of conversation and speculation interaction produces a modified \"Gestalt\" at every discussion of the rumor. A theoretical framework is developed that demonstrates that the seemingly contradictory research conclusions that rumors expand and contract are actually complementary and that each is correct given the circumstances of its derivation. There is general agreement in the field that a rumor is an unconfirmed message passed from 1 person to another in face-to-face interaction that refers to an object person or situation rather than an idea or theory. Whether a rumor is truthful or untruthful is unimportant in studying its transmission. The essential features of a rumor are that it is unconfirmed at the time of transmission and that is passed from 1 person to another. The individual may find himself/herself in 1 of 3 orientations or situations in relation to a rumor: the rumor may cause the individual to take a critical set an uncritical set or a transmission set toward it. Except for the natural redundancy of language past experiments on rumor transmission do not have redundancies. In a face-to-face conversation a person hears a rumor and asks for a clarification of message or source if he/she does not understand it. In a situation where a rumor is a topic of conversation and speculation interaction produces a modified \"Gestalt\" at every discussion of the rumor. There is another type of redundancy besides that brought about by the normal community setting the individual would probably hear the rumor more than once. If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If an individual takes an uncritical set it means that he/she is unable to use \"critical ability\" to test the truth of the rumor he/she hears. Implicit in the discussion of single and multiple interactions is the idea of 2 different kinds of rumor patterns. If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If an individual takes an uncritical set it means that he/she is unable to use \"critical ability\" to test the truth of the rumor he/she hears. Implicit in the discussion of single and multiple interactions is the idea of 2 different kinds of rumor patterns. In the 1st type the chain the rumor moves from person to person in a serial manner in a series of single interactions. If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If an individual takes an uncritical set it means that he/she is unable to use \"critical ability\" to test the truth of the rumor he/she hears. Implicit in the discussion of single and multiple interactions is the idea of 2 different kinds of rumor patterns. In the 1st type the chain the rumor moves from person to person in a serial manner in a series of single interactions. In the 2nd type the network many people hear the rumor from more than 1 source. If the individual takes a critical set it means that he/she is capable of using \"critical ability\" to separate the true from the false in rumors. If an individual takes an uncritical set it means that he/she is unable to use \"critical ability\" to test the truth of the rumor he/she hears. Implicit in the discussion of single and multiple interactions is the idea of 2 different kinds of rumor patterns. In the 1st type the chain the rumor moves from person to person in a serial manner in a series of single interactions. In the 2nd type the network many people hear the rumor from more than 1 source. 2 group level variables operate to promote or retard the spreading or repeating of rumors: the structure of the group or public through which the rumor is spreading and the involvement or interest the group has in the topic. If the individual takes the transmission set usually found in laboratory experiments his/her critical ability is irrelevant. The empirical evidence suggests that where individuals have critical ability and interact with more than 1 person the rumor will become more precise with each transmission it will have its false elements stripped away and it will become more accurate because of cross checking with knowledgeable sources."}, {"paper_id": "15885466", "adju_relevance": 0, "title": "Rumors detection in Chinese via crowd responses", "background_label": "In recent years, microblogging platforms have become good places to spread various spams, making the problem of gauging information credibility on social networks receive considerable attention especially under an emergency situation.", "abstract": "In recent years, microblogging platforms have become good places to spread various spams, making the problem of gauging information credibility on social networks receive considerable attention especially under an emergency situation."}, {"paper_id": "3101294", "adju_relevance": 0, "title": "Phonological (un)certainty weights lexical activation", "background_label": "Spoken word recognition involves at least two basic computations. First is matching acoustic input to phonological categories (e.g. /b/, /p/, /d/). Second is activating words consistent with those phonological categories.", "method_label": "Here we test the hypothesis that the listener's probability distribution over lexical items is weighted by the outcome of both computations: uncertainty about phonological discretisation and the frequency of the selected word(s). To test this, we record neural responses in auditory cortex using magnetoencephalography, and model this activity as a function of the size and relative activation of lexical candidates.", "result_label": "Our findings indicate that towards the beginning of a word, the processing system indeed weights lexical candidates by both phonological certainty and lexical frequency; however, later into the word, activation is weighted by frequency alone.", "abstract": "Spoken word recognition involves at least two basic computations. Spoken word recognition involves at least two basic computations. First is matching acoustic input to phonological categories (e.g. Spoken word recognition involves at least two basic computations. First is matching acoustic input to phonological categories (e.g. /b/, /p/, /d/). Spoken word recognition involves at least two basic computations. First is matching acoustic input to phonological categories (e.g. /b/, /p/, /d/). Second is activating words consistent with those phonological categories. Here we test the hypothesis that the listener's probability distribution over lexical items is weighted by the outcome of both computations: uncertainty about phonological discretisation and the frequency of the selected word(s). Here we test the hypothesis that the listener's probability distribution over lexical items is weighted by the outcome of both computations: uncertainty about phonological discretisation and the frequency of the selected word(s). To test this, we record neural responses in auditory cortex using magnetoencephalography, and model this activity as a function of the size and relative activation of lexical candidates. Our findings indicate that towards the beginning of a word, the processing system indeed weights lexical candidates by both phonological certainty and lexical frequency; however, later into the word, activation is weighted by frequency alone."}, {"paper_id": "10144422", "adju_relevance": 0, "title": "TweetCred: Real-Time Credibility Assessment of Content on Twitter", "background_label": "During sudden onset crisis events, the presence of spam, rumors and fake content on Twitter reduces the value of information contained on its messages (or\"tweets\"). A possible solution to this problem is to use machine learning to automatically evaluate the credibility of a tweet, i.e.", "abstract": "During sudden onset crisis events, the presence of spam, rumors and fake content on Twitter reduces the value of information contained on its messages (or\"tweets\"). During sudden onset crisis events, the presence of spam, rumors and fake content on Twitter reduces the value of information contained on its messages (or\"tweets\"). A possible solution to this problem is to use machine learning to automatically evaluate the credibility of a tweet, i.e."}, {"paper_id": "7710753", "adju_relevance": 0, "title": "MoodLens: an emoticon-based sentiment analysis system for chinese tweets", "background_label": "Recent years have witnessed the explosive growth of online social media. Weibo, a Twitter-like online social network in China, has attracted more than 300 million users in less than three years, with more than 1000 tweets generated in every second. These tweets not only convey the factual information, but also reflect the emotional states of the authors, which are very important for understanding user behaviors. However, a tweet in Weibo is extremely short and the words it contains evolve extraordinarily fast. Moreover, the Chinese corpus of sentiments is still very small, which prevents the conventional keyword-based methods from being used.", "method_label": "In light of this, we build a system called MoodLens, which to our best knowledge is the first system for sentiment analysis of Chinese tweets in Weibo.", "abstract": "Recent years have witnessed the explosive growth of online social media. Recent years have witnessed the explosive growth of online social media. Weibo, a Twitter-like online social network in China, has attracted more than 300 million users in less than three years, with more than 1000 tweets generated in every second. Recent years have witnessed the explosive growth of online social media. Weibo, a Twitter-like online social network in China, has attracted more than 300 million users in less than three years, with more than 1000 tweets generated in every second. These tweets not only convey the factual information, but also reflect the emotional states of the authors, which are very important for understanding user behaviors. Recent years have witnessed the explosive growth of online social media. Weibo, a Twitter-like online social network in China, has attracted more than 300 million users in less than three years, with more than 1000 tweets generated in every second. These tweets not only convey the factual information, but also reflect the emotional states of the authors, which are very important for understanding user behaviors. However, a tweet in Weibo is extremely short and the words it contains evolve extraordinarily fast. Recent years have witnessed the explosive growth of online social media. Weibo, a Twitter-like online social network in China, has attracted more than 300 million users in less than three years, with more than 1000 tweets generated in every second. These tweets not only convey the factual information, but also reflect the emotional states of the authors, which are very important for understanding user behaviors. However, a tweet in Weibo is extremely short and the words it contains evolve extraordinarily fast. Moreover, the Chinese corpus of sentiments is still very small, which prevents the conventional keyword-based methods from being used. In light of this, we build a system called MoodLens, which to our best knowledge is the first system for sentiment analysis of Chinese tweets in Weibo."}, {"paper_id": "4234479", "adju_relevance": 0, "title": "Meme-tracking and the dynamics of the news cycle", "background_label": "Tracking new topics, ideas, and \"memes\" across the Web has been an issue of considerable interest. Recent work has developed methods for tracking topic shifts over long time scales, as well as abrupt spikes in the appearance of particular named entities. However, these approaches are less well suited to the identification of content that spreads widely and then fades over time scales on the order of days - the time scale at which we perceive news and events.", "method_label": "We develop a framework for tracking short, distinctive phrases that travel relatively intact through on-line text; developing scalable algorithms for clustering textual variants of such phrases, we identify a broad class of memes that exhibit wide spread and rich variation on a daily basis. As our principal domain of study, we show how such a meme-tracking approach can provide a coherent representation of the news cycle - the daily rhythms in the news media that have long been the subject of qualitative interpretation but have never been captured accurately enough to permit actual quantitative analysis. We tracked 1.6 million mainstream media sites and blogs over a period of three months with the total of 90 million articles and we find a set of novel and persistent temporal patterns in the news cycle.", "result_label": "In particular, we observe a typical lag of 2.5 hours between the peaks of attention to a phrase in the news media and in blogs respectively, with divergent behavior around the overall peak and a \"heartbeat\"-like pattern in the handoff between news and blogs. We also develop and analyze a mathematical model for the kinds of temporal variation that the system exhibits.", "abstract": "Tracking new topics, ideas, and \"memes\" across the Web has been an issue of considerable interest. Tracking new topics, ideas, and \"memes\" across the Web has been an issue of considerable interest. Recent work has developed methods for tracking topic shifts over long time scales, as well as abrupt spikes in the appearance of particular named entities. Tracking new topics, ideas, and \"memes\" across the Web has been an issue of considerable interest. Recent work has developed methods for tracking topic shifts over long time scales, as well as abrupt spikes in the appearance of particular named entities. However, these approaches are less well suited to the identification of content that spreads widely and then fades over time scales on the order of days - the time scale at which we perceive news and events. We develop a framework for tracking short, distinctive phrases that travel relatively intact through on-line text; developing scalable algorithms for clustering textual variants of such phrases, we identify a broad class of memes that exhibit wide spread and rich variation on a daily basis. We develop a framework for tracking short, distinctive phrases that travel relatively intact through on-line text; developing scalable algorithms for clustering textual variants of such phrases, we identify a broad class of memes that exhibit wide spread and rich variation on a daily basis. As our principal domain of study, we show how such a meme-tracking approach can provide a coherent representation of the news cycle - the daily rhythms in the news media that have long been the subject of qualitative interpretation but have never been captured accurately enough to permit actual quantitative analysis. We develop a framework for tracking short, distinctive phrases that travel relatively intact through on-line text; developing scalable algorithms for clustering textual variants of such phrases, we identify a broad class of memes that exhibit wide spread and rich variation on a daily basis. As our principal domain of study, we show how such a meme-tracking approach can provide a coherent representation of the news cycle - the daily rhythms in the news media that have long been the subject of qualitative interpretation but have never been captured accurately enough to permit actual quantitative analysis. We tracked 1.6 million mainstream media sites and blogs over a period of three months with the total of 90 million articles and we find a set of novel and persistent temporal patterns in the news cycle. In particular, we observe a typical lag of 2.5 hours between the peaks of attention to a phrase in the news media and in blogs respectively, with divergent behavior around the overall peak and a \"heartbeat\"-like pattern in the handoff between news and blogs. In particular, we observe a typical lag of 2.5 hours between the peaks of attention to a phrase in the news media and in blogs respectively, with divergent behavior around the overall peak and a \"heartbeat\"-like pattern in the handoff between news and blogs. We also develop and analyze a mathematical model for the kinds of temporal variation that the system exhibits."}, {"paper_id": "7445083", "adju_relevance": 0, "title": "Rumor Identification and Belief Investigation on Twitter", "background_label": "AbstractSocial media users spend several hours a day to read, post and search for news on microblogging platforms. Social media is becoming a key means for discovering news. However, verifying the trustworthiness of this information is becoming even more challenging.", "abstract": "AbstractSocial media users spend several hours a day to read, post and search for news on microblogging platforms. AbstractSocial media users spend several hours a day to read, post and search for news on microblogging platforms. Social media is becoming a key means for discovering news. AbstractSocial media users spend several hours a day to read, post and search for news on microblogging platforms. Social media is becoming a key means for discovering news. However, verifying the trustworthiness of this information is becoming even more challenging."}, {"paper_id": "12734321", "adju_relevance": 0, "title": "Nonlinear spread of rumor and inoculation strategies in the nodes with degree dependent tie strength in complex networks", "background_label": "In earlier rumor spreading models, at each time step nodes contact all of their neighbors. In more realistic scenario it is possible that a node may contact only some of its neighbors to spread the rumor. Therefore it is must in real world complex networks, the classic rumor spreading model need to be modified to consider the dependence of rumor spread rate on the degree of the spreader and the informed nodes. In any social network, rumors can spread may have undesirable effect. One of the possible solutions to control rumor spread, is to inoculate a certain fraction of nodes against rumors.", "method_label": "We have given a modified rumor spreading model to accommodate these facts. This new model, has been studied for rumor spreading in complex networks in this work. Nonlinear rumor spread exponent $\\alpha$ and degree dependent tie strength exponent $\\beta$ in any complex network gives rumor threshold as some finite value. In the present work, the modified rumor spreading model has been studied in scale free networks.", "result_label": "It is also found that if $ \\alpha $ and $ \\beta $ parameters are tuned to appropriate value, the rumor threshold becomes independent of network size.", "abstract": "In earlier rumor spreading models, at each time step nodes contact all of their neighbors. In earlier rumor spreading models, at each time step nodes contact all of their neighbors. In more realistic scenario it is possible that a node may contact only some of its neighbors to spread the rumor. In earlier rumor spreading models, at each time step nodes contact all of their neighbors. In more realistic scenario it is possible that a node may contact only some of its neighbors to spread the rumor. Therefore it is must in real world complex networks, the classic rumor spreading model need to be modified to consider the dependence of rumor spread rate on the degree of the spreader and the informed nodes. We have given a modified rumor spreading model to accommodate these facts. We have given a modified rumor spreading model to accommodate these facts. This new model, has been studied for rumor spreading in complex networks in this work. We have given a modified rumor spreading model to accommodate these facts. This new model, has been studied for rumor spreading in complex networks in this work. Nonlinear rumor spread exponent $\\alpha$ and degree dependent tie strength exponent $\\beta$ in any complex network gives rumor threshold as some finite value. We have given a modified rumor spreading model to accommodate these facts. This new model, has been studied for rumor spreading in complex networks in this work. Nonlinear rumor spread exponent $\\alpha$ and degree dependent tie strength exponent $\\beta$ in any complex network gives rumor threshold as some finite value. In the present work, the modified rumor spreading model has been studied in scale free networks. It is also found that if $ \\alpha $ and $ \\beta $ parameters are tuned to appropriate value, the rumor threshold becomes independent of network size. In earlier rumor spreading models, at each time step nodes contact all of their neighbors. In more realistic scenario it is possible that a node may contact only some of its neighbors to spread the rumor. Therefore it is must in real world complex networks, the classic rumor spreading model need to be modified to consider the dependence of rumor spread rate on the degree of the spreader and the informed nodes. In any social network, rumors can spread may have undesirable effect. In earlier rumor spreading models, at each time step nodes contact all of their neighbors. In more realistic scenario it is possible that a node may contact only some of its neighbors to spread the rumor. Therefore it is must in real world complex networks, the classic rumor spreading model need to be modified to consider the dependence of rumor spread rate on the degree of the spreader and the informed nodes. In any social network, rumors can spread may have undesirable effect. One of the possible solutions to control rumor spread, is to inoculate a certain fraction of nodes against rumors."}, {"paper_id": "17057403", "adju_relevance": 0, "title": "A model of (often mixed) stereotype content: Competence and warmth respectively follow from perceived status and competition", "background_label": "Stereotype research emphasizes systematic processes over seemingly arbitrary contents, but content also may prove systematic.", "method_label": "On the basis of stereotypes' intergroup functions, the stereotype content model hypothesizes that (a) 2 primary dimensions are competence and warmth, (b) frequent mixed clusters combine high warmth with low competence (paternalistic) or high competence with low warmth (envious), and (c) distinct emotions (pity, envy, admiration, contempt) differentiate the 4 competence-warmth combinations. Stereotypically, (d) status predicts high competence, and competition predicts low warmth.", "result_label": "Nine varied samples rated gender, ethnicity, race, class, age, and disability out-groups. Contrary to antipathy models, 2 dimensions mattered, and many stereotypes were mixed, either pitying (low competence, high warmth subordinates) or envying (high competence, low warmth competitors). Stereotypically, status predicted competence, and competition predicted low warmth.", "abstract": "Stereotype research emphasizes systematic processes over seemingly arbitrary contents, but content also may prove systematic. On the basis of stereotypes' intergroup functions, the stereotype content model hypothesizes that (a) 2 primary dimensions are competence and warmth, (b) frequent mixed clusters combine high warmth with low competence (paternalistic) or high competence with low warmth (envious), and (c) distinct emotions (pity, envy, admiration, contempt) differentiate the 4 competence-warmth combinations. On the basis of stereotypes' intergroup functions, the stereotype content model hypothesizes that (a) 2 primary dimensions are competence and warmth, (b) frequent mixed clusters combine high warmth with low competence (paternalistic) or high competence with low warmth (envious), and (c) distinct emotions (pity, envy, admiration, contempt) differentiate the 4 competence-warmth combinations. Stereotypically, (d) status predicts high competence, and competition predicts low warmth. Nine varied samples rated gender, ethnicity, race, class, age, and disability out-groups. Nine varied samples rated gender, ethnicity, race, class, age, and disability out-groups. Contrary to antipathy models, 2 dimensions mattered, and many stereotypes were mixed, either pitying (low competence, high warmth subordinates) or envying (high competence, low warmth competitors). Nine varied samples rated gender, ethnicity, race, class, age, and disability out-groups. Contrary to antipathy models, 2 dimensions mattered, and many stereotypes were mixed, either pitying (low competence, high warmth subordinates) or envying (high competence, low warmth competitors). Stereotypically, status predicted competence, and competition predicted low warmth."}, {"paper_id": "378229", "adju_relevance": 0, "title": "Modelling Valence and Arousal in Facebook posts", "background_label": "Access to expressions of subjective personal posts increased with the popularity of Social Media. However, most of the work in sentiment analysis focuses on predicting only valence from text and usually targeted at a product, rather than affective states.", "abstract": "Access to expressions of subjective personal posts increased with the popularity of Social Media. Access to expressions of subjective personal posts increased with the popularity of Social Media. However, most of the work in sentiment analysis focuses on predicting only valence from text and usually targeted at a product, rather than affective states."}, {"paper_id": "4005247", "adju_relevance": 0, "title": "A study of rumor control strategies on social networks", "background_label": "In this paper we study and evaluate rumor-like methods for combating the spread of rumors on a social network.", "method_label": "We model rumor spread as a diffusion process on a network and suggest the use of an \"anti-rumor\" process similar to the rumor process. We study two natural models by which these anti-rumors may arise. The main metrics we study are the belief time, i.e., the duration for which a person believes the rumor to be true and point of decline, i.e., point after which anti-rumor process dominates the rumor process.", "result_label": "We evaluate our methods by simulating rumor spread and anti-rumor spread on a data set derived from the social networking site Twitter and on a synthetic network generated according to the Watts and Strogatz model. We find that the lifetime of a rumor increases if the delay in detecting it increases, and the relationship is at least linear. Further our findings show that coupling the detection and anti-rumor strategy by embedding agents in the network, we call them beacons, is an effective means of fighting the spread of rumor, even if these beacons do not share information.", "abstract": "In this paper we study and evaluate rumor-like methods for combating the spread of rumors on a social network. We model rumor spread as a diffusion process on a network and suggest the use of an \"anti-rumor\" process similar to the rumor process. We model rumor spread as a diffusion process on a network and suggest the use of an \"anti-rumor\" process similar to the rumor process. We study two natural models by which these anti-rumors may arise. We model rumor spread as a diffusion process on a network and suggest the use of an \"anti-rumor\" process similar to the rumor process. We study two natural models by which these anti-rumors may arise. The main metrics we study are the belief time, i.e., the duration for which a person believes the rumor to be true and point of decline, i.e., point after which anti-rumor process dominates the rumor process. We evaluate our methods by simulating rumor spread and anti-rumor spread on a data set derived from the social networking site Twitter and on a synthetic network generated according to the Watts and Strogatz model. We evaluate our methods by simulating rumor spread and anti-rumor spread on a data set derived from the social networking site Twitter and on a synthetic network generated according to the Watts and Strogatz model. We find that the lifetime of a rumor increases if the delay in detecting it increases, and the relationship is at least linear. We evaluate our methods by simulating rumor spread and anti-rumor spread on a data set derived from the social networking site Twitter and on a synthetic network generated according to the Watts and Strogatz model. We find that the lifetime of a rumor increases if the delay in detecting it increases, and the relationship is at least linear. Further our findings show that coupling the detection and anti-rumor strategy by embedding agents in the network, we call them beacons, is an effective means of fighting the spread of rumor, even if these beacons do not share information."}, {"paper_id": "143454424", "adju_relevance": 0, "title": "The influence of consumer value-based factors on attitude-behavioral intention in social commerce: the differences between high- and low-technology experience groups.", "abstract": ""}, {"paper_id": "15932406", "adju_relevance": 0, "title": "Generating More Specific Questions for Acquiring Attributes of Unknown Concepts from Users", "background_label": "A word unknown to spoken dialogue systems can appear in user utterances, and systems should be capable of acquiring information on it from the conversation partner as a kind of selflearning process.", "method_label": "As a first step, we propose a method for generating more specific questions than simple wh-questions to acquire the attributes, as such questions can narrow down the variation of the following user response and accordingly avoid possible speech recognition errors. Specifically, we obtain an appropriately distributed confidence measure (CM) on the attributes to generate more specific questions. Two basic CMs are defined using (1) character and word distributions in the target database and (2) frequency of occurrence of restaurant attributes on Web pages. These are integrated to complement each other and used as the final CM. We evaluated distributions of the CMs by average errors from the reference.", "result_label": "Results showed that the integrated CM outperformed the two basic CMs.", "abstract": " A word unknown to spoken dialogue systems can appear in user utterances, and systems should be capable of acquiring information on it from the conversation partner as a kind of selflearning process. As a first step, we propose a method for generating more specific questions than simple wh-questions to acquire the attributes, as such questions can narrow down the variation of the following user response and accordingly avoid possible speech recognition errors. As a first step, we propose a method for generating more specific questions than simple wh-questions to acquire the attributes, as such questions can narrow down the variation of the following user response and accordingly avoid possible speech recognition errors. Specifically, we obtain an appropriately distributed confidence measure (CM) on the attributes to generate more specific questions. As a first step, we propose a method for generating more specific questions than simple wh-questions to acquire the attributes, as such questions can narrow down the variation of the following user response and accordingly avoid possible speech recognition errors. Specifically, we obtain an appropriately distributed confidence measure (CM) on the attributes to generate more specific questions. Two basic CMs are defined using (1) character and word distributions in the target database and (2) frequency of occurrence of restaurant attributes on Web pages. As a first step, we propose a method for generating more specific questions than simple wh-questions to acquire the attributes, as such questions can narrow down the variation of the following user response and accordingly avoid possible speech recognition errors. Specifically, we obtain an appropriately distributed confidence measure (CM) on the attributes to generate more specific questions. Two basic CMs are defined using (1) character and word distributions in the target database and (2) frequency of occurrence of restaurant attributes on Web pages. These are integrated to complement each other and used as the final CM. As a first step, we propose a method for generating more specific questions than simple wh-questions to acquire the attributes, as such questions can narrow down the variation of the following user response and accordingly avoid possible speech recognition errors. Specifically, we obtain an appropriately distributed confidence measure (CM) on the attributes to generate more specific questions. Two basic CMs are defined using (1) character and word distributions in the target database and (2) frequency of occurrence of restaurant attributes on Web pages. These are integrated to complement each other and used as the final CM. We evaluated distributions of the CMs by average errors from the reference. Results showed that the integrated CM outperformed the two basic CMs."}, {"paper_id": "32312711", "adju_relevance": 0, "title": "Can Humans Detect the Authenticity of Social Media Accounts? On the Impact of Verbal and Non-Verbal Cues on Credibility Judgements of Twitter Profiles", "method_label": "We tested the hypotheses that the trustworthiness conveyed by the profile picture, morality-related trait adjectives included in the profile summary and the profile owner's gender would increase people's credibility judgments of those fake Twitter profiles. 24 participants assessed 16 fake profiles on their credibility. They also expressed their confidence in their credibility judgements and they answered an open-ended question on which parts of the profile influenced their credibility judgements.", "result_label": "The results showed that overall participants did not trust the Twitter profiles. Furthermore, confidence judgements were higher when profiles included competence-related traits in the profile summaries. Verbal rather than non- verbal cues had thus more influence on participants' judgements. The open-ended responses revealed a large reliance on the content of the profile, which is what the mobile app relies on. We discussed these findings in light of the relative lack of credibility of the profiles generated by the mobile app. The new insights can help improve designs of systems depending on automated social media accounts and will provide useful clues about other applications where cognitive computing plays a role.", "abstract": " We tested the hypotheses that the trustworthiness conveyed by the profile picture, morality-related trait adjectives included in the profile summary and the profile owner's gender would increase people's credibility judgments of those fake Twitter profiles. We tested the hypotheses that the trustworthiness conveyed by the profile picture, morality-related trait adjectives included in the profile summary and the profile owner's gender would increase people's credibility judgments of those fake Twitter profiles. 24 participants assessed 16 fake profiles on their credibility. We tested the hypotheses that the trustworthiness conveyed by the profile picture, morality-related trait adjectives included in the profile summary and the profile owner's gender would increase people's credibility judgments of those fake Twitter profiles. 24 participants assessed 16 fake profiles on their credibility. They also expressed their confidence in their credibility judgements and they answered an open-ended question on which parts of the profile influenced their credibility judgements. The results showed that overall participants did not trust the Twitter profiles. The results showed that overall participants did not trust the Twitter profiles. Furthermore, confidence judgements were higher when profiles included competence-related traits in the profile summaries. The results showed that overall participants did not trust the Twitter profiles. Furthermore, confidence judgements were higher when profiles included competence-related traits in the profile summaries. Verbal rather than non- verbal cues had thus more influence on participants' judgements. The results showed that overall participants did not trust the Twitter profiles. Furthermore, confidence judgements were higher when profiles included competence-related traits in the profile summaries. Verbal rather than non- verbal cues had thus more influence on participants' judgements. The open-ended responses revealed a large reliance on the content of the profile, which is what the mobile app relies on. The results showed that overall participants did not trust the Twitter profiles. Furthermore, confidence judgements were higher when profiles included competence-related traits in the profile summaries. Verbal rather than non- verbal cues had thus more influence on participants' judgements. The open-ended responses revealed a large reliance on the content of the profile, which is what the mobile app relies on. We discussed these findings in light of the relative lack of credibility of the profiles generated by the mobile app. The results showed that overall participants did not trust the Twitter profiles. Furthermore, confidence judgements were higher when profiles included competence-related traits in the profile summaries. Verbal rather than non- verbal cues had thus more influence on participants' judgements. The open-ended responses revealed a large reliance on the content of the profile, which is what the mobile app relies on. We discussed these findings in light of the relative lack of credibility of the profiles generated by the mobile app. The new insights can help improve designs of systems depending on automated social media accounts and will provide useful clues about other applications where cognitive computing plays a role."}, {"paper_id": "8990763", "adju_relevance": 0, "title": "Noun\u2013noun combination: Meaningfulness ratings and lexical statistics for 2,160 word pairs", "background_label": "The combining of individual concepts to form an emergent concept is a fundamental aspect of language, yet much less is known about it than about processing isolated words or sentences. To facilitate research on conceptual combination, we provide meaningfulness ratings for a large set of (2,160) noun-noun pairs.", "method_label": "Half of these pairs (1,080) are reversed versions of the other half (e.g., SKI JACKET and JACKET SKI), to facilitate the comparison of successful and unsuccessful conceptual combination independently of constituent lexical items. The computer code used for obtaining these ratings through a Web interface is provided. To further enhance the usefulness of this resource, ancillary measures obtained from other sources are also provided for each pair. These measures include associate production norms, contextual relatedness in terms of latent semantic analysis distance, total number of letters, phrase-level usage frequency, and word-level usage frequency summed across the words in each pair.", "result_label": "Results of correlation and regression analyses are also provided for a quantitative description of the stimulus set. A subset of these stimuli was used to identify neural correlates of successful conceptual combination Graves, Binder, Desai, Conant, & Seidenberg, (NeuroImage 53:638-646, 2010). The stimuli can be used in other research and also provide benchmark data for evaluating the effectiveness of computational algorithms for predicting meaningfulness of noun-noun pairs.", "abstract": "The combining of individual concepts to form an emergent concept is a fundamental aspect of language, yet much less is known about it than about processing isolated words or sentences. The combining of individual concepts to form an emergent concept is a fundamental aspect of language, yet much less is known about it than about processing isolated words or sentences. To facilitate research on conceptual combination, we provide meaningfulness ratings for a large set of (2,160) noun-noun pairs. Half of these pairs (1,080) are reversed versions of the other half (e.g., SKI JACKET and JACKET SKI), to facilitate the comparison of successful and unsuccessful conceptual combination independently of constituent lexical items. Half of these pairs (1,080) are reversed versions of the other half (e.g., SKI JACKET and JACKET SKI), to facilitate the comparison of successful and unsuccessful conceptual combination independently of constituent lexical items. The computer code used for obtaining these ratings through a Web interface is provided. Half of these pairs (1,080) are reversed versions of the other half (e.g., SKI JACKET and JACKET SKI), to facilitate the comparison of successful and unsuccessful conceptual combination independently of constituent lexical items. The computer code used for obtaining these ratings through a Web interface is provided. To further enhance the usefulness of this resource, ancillary measures obtained from other sources are also provided for each pair. Half of these pairs (1,080) are reversed versions of the other half (e.g., SKI JACKET and JACKET SKI), to facilitate the comparison of successful and unsuccessful conceptual combination independently of constituent lexical items. The computer code used for obtaining these ratings through a Web interface is provided. To further enhance the usefulness of this resource, ancillary measures obtained from other sources are also provided for each pair. These measures include associate production norms, contextual relatedness in terms of latent semantic analysis distance, total number of letters, phrase-level usage frequency, and word-level usage frequency summed across the words in each pair. Results of correlation and regression analyses are also provided for a quantitative description of the stimulus set. Results of correlation and regression analyses are also provided for a quantitative description of the stimulus set. A subset of these stimuli was used to identify neural correlates of successful conceptual combination Graves, Binder, Desai, Conant, & Seidenberg, (NeuroImage 53:638-646, 2010). Results of correlation and regression analyses are also provided for a quantitative description of the stimulus set. A subset of these stimuli was used to identify neural correlates of successful conceptual combination Graves, Binder, Desai, Conant, & Seidenberg, (NeuroImage 53:638-646, 2010). The stimuli can be used in other research and also provide benchmark data for evaluating the effectiveness of computational algorithms for predicting meaningfulness of noun-noun pairs."}, {"paper_id": "10040497", "adju_relevance": 0, "title": "On the usefulness of lexical and syntactic processing in polarity classification of Twitter messages", "background_label": "AbstractMillions of micro texts are published every day on Twitter. Identifying the sentiment present in them can be helpful for measuring the frame of mind of the public, their satisfaction with respect to a product or their support of a social event. In this context, polarity classification is a subfield of sentiment analysis focussed on determining whether the content of a text is objective or subjective, and in the latter case, if it conveys a positive or a negative opinion. Most polarity detection techniques tend to take into account individual terms in the text and even some degree of linguistic knowledge, but they do not usually consider syntactic relations between words.", "abstract": "AbstractMillions of micro texts are published every day on Twitter. AbstractMillions of micro texts are published every day on Twitter. Identifying the sentiment present in them can be helpful for measuring the frame of mind of the public, their satisfaction with respect to a product or their support of a social event. AbstractMillions of micro texts are published every day on Twitter. Identifying the sentiment present in them can be helpful for measuring the frame of mind of the public, their satisfaction with respect to a product or their support of a social event. In this context, polarity classification is a subfield of sentiment analysis focussed on determining whether the content of a text is objective or subjective, and in the latter case, if it conveys a positive or a negative opinion. AbstractMillions of micro texts are published every day on Twitter. Identifying the sentiment present in them can be helpful for measuring the frame of mind of the public, their satisfaction with respect to a product or their support of a social event. In this context, polarity classification is a subfield of sentiment analysis focussed on determining whether the content of a text is objective or subjective, and in the latter case, if it conveys a positive or a negative opinion. Most polarity detection techniques tend to take into account individual terms in the text and even some degree of linguistic knowledge, but they do not usually consider syntactic relations between words."}, {"paper_id": "1282", "adju_relevance": 0, "title": "Morphological Cues for Lexical Semantics", "background_label": "Most natural language processing tasks require lexical semantic information. Automated acquisition of this information would thus increase the robustness and portability of NLP systems.", "method_label": "This paper describes an acquisition method which makes use of fixed correspondences between derivational affixes and lexical semantic information. One advantage of this method, and of other methods that rely only on surface characteristics of language, is that the necessary input is currently available.", "abstract": "Most natural language processing tasks require lexical semantic information. Most natural language processing tasks require lexical semantic information. Automated acquisition of this information would thus increase the robustness and portability of NLP systems. This paper describes an acquisition method which makes use of fixed correspondences between derivational affixes and lexical semantic information. This paper describes an acquisition method which makes use of fixed correspondences between derivational affixes and lexical semantic information. One advantage of this method, and of other methods that rely only on surface characteristics of language, is that the necessary input is currently available."}, {"paper_id": "12046735", "adju_relevance": 0, "title": "Did It Happen? The Pragmatic Complexity of Veridicality Assessment", "background_label": "Natural language understanding depends heavily on assessing veridicality\u2014whether events mentioned in a text are viewed as happening or not\u2014but little consideration is given to this property in current relation and event extraction systems. Furthermore, the work that has been done has generally assumed that veridicality can be captured by lexical semantic properties whereas we show that context and world knowledge play a significant role in shaping veridicality.", "method_label": "We extend the FactBank corpus, which contains semantically driven veridicality annotations, with pragmatically informed ones. Our annotations are more complex than the lexical assumption predicts but systematic enough to be included in computational work on textual understanding. They also indicate that veridicality judgments are not always categorical, and should therefore be modeled as distributions. We build a classifier to automatically assign event veridicality distributions based on our new annotations.", "abstract": "Natural language understanding depends heavily on assessing veridicality\u2014whether events mentioned in a text are viewed as happening or not\u2014but little consideration is given to this property in current relation and event extraction systems. Natural language understanding depends heavily on assessing veridicality\u2014whether events mentioned in a text are viewed as happening or not\u2014but little consideration is given to this property in current relation and event extraction systems. Furthermore, the work that has been done has generally assumed that veridicality can be captured by lexical semantic properties whereas we show that context and world knowledge play a significant role in shaping veridicality. We extend the FactBank corpus, which contains semantically driven veridicality annotations, with pragmatically informed ones. We extend the FactBank corpus, which contains semantically driven veridicality annotations, with pragmatically informed ones. Our annotations are more complex than the lexical assumption predicts but systematic enough to be included in computational work on textual understanding. We extend the FactBank corpus, which contains semantically driven veridicality annotations, with pragmatically informed ones. Our annotations are more complex than the lexical assumption predicts but systematic enough to be included in computational work on textual understanding. They also indicate that veridicality judgments are not always categorical, and should therefore be modeled as distributions. We extend the FactBank corpus, which contains semantically driven veridicality annotations, with pragmatically informed ones. Our annotations are more complex than the lexical assumption predicts but systematic enough to be included in computational work on textual understanding. They also indicate that veridicality judgments are not always categorical, and should therefore be modeled as distributions. We build a classifier to automatically assign event veridicality distributions based on our new annotations."}, {"paper_id": "17339170", "adju_relevance": 0, "title": "Trends in High-Performance Computing", "background_label": "HPC system architectures are shifting from the traditional clusters of homogeneous nodes to clusters of heterogeneous nodes and accelerators. The future of high-performance computing (HPC) from the technologies developed today to showcase the leadership-class compute systems, the supercomputers. These machines are usually designed to achieve the highest possible performance in terms of the number of 64-bit floating-point operations per second (flops).", "result_label": "Their architecture has evolved from early custom design systems to the current clusters of commodity multisocket, multicore systems.", "abstract": "HPC system architectures are shifting from the traditional clusters of homogeneous nodes to clusters of heterogeneous nodes and accelerators. HPC system architectures are shifting from the traditional clusters of homogeneous nodes to clusters of heterogeneous nodes and accelerators. The future of high-performance computing (HPC) from the technologies developed today to showcase the leadership-class compute systems, the supercomputers. HPC system architectures are shifting from the traditional clusters of homogeneous nodes to clusters of heterogeneous nodes and accelerators. The future of high-performance computing (HPC) from the technologies developed today to showcase the leadership-class compute systems, the supercomputers. These machines are usually designed to achieve the highest possible performance in terms of the number of 64-bit floating-point operations per second (flops). Their architecture has evolved from early custom design systems to the current clusters of commodity multisocket, multicore systems."}, {"paper_id": "196831267", "adju_relevance": 0, "title": "Neural Language Model Based Training Data Augmentation for Weakly Supervised Early Rumor Detection", "background_label": "The scarcity and class imbalance of training data are known issues in current rumor detection tasks. We propose a straight-forward and general-purpose data augmentation technique which is beneficial to early rumor detection relying on event propagation patterns.", "abstract": "The scarcity and class imbalance of training data are known issues in current rumor detection tasks. The scarcity and class imbalance of training data are known issues in current rumor detection tasks. We propose a straight-forward and general-purpose data augmentation technique which is beneficial to early rumor detection relying on event propagation patterns."}, {"paper_id": "8812236", "adju_relevance": 0, "title": "Sentiment Expression via Emoticons on Social Media", "background_label": "Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and other NLP tasks as features to ma- chine learning algorithms or as entries of sentiment lexicons. In this paper, we argue that while emoticons are strong and common signals of sentiment expression on social media the relationship between emoticons and sentiment polarity are not always clear. Thus, any algorithm that deals with sentiment polarity should take emoticons into account but extreme cau- tion should be exercised in which emoticons to depend on.", "method_label": "First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons. The second analysis examined clustering of words and emoti- cons to better understand the meaning conveyed by the emoti- cons. The third analysis compared the sentiment polarity of microblog posts before and after emoticons were removed from the text. The last analysis tested the hypothesis that removing emoticons from text hurts sentiment classification by training two machine learning models with and without emoticons in the text respectively.", "result_label": "The results confirms the arguments that: 1) a few emoticons are strong and reliable signals of sentiment polarity and one should take advantage of them in any senti- ment analysis; 2) a large group of the emoticons conveys com- plicated sentiment hence they should be treated with extreme caution.", "abstract": "Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and other NLP tasks as features to ma- chine learning algorithms or as entries of sentiment lexicons. Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and other NLP tasks as features to ma- chine learning algorithms or as entries of sentiment lexicons. In this paper, we argue that while emoticons are strong and common signals of sentiment expression on social media the relationship between emoticons and sentiment polarity are not always clear. Emoticons (e.g., :) and :( ) have been widely used in sentiment analysis and other NLP tasks as features to ma- chine learning algorithms or as entries of sentiment lexicons. In this paper, we argue that while emoticons are strong and common signals of sentiment expression on social media the relationship between emoticons and sentiment polarity are not always clear. Thus, any algorithm that deals with sentiment polarity should take emoticons into account but extreme cau- tion should be exercised in which emoticons to depend on. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons. The second analysis examined clustering of words and emoti- cons to better understand the meaning conveyed by the emoti- cons. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons. The second analysis examined clustering of words and emoti- cons to better understand the meaning conveyed by the emoti- cons. The third analysis compared the sentiment polarity of microblog posts before and after emoticons were removed from the text. First, to demonstrate the prevalence of emoticons on social media, we analyzed the frequency of emoticons in a large re- cent Twitter data set. Then we carried out four analyses to examine the relationship between emoticons and sentiment polarity as well as the contexts in which emoticons are used. The first analysis surveyed a group of participants for their perceived sentiment polarity of the most frequent emoticons. The second analysis examined clustering of words and emoti- cons to better understand the meaning conveyed by the emoti- cons. The third analysis compared the sentiment polarity of microblog posts before and after emoticons were removed from the text. The last analysis tested the hypothesis that removing emoticons from text hurts sentiment classification by training two machine learning models with and without emoticons in the text respectively. The results confirms the arguments that: 1) a few emoticons are strong and reliable signals of sentiment polarity and one should take advantage of them in any senti- ment analysis; 2) a large group of the emoticons conveys com- plicated sentiment hence they should be treated with extreme caution."}, {"paper_id": "118988729", "adju_relevance": 0, "title": "A Microphotonic Astrocomb", "background_label": "One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers.", "method_label": "Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer.", "result_label": "As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research.", "abstract": "One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers. Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer. As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research."}, {"paper_id": "14278534", "adju_relevance": 0, "title": "Who gives a tweet?: evaluating microblog content value", "background_label": "While microblog readers have a wide variety of reactions to the content they see, studies have tended to focus on extremes such as retweeting and unfollowing.", "method_label": "To understand the broad continuum of reactions in-between, which are typically not shared publicly, we designed a website that collected the first large corpus of follower ratings on Twitter updates. Using our dataset of over 43,000 voluntary ratings, we find that nearly 36% of the rated tweets are worth reading, 25% are not, and 39% are middling.", "result_label": "These results suggest that users tolerate a large amount of less-desired content in their feeds. We find that users value information sharing and random thoughts above me-oriented or presence updates. We also offer insight into evolving social norms, such as lack of context and misuse of @mentions and hashtags. We discuss implications for emerging practice and tool design.", "abstract": "While microblog readers have a wide variety of reactions to the content they see, studies have tended to focus on extremes such as retweeting and unfollowing. To understand the broad continuum of reactions in-between, which are typically not shared publicly, we designed a website that collected the first large corpus of follower ratings on Twitter updates. To understand the broad continuum of reactions in-between, which are typically not shared publicly, we designed a website that collected the first large corpus of follower ratings on Twitter updates. Using our dataset of over 43,000 voluntary ratings, we find that nearly 36% of the rated tweets are worth reading, 25% are not, and 39% are middling. These results suggest that users tolerate a large amount of less-desired content in their feeds. These results suggest that users tolerate a large amount of less-desired content in their feeds. We find that users value information sharing and random thoughts above me-oriented or presence updates. These results suggest that users tolerate a large amount of less-desired content in their feeds. We find that users value information sharing and random thoughts above me-oriented or presence updates. We also offer insight into evolving social norms, such as lack of context and misuse of @mentions and hashtags. These results suggest that users tolerate a large amount of less-desired content in their feeds. We find that users value information sharing and random thoughts above me-oriented or presence updates. We also offer insight into evolving social norms, such as lack of context and misuse of @mentions and hashtags. We discuss implications for emerging practice and tool design."}, {"paper_id": "5191015", "adju_relevance": 0, "title": "The application of certainty factors to neural computing for rule discovery.", "background_label": "Discovery of domain principles has been a major long-term goal for scientists.", "abstract": "Discovery of domain principles has been a major long-term goal for scientists."}, {"paper_id": "57375726", "adju_relevance": 0, "title": "Event detection in Twitter: A keyword volume approach", "background_label": "Event detection using social media streams needs a set of informative features with strong signals that need minimal preprocessing and are highly associated with events of interest. Identifying these informative features as keywords from Twitter is challenging, as people use informal language to express their thoughts and feelings. This informality includes acronyms, misspelled words, synonyms, transliteration and ambiguous terms.", "method_label": "In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. The volume of these keywords is tracked in real time to identify the events of interest in a binary classification scheme. We use keywords within word-pairs to capture the context. The proposed method is to binarize vectors of daily counts for each word-pair by applying a spike detection temporal filter, then use the Jaccard metric to measure the similarity of the binary vector for each word-pair with the binary vector describing event occurrence. The top n word-pairs are used as features to classify any day to be an event or non-event day. The selected features are tested using multiple classifiers such as Naive Bayes, SVM, Logistic Regression, KNN and decision trees.", "result_label": "They all produced AUC ROC scores up to 0.91 and F1 scores up to 0.79. The experiment is performed using the English language in multiple cities such as Melbourne, Sydney and Brisbane as well as the Indonesian language in Jakarta. The two experiments, comprising different languages and locations, yielded similar results.", "abstract": "Event detection using social media streams needs a set of informative features with strong signals that need minimal preprocessing and are highly associated with events of interest. Event detection using social media streams needs a set of informative features with strong signals that need minimal preprocessing and are highly associated with events of interest. Identifying these informative features as keywords from Twitter is challenging, as people use informal language to express their thoughts and feelings. Event detection using social media streams needs a set of informative features with strong signals that need minimal preprocessing and are highly associated with events of interest. Identifying these informative features as keywords from Twitter is challenging, as people use informal language to express their thoughts and feelings. This informality includes acronyms, misspelled words, synonyms, transliteration and ambiguous terms. In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. The volume of these keywords is tracked in real time to identify the events of interest in a binary classification scheme. In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. The volume of these keywords is tracked in real time to identify the events of interest in a binary classification scheme. We use keywords within word-pairs to capture the context. In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. The volume of these keywords is tracked in real time to identify the events of interest in a binary classification scheme. We use keywords within word-pairs to capture the context. The proposed method is to binarize vectors of daily counts for each word-pair by applying a spike detection temporal filter, then use the Jaccard metric to measure the similarity of the binary vector for each word-pair with the binary vector describing event occurrence. In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. The volume of these keywords is tracked in real time to identify the events of interest in a binary classification scheme. We use keywords within word-pairs to capture the context. The proposed method is to binarize vectors of daily counts for each word-pair by applying a spike detection temporal filter, then use the Jaccard metric to measure the similarity of the binary vector for each word-pair with the binary vector describing event occurrence. The top n word-pairs are used as features to classify any day to be an event or non-event day. In this paper, we propose an efficient method to select the keywords frequently used in Twitter that are mostly associated with events of interest such as protests. The volume of these keywords is tracked in real time to identify the events of interest in a binary classification scheme. We use keywords within word-pairs to capture the context. The proposed method is to binarize vectors of daily counts for each word-pair by applying a spike detection temporal filter, then use the Jaccard metric to measure the similarity of the binary vector for each word-pair with the binary vector describing event occurrence. The top n word-pairs are used as features to classify any day to be an event or non-event day. The selected features are tested using multiple classifiers such as Naive Bayes, SVM, Logistic Regression, KNN and decision trees. They all produced AUC ROC scores up to 0.91 and F1 scores up to 0.79. They all produced AUC ROC scores up to 0.91 and F1 scores up to 0.79. The experiment is performed using the English language in multiple cities such as Melbourne, Sydney and Brisbane as well as the Indonesian language in Jakarta. They all produced AUC ROC scores up to 0.91 and F1 scores up to 0.79. The experiment is performed using the English language in multiple cities such as Melbourne, Sydney and Brisbane as well as the Indonesian language in Jakarta. The two experiments, comprising different languages and locations, yielded similar results."}, {"paper_id": "16137301", "adju_relevance": 0, "title": "GeoTextTagger: High-Precision Location Tagging of Textual Documents using a Natural Language Processing Approach", "background_label": "Location tagging, also known as geotagging or geolocation, is the process of assigning geographical coordinates to input data.", "abstract": "Location tagging, also known as geotagging or geolocation, is the process of assigning geographical coordinates to input data."}, {"paper_id": "2239324", "adju_relevance": 0, "title": "Are You Sure That This Happened? Assessing the Factuality Degree of Events in Text", "background_label": "Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual. Event factuality involves two separate levels of information. On the one hand, it deals with polarity, which distinguishes between positive and negative instantiations of events. On the other, it has to do with degrees of certainty (e.g., possible, probable), an information level generally subsumed under the category of epistemic modality.", "abstract": "Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual. Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual. Event factuality involves two separate levels of information. Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual. Event factuality involves two separate levels of information. On the one hand, it deals with polarity, which distinguishes between positive and negative instantiations of events. Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse. Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual. Event factuality involves two separate levels of information. On the one hand, it deals with polarity, which distinguishes between positive and negative instantiations of events. On the other, it has to do with degrees of certainty (e.g., possible, probable), an information level generally subsumed under the category of epistemic modality."}, {"paper_id": "21187480", "adju_relevance": 0, "title": "Sickness Absence and Works Councils: Evidence from German Individual and Linked Employer-Employee Data", "background_label": "Using both household and linked employer-employee data for Germany, we assess the effects of non-union representation in the form of works councils on (1) individual sickness absence rates and (2) a subjective measure of personnel problems due to sickness absence as perceived by a firm's management.", "result_label": "We find that the existence of a works council is positively correlated with the incidence and the annual duration of absence. We observe a more pronounced correlation in western Germany which can also be interpreted causally. Further, personnel problems due to absence are more likely to occur in plants with a works council.", "abstract": "Using both household and linked employer-employee data for Germany, we assess the effects of non-union representation in the form of works councils on (1) individual sickness absence rates and (2) a subjective measure of personnel problems due to sickness absence as perceived by a firm's management. We find that the existence of a works council is positively correlated with the incidence and the annual duration of absence. We find that the existence of a works council is positively correlated with the incidence and the annual duration of absence. We observe a more pronounced correlation in western Germany which can also be interpreted causally. We find that the existence of a works council is positively correlated with the incidence and the annual duration of absence. We observe a more pronounced correlation in western Germany which can also be interpreted causally. Further, personnel problems due to absence are more likely to occur in plants with a works council."}, {"paper_id": "3882934", "adju_relevance": 0, "title": "*SEM 2012 Shared Task: Resolving the Scope and Focus of Negation", "background_label": "AbstractThe Joint Conference on Lexical and Computational Semantics (*SEM) each year hosts a shared task on semantic related topics. In its first edition held in 2012, the shared task was dedicated to resolving the scope and focus of negation.", "abstract": "AbstractThe Joint Conference on Lexical and Computational Semantics (*SEM) each year hosts a shared task on semantic related topics. AbstractThe Joint Conference on Lexical and Computational Semantics (*SEM) each year hosts a shared task on semantic related topics. In its first edition held in 2012, the shared task was dedicated to resolving the scope and focus of negation."}, {"paper_id": "143590929", "adju_relevance": 0, "title": "Developmental Trends in Lexical Diversity", "method_label": "The procedure for obtaining values for D directly from transcripts using software (vocd) is introduced, and then applied to thirty-two children from the Bristol Study of Language Development (Wells 1985) at ten different ages. A significant developmental trend is shown for D and an indication is given of the average scores and ranges to be expected between the ages of 18 and 42 months and at 5 years for these L1 English speakers.", "result_label": "The meaning attributable to further ranges of values for D is illustrated by analysing the lexical diversity of academic writing, and its wider application is demonstrated with examples from specific language impairment, morphological development, and foreign/second language learning.", "abstract": " The procedure for obtaining values for D directly from transcripts using software (vocd) is introduced, and then applied to thirty-two children from the Bristol Study of Language Development (Wells 1985) at ten different ages. The procedure for obtaining values for D directly from transcripts using software (vocd) is introduced, and then applied to thirty-two children from the Bristol Study of Language Development (Wells 1985) at ten different ages. A significant developmental trend is shown for D and an indication is given of the average scores and ranges to be expected between the ages of 18 and 42 months and at 5 years for these L1 English speakers. The meaning attributable to further ranges of values for D is illustrated by analysing the lexical diversity of academic writing, and its wider application is demonstrated with examples from specific language impairment, morphological development, and foreign/second language learning."}, {"paper_id": "3391127", "adju_relevance": 0, "title": "Investigating Rumor News Using Agreement-Aware Search", "background_label": "Recent years have witnessed a widespread increase of rumor news generated by humans and machines. Therefore, tools for investigating rumor news have become an urgent necessity. One useful function of such tools is to see ways a specific topic or event is represented by presenting different points of view from multiple sources.", "abstract": "Recent years have witnessed a widespread increase of rumor news generated by humans and machines. Recent years have witnessed a widespread increase of rumor news generated by humans and machines. Therefore, tools for investigating rumor news have become an urgent necessity. Recent years have witnessed a widespread increase of rumor news generated by humans and machines. Therefore, tools for investigating rumor news have become an urgent necessity. One useful function of such tools is to see ways a specific topic or event is represented by presenting different points of view from multiple sources."}, {"paper_id": "16256392", "adju_relevance": 0, "title": "On Gobbledygook and Mood of the Philippine Senate: An Exploratory Study on the Readability and Sentiment of Selected Philippine Senators' Microposts", "result_label": "Using the Simple Measure of Gobbledygook (SMOG), tweets of Senators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and Escudero were assessed. Results showed that on the average, the six senators are tweeting at an eight to ten SMOG level. This means that, at least a sixth grader will be able to understand the senators' tweets. Moreover, their tweets are mostly neutral and their sentiments vary in unison at some period of time. This could mean that a senator's tweet sentiment is affected by specific Philippine-based events.", "method_label": "A sentiment analysis was also done to determine the polarity of the senators' respective microposts.", "abstract": " Using the Simple Measure of Gobbledygook (SMOG), tweets of Senators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and Escudero were assessed. A sentiment analysis was also done to determine the polarity of the senators' respective microposts. Using the Simple Measure of Gobbledygook (SMOG), tweets of Senators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and Escudero were assessed. Results showed that on the average, the six senators are tweeting at an eight to ten SMOG level. Using the Simple Measure of Gobbledygook (SMOG), tweets of Senators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and Escudero were assessed. Results showed that on the average, the six senators are tweeting at an eight to ten SMOG level. This means that, at least a sixth grader will be able to understand the senators' tweets. Using the Simple Measure of Gobbledygook (SMOG), tweets of Senators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and Escudero were assessed. Results showed that on the average, the six senators are tweeting at an eight to ten SMOG level. This means that, at least a sixth grader will be able to understand the senators' tweets. Moreover, their tweets are mostly neutral and their sentiments vary in unison at some period of time. Using the Simple Measure of Gobbledygook (SMOG), tweets of Senators Cayetano, Defensor-Santiago, Pangilinan, Marcos, Guingona, and Escudero were assessed. Results showed that on the average, the six senators are tweeting at an eight to ten SMOG level. This means that, at least a sixth grader will be able to understand the senators' tweets. Moreover, their tweets are mostly neutral and their sentiments vary in unison at some period of time. This could mean that a senator's tweet sentiment is affected by specific Philippine-based events."}, {"paper_id": "35414715", "adju_relevance": 0, "title": "Tweet credibility analysis evaluation by improving sentiment dictionary", "method_label": "To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To identify an opinion (positive or negative) about a tweet, sentiment analysis is performed using a semantic orientation dictionary. However, it is a kind of imbalanced data analysis to identify usually very few false tweets and the accuracy is a problem. The accuracy of the originally proposed method was susceptible since the sentiment opinion of most tweets was identified negative by the baseline (namely Takamura's) semantic orientation dictionary. To cope with this problem, a method for extracting sentiment orientations of words and phrases is also proposed to improve the evaluation for analyzing the credibility of tweet information. This method 1) evolutionally learns from a large amount of social data on Twitter, 2) focuses on adjective predicates, and 3) considers co-occurrences with negation expressions or multiple adjectives, between subjects and predicates, etc.", "result_label": "The effects are proven by experiments using a large number of real tweets, in which we could detect rumor tweet much more accurately. In opposition to the baseline semantic dictionary, our method leads to succeed in imbalanced data analysis.", "abstract": "To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To identify an opinion (positive or negative) about a tweet, sentiment analysis is performed using a semantic orientation dictionary. To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To identify an opinion (positive or negative) about a tweet, sentiment analysis is performed using a semantic orientation dictionary. However, it is a kind of imbalanced data analysis to identify usually very few false tweets and the accuracy is a problem. To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To identify an opinion (positive or negative) about a tweet, sentiment analysis is performed using a semantic orientation dictionary. However, it is a kind of imbalanced data analysis to identify usually very few false tweets and the accuracy is a problem. The accuracy of the originally proposed method was susceptible since the sentiment opinion of most tweets was identified negative by the baseline (namely Takamura's) semantic orientation dictionary. To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To identify an opinion (positive or negative) about a tweet, sentiment analysis is performed using a semantic orientation dictionary. However, it is a kind of imbalanced data analysis to identify usually very few false tweets and the accuracy is a problem. The accuracy of the originally proposed method was susceptible since the sentiment opinion of most tweets was identified negative by the baseline (namely Takamura's) semantic orientation dictionary. To cope with this problem, a method for extracting sentiment orientations of words and phrases is also proposed to improve the evaluation for analyzing the credibility of tweet information. To detect false information or rumors spread on Twitter on and after the Great East Japan Earthquake, a tweet credibility assessing method was proposed, based on the topic and opinion classification. The credibility is assessed by calculating the ratio of the same opinions to all opinions about a topic identified by topic models generated using Latent Dirichlet Allocation. To identify an opinion (positive or negative) about a tweet, sentiment analysis is performed using a semantic orientation dictionary. However, it is a kind of imbalanced data analysis to identify usually very few false tweets and the accuracy is a problem. The accuracy of the originally proposed method was susceptible since the sentiment opinion of most tweets was identified negative by the baseline (namely Takamura's) semantic orientation dictionary. To cope with this problem, a method for extracting sentiment orientations of words and phrases is also proposed to improve the evaluation for analyzing the credibility of tweet information. This method 1) evolutionally learns from a large amount of social data on Twitter, 2) focuses on adjective predicates, and 3) considers co-occurrences with negation expressions or multiple adjectives, between subjects and predicates, etc. The effects are proven by experiments using a large number of real tweets, in which we could detect rumor tweet much more accurately. The effects are proven by experiments using a large number of real tweets, in which we could detect rumor tweet much more accurately. In opposition to the baseline semantic dictionary, our method leads to succeed in imbalanced data analysis."}, {"paper_id": "15253141", "adju_relevance": 0, "title": "Automatic Detection of Political Opinions in Tweets", "background_label": "In this paper, we discuss a variety of issues related to opinion mining from microposts, and the challenges they impose on an NLP system, along with an example application we have developed to determine political leanings from a set of pre-election tweets.", "method_label": "While there are a number of sentiment analysis tools available which summarise positive, negative and neutral tweets about a given keyword or topic, these tools generally produce poor results, and operate in a fairly simplistic way, using only the presence of certain positive and negative adjectives as indicators, or simple learning techniques which do not work well on short microposts. On the other hand, intelligent tools which work well on movie and customer reviews cannot be used on microposts due to their brevity and lack of context. Our methods make use of a variety of sophisticated NLP techniques in order to extract more meaningful and higher quality opinions, and incorporate extra-linguistic contextual information.", "abstract": " In this paper, we discuss a variety of issues related to opinion mining from microposts, and the challenges they impose on an NLP system, along with an example application we have developed to determine political leanings from a set of pre-election tweets. While there are a number of sentiment analysis tools available which summarise positive, negative and neutral tweets about a given keyword or topic, these tools generally produce poor results, and operate in a fairly simplistic way, using only the presence of certain positive and negative adjectives as indicators, or simple learning techniques which do not work well on short microposts. While there are a number of sentiment analysis tools available which summarise positive, negative and neutral tweets about a given keyword or topic, these tools generally produce poor results, and operate in a fairly simplistic way, using only the presence of certain positive and negative adjectives as indicators, or simple learning techniques which do not work well on short microposts. On the other hand, intelligent tools which work well on movie and customer reviews cannot be used on microposts due to their brevity and lack of context. While there are a number of sentiment analysis tools available which summarise positive, negative and neutral tweets about a given keyword or topic, these tools generally produce poor results, and operate in a fairly simplistic way, using only the presence of certain positive and negative adjectives as indicators, or simple learning techniques which do not work well on short microposts. On the other hand, intelligent tools which work well on movie and customer reviews cannot be used on microposts due to their brevity and lack of context. Our methods make use of a variety of sophisticated NLP techniques in order to extract more meaningful and higher quality opinions, and incorporate extra-linguistic contextual information."}, {"paper_id": "167436934", "adju_relevance": 0, "title": "The Influence of Multiple Store Environment Cues on Perceived Merchandise Value and Patronage Intentions", "background_label": "Abstract Research on how store environment cues influence consumers\u2019 store choice decision criteria, such as perceived merchandise value and shopping experience costs, is sparse. Especially absent is research on the simultaneous impact of multiple store environment cues.", "method_label": "The authors propose a comprehensive store choice model that includes (1) three types of store environment cues (social, design, and ambient) as exogenous constructs, (2) various store choice criteria (including shopping experience costs that heretofore have not been included in store choice models) as mediating constructs, and (3) store patronage intentions as the endogenous construct. They then empirically examine the extent to which environmental cues influence consumers\u2019 assessments of a store on various store choice criteria and how those assessments, in turn, influence patronage intentions.", "result_label": "The results of two different studies provide support for the model. The authors conclude by discussing the results to develop an agenda for addit...", "abstract": "Abstract Research on how store environment cues influence consumers\u2019 store choice decision criteria, such as perceived merchandise value and shopping experience costs, is sparse. Abstract Research on how store environment cues influence consumers\u2019 store choice decision criteria, such as perceived merchandise value and shopping experience costs, is sparse. Especially absent is research on the simultaneous impact of multiple store environment cues. The authors propose a comprehensive store choice model that includes (1) three types of store environment cues (social, design, and ambient) as exogenous constructs, (2) various store choice criteria (including shopping experience costs that heretofore have not been included in store choice models) as mediating constructs, and (3) store patronage intentions as the endogenous construct. The authors propose a comprehensive store choice model that includes (1) three types of store environment cues (social, design, and ambient) as exogenous constructs, (2) various store choice criteria (including shopping experience costs that heretofore have not been included in store choice models) as mediating constructs, and (3) store patronage intentions as the endogenous construct. They then empirically examine the extent to which environmental cues influence consumers\u2019 assessments of a store on various store choice criteria and how those assessments, in turn, influence patronage intentions. The results of two different studies provide support for the model. The results of two different studies provide support for the model. The authors conclude by discussing the results to develop an agenda for addit..."}, {"paper_id": "18796493", "adju_relevance": 0, "title": "Prototypicality, distinctiveness, and intercorrelation: Analyses of the semantic attributes of living and nonliving concepts.", "background_label": "Many cognitive psychological, computational, and neuropsychological approaches to the organisation of semantic memory have incorporated the idea that concepts are, at least partly, represented in terms of their fine-grained features.", "method_label": "We asked 20 normal volunteers to provide properties of 64 concrete items, drawn from living and nonliving categories, by completing simple sentence stems (e.g., an owl is __, has __, can__). At a later date, the same participants rated the same concepts for prototypicality and familiarity. The features generated were classified as to type of knowledge (sensory, functional, or encyclopaedic), and also quantified with regard to both dominance (the number of participants specifying that property for that concept) and distinctiveness (the proportion of exemplars within a conceptual category of which that feature was considered characteristic).", "result_label": "The results demonstrate that rated prototypicality is related to both the familiarity of the concept and its distance from the average of the exemplars within the same category (the category centroid). The feature database was also used to replicate, resolve, and extend a variety of previous observations on the structure of semantic representations. Specifically, the results of our analyses (1) resolve two conflicting claims regarding the relative ratio of sensory to other kinds of attributes in living vs. nonliving concepts; (2) offer new information regarding the types of features-across different domains-that distinguish concepts from their category coordinates; and (3) corroborate some previous claims of higher intercorrelations between features of living things than those of artefacts.", "abstract": "Many cognitive psychological, computational, and neuropsychological approaches to the organisation of semantic memory have incorporated the idea that concepts are, at least partly, represented in terms of their fine-grained features. We asked 20 normal volunteers to provide properties of 64 concrete items, drawn from living and nonliving categories, by completing simple sentence stems (e.g., an owl is __, has __, can__). We asked 20 normal volunteers to provide properties of 64 concrete items, drawn from living and nonliving categories, by completing simple sentence stems (e.g., an owl is __, has __, can__). At a later date, the same participants rated the same concepts for prototypicality and familiarity. We asked 20 normal volunteers to provide properties of 64 concrete items, drawn from living and nonliving categories, by completing simple sentence stems (e.g., an owl is __, has __, can__). At a later date, the same participants rated the same concepts for prototypicality and familiarity. The features generated were classified as to type of knowledge (sensory, functional, or encyclopaedic), and also quantified with regard to both dominance (the number of participants specifying that property for that concept) and distinctiveness (the proportion of exemplars within a conceptual category of which that feature was considered characteristic). The results demonstrate that rated prototypicality is related to both the familiarity of the concept and its distance from the average of the exemplars within the same category (the category centroid). The results demonstrate that rated prototypicality is related to both the familiarity of the concept and its distance from the average of the exemplars within the same category (the category centroid). The feature database was also used to replicate, resolve, and extend a variety of previous observations on the structure of semantic representations. The results demonstrate that rated prototypicality is related to both the familiarity of the concept and its distance from the average of the exemplars within the same category (the category centroid). The feature database was also used to replicate, resolve, and extend a variety of previous observations on the structure of semantic representations. Specifically, the results of our analyses (1) resolve two conflicting claims regarding the relative ratio of sensory to other kinds of attributes in living vs. nonliving concepts; (2) offer new information regarding the types of features-across different domains-that distinguish concepts from their category coordinates; and (3) corroborate some previous claims of higher intercorrelations between features of living things than those of artefacts."}, {"paper_id": "144863984", "adju_relevance": 0, "title": "Nonverbal cues and interpersonal judgments: Participant and observer perceptions of intimacy, dominance, composure, and formality", "background_label": "Nonverbal cues play a central role in person and social perception.", "method_label": "The impact of such cues on participants\u2019 and observers\u2019 perceptions of relational messages was examined in an experiment in which participants interacted with a confederate who systematically varied his or her communication style then assessed the implicit relational messages in the confederate's communication. Observers watched the videotaped interactions and made similar ratings.", "result_label": "Nonverbal indicators of involvement and pleasantness were found to be systematically related to relational message perceptions of intimacy, dominance, composure, and informality. Participants and observers perceived relational messages in similar ways, although participants tended to give more favorable ratings. Results support a social meaning model of nonverbal interpretations, the multiplicity of nonverbal behaviors responsible for communicating relational messages, and the high congruence between participant and observer perspectives, despite some positivit...", "abstract": "Nonverbal cues play a central role in person and social perception. The impact of such cues on participants\u2019 and observers\u2019 perceptions of relational messages was examined in an experiment in which participants interacted with a confederate who systematically varied his or her communication style then assessed the implicit relational messages in the confederate's communication. The impact of such cues on participants\u2019 and observers\u2019 perceptions of relational messages was examined in an experiment in which participants interacted with a confederate who systematically varied his or her communication style then assessed the implicit relational messages in the confederate's communication. Observers watched the videotaped interactions and made similar ratings. Nonverbal indicators of involvement and pleasantness were found to be systematically related to relational message perceptions of intimacy, dominance, composure, and informality. Nonverbal indicators of involvement and pleasantness were found to be systematically related to relational message perceptions of intimacy, dominance, composure, and informality. Participants and observers perceived relational messages in similar ways, although participants tended to give more favorable ratings. Nonverbal indicators of involvement and pleasantness were found to be systematically related to relational message perceptions of intimacy, dominance, composure, and informality. Participants and observers perceived relational messages in similar ways, although participants tended to give more favorable ratings. Results support a social meaning model of nonverbal interpretations, the multiplicity of nonverbal behaviors responsible for communicating relational messages, and the high congruence between participant and observer perspectives, despite some positivit..."}, {"paper_id": "10460485", "adju_relevance": 0, "title": "Computing Lexical Contrast", "background_label": "Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as {\\rm hot} and {\\rm cold}. Opposites are of many kinds such as antipodals, complementaries, and gradable. However, existing lexicons often do not classify opposites into the different kinds. (For example, there exists the pair of opposites {\\rm hot} and {\\rm cold} such that {\\rm tropical} is related to {\\rm hot,} and {\\rm freezing} is related to {\\rm cold}.) We will call this the contrast hypothesis.", "method_label": "They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as {\\rm warm} and {\\rm cold} or {\\rm tropical} and {\\rm freezing}. We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process, we flesh out key features of different kinds of opposites. We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis, corpus statistics, and the structure of a {\\it Roget}-like thesaurus.", "result_label": "We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words, $A$ and $B$, are contrasting, then there is a pair of opposites, $C$ and $D$, such that $A$ and $C$ are strongly related and $B$ and $D$ are strongly related. We show that the proposed measure of lexical contrast obtains high precision and large coverage, outperforming existing methods.", "abstract": "Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as {\\rm hot} and {\\rm cold}. Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as {\\rm hot} and {\\rm cold}. Opposites are of many kinds such as antipodals, complementaries, and gradable. Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as {\\rm hot} and {\\rm cold}. Opposites are of many kinds such as antipodals, complementaries, and gradable. However, existing lexicons often do not classify opposites into the different kinds. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as {\\rm warm} and {\\rm cold} or {\\rm tropical} and {\\rm freezing}. We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words, $A$ and $B$, are contrasting, then there is a pair of opposites, $C$ and $D$, such that $A$ and $C$ are strongly related and $B$ and $D$ are strongly related. Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as {\\rm hot} and {\\rm cold}. Opposites are of many kinds such as antipodals, complementaries, and gradable. However, existing lexicons often do not classify opposites into the different kinds. (For example, there exists the pair of opposites {\\rm hot} and {\\rm cold} such that {\\rm tropical} is related to {\\rm hot,} and {\\rm freezing} is related to {\\rm cold}.) Knowing the degree of semantic contrast between words has widespread application in natural language processing, including machine translation, information retrieval, and dialogue systems. Manually-created lexicons focus on opposites, such as {\\rm hot} and {\\rm cold}. Opposites are of many kinds such as antipodals, complementaries, and gradable. However, existing lexicons often do not classify opposites into the different kinds. (For example, there exists the pair of opposites {\\rm hot} and {\\rm cold} such that {\\rm tropical} is related to {\\rm hot,} and {\\rm freezing} is related to {\\rm cold}.) We will call this the contrast hypothesis. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as {\\rm warm} and {\\rm cold} or {\\rm tropical} and {\\rm freezing}. We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as {\\rm warm} and {\\rm cold} or {\\rm tropical} and {\\rm freezing}. We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process, we flesh out key features of different kinds of opposites. They also do not explicitly list word pairs that are not opposites but yet have some degree of contrast in meaning, such as {\\rm warm} and {\\rm cold} or {\\rm tropical} and {\\rm freezing}. We begin with a large crowdsourcing experiment to determine the amount of human agreement on the concept of oppositeness and its different kinds. In the process, we flesh out key features of different kinds of opposites. We then present an automatic and empirical measure of lexical contrast that relies on the contrast hypothesis, corpus statistics, and the structure of a {\\it Roget}-like thesaurus. We propose an automatic method to identify contrasting word pairs that is based on the hypothesis that if a pair of words, $A$ and $B$, are contrasting, then there is a pair of opposites, $C$ and $D$, such that $A$ and $C$ are strongly related and $B$ and $D$ are strongly related. We show that the proposed measure of lexical contrast obtains high precision and large coverage, outperforming existing methods."}, {"paper_id": "9828393", "adju_relevance": 0, "title": "The role of polarity in antonym and synonym conceptual knowledge: Evidence from stroke aphasia and multidimensional ratings of abstract words", "background_label": "This study describes an investigation of different types of semantic relationship among abstract words: antonyms (e.g. good-bad), synonyms (e.g.", "abstract": "This study describes an investigation of different types of semantic relationship among abstract words: antonyms (e.g. This study describes an investigation of different types of semantic relationship among abstract words: antonyms (e.g. good-bad), synonyms (e.g."}, {"paper_id": "219199", "adju_relevance": 0, "title": "How Information Snowballs: Exploring the Role of Exposure in Online Rumor Propagation", "background_label": "In this paper we highlight three distinct approaches to studying rumor dynamics\u00e2\u0080\u0094volume, exposure, and content production. Expanding upon prior work, which has focused on rumor volume, we argue that considering the size of the exposed population is a vital component of understanding rumoring.", "method_label": "Additionally, by combining all three approaches we discover subtle features of rumoring behavior that would have been missed by applying each approach in isolation. Using a case study of rumoring on Twitter during a hostage crisis in Sydney, Australia, we apply a mixed-methods framework to explore rumoring and its consequences through these three lenses, focusing on the added dimension of exposure in particular. Our approach demonstrates the importance of considering both rumor content and the people engaging with rumor content to arrive at a more holistic understanding of communication dynamics.", "result_label": "These results have implications for emergency responders and official use of social media during crisis management.", "abstract": "In this paper we highlight three distinct approaches to studying rumor dynamics\u00e2\u0080\u0094volume, exposure, and content production. In this paper we highlight three distinct approaches to studying rumor dynamics\u00e2\u0080\u0094volume, exposure, and content production. Expanding upon prior work, which has focused on rumor volume, we argue that considering the size of the exposed population is a vital component of understanding rumoring. Additionally, by combining all three approaches we discover subtle features of rumoring behavior that would have been missed by applying each approach in isolation. Additionally, by combining all three approaches we discover subtle features of rumoring behavior that would have been missed by applying each approach in isolation. Using a case study of rumoring on Twitter during a hostage crisis in Sydney, Australia, we apply a mixed-methods framework to explore rumoring and its consequences through these three lenses, focusing on the added dimension of exposure in particular. Additionally, by combining all three approaches we discover subtle features of rumoring behavior that would have been missed by applying each approach in isolation. Using a case study of rumoring on Twitter during a hostage crisis in Sydney, Australia, we apply a mixed-methods framework to explore rumoring and its consequences through these three lenses, focusing on the added dimension of exposure in particular. Our approach demonstrates the importance of considering both rumor content and the people engaging with rumor content to arrive at a more holistic understanding of communication dynamics. These results have implications for emergency responders and official use of social media during crisis management."}, {"paper_id": "143509740", "adju_relevance": 0, "title": "Rumor clustering, consensus, and polarization: Dynamic social impact and self-organization of hearsay", "background_label": "Abstract The \u201cbottom-up\u201d self-organization of shared sense-making and group decision-making through rumor (unverified information statements in circulation) was investigated in two computer-mediated laboratory experiments on the effects of network clustering (i.e., structural \u201ccliquishness\u201d).", "method_label": "Participants in 27 (Study 1) and 33 (Study 2) 16-person laboratory-created networks at three institutions discussed ambiguous situations (e.g., \u201ca professor was found dead\u201d) and then chose one of four possible rumors in a judgment task (e.g., \u201che was killed by an angry student\u201d) to explain each situation. Static lattice, \u201cribbon\u201d (street-like), \u201cfamily\u201d (connected clusters), random, and dynamic-random configurations were employed. Network clustering led to rumor clustering (emergence of homogenous pockets of rumor choices). There was also evidence for increased consensus, rumor persistence, and belief polarization.", "result_label": "Belief polarization was amplified by rumor clustering and consensus. In addition, the extent to which \u201cneighbors\u201d were unified in their disagreement (versus agreement) with the participant tempered confidence increases and strongly affected the selection of rumors that \u201cmade the most sense.\u201d Results explain rumor persistence and variation, document the role of patterns of connectivity and dynamic social influence processes in unverified collective beliefs, and suggest modification of Dynamic Social Impact Theory to include belief polarization mediated by emergent \u201cecho chambers.\u201d", "abstract": "Abstract The \u201cbottom-up\u201d self-organization of shared sense-making and group decision-making through rumor (unverified information statements in circulation) was investigated in two computer-mediated laboratory experiments on the effects of network clustering (i.e., structural \u201ccliquishness\u201d). Participants in 27 (Study 1) and 33 (Study 2) 16-person laboratory-created networks at three institutions discussed ambiguous situations (e.g., \u201ca professor was found dead\u201d) and then chose one of four possible rumors in a judgment task (e.g., \u201che was killed by an angry student\u201d) to explain each situation. Participants in 27 (Study 1) and 33 (Study 2) 16-person laboratory-created networks at three institutions discussed ambiguous situations (e.g., \u201ca professor was found dead\u201d) and then chose one of four possible rumors in a judgment task (e.g., \u201che was killed by an angry student\u201d) to explain each situation. Static lattice, \u201cribbon\u201d (street-like), \u201cfamily\u201d (connected clusters), random, and dynamic-random configurations were employed. Participants in 27 (Study 1) and 33 (Study 2) 16-person laboratory-created networks at three institutions discussed ambiguous situations (e.g., \u201ca professor was found dead\u201d) and then chose one of four possible rumors in a judgment task (e.g., \u201che was killed by an angry student\u201d) to explain each situation. Static lattice, \u201cribbon\u201d (street-like), \u201cfamily\u201d (connected clusters), random, and dynamic-random configurations were employed. Network clustering led to rumor clustering (emergence of homogenous pockets of rumor choices). Participants in 27 (Study 1) and 33 (Study 2) 16-person laboratory-created networks at three institutions discussed ambiguous situations (e.g., \u201ca professor was found dead\u201d) and then chose one of four possible rumors in a judgment task (e.g., \u201che was killed by an angry student\u201d) to explain each situation. Static lattice, \u201cribbon\u201d (street-like), \u201cfamily\u201d (connected clusters), random, and dynamic-random configurations were employed. Network clustering led to rumor clustering (emergence of homogenous pockets of rumor choices). There was also evidence for increased consensus, rumor persistence, and belief polarization. Belief polarization was amplified by rumor clustering and consensus. Belief polarization was amplified by rumor clustering and consensus. In addition, the extent to which \u201cneighbors\u201d were unified in their disagreement (versus agreement) with the participant tempered confidence increases and strongly affected the selection of rumors that \u201cmade the most sense.\u201d Results explain rumor persistence and variation, document the role of patterns of connectivity and dynamic social influence processes in unverified collective beliefs, and suggest modification of Dynamic Social Impact Theory to include belief polarization mediated by emergent \u201cecho chambers.\u201d"}, {"paper_id": "6044621", "adju_relevance": 0, "title": "Automatic Prediction of Perceived Traits Using Visual Cues under Varied Situational Context", "background_label": "Automatic assessment of human personality traits is a non-trivial problem, especially when perception is marked over a fairly short duration of time. In this study, thin slices of behavioral data are analyzed.", "method_label": "Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. The relationship between various traits is investigated to obtain a better understanding of observer perception and assessment. Perception change is also considered when participants interact with several virtual characters each with a distinct emotional style. Encapsulating these observations and analysis, an automated system is proposed by firstly computing low level visual features. Using these features a separate model is trained for each trait and performance is evaluated. Further, a weighted model based on rater credibility is proposed to address observer biases.", "result_label": "Experimental results indicate that a weighted model show major improvement for automatic prediction of perceived physical and behavioral traits.", "abstract": "Automatic assessment of human personality traits is a non-trivial problem, especially when perception is marked over a fairly short duration of time. Automatic assessment of human personality traits is a non-trivial problem, especially when perception is marked over a fairly short duration of time. In this study, thin slices of behavioral data are analyzed. Perceived physical and behavioral traits are assessed by external observers (raters). Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. The relationship between various traits is investigated to obtain a better understanding of observer perception and assessment. Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. The relationship between various traits is investigated to obtain a better understanding of observer perception and assessment. Perception change is also considered when participants interact with several virtual characters each with a distinct emotional style. Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. The relationship between various traits is investigated to obtain a better understanding of observer perception and assessment. Perception change is also considered when participants interact with several virtual characters each with a distinct emotional style. Encapsulating these observations and analysis, an automated system is proposed by firstly computing low level visual features. Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. The relationship between various traits is investigated to obtain a better understanding of observer perception and assessment. Perception change is also considered when participants interact with several virtual characters each with a distinct emotional style. Encapsulating these observations and analysis, an automated system is proposed by firstly computing low level visual features. Using these features a separate model is trained for each trait and performance is evaluated. Perceived physical and behavioral traits are assessed by external observers (raters). Along with the big-five personality trait model, four new traits are introduced and assessed in this work. The relationship between various traits is investigated to obtain a better understanding of observer perception and assessment. Perception change is also considered when participants interact with several virtual characters each with a distinct emotional style. Encapsulating these observations and analysis, an automated system is proposed by firstly computing low level visual features. Using these features a separate model is trained for each trait and performance is evaluated. Further, a weighted model based on rater credibility is proposed to address observer biases. Experimental results indicate that a weighted model show major improvement for automatic prediction of perceived physical and behavioral traits."}, {"paper_id": "16110289", "adju_relevance": 0, "title": "Comparing parameterizations of pitch register and its discontinuities at prosodic boundaries for Hungarian", "background_label": "We examined how well prosodic boundary strength can be captured by two declination stylization methods as well as by four different representations of pitch register. In the stylization proposed by Liebermann et al.", "method_label": "(1985) base- and topline are fitted to peaks and valleys of the pitch contour, whereas in Reichel&Mady (2013) these lines are fitted to medians below and above certain pitch percentiles. From each of the stylizations four feature pools were induced representing different aspects of register discontinuity at word boundaries: discontinuities related to the base-, mid-, and topline, as well as to the range between base- and topline.", "result_label": "Concerning stylization the median-based fitting approach turned out to be more robust with respect to declination line crossing errors and yielded base-, topline and range-related discontinuity characteristics with higher correlations to perceived boundary strength. Concerning register representation, for the peak/valley fitting approach the base- and  topline patterns showed weaker correspondences to boundary strength than the other feature pools. We furthermore trained generalized linear regression models for boundary strength prediction on each feature pool. It turned out that neither the stylization method nor the register representation had a significant influence on the overall good prediction performance.", "abstract": "We examined how well prosodic boundary strength can be captured by two declination stylization methods as well as by four different representations of pitch register. We examined how well prosodic boundary strength can be captured by two declination stylization methods as well as by four different representations of pitch register. In the stylization proposed by Liebermann et al. (1985) base- and topline are fitted to peaks and valleys of the pitch contour, whereas in Reichel&Mady (2013) these lines are fitted to medians below and above certain pitch percentiles. (1985) base- and topline are fitted to peaks and valleys of the pitch contour, whereas in Reichel&Mady (2013) these lines are fitted to medians below and above certain pitch percentiles. From each of the stylizations four feature pools were induced representing different aspects of register discontinuity at word boundaries: discontinuities related to the base-, mid-, and topline, as well as to the range between base- and topline. Concerning stylization the median-based fitting approach turned out to be more robust with respect to declination line crossing errors and yielded base-, topline and range-related discontinuity characteristics with higher correlations to perceived boundary strength. Concerning stylization the median-based fitting approach turned out to be more robust with respect to declination line crossing errors and yielded base-, topline and range-related discontinuity characteristics with higher correlations to perceived boundary strength. Concerning register representation, for the peak/valley fitting approach the base- and  topline patterns showed weaker correspondences to boundary strength than the other feature pools. Concerning stylization the median-based fitting approach turned out to be more robust with respect to declination line crossing errors and yielded base-, topline and range-related discontinuity characteristics with higher correlations to perceived boundary strength. Concerning register representation, for the peak/valley fitting approach the base- and  topline patterns showed weaker correspondences to boundary strength than the other feature pools. We furthermore trained generalized linear regression models for boundary strength prediction on each feature pool. Concerning stylization the median-based fitting approach turned out to be more robust with respect to declination line crossing errors and yielded base-, topline and range-related discontinuity characteristics with higher correlations to perceived boundary strength. Concerning register representation, for the peak/valley fitting approach the base- and  topline patterns showed weaker correspondences to boundary strength than the other feature pools. We furthermore trained generalized linear regression models for boundary strength prediction on each feature pool. It turned out that neither the stylization method nor the register representation had a significant influence on the overall good prediction performance."}, {"paper_id": "17482871", "adju_relevance": 0, "title": "Similarities and Differences in Chinese and Caucasian Adults' Use of Facial Cues for Trustworthiness Judgments", "background_label": "BACKGROUND All cultural groups in the world place paramount value on interpersonal trust. Existing research suggests that although accurate judgments of another's trustworthiness require extensive interactions with the person, we often make trustworthiness judgments based on facial cues on the first encounter. However, little is known about what facial cues are used for such judgments and what the bases are on which individuals make their trustworthiness judgments.", "abstract": "BACKGROUND All cultural groups in the world place paramount value on interpersonal trust. BACKGROUND All cultural groups in the world place paramount value on interpersonal trust. Existing research suggests that although accurate judgments of another's trustworthiness require extensive interactions with the person, we often make trustworthiness judgments based on facial cues on the first encounter. BACKGROUND All cultural groups in the world place paramount value on interpersonal trust. Existing research suggests that although accurate judgments of another's trustworthiness require extensive interactions with the person, we often make trustworthiness judgments based on facial cues on the first encounter. However, little is known about what facial cues are used for such judgments and what the bases are on which individuals make their trustworthiness judgments."}, {"paper_id": "34511131", "adju_relevance": 0, "title": "FactBank: a corpus annotated with event factuality", "background_label": "Recent work in computational linguistics points out the need for systems to be sensitive to the veracity or factuality of events as mentioned in text; that is, to recognize whether events are presented as corresponding to actual situations in the world, situations that have not happened, or situations of uncertain interpretation. Event factuality is an important aspect of the representation of events in discourse, but the annotation of such information poses a representational challenge, largely because factuality is expressed through the interaction of numerous linguistic markers and constructions. Many of these markers are already encoded in existing corpora, albeit in a somewhat fragmented way.", "abstract": "Recent work in computational linguistics points out the need for systems to be sensitive to the veracity or factuality of events as mentioned in text; that is, to recognize whether events are presented as corresponding to actual situations in the world, situations that have not happened, or situations of uncertain interpretation. Recent work in computational linguistics points out the need for systems to be sensitive to the veracity or factuality of events as mentioned in text; that is, to recognize whether events are presented as corresponding to actual situations in the world, situations that have not happened, or situations of uncertain interpretation. Event factuality is an important aspect of the representation of events in discourse, but the annotation of such information poses a representational challenge, largely because factuality is expressed through the interaction of numerous linguistic markers and constructions. Recent work in computational linguistics points out the need for systems to be sensitive to the veracity or factuality of events as mentioned in text; that is, to recognize whether events are presented as corresponding to actual situations in the world, situations that have not happened, or situations of uncertain interpretation. Event factuality is an important aspect of the representation of events in discourse, but the annotation of such information poses a representational challenge, largely because factuality is expressed through the interaction of numerous linguistic markers and constructions. Many of these markers are already encoded in existing corpora, albeit in a somewhat fragmented way."}, {"paper_id": "1649240", "adju_relevance": 0, "title": "Factuality Detection on the Cheap: Inferring Factuality for Increased Precision in Detecting Negated Events", "background_label": "AbstractThis paper describes a system for discriminating between factual and non-factual contexts, trained on weakly labeled data by taking advantage of information implicit in annotations of negated events.", "method_label": "In addition to evaluating factuality detection in isolation, we also evaluate its impact on a system for event detection.", "result_label": "The two components for factuality detection and event detection form part of a system for identifying negative factual events, or counterfacts, with top-ranked results in the *SEM 2012 shared task.", "abstract": "AbstractThis paper describes a system for discriminating between factual and non-factual contexts, trained on weakly labeled data by taking advantage of information implicit in annotations of negated events. In addition to evaluating factuality detection in isolation, we also evaluate its impact on a system for event detection. The two components for factuality detection and event detection form part of a system for identifying negative factual events, or counterfacts, with top-ranked results in the *SEM 2012 shared task."}, {"paper_id": "35291896", "adju_relevance": 0, "title": "Beyond the abstract-concrete dichotomy: mode of acquisition, concreteness, imageability, familiarity, age of acquisition, context availability, and abstractness norms for a set of 417 Italian words.", "background_label": "MoA refers to the way in which concepts are acquired: through experience, through language, or through both.", "method_label": "We asked 250 participants to rate 417 words on seven dimensions: age of acquisition, concreteness, familiarity, context availability, imageability, abstractness, and MoA. The data were analyzed by considering MoA ratings and their relationship with the other psycholinguistic variables. Distributions for concreteness, abstractness, and MoA ratings indicate that they are qualitatively different.", "result_label": "A partial correlation analysis revealed that MoA is an independent predictor of concreteness or abstractness, and a hierarchical multiple regression analysis confirmed MoA as being a valid predictor of abstractness. Strong correlations with measures for the English translation equivalents in the MRC database confirmed the reliability of our norms.", "abstract": " MoA refers to the way in which concepts are acquired: through experience, through language, or through both. We asked 250 participants to rate 417 words on seven dimensions: age of acquisition, concreteness, familiarity, context availability, imageability, abstractness, and MoA. We asked 250 participants to rate 417 words on seven dimensions: age of acquisition, concreteness, familiarity, context availability, imageability, abstractness, and MoA. The data were analyzed by considering MoA ratings and their relationship with the other psycholinguistic variables. We asked 250 participants to rate 417 words on seven dimensions: age of acquisition, concreteness, familiarity, context availability, imageability, abstractness, and MoA. The data were analyzed by considering MoA ratings and their relationship with the other psycholinguistic variables. Distributions for concreteness, abstractness, and MoA ratings indicate that they are qualitatively different. A partial correlation analysis revealed that MoA is an independent predictor of concreteness or abstractness, and a hierarchical multiple regression analysis confirmed MoA as being a valid predictor of abstractness. A partial correlation analysis revealed that MoA is an independent predictor of concreteness or abstractness, and a hierarchical multiple regression analysis confirmed MoA as being a valid predictor of abstractness. Strong correlations with measures for the English translation equivalents in the MRC database confirmed the reliability of our norms."}, {"paper_id": "1738460", "adju_relevance": 0, "title": "Modeling Factuality Judgments in Social Media Text", "background_label": "How do journalists mark quoted content as certain or uncertain, and how do readers interpret these signals? Predicates such as thinks, claims, and admits offer a range of options for framing quoted content according to the author\u2019s own perceptions of its credibility.", "method_label": "We gather a new dataset of direct and indirect quotes from Twitter, and obtain annotations of the perceived certainty of the quoted statements. We then compare the ability of linguistic and extra-linguistic features to predict readers\u2019 assessment of the certainty of quoted content.", "result_label": "We see that readers are indeed influenced by such framing devices \u2014 and we find no evidence that they consider other factors, such as the source, journalist, or the content itself. In addition, we examine the impact of specific framing devices on perceptions of credibility.", "abstract": "How do journalists mark quoted content as certain or uncertain, and how do readers interpret these signals? How do journalists mark quoted content as certain or uncertain, and how do readers interpret these signals? Predicates such as thinks, claims, and admits offer a range of options for framing quoted content according to the author\u2019s own perceptions of its credibility. We gather a new dataset of direct and indirect quotes from Twitter, and obtain annotations of the perceived certainty of the quoted statements. We gather a new dataset of direct and indirect quotes from Twitter, and obtain annotations of the perceived certainty of the quoted statements. We then compare the ability of linguistic and extra-linguistic features to predict readers\u2019 assessment of the certainty of quoted content. We see that readers are indeed influenced by such framing devices \u2014 and we find no evidence that they consider other factors, such as the source, journalist, or the content itself. We see that readers are indeed influenced by such framing devices \u2014 and we find no evidence that they consider other factors, such as the source, journalist, or the content itself. In addition, we examine the impact of specific framing devices on perceptions of credibility."}, {"paper_id": "1079612", "adju_relevance": 0, "title": "Information-Theoretic Measures of Influence Based on Content Dynamics", "background_label": "The fundamental building block of social influence is for one person to elicit a response in another. Researchers measuring a\"response\"in social media typically depend either on detailed models of human behavior or on platform-specific cues such as re-tweets, hash tags, URLs, or mentions. Most content on social networks is difficult to model because the modes and motivation of human expression are diverse and incompletely understood.", "method_label": "We introduce content transfer, an information-theoretic measure with a predictive interpretation that directly quantifies the strength of the effect of one user's content on another's in a model-free way. Estimating this measure is made possible by combining recent advances in non-parametric entropy estimation with increasingly sophisticated tools for content representation.", "result_label": "We demonstrate on Twitter data collected for thousands of users that content transfer is able to capture non-trivial, predictive relationships even for pairs of users not linked in the follower or mention graph. We suggest that this measure makes large quantities of previously under-utilized social media content accessible to rigorous statistical causal analysis.", "abstract": "The fundamental building block of social influence is for one person to elicit a response in another. The fundamental building block of social influence is for one person to elicit a response in another. Researchers measuring a\"response\"in social media typically depend either on detailed models of human behavior or on platform-specific cues such as re-tweets, hash tags, URLs, or mentions. The fundamental building block of social influence is for one person to elicit a response in another. Researchers measuring a\"response\"in social media typically depend either on detailed models of human behavior or on platform-specific cues such as re-tweets, hash tags, URLs, or mentions. Most content on social networks is difficult to model because the modes and motivation of human expression are diverse and incompletely understood. We introduce content transfer, an information-theoretic measure with a predictive interpretation that directly quantifies the strength of the effect of one user's content on another's in a model-free way. We introduce content transfer, an information-theoretic measure with a predictive interpretation that directly quantifies the strength of the effect of one user's content on another's in a model-free way. Estimating this measure is made possible by combining recent advances in non-parametric entropy estimation with increasingly sophisticated tools for content representation. We demonstrate on Twitter data collected for thousands of users that content transfer is able to capture non-trivial, predictive relationships even for pairs of users not linked in the follower or mention graph. We demonstrate on Twitter data collected for thousands of users that content transfer is able to capture non-trivial, predictive relationships even for pairs of users not linked in the follower or mention graph. We suggest that this measure makes large quantities of previously under-utilized social media content accessible to rigorous statistical causal analysis."}, {"paper_id": "10890041", "adju_relevance": 0, "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "background_label": "In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. As a consequence, SNSs are also increasingly used as vectors for the diffusion of misinformation and hoaxes. The amount of disseminated information and the rapidity of its diffusion make it practically impossible to assess reliability in a timely manner, highlighting the need for automatic hoax detection systems.", "abstract": "In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. As a consequence, SNSs are also increasingly used as vectors for the diffusion of misinformation and hoaxes. In recent years, the reliability of information on the Internet has emerged as a crucial issue of modern society. Social network sites (SNSs) have revolutionized the way in which information is spread by allowing users to freely share content. As a consequence, SNSs are also increasingly used as vectors for the diffusion of misinformation and hoaxes. The amount of disseminated information and the rapidity of its diffusion make it practically impossible to assess reliability in a timely manner, highlighting the need for automatic hoax detection systems."}, {"paper_id": "36117198", "adju_relevance": 0, "title": "DeepMind_Commentary", "background_label": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy.", "abstract": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy."}, {"paper_id": "19152314", "adju_relevance": 0, "title": "Model for rumor spreading over networks.", "background_label": "An alternate model for rumor spreading over networks is suggested, in which two rumors (termed rumor 1 and rumor 2) with different probabilities of acceptance may propagate among nodes. The propagation is not symmetric in the sense that when deciding which rumor to adopt, nodes always consider rumor 1 first. The model is a natural generalization of the well-known epidemic SIS (susceptible-infective-susceptible) model and reduces to it when some of the parameters of this model are zero.", "method_label": "We find that preferred rumor 1 is dominant in the network when the degree of nodes is high enough and/or when the network contains large clustered groups of nodes, expelling rumor 2.", "result_label": "However, numerical simulations on synthetic networks show that it is possible for rumor 2 to occupy a nonzero fraction of the nodes in many cases as well. Specifically, in the Watts-Strogatz small-world model a moderate level of clustering supports its adoption, while increasing randomness reduces it. For Erdos-Renyi networks, a low average degree allows the coexistence of the two types of rumors. In Barabasi-Albert networks generated with a low m , where m is the number of links when a new node is added, it is also possible for rumor 2 to spread over the network.", "abstract": "An alternate model for rumor spreading over networks is suggested, in which two rumors (termed rumor 1 and rumor 2) with different probabilities of acceptance may propagate among nodes. An alternate model for rumor spreading over networks is suggested, in which two rumors (termed rumor 1 and rumor 2) with different probabilities of acceptance may propagate among nodes. The propagation is not symmetric in the sense that when deciding which rumor to adopt, nodes always consider rumor 1 first. An alternate model for rumor spreading over networks is suggested, in which two rumors (termed rumor 1 and rumor 2) with different probabilities of acceptance may propagate among nodes. The propagation is not symmetric in the sense that when deciding which rumor to adopt, nodes always consider rumor 1 first. The model is a natural generalization of the well-known epidemic SIS (susceptible-infective-susceptible) model and reduces to it when some of the parameters of this model are zero. We find that preferred rumor 1 is dominant in the network when the degree of nodes is high enough and/or when the network contains large clustered groups of nodes, expelling rumor 2. However, numerical simulations on synthetic networks show that it is possible for rumor 2 to occupy a nonzero fraction of the nodes in many cases as well. However, numerical simulations on synthetic networks show that it is possible for rumor 2 to occupy a nonzero fraction of the nodes in many cases as well. Specifically, in the Watts-Strogatz small-world model a moderate level of clustering supports its adoption, while increasing randomness reduces it. However, numerical simulations on synthetic networks show that it is possible for rumor 2 to occupy a nonzero fraction of the nodes in many cases as well. Specifically, in the Watts-Strogatz small-world model a moderate level of clustering supports its adoption, while increasing randomness reduces it. For Erdos-Renyi networks, a low average degree allows the coexistence of the two types of rumors. However, numerical simulations on synthetic networks show that it is possible for rumor 2 to occupy a nonzero fraction of the nodes in many cases as well. Specifically, in the Watts-Strogatz small-world model a moderate level of clustering supports its adoption, while increasing randomness reduces it. For Erdos-Renyi networks, a low average degree allows the coexistence of the two types of rumors. In Barabasi-Albert networks generated with a low m , where m is the number of links when a new node is added, it is also possible for rumor 2 to spread over the network."}, {"paper_id": "153314800", "adju_relevance": 0, "title": "Psychology and morality of political extremists: evidence from Twitter language analysis of alt-right and Antifa", "background_label": "The recent rise of the political extremism in Western countries has spurred renewed interest in the psychological and moral appeal of political extremism. Empirical support for the psychological explanation using surveys has been limited by lack of access to extremist groups, while field studies have missed psychological measures and failed to compare extremists with contrast groups.", "method_label": "We revisit the debate over the psychological and moral appeal of extremism in the U.S. context by analyzing Twitter data of 10,000 political extremists and comparing their text-based psychological constructs with those of 5000 liberal and 5000 conservative users.", "result_label": "The results reveal that extremists show a lower positive emotion and a higher negative emotion than partisan users, but their differences in certainty is not significant. In addition, while left-wing extremists express more language indicative of anxiety than liberals, right-wing extremists express lower anxiety than conservatives. Moreover, our results mostly lend support to Moral Foundations Theory for partisan users and extend it to the political extremists. With the exception of ingroup loyalty, we found evidences supporting the Moral Foundations Theory among left- and right-wing extremists. However, we found no evidence for elevated moral foundations among political extremists.", "abstract": "The recent rise of the political extremism in Western countries has spurred renewed interest in the psychological and moral appeal of political extremism. The recent rise of the political extremism in Western countries has spurred renewed interest in the psychological and moral appeal of political extremism. Empirical support for the psychological explanation using surveys has been limited by lack of access to extremist groups, while field studies have missed psychological measures and failed to compare extremists with contrast groups. We revisit the debate over the psychological and moral appeal of extremism in the U.S. context by analyzing Twitter data of 10,000 political extremists and comparing their text-based psychological constructs with those of 5000 liberal and 5000 conservative users. The results reveal that extremists show a lower positive emotion and a higher negative emotion than partisan users, but their differences in certainty is not significant. The results reveal that extremists show a lower positive emotion and a higher negative emotion than partisan users, but their differences in certainty is not significant. In addition, while left-wing extremists express more language indicative of anxiety than liberals, right-wing extremists express lower anxiety than conservatives. The results reveal that extremists show a lower positive emotion and a higher negative emotion than partisan users, but their differences in certainty is not significant. In addition, while left-wing extremists express more language indicative of anxiety than liberals, right-wing extremists express lower anxiety than conservatives. Moreover, our results mostly lend support to Moral Foundations Theory for partisan users and extend it to the political extremists. The results reveal that extremists show a lower positive emotion and a higher negative emotion than partisan users, but their differences in certainty is not significant. In addition, while left-wing extremists express more language indicative of anxiety than liberals, right-wing extremists express lower anxiety than conservatives. Moreover, our results mostly lend support to Moral Foundations Theory for partisan users and extend it to the political extremists. With the exception of ingroup loyalty, we found evidences supporting the Moral Foundations Theory among left- and right-wing extremists. The results reveal that extremists show a lower positive emotion and a higher negative emotion than partisan users, but their differences in certainty is not significant. In addition, while left-wing extremists express more language indicative of anxiety than liberals, right-wing extremists express lower anxiety than conservatives. Moreover, our results mostly lend support to Moral Foundations Theory for partisan users and extend it to the political extremists. With the exception of ingroup loyalty, we found evidences supporting the Moral Foundations Theory among left- and right-wing extremists. However, we found no evidence for elevated moral foundations among political extremists."}, {"paper_id": "5462493", "adju_relevance": 0, "title": "Turing at SemEval-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-LSTM", "background_label": "This paper describes team Turing's submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A).", "abstract": "This paper describes team Turing's submission to SemEval 2017 RumourEval: Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A)."}, {"paper_id": "5919237", "adju_relevance": 0, "title": "Information credibility on twitter", "background_label": "We analyze the information credibility of news propagated through Twitter, a popular microblogging service. Previous research has shown that most of the messages posted on Twitter are truthful, but the service is also used to spread misinformation and false rumors, often unintentionally.", "abstract": "We analyze the information credibility of news propagated through Twitter, a popular microblogging service. We analyze the information credibility of news propagated through Twitter, a popular microblogging service. Previous research has shown that most of the messages posted on Twitter are truthful, but the service is also used to spread misinformation and false rumors, often unintentionally."}, {"paper_id": "62432635", "adju_relevance": 0, "title": "A Short Introduction to Boosting", "background_label": "Boosting is a general method for improving the accuracy of any given learning algorithm.", "method_label": "This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting\u2019s relationship to support-vector machines. Some examples of recent applications of boosting are also described.", "abstract": "Boosting is a general method for improving the accuracy of any given learning algorithm. This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting\u2019s relationship to support-vector machines. This short overview paper introduces the boosting algorithm AdaBoost, and explains the underlying theory of boosting, including an explanation of why boosting often does not suffer from overfitting as well as boosting\u2019s relationship to support-vector machines. Some examples of recent applications of boosting are also described."}, {"paper_id": "15754795", "adju_relevance": 0, "title": "Focus cues affect perceived depth", "background_label": "Depth information from focus cues--accommodation and the gradient of retinal blur--is typically incorrect in three-dimensional (3-D) displays because the light comes from a planar display surface. If the visual system incorporates information from focus cues into its calculation of 3-D scene parameters, this could cause distortions in perceived depth even when the 2-D retinal images are geometrically correct. In Experiment 2, we examined whether focus cues also have an indirect effect on perceived slant via the distance estimate used in disparity scaling.", "method_label": "In Experiment 1 we measured the direct contribution of focus cues to perceived slant by varying independently the physical slant of the display surface and the slant of a simulated surface specified by binocular disparity (binocular viewing) or perspective/texture (monocular viewing). In the binocular condition, slant estimates were unaffected by display slant. We varied independently the simulated distance and the focal distance to a disparity-defined 3-D stimulus. Perceived slant was systematically affected by changes in focal distance. Accordingly, depth constancy (with respect to simulated distance) was significantly reduced when focal distance was held constant compared to when it varied appropriately with the simulated distance to the stimulus.", "result_label": "In the monocular condition, display slant had a systematic effect on slant estimates. Estimates were consistent with a weighted average of slant from focus cues and slant from disparity/texture, where the cue weights are determined by the reliability of each cue. The results of both experiments show that focus cues can contribute to estimates of 3-D scene parameters. Inappropriate focus cues in typical 3-D displays may therefore contribute to distortions in perceived space.", "abstract": "Depth information from focus cues--accommodation and the gradient of retinal blur--is typically incorrect in three-dimensional (3-D) displays because the light comes from a planar display surface. Depth information from focus cues--accommodation and the gradient of retinal blur--is typically incorrect in three-dimensional (3-D) displays because the light comes from a planar display surface. If the visual system incorporates information from focus cues into its calculation of 3-D scene parameters, this could cause distortions in perceived depth even when the 2-D retinal images are geometrically correct. In Experiment 1 we measured the direct contribution of focus cues to perceived slant by varying independently the physical slant of the display surface and the slant of a simulated surface specified by binocular disparity (binocular viewing) or perspective/texture (monocular viewing). In Experiment 1 we measured the direct contribution of focus cues to perceived slant by varying independently the physical slant of the display surface and the slant of a simulated surface specified by binocular disparity (binocular viewing) or perspective/texture (monocular viewing). In the binocular condition, slant estimates were unaffected by display slant. In the monocular condition, display slant had a systematic effect on slant estimates. In the monocular condition, display slant had a systematic effect on slant estimates. Estimates were consistent with a weighted average of slant from focus cues and slant from disparity/texture, where the cue weights are determined by the reliability of each cue. Depth information from focus cues--accommodation and the gradient of retinal blur--is typically incorrect in three-dimensional (3-D) displays because the light comes from a planar display surface. If the visual system incorporates information from focus cues into its calculation of 3-D scene parameters, this could cause distortions in perceived depth even when the 2-D retinal images are geometrically correct. In Experiment 2, we examined whether focus cues also have an indirect effect on perceived slant via the distance estimate used in disparity scaling. In Experiment 1 we measured the direct contribution of focus cues to perceived slant by varying independently the physical slant of the display surface and the slant of a simulated surface specified by binocular disparity (binocular viewing) or perspective/texture (monocular viewing). In the binocular condition, slant estimates were unaffected by display slant. We varied independently the simulated distance and the focal distance to a disparity-defined 3-D stimulus. In Experiment 1 we measured the direct contribution of focus cues to perceived slant by varying independently the physical slant of the display surface and the slant of a simulated surface specified by binocular disparity (binocular viewing) or perspective/texture (monocular viewing). In the binocular condition, slant estimates were unaffected by display slant. We varied independently the simulated distance and the focal distance to a disparity-defined 3-D stimulus. Perceived slant was systematically affected by changes in focal distance. In Experiment 1 we measured the direct contribution of focus cues to perceived slant by varying independently the physical slant of the display surface and the slant of a simulated surface specified by binocular disparity (binocular viewing) or perspective/texture (monocular viewing). In the binocular condition, slant estimates were unaffected by display slant. We varied independently the simulated distance and the focal distance to a disparity-defined 3-D stimulus. Perceived slant was systematically affected by changes in focal distance. Accordingly, depth constancy (with respect to simulated distance) was significantly reduced when focal distance was held constant compared to when it varied appropriately with the simulated distance to the stimulus. In the monocular condition, display slant had a systematic effect on slant estimates. Estimates were consistent with a weighted average of slant from focus cues and slant from disparity/texture, where the cue weights are determined by the reliability of each cue. The results of both experiments show that focus cues can contribute to estimates of 3-D scene parameters. In the monocular condition, display slant had a systematic effect on slant estimates. Estimates were consistent with a weighted average of slant from focus cues and slant from disparity/texture, where the cue weights are determined by the reliability of each cue. The results of both experiments show that focus cues can contribute to estimates of 3-D scene parameters. Inappropriate focus cues in typical 3-D displays may therefore contribute to distortions in perceived space."}, {"paper_id": "115691579", "adju_relevance": 0, "title": "Assessing the effect of persuasive robots interactive social cues on users' psychological reactance, liking, trusting beliefs and compliance", "background_label": "ABSTRACTResearch in the field of social robotics suggests that enhancing social cues in robots can elicit more social responses in users. It is however not clear how users respond socially to persuasive social robots and whether such reactions will be more pronounced when the robots feature more interactive social cues.", "abstract": "ABSTRACTResearch in the field of social robotics suggests that enhancing social cues in robots can elicit more social responses in users. ABSTRACTResearch in the field of social robotics suggests that enhancing social cues in robots can elicit more social responses in users. It is however not clear how users respond socially to persuasive social robots and whether such reactions will be more pronounced when the robots feature more interactive social cues."}, {"paper_id": "17535443", "adju_relevance": 0, "title": "The control of the false discovery rate in multiple testing under dependency", "background_label": "Benjamini and Hochberg suggest that the false discovery rate may be the appropriate error rate to control in many applied multiple testing problems.", "method_label": "A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. This condition for positive dependency is general enough to cover many problems of practical interest, including the comparisons of many treatments with a single control, multivariate normal test statistics with positive correlation matrix and multivariate t. Furthermore, the test statistics may be discrete, and the tested hypotheses composite without posing special difficulties. For all other forms of dependency, a simple conservative modification of the procedure controls the false discovery rate.", "result_label": "Thus the range of problems for which a procedure with proven FDR control can be offered is greatly increased.", "abstract": "Benjamini and Hochberg suggest that the false discovery rate may be the appropriate error rate to control in many applied multiple testing problems. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. This condition for positive dependency is general enough to cover many problems of practical interest, including the comparisons of many treatments with a single control, multivariate normal test statistics with positive correlation matrix and multivariate t. Furthermore, the test statistics may be discrete, and the tested hypotheses composite without posing special difficulties. A simple procedure was given there as an FDR controlling procedure for independent test statistics and was shown to be much more powerful than comparable procedures which control the traditional familywise error rate. We prove that this same procedure also controls the false discovery rate when the test statistics have positive regression dependency on each of the test statistics corresponding to the true null hypotheses. This condition for positive dependency is general enough to cover many problems of practical interest, including the comparisons of many treatments with a single control, multivariate normal test statistics with positive correlation matrix and multivariate t. Furthermore, the test statistics may be discrete, and the tested hypotheses composite without posing special difficulties. For all other forms of dependency, a simple conservative modification of the procedure controls the false discovery rate. Thus the range of problems for which a procedure with proven FDR control can be offered is greatly increased."}, {"paper_id": "13242264", "adju_relevance": 0, "title": "Contradiction Detection for Rumorous Claims", "background_label": "The utilization of social media material in journalistic workflows is increasing, demanding automated methods for the identification of mis- and disinformation.", "abstract": "The utilization of social media material in journalistic workflows is increasing, demanding automated methods for the identification of mis- and disinformation."}, {"paper_id": "2680881", "adju_relevance": 0, "title": "Determining the Veracity of Rumours on Twitter", "background_label": "While social networks can provide an ideal platform for up-to-date information from individuals across the world, it has also proved to be a place where rumours fester and accidental or deliberate misinformation often emerges.", "abstract": "While social networks can provide an ideal platform for up-to-date information from individuals across the world, it has also proved to be a place where rumours fester and accidental or deliberate misinformation often emerges."}, {"paper_id": "40141348", "adju_relevance": 0, "title": "Demographic and psychosocial features of participants in bondage and discipline, \"sadomasochism\" or dominance and submission (BDSM): data from a national survey.", "background_label": "INTRODUCTION People with sexual interests in bondage and discipline, \"sadomasochism\" or dominance and submission (BDSM) have been seen by many professionals as damaged or dangerous.", "abstract": "INTRODUCTION People with sexual interests in bondage and discipline, \"sadomasochism\" or dominance and submission (BDSM) have been seen by many professionals as damaged or dangerous."}, {"paper_id": "9454766", "adju_relevance": 0, "title": "Reading between the lines: linguistic cues to deception in online dating profiles", "method_label": "We objectively measure deception in online dating profiles and analyze the linguistic composition of the open-ended component of the profile (i.e., \"about me\" section) using computerized text analysis.", "result_label": "Results show that profile deceptions correlate with fewer self-references, increased negations, fewer negative emotion words and fewer overall words used in the textual self-description. Results are discussed in terms of (1) practical implications for detecting deception in online profiles; and (2) theoretical implications regarding the impact of media affordances (i.e., asynchronicity and editability) on the occurrence of linguistic cues to deception.", "abstract": " We objectively measure deception in online dating profiles and analyze the linguistic composition of the open-ended component of the profile (i.e., \"about me\" section) using computerized text analysis. Results show that profile deceptions correlate with fewer self-references, increased negations, fewer negative emotion words and fewer overall words used in the textual self-description. Results show that profile deceptions correlate with fewer self-references, increased negations, fewer negative emotion words and fewer overall words used in the textual self-description. Results are discussed in terms of (1) practical implications for detecting deception in online profiles; and (2) theoretical implications regarding the impact of media affordances (i.e., asynchronicity and editability) on the occurrence of linguistic cues to deception."}, {"paper_id": "10060667", "adju_relevance": 0, "title": "An exploration of relations between visual appeal, trustworthiness and perceived usability of homepages", "background_label": "Extremely high correlations between repeated judgments of visual appeal of homepages shown for 50 milliseconds have been interpreted as evidence for a mere exposure effect [Lindgaard et al. 2006].", "abstract": "Extremely high correlations between repeated judgments of visual appeal of homepages shown for 50 milliseconds have been interpreted as evidence for a mere exposure effect [Lindgaard et al. Extremely high correlations between repeated judgments of visual appeal of homepages shown for 50 milliseconds have been interpreted as evidence for a mere exposure effect [Lindgaard et al. 2006]."}, {"paper_id": "6716045", "adju_relevance": 0, "title": "Effects of titles on the processing of text and lexically ambiguous words: evidence from eye movements.", "background_label": "Providing titles for passages improves the comprehension and memorability of text. Titles have generally been thought to facilitate comprehension at later stages of processing. Consistent with prior research, we found that passages presented with titles were better recalled than those without titles.", "method_label": "Furthermore, in Experiment 1, the presence of titles led to fewer regressive eye movements, shorter end-of-sentence reading times, and shorter fixation times on target nouns. Experiments 2 and 3, using ambiguous target words, indicated that except when a very infrequent sense of a word is required, titles provide a strong enough context to allow for ambiguous words to be processed as quickly as control words.", "result_label": "The results of the three experiments suggest that titles affect processing at both integrative and lexical stages of reading.", "abstract": "Providing titles for passages improves the comprehension and memorability of text. Providing titles for passages improves the comprehension and memorability of text. Titles have generally been thought to facilitate comprehension at later stages of processing. Providing titles for passages improves the comprehension and memorability of text. Titles have generally been thought to facilitate comprehension at later stages of processing. Consistent with prior research, we found that passages presented with titles were better recalled than those without titles. Furthermore, in Experiment 1, the presence of titles led to fewer regressive eye movements, shorter end-of-sentence reading times, and shorter fixation times on target nouns. Furthermore, in Experiment 1, the presence of titles led to fewer regressive eye movements, shorter end-of-sentence reading times, and shorter fixation times on target nouns. Experiments 2 and 3, using ambiguous target words, indicated that except when a very infrequent sense of a word is required, titles provide a strong enough context to allow for ambiguous words to be processed as quickly as control words. The results of the three experiments suggest that titles affect processing at both integrative and lexical stages of reading."}, {"paper_id": "141539970", "adju_relevance": 0, "title": "Information Structural Expectations in the Perception of Prosodic Prominence", "background_label": "A number of previous investigations using context matching (e.g., Gussenhoven 1983) and appropriateness rating tasks (Birch and Clifton 1995, Welby 2003) suggest that English-speaking listeners lack expectations regarding how the size of a focused constituent (broad versus narrow) can be expressed prosodically in certain constructions.", "method_label": "In the present study English-speaking listeners were presented with the same SVO sentence (e.g., I bought a motorcycle) presented in either broad or narrow question contexts, and were asked to rate the prominence of the words in those sentences. In general, listeners reported sentence-final objects to be relatively more prominent than preceding verbs in the test sentences when those sentences were presented in narrow-object (What did you buy?)", "result_label": "rather than broad-VP (What did you do?) or sentence (What happened?) focus contexts. This effect was found to be stronger in Experiment 2, where the answer was a correction. The findings suggest listeners do have expectations about the relationship between the size of a sentence\u2019s focus constituent and its prosodic realization. It is argued that these expectations are well founded given the listeners\u2019 likely experience with productions of this particular information structural contrast.", "abstract": "A number of previous investigations using context matching (e.g., Gussenhoven 1983) and appropriateness rating tasks (Birch and Clifton 1995, Welby 2003) suggest that English-speaking listeners lack expectations regarding how the size of a focused constituent (broad versus narrow) can be expressed prosodically in certain constructions. In the present study English-speaking listeners were presented with the same SVO sentence (e.g., I bought a motorcycle) presented in either broad or narrow question contexts, and were asked to rate the prominence of the words in those sentences. In the present study English-speaking listeners were presented with the same SVO sentence (e.g., I bought a motorcycle) presented in either broad or narrow question contexts, and were asked to rate the prominence of the words in those sentences. In general, listeners reported sentence-final objects to be relatively more prominent than preceding verbs in the test sentences when those sentences were presented in narrow-object (What did you buy?) rather than broad-VP (What did you do?) rather than broad-VP (What did you do?) or sentence (What happened?) rather than broad-VP (What did you do?) or sentence (What happened?) focus contexts. rather than broad-VP (What did you do?) or sentence (What happened?) focus contexts. This effect was found to be stronger in Experiment 2, where the answer was a correction. rather than broad-VP (What did you do?) or sentence (What happened?) focus contexts. This effect was found to be stronger in Experiment 2, where the answer was a correction. The findings suggest listeners do have expectations about the relationship between the size of a sentence\u2019s focus constituent and its prosodic realization. rather than broad-VP (What did you do?) or sentence (What happened?) focus contexts. This effect was found to be stronger in Experiment 2, where the answer was a correction. The findings suggest listeners do have expectations about the relationship between the size of a sentence\u2019s focus constituent and its prosodic realization. It is argued that these expectations are well founded given the listeners\u2019 likely experience with productions of this particular information structural contrast."}, {"paper_id": "44220891", "adju_relevance": 0, "title": "Nonverbal cues in the employment interview: Links between applicant qualities and interviewer judgments.", "background_label": "The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Implications for employment interview training are discussed. Not much empirical evidence supports the validity o f the employment interview as a means o f personnel selection (Ulrich & Trumbo, 1965). However, as the interview is considered by most employers to be an important part of the hiring process, investigators have examined various components o f the interview process t o discover what distinguishes a n unsuccessful interview from a successful interview. The applicant's nonverbal behaviors are often assumed by interviewers to provide useful information that is not likely t o b e expressed verbally (Schlenker, 1980). Recent research has demonstrated the importance of nonverbal behaviors in the interview situation (Edinger & Patterson, 1983).", "method_label": "Job applicants' self-appraised motivation to work and social skill were assessed, and their nonverbal behaviors during the interview were scored.", "result_label": "Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Social skill was found to be more accurately inferred by the judges a s a group than was motivation t o work. Applicants' social skill was apparently transmitted t o the judges via three nonverbal cues. In contrast, there was a lack o f correspondence between cues correlated with applicants' selfappraised motivation to work and those used by judges in making their attributions. Unfortunately, most previous research focuses on only half the role of nonverbal behaviors\u2014 connections between the job applicant's behavior and the interviewer's attributions. The present study investigates the full role o f nonverbal behaviors in job interviews, that is, the connections between the applicant's job-related qualities and nonverbal behaviors,", "abstract": "The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Job applicants' self-appraised motivation to work and social skill were assessed, and their nonverbal behaviors during the interview were scored. Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Social skill was found to be more accurately inferred by the judges a s a group than was motivation t o work. Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Social skill was found to be more accurately inferred by the judges a s a group than was motivation t o work. Applicants' social skill was apparently transmitted t o the judges via three nonverbal cues. Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Social skill was found to be more accurately inferred by the judges a s a group than was motivation t o work. Applicants' social skill was apparently transmitted t o the judges via three nonverbal cues. In contrast, there was a lack o f correspondence between cues correlated with applicants' selfappraised motivation to work and those used by judges in making their attributions. The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Implications for employment interview training are discussed. The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Implications for employment interview training are discussed. Not much empirical evidence supports the validity o f the employment interview as a means o f personnel selection (Ulrich & Trumbo, 1965). The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Implications for employment interview training are discussed. Not much empirical evidence supports the validity o f the employment interview as a means o f personnel selection (Ulrich & Trumbo, 1965). However, as the interview is considered by most employers to be an important part of the hiring process, investigators have examined various components o f the interview process t o discover what distinguishes a n unsuccessful interview from a successful interview. The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Implications for employment interview training are discussed. Not much empirical evidence supports the validity o f the employment interview as a means o f personnel selection (Ulrich & Trumbo, 1965). However, as the interview is considered by most employers to be an important part of the hiring process, investigators have examined various components o f the interview process t o discover what distinguishes a n unsuccessful interview from a successful interview. The applicant's nonverbal behaviors are often assumed by interviewers to provide useful information that is not likely t o b e expressed verbally (Schlenker, 1980). The role of nonverbal behavior in the employment interview inference process was investigated using a modified Brunswik lens model. Thirty-four job interviews for a n actual research assistant position were conducted and videotaped. Implications for employment interview training are discussed. Not much empirical evidence supports the validity o f the employment interview as a means o f personnel selection (Ulrich & Trumbo, 1965). However, as the interview is considered by most employers to be an important part of the hiring process, investigators have examined various components o f the interview process t o discover what distinguishes a n unsuccessful interview from a successful interview. The applicant's nonverbal behaviors are often assumed by interviewers to provide useful information that is not likely t o b e expressed verbally (Schlenker, 1980). Recent research has demonstrated the importance of nonverbal behaviors in the interview situation (Edinger & Patterson, 1983). Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Social skill was found to be more accurately inferred by the judges a s a group than was motivation t o work. Applicants' social skill was apparently transmitted t o the judges via three nonverbal cues. In contrast, there was a lack o f correspondence between cues correlated with applicants' selfappraised motivation to work and those used by judges in making their attributions. Unfortunately, most previous research focuses on only half the role of nonverbal behaviors\u2014 connections between the job applicant's behavior and the interviewer's attributions. Eighteen judges with training and several years' experience in employment interviewing watched the videotaped interviews and rated the applicants on their motivation, social skill, and \"hireability.\" Social skill was found to be more accurately inferred by the judges a s a group than was motivation t o work. Applicants' social skill was apparently transmitted t o the judges via three nonverbal cues. In contrast, there was a lack o f correspondence between cues correlated with applicants' selfappraised motivation to work and those used by judges in making their attributions. Unfortunately, most previous research focuses on only half the role of nonverbal behaviors\u2014 connections between the job applicant's behavior and the interviewer's attributions. The present study investigates the full role o f nonverbal behaviors in job interviews, that is, the connections between the applicant's job-related qualities and nonverbal behaviors,"}, {"paper_id": "11922652", "adju_relevance": 0, "title": "Understanding Karma Police: The Perceived Plausibility of Noun Compounds as Predicted by Distributional Models of Semantic Representation", "background_label": "Noun compounds, consisting of two nouns (the head and the modifier) that are combined into a single concept, differ in terms of their plausibility: school bus is a more plausible compound than saddle olive.", "abstract": "Noun compounds, consisting of two nouns (the head and the modifier) that are combined into a single concept, differ in terms of their plausibility: school bus is a more plausible compound than saddle olive."}, {"paper_id": "549335", "adju_relevance": 0, "title": "The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text", "background_label": "AbstractThe CoNLL-2010 Shared Task was dedicated to the detection of uncertainty cues and their linguistic scope in natural language texts.", "abstract": "AbstractThe CoNLL-2010 Shared Task was dedicated to the detection of uncertainty cues and their linguistic scope in natural language texts."}, {"paper_id": "145553387", "adju_relevance": 0, "title": "Effects of Attitudinal Ambivalence on Information Processing and Attitude-Intention Consistency \u2606", "background_label": "We hypothesize that, when encountering a new or unfamiliar attitude object that has both positiveandnegative attributes, such evaluatively inconsistent information leads toattitudinal ambivalence,that is, a coexistence of positive and negative evaluation of the particular object.", "method_label": "By drawing upon the heuristic-systematic model (Chaiken, Liberman, & Eagly, 1989), we predict that (a) ambivalence decreases the individual's confidence in his or her own attitude toward behaviors involving the object, (b) the decreased confidence evokes systematic processing of relevant information, and (c) systematic processing increases consistency between ambivalent attitudes and pertinent behavioral intentions. To test these hypotheses, ambivalence was manipulated in two experiments by providing participants with either evaluatively inconsistent or consistent information about fictional shampoos.", "result_label": "As predicted, in both experiments more consistency between the attitude toward buying the shampoo and the behavioral intention was obtained in the ambivalent condition than in the nonambivalent condition. Experiment 2 also provided data confirming the postulated mediating processes.", "abstract": "We hypothesize that, when encountering a new or unfamiliar attitude object that has both positiveandnegative attributes, such evaluatively inconsistent information leads toattitudinal ambivalence,that is, a coexistence of positive and negative evaluation of the particular object. By drawing upon the heuristic-systematic model (Chaiken, Liberman, & Eagly, 1989), we predict that (a) ambivalence decreases the individual's confidence in his or her own attitude toward behaviors involving the object, (b) the decreased confidence evokes systematic processing of relevant information, and (c) systematic processing increases consistency between ambivalent attitudes and pertinent behavioral intentions. By drawing upon the heuristic-systematic model (Chaiken, Liberman, & Eagly, 1989), we predict that (a) ambivalence decreases the individual's confidence in his or her own attitude toward behaviors involving the object, (b) the decreased confidence evokes systematic processing of relevant information, and (c) systematic processing increases consistency between ambivalent attitudes and pertinent behavioral intentions. To test these hypotheses, ambivalence was manipulated in two experiments by providing participants with either evaluatively inconsistent or consistent information about fictional shampoos. As predicted, in both experiments more consistency between the attitude toward buying the shampoo and the behavioral intention was obtained in the ambivalent condition than in the nonambivalent condition. As predicted, in both experiments more consistency between the attitude toward buying the shampoo and the behavioral intention was obtained in the ambivalent condition than in the nonambivalent condition. Experiment 2 also provided data confirming the postulated mediating processes."}]