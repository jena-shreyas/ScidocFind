[{"paper_id": "52194540", "title": "Hate Speech Dataset from a White Supremacy Forum", "background_label": "Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. Due to the massive rise of user-generated web content on social media, the amount of hate speech is also steadily increasing. Over the past years, interest in online hate speech detection and, particularly, the automation of this task has continuously grown, along with the societal impact of the phenomenon.", "abstract": "Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. Due to the massive rise of user-generated web content on social media, the amount of hate speech is also steadily increasing. Hate speech is commonly defined as any communication that disparages a target group of people based on some characteristic such as race, colour, ethnicity, gender, sexual orientation, nationality, religion, or other characteristic. Due to the massive rise of user-generated web content on social media, the amount of hate speech is also steadily increasing. Over the past years, interest in online hate speech detection and, particularly, the automation of this task has continuously grown, along with the societal impact of the phenomenon."}, {"paper_id": "15438425", "adju_relevance": 3, "title": "Measuring online affects in a white supremacy forum", "background_label": "Since the inception of the World Wide Web, security agencies, researchers, and analysts have focused much of their attention on the sentiment found on hate-inspired web-forums.", "abstract": "Since the inception of the World Wide Web, security agencies, researchers, and analysts have focused much of their attention on the sentiment found on hate-inspired web-forums."}, {"paper_id": "48353722", "adju_relevance": 2, "title": "Degree based Classification of Harmful Speech using Twitter Data", "background_label": "Harmful speech has various forms and it has been plaguing the social media in different ways. If we need to crackdown different degrees of hate speech and abusive behavior amongst it, the classification needs to be based on complex ramifications which needs to be defined and hold accountable for, other than racist, sexist or against some particular group and community.", "method_label": "This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent, and used it to annotate twitter data accordingly. The key contribution of this paper is the new dataset of tweets we created based on ontological classes and degrees of harmful speech found in the text. We also propose supervised classification system for recognizing these respective harmful speech classes in the texts hence.", "abstract": "Harmful speech has various forms and it has been plaguing the social media in different ways. Harmful speech has various forms and it has been plaguing the social media in different ways. If we need to crackdown different degrees of hate speech and abusive behavior amongst it, the classification needs to be based on complex ramifications which needs to be defined and hold accountable for, other than racist, sexist or against some particular group and community. This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent, and used it to annotate twitter data accordingly. This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent, and used it to annotate twitter data accordingly. The key contribution of this paper is the new dataset of tweets we created based on ontological classes and degrees of harmful speech found in the text. This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent, and used it to annotate twitter data accordingly. The key contribution of this paper is the new dataset of tweets we created based on ontological classes and degrees of harmful speech found in the text. We also propose supervised classification system for recognizing these respective harmful speech classes in the texts hence."}, {"paper_id": "51881821", "adju_relevance": 2, "title": "A Dataset of Hindi-English Code-Mixed Social Media Text for Hate Speech Detection", "background_label": "AbstractHate speech detection in social media texts is an important Natural language Processing task, which has several crucial applications like sentiment analysis, investigating cyber bullying and examining socio-political controversies.", "abstract": "AbstractHate speech detection in social media texts is an important Natural language Processing task, which has several crucial applications like sentiment analysis, investigating cyber bullying and examining socio-political controversies."}, {"paper_id": "25546900", "adju_relevance": 2, "title": "Surfacing contextual hate speech words within social media", "background_label": "Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Most of these rely on annotated data, keywords, and a classification technique. While this approach provides good coverage, it can fall short when dealing with new terms produced by online extremist communities which act as original sources of words which have alternate hate speech meanings. These code words (which can be both created and adopted words) are designed to evade automatic detection and often have benign meanings in regular discourse. As an example,\"skypes\",\"googles\", and\"yahoos\"are all instances of words which have an alternate meaning that can be used for hate speech. This overlap introduces additional challenges when relying on keywords for both the collection of data that is specific to hate speech, and downstream classification.", "abstract": "Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Most of these rely on annotated data, keywords, and a classification technique. Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Most of these rely on annotated data, keywords, and a classification technique. While this approach provides good coverage, it can fall short when dealing with new terms produced by online extremist communities which act as original sources of words which have alternate hate speech meanings. Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Most of these rely on annotated data, keywords, and a classification technique. While this approach provides good coverage, it can fall short when dealing with new terms produced by online extremist communities which act as original sources of words which have alternate hate speech meanings. These code words (which can be both created and adopted words) are designed to evade automatic detection and often have benign meanings in regular discourse. Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Most of these rely on annotated data, keywords, and a classification technique. While this approach provides good coverage, it can fall short when dealing with new terms produced by online extremist communities which act as original sources of words which have alternate hate speech meanings. These code words (which can be both created and adopted words) are designed to evade automatic detection and often have benign meanings in regular discourse. As an example,\"skypes\",\"googles\", and\"yahoos\"are all instances of words which have an alternate meaning that can be used for hate speech. Social media platforms have recently seen an increase in the occurrence of hate speech discourse which has led to calls for improved detection methods. Most of these rely on annotated data, keywords, and a classification technique. While this approach provides good coverage, it can fall short when dealing with new terms produced by online extremist communities which act as original sources of words which have alternate hate speech meanings. These code words (which can be both created and adopted words) are designed to evade automatic detection and often have benign meanings in regular discourse. As an example,\"skypes\",\"googles\", and\"yahoos\"are all instances of words which have an alternate meaning that can be used for hate speech. This overlap introduces additional challenges when relying on keywords for both the collection of data that is specific to hate speech, and downstream classification."}, {"paper_id": "54458291", "adju_relevance": 2, "title": "Spread of hate speech in online social media", "background_label": "The present online social media platform is afflicted with several issues, with hate speech being on the predominant forefront. The prevalence of online hate speech has fueled horrific real-world hate-crime such as the mass-genocide of Rohingya Muslims, communal violence in Colombo and the recent massacre in the Pittsburgh synagogue. Consequently, It is imperative to understand the diffusion of such hateful content in an online setting.", "method_label": "We conduct the first study that analyses the flow and dynamics of posts generated by hateful and non-hateful users on Gab (gab.com) over a massive dataset of 341K users and 21M posts.", "result_label": "Our observations confirms that hateful content diffuse farther, wider and faster and have a greater outreach than those of non-hateful users. A deeper inspection into the profiles and network of hateful and non-hateful users reveals that the former are more influential, popular and cohesive. Thus, our research explores the interesting facets of diffusion dynamics of hateful users and broadens our understanding of hate speech in the online world.", "abstract": "The present online social media platform is afflicted with several issues, with hate speech being on the predominant forefront. The present online social media platform is afflicted with several issues, with hate speech being on the predominant forefront. The prevalence of online hate speech has fueled horrific real-world hate-crime such as the mass-genocide of Rohingya Muslims, communal violence in Colombo and the recent massacre in the Pittsburgh synagogue. The present online social media platform is afflicted with several issues, with hate speech being on the predominant forefront. The prevalence of online hate speech has fueled horrific real-world hate-crime such as the mass-genocide of Rohingya Muslims, communal violence in Colombo and the recent massacre in the Pittsburgh synagogue. Consequently, It is imperative to understand the diffusion of such hateful content in an online setting. We conduct the first study that analyses the flow and dynamics of posts generated by hateful and non-hateful users on Gab (gab.com) over a massive dataset of 341K users and 21M posts. Our observations confirms that hateful content diffuse farther, wider and faster and have a greater outreach than those of non-hateful users. Our observations confirms that hateful content diffuse farther, wider and faster and have a greater outreach than those of non-hateful users. A deeper inspection into the profiles and network of hateful and non-hateful users reveals that the former are more influential, popular and cohesive. Our observations confirms that hateful content diffuse farther, wider and faster and have a greater outreach than those of non-hateful users. A deeper inspection into the profiles and network of hateful and non-hateful users reveals that the former are more influential, popular and cohesive. Thus, our research explores the interesting facets of diffusion dynamics of hateful users and broadens our understanding of hate speech in the online world."}, {"paper_id": "8564811", "adju_relevance": 2, "title": "Detecting Online Hate Speech Using Context Aware Models", "background_label": "In the wake of a polarizing election, the cyber world is laden with hate speech. Context accompanying a hate speech text is useful for identifying hate speech, which however has been largely overlooked in existing datasets and hate speech detection models.", "method_label": "In this paper, we provide an annotated corpus of hate speech with context information well kept. Then we propose two types of hate speech detection models that incorporate context information, a logistic regression model with context features and a neural network model with learning components for context.", "result_label": "Our evaluation shows that both models outperform a strong baseline by around 3% to 4% in F1 score and combining these two models further improve the performance by another 7% in F1 score.", "abstract": "In the wake of a polarizing election, the cyber world is laden with hate speech. In the wake of a polarizing election, the cyber world is laden with hate speech. Context accompanying a hate speech text is useful for identifying hate speech, which however has been largely overlooked in existing datasets and hate speech detection models. In this paper, we provide an annotated corpus of hate speech with context information well kept. In this paper, we provide an annotated corpus of hate speech with context information well kept. Then we propose two types of hate speech detection models that incorporate context information, a logistic regression model with context features and a neural network model with learning components for context. Our evaluation shows that both models outperform a strong baseline by around 3% to 4% in F1 score and combining these two models further improve the performance by another 7% in F1 score."}, {"paper_id": "145214652", "adju_relevance": 2, "title": "Responses to Internet Hate Sites: Is Speech Too Free in Cyberspace?", "background_label": "This descriptive study investigates people's responses to incendiary hate sites found on the World Wide Web.", "abstract": "This descriptive study investigates people's responses to incendiary hate sites found on the World Wide Web."}, {"paper_id": "199552117", "adju_relevance": 2, "title": "Offensive Language and Hate Speech Detection for Danish", "background_label": "The presence of offensive language on social media platforms and the implications this poses is becoming a major concern in modern society. Given the enormous amount of content created every day, automatic methods are required to detect and deal with this type of content. Until now, most of the research has focused on solving the problem for the English language, while the problem is multilingual. Our dataset is annotated to capture various types and target of offensive language.", "method_label": "We construct a Danish dataset containing user-generated comments from \\textit{Reddit} and \\textit{Facebook}. We develop four automatic classification systems, each designed to work for both the English and the Danish language. In the detection of offensive language in English, the best performing system achieves a macro averaged F1-score of $0.74$, and the best performing system for Danish achieves a macro averaged F1-score of $0.70$. In the detection of whether or not an offensive post is targeted, the best performing system for English achieves a macro averaged F1-score of $0.62$, while the best performing system for Danish achieves a macro averaged F1-score of $0.73$.", "result_label": "It contains user generated comments from various social media platforms, and to our knowledge, it is the first of its kind. Finally, in the detection of the target type in a targeted offensive post, the best performing system for English achieves a macro averaged F1-score of $0.56$, and the best performing system for Danish achieves a macro averaged F1-score of $0.63$. Our work for both the English and the Danish language captures the type and targets of offensive language, and present automatic methods for detecting different kinds of offensive language such as hate speech and cyberbullying.", "abstract": "The presence of offensive language on social media platforms and the implications this poses is becoming a major concern in modern society. The presence of offensive language on social media platforms and the implications this poses is becoming a major concern in modern society. Given the enormous amount of content created every day, automatic methods are required to detect and deal with this type of content. The presence of offensive language on social media platforms and the implications this poses is becoming a major concern in modern society. Given the enormous amount of content created every day, automatic methods are required to detect and deal with this type of content. Until now, most of the research has focused on solving the problem for the English language, while the problem is multilingual. We construct a Danish dataset containing user-generated comments from \\textit{Reddit} and \\textit{Facebook}. It contains user generated comments from various social media platforms, and to our knowledge, it is the first of its kind. The presence of offensive language on social media platforms and the implications this poses is becoming a major concern in modern society. Given the enormous amount of content created every day, automatic methods are required to detect and deal with this type of content. Until now, most of the research has focused on solving the problem for the English language, while the problem is multilingual. Our dataset is annotated to capture various types and target of offensive language. We construct a Danish dataset containing user-generated comments from \\textit{Reddit} and \\textit{Facebook}. We develop four automatic classification systems, each designed to work for both the English and the Danish language. We construct a Danish dataset containing user-generated comments from \\textit{Reddit} and \\textit{Facebook}. We develop four automatic classification systems, each designed to work for both the English and the Danish language. In the detection of offensive language in English, the best performing system achieves a macro averaged F1-score of $0.74$, and the best performing system for Danish achieves a macro averaged F1-score of $0.70$. We construct a Danish dataset containing user-generated comments from \\textit{Reddit} and \\textit{Facebook}. We develop four automatic classification systems, each designed to work for both the English and the Danish language. In the detection of offensive language in English, the best performing system achieves a macro averaged F1-score of $0.74$, and the best performing system for Danish achieves a macro averaged F1-score of $0.70$. In the detection of whether or not an offensive post is targeted, the best performing system for English achieves a macro averaged F1-score of $0.62$, while the best performing system for Danish achieves a macro averaged F1-score of $0.73$. It contains user generated comments from various social media platforms, and to our knowledge, it is the first of its kind. Finally, in the detection of the target type in a targeted offensive post, the best performing system for English achieves a macro averaged F1-score of $0.56$, and the best performing system for Danish achieves a macro averaged F1-score of $0.63$. It contains user generated comments from various social media platforms, and to our knowledge, it is the first of its kind. Finally, in the detection of the target type in a targeted offensive post, the best performing system for English achieves a macro averaged F1-score of $0.56$, and the best performing system for Danish achieves a macro averaged F1-score of $0.63$. Our work for both the English and the Danish language captures the type and targets of offensive language, and present automatic methods for detecting different kinds of offensive language such as hate speech and cyberbullying."}, {"paper_id": "1721388", "adju_relevance": 2, "title": "Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter", "background_label": "Hate speech in the form of racist and sexist remarks are a common occurrence on social media. For that reason, many social media services address the problem of identifying hate speech, but the definition of hate speech varies markedly and is largely a manual effort (BBC, 2015; Lomas, 2015).", "method_label": "We provide a list of criteria founded in critical race theory, and use them to annotate a publicly available corpus of more than 16k tweets. We analyze the impact of various extra-linguistic features in conjunction with character n-grams for hatespeech detection.", "result_label": "We also present a dictionary based the most indicative words in our data.", "abstract": "Hate speech in the form of racist and sexist remarks are a common occurrence on social media. Hate speech in the form of racist and sexist remarks are a common occurrence on social media. For that reason, many social media services address the problem of identifying hate speech, but the definition of hate speech varies markedly and is largely a manual effort (BBC, 2015; Lomas, 2015). We provide a list of criteria founded in critical race theory, and use them to annotate a publicly available corpus of more than 16k tweets. We provide a list of criteria founded in critical race theory, and use them to annotate a publicly available corpus of more than 16k tweets. We analyze the impact of various extra-linguistic features in conjunction with character n-grams for hatespeech detection. We also present a dictionary based the most indicative words in our data."}, {"paper_id": "53081895", "adju_relevance": 2, "title": "Are they Our Brothers? Analysis and Detection of Religious Hate Speech in the Arabic Twittersphere", "background_label": "Religious hate speech in the Arabic Twittersphere is a notable problem that requires developing automated tools to detect messages that use inflammatory sectarian language to promote hatred and violence against people on the basis of religious affiliation. Distinguishing hate speech from other profane and vulgar language is quite a challenging task that requires deep linguistic analysis. The richness of the Arabic morphology and the limited available resources for the Arabic language make this task even more challenging.", "abstract": "Religious hate speech in the Arabic Twittersphere is a notable problem that requires developing automated tools to detect messages that use inflammatory sectarian language to promote hatred and violence against people on the basis of religious affiliation. Religious hate speech in the Arabic Twittersphere is a notable problem that requires developing automated tools to detect messages that use inflammatory sectarian language to promote hatred and violence against people on the basis of religious affiliation. Distinguishing hate speech from other profane and vulgar language is quite a challenging task that requires deep linguistic analysis. Religious hate speech in the Arabic Twittersphere is a notable problem that requires developing automated tools to detect messages that use inflammatory sectarian language to promote hatred and violence against people on the basis of religious affiliation. Distinguishing hate speech from other profane and vulgar language is quite a challenging task that requires deep linguistic analysis. The richness of the Arabic morphology and the limited available resources for the Arabic language make this task even more challenging."}, {"paper_id": "12477446", "adju_relevance": 2, "title": "Detecting Hate Speech on the World Wide Web", "background_label": "AbstractWe present an approach to detecting hate speech in online text, where hate speech is defined as abusive speech targeting specific group characteristics, such as ethnic origin, religion, gender, or sexual orientation. While hate speech against any group may exhibit some common characteristics, we have observed that hatred against each different group is typically characterized by the use of a small set of high frequency stereotypical words; however, such words may be used in either a positive or a negative sense, making our task similar to that of words sense disambiguation.", "method_label": "In this paper we describe our definition of hate speech, the collection and annotation of our hate speech corpus, and a mechanism for detecting some commonly used methods of evading common \"dirty word\" filters.", "result_label": "We describe pilot classification experiments in which we classify anti-semitic speech reaching an accuracy 94%, precision of 68% and recall at 60%, for an F1 measure of .6375.", "abstract": "AbstractWe present an approach to detecting hate speech in online text, where hate speech is defined as abusive speech targeting specific group characteristics, such as ethnic origin, religion, gender, or sexual orientation. AbstractWe present an approach to detecting hate speech in online text, where hate speech is defined as abusive speech targeting specific group characteristics, such as ethnic origin, religion, gender, or sexual orientation. While hate speech against any group may exhibit some common characteristics, we have observed that hatred against each different group is typically characterized by the use of a small set of high frequency stereotypical words; however, such words may be used in either a positive or a negative sense, making our task similar to that of words sense disambiguation. In this paper we describe our definition of hate speech, the collection and annotation of our hate speech corpus, and a mechanism for detecting some commonly used methods of evading common \"dirty word\" filters. We describe pilot classification experiments in which we classify anti-semitic speech reaching an accuracy 94%, precision of 68% and recall at 60%, for an F1 measure of .6375."}, {"paper_id": "4786091", "adju_relevance": 2, "title": "Peer to Peer Hate: Hate Speech Instigators and Their Targets", "background_label": "While social media has become an empowering agent to individual voices and freedom of expression, it also facilitates anti-social behaviors including online harassment, cyberbullying, and hate speech.", "abstract": "While social media has become an empowering agent to individual voices and freedom of expression, it also facilitates anti-social behaviors including online harassment, cyberbullying, and hate speech."}, {"paper_id": "51906916", "adju_relevance": 1, "title": "AVA-Speech: A Densely Labeled Dataset of Speech Activity in Movies", "background_label": "Speech activity detection (or endpointing) is an important processing step for applications such as speech recognition, language identification and speaker diarization. Both audio- and vision-based approaches have been used for this task in various settings, often tailored toward end applications. However, much of the prior work reports results in synthetic settings, on task-specific datasets, or on datasets that are not openly available. This makes it difficult to compare approaches and understand their strengths and weaknesses.", "abstract": "Speech activity detection (or endpointing) is an important processing step for applications such as speech recognition, language identification and speaker diarization. Speech activity detection (or endpointing) is an important processing step for applications such as speech recognition, language identification and speaker diarization. Both audio- and vision-based approaches have been used for this task in various settings, often tailored toward end applications. Speech activity detection (or endpointing) is an important processing step for applications such as speech recognition, language identification and speaker diarization. Both audio- and vision-based approaches have been used for this task in various settings, often tailored toward end applications. However, much of the prior work reports results in synthetic settings, on task-specific datasets, or on datasets that are not openly available. Speech activity detection (or endpointing) is an important processing step for applications such as speech recognition, language identification and speaker diarization. Both audio- and vision-based approaches have been used for this task in various settings, often tailored toward end applications. However, much of the prior work reports results in synthetic settings, on task-specific datasets, or on datasets that are not openly available. This makes it difficult to compare approaches and understand their strengths and weaknesses."}, {"paper_id": "17327101", "adju_relevance": 1, "title": "ORCHID : Thai Part-Of-Speech Tagged Corpus", "background_label": "This paper presents a procedure in building a Thai part-of-speech (POS) tagged corpus named ORCHID [1]. It is a collaboration project between Communications Research Laboratory (CRL) of Japan and National Electronics and Computer Technology Center (NECTEC) of Thailand.", "abstract": "This paper presents a procedure in building a Thai part-of-speech (POS) tagged corpus named ORCHID [1]. This paper presents a procedure in building a Thai part-of-speech (POS) tagged corpus named ORCHID [1]. It is a collaboration project between Communications Research Laboratory (CRL) of Japan and National Electronics and Computer Technology Center (NECTEC) of Thailand."}, {"paper_id": "11432160", "adju_relevance": 1, "title": "Idioms-Proverbs Lexicon for Modern Standard Arabic and Colloquial Sentiment Analysis", "background_label": "Although, the fair amount of works in sentiment analysis (SA) and opinion mining (OM) systems in the last decade and with respect to the performance of these systems, but it still not desired performance, especially for morphologically-Rich Language (MRL) such as Arabic, due to the complexities and challenges exist in the nature of the languages itself. One of these challenges is the detection of idioms or proverbs phrases within the writer text or comment. An idiom or proverb is a form of speech or an expression that is peculiar to itself. Grammatically, it cannot be understood from the individual meanings of its elements and can yield different sentiment when treats as separate words.", "abstract": "Although, the fair amount of works in sentiment analysis (SA) and opinion mining (OM) systems in the last decade and with respect to the performance of these systems, but it still not desired performance, especially for morphologically-Rich Language (MRL) such as Arabic, due to the complexities and challenges exist in the nature of the languages itself. Although, the fair amount of works in sentiment analysis (SA) and opinion mining (OM) systems in the last decade and with respect to the performance of these systems, but it still not desired performance, especially for morphologically-Rich Language (MRL) such as Arabic, due to the complexities and challenges exist in the nature of the languages itself. One of these challenges is the detection of idioms or proverbs phrases within the writer text or comment. Although, the fair amount of works in sentiment analysis (SA) and opinion mining (OM) systems in the last decade and with respect to the performance of these systems, but it still not desired performance, especially for morphologically-Rich Language (MRL) such as Arabic, due to the complexities and challenges exist in the nature of the languages itself. One of these challenges is the detection of idioms or proverbs phrases within the writer text or comment. An idiom or proverb is a form of speech or an expression that is peculiar to itself. Although, the fair amount of works in sentiment analysis (SA) and opinion mining (OM) systems in the last decade and with respect to the performance of these systems, but it still not desired performance, especially for morphologically-Rich Language (MRL) such as Arabic, due to the complexities and challenges exist in the nature of the languages itself. One of these challenges is the detection of idioms or proverbs phrases within the writer text or comment. An idiom or proverb is a form of speech or an expression that is peculiar to itself. Grammatically, it cannot be understood from the individual meanings of its elements and can yield different sentiment when treats as separate words."}, {"paper_id": "1023931", "adju_relevance": 1, "title": "The impact of image descriptions on user tagging behavior: A study of the nature and functionality of crowdsourced tags", "background_label": "AbstractCrowdsourcing has been emerging to harvest social wisdom from thousands of volunteers to perform series of tasks online. However, little research has been devoted to exploring the impact of various factors such as the content of a resource or crowdsourcing interface design to user tagging behavior. While images' titles and descriptions are frequently available in image digital libraries, it is not clear whether they should be displayed to crowdworkers engaged in tagging.", "abstract": "AbstractCrowdsourcing has been emerging to harvest social wisdom from thousands of volunteers to perform series of tasks online. AbstractCrowdsourcing has been emerging to harvest social wisdom from thousands of volunteers to perform series of tasks online. However, little research has been devoted to exploring the impact of various factors such as the content of a resource or crowdsourcing interface design to user tagging behavior. AbstractCrowdsourcing has been emerging to harvest social wisdom from thousands of volunteers to perform series of tasks online. However, little research has been devoted to exploring the impact of various factors such as the content of a resource or crowdsourcing interface design to user tagging behavior. While images' titles and descriptions are frequently available in image digital libraries, it is not clear whether they should be displayed to crowdworkers engaged in tagging."}, {"paper_id": "53224297", "adju_relevance": 1, "title": "NIPS4Bplus: a richly annotated birdsong audio dataset", "background_label": "Recent advances in birdsong detection and classification have approached a limit due to the lack of fully annotated recordings.", "abstract": "Recent advances in birdsong detection and classification have approached a limit due to the lack of fully annotated recordings."}, {"paper_id": "3936688", "adju_relevance": 1, "title": "Challenges in Discriminating Profanity from Hate Speech", "background_label": "In this study we approach the problem of distinguishing general profanity from hate speech in social media, something which has not been widely considered.", "method_label": "Using a new dataset annotated specifically for this task, we employ supervised classification along with a set of features that includes n-grams, skip-grams and clustering-based word representations. We apply approaches based on single classifiers as well as more advanced ensemble classifiers and stacked generalization, achieving the best result of 80% accuracy for this 3-class classification task.", "result_label": "Analysis of the results reveals that discriminating hate speech and profanity is not a simple task, which may require features that capture a deeper understanding of the text not always possible with surface n-grams. The variability of gold labels in the annotated data, due to differences in the subjective adjudications of the annotators, is also an issue. Other directions for future work are discussed.", "abstract": "In this study we approach the problem of distinguishing general profanity from hate speech in social media, something which has not been widely considered. Using a new dataset annotated specifically for this task, we employ supervised classification along with a set of features that includes n-grams, skip-grams and clustering-based word representations. Using a new dataset annotated specifically for this task, we employ supervised classification along with a set of features that includes n-grams, skip-grams and clustering-based word representations. We apply approaches based on single classifiers as well as more advanced ensemble classifiers and stacked generalization, achieving the best result of 80% accuracy for this 3-class classification task. Analysis of the results reveals that discriminating hate speech and profanity is not a simple task, which may require features that capture a deeper understanding of the text not always possible with surface n-grams. Analysis of the results reveals that discriminating hate speech and profanity is not a simple task, which may require features that capture a deeper understanding of the text not always possible with surface n-grams. The variability of gold labels in the annotated data, due to differences in the subjective adjudications of the annotators, is also an issue. Analysis of the results reveals that discriminating hate speech and profanity is not a simple task, which may require features that capture a deeper understanding of the text not always possible with surface n-grams. The variability of gold labels in the annotated data, due to differences in the subjective adjudications of the annotators, is also an issue. Other directions for future work are discussed."}, {"paper_id": "21732554", "adju_relevance": 1, "title": "Humor Detection in English-Hindi Code-Mixed Social Media Content : Corpus and Baseline System", "background_label": "The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. In depth semantic understanding of the text is required to detect humor which makes the problem difficult to automate. With increase in the number of social media users, many multilingual speakers often interchange between languages while posting on social media which is called code-mixing. It introduces some challenges in the field of linguistic analysis of social media content (Barman et al., 2014), like spelling variations and non-grammatical structures in a sentence. Past researches include detecting puns in texts (Kao et al., 2016) and humor in one-lines (Mihalcea et al., 2010) in a single language, but with the tremendous amount of code-mixed data available online, there is a need to develop techniques which detects humor in code-mixed tweets.", "abstract": "The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. In depth semantic understanding of the text is required to detect humor which makes the problem difficult to automate. The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. In depth semantic understanding of the text is required to detect humor which makes the problem difficult to automate. With increase in the number of social media users, many multilingual speakers often interchange between languages while posting on social media which is called code-mixing. The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. In depth semantic understanding of the text is required to detect humor which makes the problem difficult to automate. With increase in the number of social media users, many multilingual speakers often interchange between languages while posting on social media which is called code-mixing. It introduces some challenges in the field of linguistic analysis of social media content (Barman et al., 2014), like spelling variations and non-grammatical structures in a sentence. The tremendous amount of user generated data through social networking sites led to the gaining popularity of automatic text classification in the field of computational linguistics over the past decade. Within this domain, one problem that has drawn the attention of many researchers is automatic humor detection in texts. In depth semantic understanding of the text is required to detect humor which makes the problem difficult to automate. With increase in the number of social media users, many multilingual speakers often interchange between languages while posting on social media which is called code-mixing. It introduces some challenges in the field of linguistic analysis of social media content (Barman et al., 2014), like spelling variations and non-grammatical structures in a sentence. Past researches include detecting puns in texts (Kao et al., 2016) and humor in one-lines (Mihalcea et al., 2010) in a single language, but with the tremendous amount of code-mixed data available online, there is a need to develop techniques which detects humor in code-mixed tweets."}, {"paper_id": "201669180", "adju_relevance": 1, "title": "Multilingual and Multi-Aspect Hate Speech Analysis", "background_label": "Current research on hate speech analysis is typically oriented towards monolingual and single classification tasks.", "method_label": "In this paper, we present a new multilingual multi-aspect hate speech analysis dataset and use it to test the current state-of-the-art multilingual multitask learning approaches.", "result_label": "We evaluate our dataset in various classification settings, then we discuss how to leverage our annotations in order to improve hate speech detection and classification in general.", "abstract": "Current research on hate speech analysis is typically oriented towards monolingual and single classification tasks. In this paper, we present a new multilingual multi-aspect hate speech analysis dataset and use it to test the current state-of-the-art multilingual multitask learning approaches. We evaluate our dataset in various classification settings, then we discuss how to leverage our annotations in order to improve hate speech detection and classification in general."}, {"paper_id": "52002120", "adju_relevance": 1, "title": "Thou shalt not hate: Countering Online Hate Speech", "background_label": "Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 13,924 manually annotated comments where the labels indicate whether a comment is a counterspeech or not.", "result_label": "Lack of carefully curated data largely inhibits such understanding. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the non-counterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. We also build multilabel models that can detect different types of counterspeech in a comment with an F1-score of 0.60.", "method_label": "This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.71.", "abstract": "Hate content in social media is ever-increasing. Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. Lack of carefully curated data largely inhibits such understanding. Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. Hate content in social media is ever-increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 13,924 manually annotated comments where the labels indicate whether a comment is a counterspeech or not. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. Lack of carefully curated data largely inhibits such understanding. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the non-counterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.71. Lack of carefully curated data largely inhibits such understanding. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the non-counterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. We also build multilabel models that can detect different types of counterspeech in a comment with an F1-score of 0.60."}, {"paper_id": "19182892", "adju_relevance": 1, "title": "Detecting Hate Speech in Social Media", "background_label": "In this paper we examine methods to detect hate speech in social media, while distinguishing this from general profanity.", "method_label": "We aim to establish lexical baselines for this task by applying supervised classification methods using a recently released dataset annotated for this purpose. As features, our system uses character n-grams, word n-grams and word skip-grams. We obtain results of 78% accuracy in identifying posts across three classes.", "result_label": "Results demonstrate that the main challenge lies in discriminating profanity and hate speech from each other. A number of directions for future work are discussed.", "abstract": "In this paper we examine methods to detect hate speech in social media, while distinguishing this from general profanity. We aim to establish lexical baselines for this task by applying supervised classification methods using a recently released dataset annotated for this purpose. We aim to establish lexical baselines for this task by applying supervised classification methods using a recently released dataset annotated for this purpose. As features, our system uses character n-grams, word n-grams and word skip-grams. We aim to establish lexical baselines for this task by applying supervised classification methods using a recently released dataset annotated for this purpose. As features, our system uses character n-grams, word n-grams and word skip-grams. We obtain results of 78% accuracy in identifying posts across three classes. Results demonstrate that the main challenge lies in discriminating profanity and hate speech from each other. Results demonstrate that the main challenge lies in discriminating profanity and hate speech from each other. A number of directions for future work are discussed."}, {"paper_id": "1733167", "adju_relevance": 1, "title": "Automated Hate Speech Detection and the Problem of Offensive Language", "background_label": "A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories.", "method_label": "We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories.", "result_label": "Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify.", "abstract": "A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify."}, {"paper_id": "53295763", "adju_relevance": 1, "title": "Analyzing and learning the language for different types of harassment", "background_label": "Disclaimer: This paper is concerned with violent online harassment. To describe the subject at an adequate level of realism, examples of our collected tweets involve violent, threatening, vulgar and hateful speech language in the context of racial, sexual, political, appearance and intellectual harassment. The presence of a significant amount of harassment in user-generated content and its negative impact calls for robust automatic detection approaches. In this paper, we introduce the notion of contextual type to harassment involving five categories: (i) sexual, (ii) racial, (iii) appearance-related, (iv) intellectual and (v) political.", "method_label": "This requires that we can identify different forms or types of harassment. Earlier work has classified harassing language in terms of hurtfulness, abusiveness, sentiment, and profanity. We utilize an annotated corpus from Twitter distinguishing these types of harassment. To study the context for each type that sheds light on the linguistic meaning, interpretation, and distribution, we conduct two lines of investigation: an extensive linguistic analysis, and a statistical distribution of unigrams. We then build type-ware classifiers to automate the identification of type-specific harassment.", "result_label": "However, to identify and understand harassment more accurately, it is essential to determine the context that represents the interrelated conditions in which they occur. Our experiments demonstrate that these classifiers provide competitive accuracy for identifying and analyzing harassment on social media. We present extensive discussion and major observations about the effectiveness of type-aware classifiers using a detailed comparison setup providing insight into the role of type-dependent features.", "abstract": "Disclaimer: This paper is concerned with violent online harassment. Disclaimer: This paper is concerned with violent online harassment. To describe the subject at an adequate level of realism, examples of our collected tweets involve violent, threatening, vulgar and hateful speech language in the context of racial, sexual, political, appearance and intellectual harassment. Disclaimer: This paper is concerned with violent online harassment. To describe the subject at an adequate level of realism, examples of our collected tweets involve violent, threatening, vulgar and hateful speech language in the context of racial, sexual, political, appearance and intellectual harassment. The presence of a significant amount of harassment in user-generated content and its negative impact calls for robust automatic detection approaches. This requires that we can identify different forms or types of harassment. This requires that we can identify different forms or types of harassment. Earlier work has classified harassing language in terms of hurtfulness, abusiveness, sentiment, and profanity. However, to identify and understand harassment more accurately, it is essential to determine the context that represents the interrelated conditions in which they occur. Disclaimer: This paper is concerned with violent online harassment. To describe the subject at an adequate level of realism, examples of our collected tweets involve violent, threatening, vulgar and hateful speech language in the context of racial, sexual, political, appearance and intellectual harassment. The presence of a significant amount of harassment in user-generated content and its negative impact calls for robust automatic detection approaches. In this paper, we introduce the notion of contextual type to harassment involving five categories: (i) sexual, (ii) racial, (iii) appearance-related, (iv) intellectual and (v) political. This requires that we can identify different forms or types of harassment. Earlier work has classified harassing language in terms of hurtfulness, abusiveness, sentiment, and profanity. We utilize an annotated corpus from Twitter distinguishing these types of harassment. This requires that we can identify different forms or types of harassment. Earlier work has classified harassing language in terms of hurtfulness, abusiveness, sentiment, and profanity. We utilize an annotated corpus from Twitter distinguishing these types of harassment. To study the context for each type that sheds light on the linguistic meaning, interpretation, and distribution, we conduct two lines of investigation: an extensive linguistic analysis, and a statistical distribution of unigrams. This requires that we can identify different forms or types of harassment. Earlier work has classified harassing language in terms of hurtfulness, abusiveness, sentiment, and profanity. We utilize an annotated corpus from Twitter distinguishing these types of harassment. To study the context for each type that sheds light on the linguistic meaning, interpretation, and distribution, we conduct two lines of investigation: an extensive linguistic analysis, and a statistical distribution of unigrams. We then build type-ware classifiers to automate the identification of type-specific harassment. However, to identify and understand harassment more accurately, it is essential to determine the context that represents the interrelated conditions in which they occur. Our experiments demonstrate that these classifiers provide competitive accuracy for identifying and analyzing harassment on social media. However, to identify and understand harassment more accurately, it is essential to determine the context that represents the interrelated conditions in which they occur. Our experiments demonstrate that these classifiers provide competitive accuracy for identifying and analyzing harassment on social media. We present extensive discussion and major observations about the effectiveness of type-aware classifiers using a detailed comparison setup providing insight into the role of type-dependent features."}, {"paper_id": "10634337", "adju_relevance": 1, "title": "Analyzing the Targets of Hate in Online Social Media", "background_label": "Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions. Although this property represents incredible and unique communication opportunities, it also brings along important challenges. Online hate speech is an archetypal example of such challenges. Despite its magnitude and scale, there is a significant gap in understanding the nature of hate speech on social media.", "abstract": "Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions. Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions. Although this property represents incredible and unique communication opportunities, it also brings along important challenges. Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions. Although this property represents incredible and unique communication opportunities, it also brings along important challenges. Online hate speech is an archetypal example of such challenges. Social media systems allow Internet users a congenial platform to freely express their thoughts and opinions. Although this property represents incredible and unique communication opportunities, it also brings along important challenges. Online hate speech is an archetypal example of such challenges. Despite its magnitude and scale, there is a significant gap in understanding the nature of hate speech on social media."}, {"paper_id": "199528395", "adju_relevance": 1, "title": "Challenging the Boundaries of Speech Recognition: The MALACH Corpus", "background_label": "There has been huge progress in speech recognition over the last several years. Tasks once thought extremely difficult, such as SWITCHBOARD, now approach levels of human performance. The MALACH corpus (LDC catalog LDC2012S05), a 375-Hour subset of a large archive of Holocaust testimonies collected by the Survivors of the Shoah Visual History Foundation, presents significant challenges to the speech community. The collection consists of unconstrained, natural speech filled with disfluencies, heavy accents, age-related coarticulations, un-cued speaker and language switching, and emotional speech - all still open problems for speech recognition systems. Transcription is challenging even for skilled human annotators.", "abstract": "There has been huge progress in speech recognition over the last several years. There has been huge progress in speech recognition over the last several years. Tasks once thought extremely difficult, such as SWITCHBOARD, now approach levels of human performance. There has been huge progress in speech recognition over the last several years. Tasks once thought extremely difficult, such as SWITCHBOARD, now approach levels of human performance. The MALACH corpus (LDC catalog LDC2012S05), a 375-Hour subset of a large archive of Holocaust testimonies collected by the Survivors of the Shoah Visual History Foundation, presents significant challenges to the speech community. There has been huge progress in speech recognition over the last several years. Tasks once thought extremely difficult, such as SWITCHBOARD, now approach levels of human performance. The MALACH corpus (LDC catalog LDC2012S05), a 375-Hour subset of a large archive of Holocaust testimonies collected by the Survivors of the Shoah Visual History Foundation, presents significant challenges to the speech community. The collection consists of unconstrained, natural speech filled with disfluencies, heavy accents, age-related coarticulations, un-cued speaker and language switching, and emotional speech - all still open problems for speech recognition systems. There has been huge progress in speech recognition over the last several years. Tasks once thought extremely difficult, such as SWITCHBOARD, now approach levels of human performance. The MALACH corpus (LDC catalog LDC2012S05), a 375-Hour subset of a large archive of Holocaust testimonies collected by the Survivors of the Shoah Visual History Foundation, presents significant challenges to the speech community. The collection consists of unconstrained, natural speech filled with disfluencies, heavy accents, age-related coarticulations, un-cued speaker and language switching, and emotional speech - all still open problems for speech recognition systems. Transcription is challenging even for skilled human annotators."}, {"paper_id": "39424091", "adju_relevance": 1, "title": "A Web of Hate: Tackling Hateful Speech in Online Social Spaces", "background_label": "Online social platforms are beset with hateful speech - content that expresses hatred for a person or group of people. Such content can frighten, intimidate, or silence platform users, and some of it can inspire other users to commit violence. Despite widespread recognition of the problems posed by such content, reliable solutions even for detecting hateful speech are lacking.", "method_label": "In the present work, we establish why keyword-based methods are insufficient for detection. We then propose an approach to detecting hateful speech that uses content produced by self-identifying hateful communities as training data. Our approach bypasses the expensive annotation process often required to train keyword systems and performs well across several established platforms, making substantial improvements over current state-of-the-art approaches.", "abstract": "Online social platforms are beset with hateful speech - content that expresses hatred for a person or group of people. Online social platforms are beset with hateful speech - content that expresses hatred for a person or group of people. Such content can frighten, intimidate, or silence platform users, and some of it can inspire other users to commit violence. Online social platforms are beset with hateful speech - content that expresses hatred for a person or group of people. Such content can frighten, intimidate, or silence platform users, and some of it can inspire other users to commit violence. Despite widespread recognition of the problems posed by such content, reliable solutions even for detecting hateful speech are lacking. In the present work, we establish why keyword-based methods are insufficient for detection. In the present work, we establish why keyword-based methods are insufficient for detection. We then propose an approach to detecting hateful speech that uses content produced by self-identifying hateful communities as training data. In the present work, we establish why keyword-based methods are insufficient for detection. We then propose an approach to detecting hateful speech that uses content produced by self-identifying hateful communities as training data. Our approach bypasses the expensive annotation process often required to train keyword systems and performs well across several established platforms, making substantial improvements over current state-of-the-art approaches."}, {"paper_id": "4425883", "adju_relevance": 1, "title": "Characterizing and Detecting Hateful Users on Twitter", "background_label": "Most current approaches to characterize and detect hate speech focus on \\textit{content} posted in Online Social Networks. They face shortcomings to collect and annotate hateful speech due to the incompleteness and noisiness of OSN text and the subjectivity of hate speech. These limitations are often aided with constraints that oversimplify the problem, such as considering only tweets containing hate-related words.", "abstract": "Most current approaches to characterize and detect hate speech focus on \\textit{content} posted in Online Social Networks. Most current approaches to characterize and detect hate speech focus on \\textit{content} posted in Online Social Networks. They face shortcomings to collect and annotate hateful speech due to the incompleteness and noisiness of OSN text and the subjectivity of hate speech. Most current approaches to characterize and detect hate speech focus on \\textit{content} posted in Online Social Networks. They face shortcomings to collect and annotate hateful speech due to the incompleteness and noisiness of OSN text and the subjectivity of hate speech. These limitations are often aided with constraints that oversimplify the problem, such as considering only tweets containing hate-related words."}, {"paper_id": "62841454", "adju_relevance": 1, "title": "Author Profiling for Hate Speech Detection", "background_label": "The rapid growth of social media in recent years has fed into some highly undesirable phenomena such as proliferation of abusive and offensive language on the Internet. Previous research suggests that such hateful content tends to come from users who share a set of common stereotypes and form communities around them. The current state-of-the-art approaches to hate speech detection are oblivious to user and community information and rely entirely on textual (i.e., lexical and semantic) cues.", "abstract": "The rapid growth of social media in recent years has fed into some highly undesirable phenomena such as proliferation of abusive and offensive language on the Internet. The rapid growth of social media in recent years has fed into some highly undesirable phenomena such as proliferation of abusive and offensive language on the Internet. Previous research suggests that such hateful content tends to come from users who share a set of common stereotypes and form communities around them. The rapid growth of social media in recent years has fed into some highly undesirable phenomena such as proliferation of abusive and offensive language on the Internet. Previous research suggests that such hateful content tends to come from users who share a set of common stereotypes and form communities around them. The current state-of-the-art approaches to hate speech detection are oblivious to user and community information and rely entirely on textual (i.e., lexical and semantic) cues."}, {"paper_id": "11922615", "adju_relevance": 1, "title": "Fuzzy Based Implicit Sentiment Analysis on Quantitative Sentences", "background_label": "With the rapid growth of social media on the web, emotional polarity computation has become a flourishing frontier in the text mining community. However, it is challenging to understand the latest trends and summarize the state or general opinions about products due to the big diversity and size of social media data and this creates the need of automated and real time opinion extraction and mining. On the other hand, the bulk of current research has been devoted to study the subjective sentences which contain opinion keywords and limited work has been reported for objective statements that imply sentiment.", "method_label": "In this paper, fuzzy based knowledge engineering model has been developed for sentiment classification of special group of such sentences including the change or deviation from desired range or value. Drug reviews are the rich source of such statements. Therefore, in this research, some experiments were carried out on patient's reviews on several different cholesterol lowering drugs to determine their sentiment polarity.", "result_label": "The main conclusion through this study is, in order to increase the accuracy level of existing drug opinion mining systems, objective sentences which imply opinion should be taken into account. Our experimental results demonstrate that our proposed model obtains over 72 percent F1 value.", "abstract": "With the rapid growth of social media on the web, emotional polarity computation has become a flourishing frontier in the text mining community. With the rapid growth of social media on the web, emotional polarity computation has become a flourishing frontier in the text mining community. However, it is challenging to understand the latest trends and summarize the state or general opinions about products due to the big diversity and size of social media data and this creates the need of automated and real time opinion extraction and mining. With the rapid growth of social media on the web, emotional polarity computation has become a flourishing frontier in the text mining community. However, it is challenging to understand the latest trends and summarize the state or general opinions about products due to the big diversity and size of social media data and this creates the need of automated and real time opinion extraction and mining. On the other hand, the bulk of current research has been devoted to study the subjective sentences which contain opinion keywords and limited work has been reported for objective statements that imply sentiment. In this paper, fuzzy based knowledge engineering model has been developed for sentiment classification of special group of such sentences including the change or deviation from desired range or value. In this paper, fuzzy based knowledge engineering model has been developed for sentiment classification of special group of such sentences including the change or deviation from desired range or value. Drug reviews are the rich source of such statements. In this paper, fuzzy based knowledge engineering model has been developed for sentiment classification of special group of such sentences including the change or deviation from desired range or value. Drug reviews are the rich source of such statements. Therefore, in this research, some experiments were carried out on patient's reviews on several different cholesterol lowering drugs to determine their sentiment polarity. The main conclusion through this study is, in order to increase the accuracy level of existing drug opinion mining systems, objective sentences which imply opinion should be taken into account. The main conclusion through this study is, in order to increase the accuracy level of existing drug opinion mining systems, objective sentences which imply opinion should be taken into account. Our experimental results demonstrate that our proposed model obtains over 72 percent F1 value."}, {"paper_id": "184483123", "adju_relevance": 1, "title": "SemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter", "background_label": "AbstractThe paper describes the organization of the SemEval 2019 Task 5 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter.", "method_label": "The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the task are described by showing how they have been collected and annotated.", "result_label": "Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks.", "abstract": "AbstractThe paper describes the organization of the SemEval 2019 Task 5 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from Twitter. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. The task is organized in two related classification subtasks: a main binary subtask for detecting the presence of hate speech, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the task are described by showing how they have been collected and annotated. Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks."}, {"paper_id": "503103", "adju_relevance": 1, "title": "Active Annotation in the LUNA Italian Corpus of Spontaneous Dialogues", "method_label": "This procedure consists in the use of a machine learner to assist human annotators in the labeling task. The computer assisted process engages human annotators to check and correct the automatic annotation rather than starting the annotation from un-annotated data. The active learning procedure is combined with an annotation error detection to control the reliablity of the annotation. With the goal of converging as fast as possible to reliable automatic annotations minimizing the human effort, we follow the active learning paradigm, which selects for annotation the most informative training examples required to achieve a better level of performance.", "result_label": "We show that this procedure allows to quickly converge on correct annotations and thus minimize the cost of human supervision.", "abstract": " This procedure consists in the use of a machine learner to assist human annotators in the labeling task. This procedure consists in the use of a machine learner to assist human annotators in the labeling task. The computer assisted process engages human annotators to check and correct the automatic annotation rather than starting the annotation from un-annotated data. This procedure consists in the use of a machine learner to assist human annotators in the labeling task. The computer assisted process engages human annotators to check and correct the automatic annotation rather than starting the annotation from un-annotated data. The active learning procedure is combined with an annotation error detection to control the reliablity of the annotation. This procedure consists in the use of a machine learner to assist human annotators in the labeling task. The computer assisted process engages human annotators to check and correct the automatic annotation rather than starting the annotation from un-annotated data. The active learning procedure is combined with an annotation error detection to control the reliablity of the annotation. With the goal of converging as fast as possible to reliable automatic annotations minimizing the human effort, we follow the active learning paradigm, which selects for annotation the most informative training examples required to achieve a better level of performance. We show that this procedure allows to quickly converge on correct annotations and thus minimize the cost of human supervision."}, {"paper_id": "51684832", "adju_relevance": 1, "title": "Suspended Accounts: A Source of Tweets with Disgust and Anger Emotions for Augmenting Hate Speech Data Sample", "abstract": ""}, {"paper_id": "5444991", "adju_relevance": 1, "title": "Measuring the Reliability of Hate Speech Annotations: The Case of the European Refugee Crisis", "background_label": "Some users of social media are spreading racist, sexist, and otherwise hateful content. For the purpose of training a hate speech detection system, the reliability of the annotations is crucial, but there is no universally agreed-upon definition.", "method_label": "We collected potentially hateful messages and asked two groups of internet users to determine whether they were hate speech or not, whether they should be banned or not and to rate their degree of offensiveness. One of the groups was shown a definition prior to completing the survey. We aimed to assess whether hate speech can be annotated reliably, and the extent to which existing definitions are in accordance with subjective ratings.", "result_label": "Our results indicate that showing users a definition caused them to partially align their own opinion with the definition but did not improve reliability, which was very low overall. We conclude that the presence of hate speech should perhaps not be considered a binary yes-or-no decision, and raters need more detailed instructions for the annotation.", "abstract": "Some users of social media are spreading racist, sexist, and otherwise hateful content. Some users of social media are spreading racist, sexist, and otherwise hateful content. For the purpose of training a hate speech detection system, the reliability of the annotations is crucial, but there is no universally agreed-upon definition. We collected potentially hateful messages and asked two groups of internet users to determine whether they were hate speech or not, whether they should be banned or not and to rate their degree of offensiveness. We collected potentially hateful messages and asked two groups of internet users to determine whether they were hate speech or not, whether they should be banned or not and to rate their degree of offensiveness. One of the groups was shown a definition prior to completing the survey. We collected potentially hateful messages and asked two groups of internet users to determine whether they were hate speech or not, whether they should be banned or not and to rate their degree of offensiveness. One of the groups was shown a definition prior to completing the survey. We aimed to assess whether hate speech can be annotated reliably, and the extent to which existing definitions are in accordance with subjective ratings. Our results indicate that showing users a definition caused them to partially align their own opinion with the definition but did not improve reliability, which was very low overall. Our results indicate that showing users a definition caused them to partially align their own opinion with the definition but did not improve reliability, which was very low overall. We conclude that the presence of hate speech should perhaps not be considered a binary yes-or-no decision, and raters need more detailed instructions for the annotation."}, {"paper_id": "7563136", "adju_relevance": 1, "title": "The Vera am Mittag German audio-visual emotional speech database", "background_label": "The lack of publicly available annotated databases is one of the major barriers to research advances on emotional information processing.", "abstract": "The lack of publicly available annotated databases is one of the major barriers to research advances on emotional information processing."}, {"paper_id": "199460105", "adju_relevance": 1, "title": "Detecting Online Hate Speech Using Context Aware Models", "background_label": "AbstractIn the wake of a polarizing election, the cyber world is laden with hate speech. Context accompanying a hate speech text is useful for identifying hate speech, which however has been largely overlooked in existing datasets and hate speech detection models.", "method_label": "In this paper, we provide an annotated corpus of hate speech with context information well kept. Then we propose two types of hate speech detection models that incorporate context information, a logistic regression model with context features and a neural network model with learning components for context.", "result_label": "Our evaluation shows that both models outperform a strong baseline by around 3% to 4% in F1 score and combining these two models further improve the performance by another 7% in F1 score.", "abstract": "AbstractIn the wake of a polarizing election, the cyber world is laden with hate speech. AbstractIn the wake of a polarizing election, the cyber world is laden with hate speech. Context accompanying a hate speech text is useful for identifying hate speech, which however has been largely overlooked in existing datasets and hate speech detection models. In this paper, we provide an annotated corpus of hate speech with context information well kept. In this paper, we provide an annotated corpus of hate speech with context information well kept. Then we propose two types of hate speech detection models that incorporate context information, a logistic regression model with context features and a neural network model with learning components for context. Our evaluation shows that both models outperform a strong baseline by around 3% to 4% in F1 score and combining these two models further improve the performance by another 7% in F1 score."}, {"paper_id": "18256736", "adju_relevance": 1, "title": "Cyber Hate Speech on Twitter: An Application of Machine Classification and Statistical Modeling for Policy and Decision Making", "background_label": "The use of \u201cBig Data\u201d in policy and decision making is a current topic of debate. The 2013 murder of Drummer Lee Rigby in Woolwich, London, UK led to an extensive public reaction on social media, providing the opportunity to study the spread of online hate speech (cyber hate) on Twitter.", "method_label": "Human annotated Twitter data was collected in the immediate aftermath of Rigby's murder to train and test a supervised machine learning text classifier that distinguishes between hateful and/or antagonistic responses with a focus on race, ethnicity, or religion; and more general responses. Classification features were derived from the content of each tweet, including grammatical dependencies between words to recognize \u201cothering\u201d phrases, incitement to respond with antagonistic action, and claims of well-founded or justified discrimination against social groups.", "result_label": "The results of the classifier were optimal using a combination of probabilistic, rule-based, and spatial-based classifiers with a voted ensemble meta-classifier. We demonstrate how the results of the classifier can be robustly utilized in a statistical model used to forecast the likely spread of cyber hate in a sample of Twitter data. The applications to policy and decision making are discussed.", "abstract": "The use of \u201cBig Data\u201d in policy and decision making is a current topic of debate. The use of \u201cBig Data\u201d in policy and decision making is a current topic of debate. The 2013 murder of Drummer Lee Rigby in Woolwich, London, UK led to an extensive public reaction on social media, providing the opportunity to study the spread of online hate speech (cyber hate) on Twitter. Human annotated Twitter data was collected in the immediate aftermath of Rigby's murder to train and test a supervised machine learning text classifier that distinguishes between hateful and/or antagonistic responses with a focus on race, ethnicity, or religion; and more general responses. Human annotated Twitter data was collected in the immediate aftermath of Rigby's murder to train and test a supervised machine learning text classifier that distinguishes between hateful and/or antagonistic responses with a focus on race, ethnicity, or religion; and more general responses. Classification features were derived from the content of each tweet, including grammatical dependencies between words to recognize \u201cothering\u201d phrases, incitement to respond with antagonistic action, and claims of well-founded or justified discrimination against social groups. The results of the classifier were optimal using a combination of probabilistic, rule-based, and spatial-based classifiers with a voted ensemble meta-classifier. The results of the classifier were optimal using a combination of probabilistic, rule-based, and spatial-based classifiers with a voted ensemble meta-classifier. We demonstrate how the results of the classifier can be robustly utilized in a statistical model used to forecast the likely spread of cyber hate in a sample of Twitter data. The results of the classifier were optimal using a combination of probabilistic, rule-based, and spatial-based classifiers with a voted ensemble meta-classifier. We demonstrate how the results of the classifier can be robustly utilized in a statistical model used to forecast the likely spread of cyber hate in a sample of Twitter data. The applications to policy and decision making are discussed."}, {"paper_id": "4354069", "adju_relevance": 1, "title": "Aggression-annotated Corpus of Hindi-English Code-mixed Data", "background_label": "As the interaction over the web has increased, incidents of aggression and related events like trolling, cyberbullying, flaming, hate speech, etc. too have increased manifold across the globe. While most of these behaviour like bullying or hate speech have predated the Internet, the reach and extent of the Internet has given these an unprecedented power and influence to affect the lives of billions of people. So it is of utmost significance and importance that some preventive measures be taken to provide safeguard to the people using the web such that the web remains a viable medium of communication and connection, in general.", "abstract": "As the interaction over the web has increased, incidents of aggression and related events like trolling, cyberbullying, flaming, hate speech, etc. As the interaction over the web has increased, incidents of aggression and related events like trolling, cyberbullying, flaming, hate speech, etc. too have increased manifold across the globe. As the interaction over the web has increased, incidents of aggression and related events like trolling, cyberbullying, flaming, hate speech, etc. too have increased manifold across the globe. While most of these behaviour like bullying or hate speech have predated the Internet, the reach and extent of the Internet has given these an unprecedented power and influence to affect the lives of billions of people. As the interaction over the web has increased, incidents of aggression and related events like trolling, cyberbullying, flaming, hate speech, etc. too have increased manifold across the globe. While most of these behaviour like bullying or hate speech have predated the Internet, the reach and extent of the Internet has given these an unprecedented power and influence to affect the lives of billions of people. So it is of utmost significance and importance that some preventive measures be taken to provide safeguard to the people using the web such that the web remains a viable medium of communication and connection, in general."}, {"paper_id": "8314665", "adju_relevance": 1, "title": "A Measurement Study of Hate Speech in Social Media", "background_label": "Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. However, this same potential of social media systems brings together an important challenge---these systems provide space for discourses that are harmful to certain groups of people. This challenge manifests itself with a number of variations, including bullying, offensive content, and hate speech. Specifically, authorities of many countries today are rapidly recognizing hate speech as a serious problem, specially because it is hard to create barriers on the Internet to prevent the dissemination of hate across countries or minorities.", "abstract": "Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. However, this same potential of social media systems brings together an important challenge---these systems provide space for discourses that are harmful to certain groups of people. Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. However, this same potential of social media systems brings together an important challenge---these systems provide space for discourses that are harmful to certain groups of people. This challenge manifests itself with a number of variations, including bullying, offensive content, and hate speech. Social media platforms provide an inexpensive communication medium that allows anyone to quickly reach millions of users. Consequently, in these platforms anyone can publish content and anyone interested in the content can obtain it, representing a transformative revolution in our society. However, this same potential of social media systems brings together an important challenge---these systems provide space for discourses that are harmful to certain groups of people. This challenge manifests itself with a number of variations, including bullying, offensive content, and hate speech. Specifically, authorities of many countries today are rapidly recognizing hate speech as a serious problem, specially because it is hard to create barriers on the Internet to prevent the dissemination of hate across countries or minorities."}, {"paper_id": "12678205", "adju_relevance": 1, "title": "The Arabic Online Commentary Dataset: an Annotated Dataset of Informal Arabic with High Dialectal Content", "background_label": "AbstractThe written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true \"native\" languages of Arabic speakers used in daily life. However, due to MSA's prevalence in written form, almost all Arabic datasets have predominantly MSA content.", "method_label": "We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset. So far, we have labeled 108K sentences, 41% of which as having dialectal content.", "result_label": "We also present experimental results on the task of automatic dialect identification, using the collected labels for training and evaluation.", "abstract": "AbstractThe written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true \"native\" languages of Arabic speakers used in daily life. AbstractThe written form of Arabic, Modern Standard Arabic (MSA), differs quite a bit from the spoken dialects of Arabic, which are the true \"native\" languages of Arabic speakers used in daily life. However, due to MSA's prevalence in written form, almost all Arabic datasets have predominantly MSA content. We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset. We present the Arabic Online Commentary Dataset, a 52M-word monolingual dataset rich in dialectal content, and we describe our long-term annotation effort to identify the dialect level (and dialect itself) in each sentence of the dataset. So far, we have labeled 108K sentences, 41% of which as having dialectal content. We also present experimental results on the task of automatic dialect identification, using the collected labels for training and evaluation."}, {"paper_id": "38001773", "adju_relevance": 0, "title": "Equality and Freedom of Expression: The Hate Speech Dilemma", "background_label": "In recent legal scholarship, writers have proposed three approaches to hate speech, each with its own internal complexities and variations. The first approach allows hate speech in order to maximize opportunities for individual expression and cultural regeneration. The second, highly controversial approach represses hate speech through sanctions that range from official and private reprimands to criminal prosecutions in order to promote equality and the nonsubordination of potential hate speech targets. Aggressive versions of this approach urge that hate speech should be punishable only when directed at members of a historically subordinated group, not dominant group members.", "method_label": "The third, emerging approach attempts to accommodate the \"worthy passions\" of the first two approaches. The accommodationists endorse tightly worded, cautiously progressive measures that tend to proscribe only targeted vilification of a person on the basis of race, gender, religion, ethnic origin, sexual orientation, or other protected characteristics.", "result_label": "These philosophical, constitutional, and practical factors illustrate the extreme difficulty of striking an appropriate balance between the strong claims of civil discourse and the strong claims of untrammeled expression. The following pages explore these complexities in greater detail and defend an endorsement of an accommodationist approach to hate speech regulation.", "abstract": "In recent legal scholarship, writers have proposed three approaches to hate speech, each with its own internal complexities and variations. In recent legal scholarship, writers have proposed three approaches to hate speech, each with its own internal complexities and variations. The first approach allows hate speech in order to maximize opportunities for individual expression and cultural regeneration. In recent legal scholarship, writers have proposed three approaches to hate speech, each with its own internal complexities and variations. The first approach allows hate speech in order to maximize opportunities for individual expression and cultural regeneration. The second, highly controversial approach represses hate speech through sanctions that range from official and private reprimands to criminal prosecutions in order to promote equality and the nonsubordination of potential hate speech targets. In recent legal scholarship, writers have proposed three approaches to hate speech, each with its own internal complexities and variations. The first approach allows hate speech in order to maximize opportunities for individual expression and cultural regeneration. The second, highly controversial approach represses hate speech through sanctions that range from official and private reprimands to criminal prosecutions in order to promote equality and the nonsubordination of potential hate speech targets. Aggressive versions of this approach urge that hate speech should be punishable only when directed at members of a historically subordinated group, not dominant group members. The third, emerging approach attempts to accommodate the \"worthy passions\" of the first two approaches. The third, emerging approach attempts to accommodate the \"worthy passions\" of the first two approaches. The accommodationists endorse tightly worded, cautiously progressive measures that tend to proscribe only targeted vilification of a person on the basis of race, gender, religion, ethnic origin, sexual orientation, or other protected characteristics. These philosophical, constitutional, and practical factors illustrate the extreme difficulty of striking an appropriate balance between the strong claims of civil discourse and the strong claims of untrammeled expression. These philosophical, constitutional, and practical factors illustrate the extreme difficulty of striking an appropriate balance between the strong claims of civil discourse and the strong claims of untrammeled expression. The following pages explore these complexities in greater detail and defend an endorsement of an accommodationist approach to hate speech regulation."}, {"paper_id": "149999186", "adju_relevance": 0, "title": "Employing sentiment analysis for gauging perceptions of minorities in multicultural societies: An analysis of Twitter feeds on the Afrikaner community of Orania in South Africa", "background_label": "South Africa is well known as a country characterised by racial and ethnic divisions, particularly for the divisions and conflicts between the white population and black population.", "abstract": "South Africa is well known as a country characterised by racial and ethnic divisions, particularly for the divisions and conflicts between the white population and black population."}, {"paper_id": "118988729", "adju_relevance": 0, "title": "A Microphotonic Astrocomb", "background_label": "One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers.", "method_label": "Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer.", "result_label": "As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research.", "abstract": "One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. One of the essential prerequisites for detection of Earth-like extra-solar planets or direct measurements of the cosmological expansion is the accurate and precise wavelength calibration of astronomical spectrometers. It has already been realized that the large number of exactly known optical frequencies provided by laser frequency combs ('astrocombs') can significantly surpass conventionally used hollow-cathode lamps as calibration light sources. A remaining challenge, however, is generation of frequency combs with lines resolvable by astronomical spectrometers. Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. Here we demonstrate an astrocomb generated via soliton formation in an on-chip microphotonic resonator ('microresonator') with a resolvable line spacing of 23.7 GHz. This comb is providing wavelength calibration on the 10 cm/s radial velocity level on the GIANO-B high-resolution near-infrared spectrometer. As such, microresonator frequency combs have the potential of providing broadband wavelength calibration for the next-generation of astronomical instruments in planet-hunting and cosmological research."}, {"paper_id": "10321545", "adju_relevance": 0, "title": "Liars and Saviors in a Sentiment Annotated Corpus of Comments to Political Debates", "background_label": "AbstractWe investigate the expression of opinions about human entities in user-generated content (UGC). A set of 2,800 online news comments (8,000 sentences) was manually annotated, following a rich annotation scheme designed for this purpose.", "method_label": "We conclude that the challenge in performing opinion mining in such type of content is correctly identifying the positive opinions, because (i) they are much less frequent than negative opinions and (ii) they are particularly exposed to verbal irony.", "result_label": "We also show that the recognition of human targets poses additional challenges on mining opinions from UGC, since they are frequently mentioned by pronouns, definite descriptions and nicknames.", "abstract": "AbstractWe investigate the expression of opinions about human entities in user-generated content (UGC). AbstractWe investigate the expression of opinions about human entities in user-generated content (UGC). A set of 2,800 online news comments (8,000 sentences) was manually annotated, following a rich annotation scheme designed for this purpose. We conclude that the challenge in performing opinion mining in such type of content is correctly identifying the positive opinions, because (i) they are much less frequent than negative opinions and (ii) they are particularly exposed to verbal irony. We also show that the recognition of human targets poses additional challenges on mining opinions from UGC, since they are frequently mentioned by pronouns, definite descriptions and nicknames."}, {"paper_id": "4718302", "adju_relevance": 0, "title": "Leveraging Intra-User and Inter-User Representation Learning for Automated Hate Speech Detection", "background_label": "Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP). Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the accuracy is still poor. The central problem is that social media posts are short and noisy, and most existing hate speech detection solutions take each post as an isolated input instance, which is likely to yield high false positive and negative rates.", "abstract": "Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP). Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP). Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the accuracy is still poor. Hate speech detection is a critical, yet challenging problem in Natural Language Processing (NLP). Despite the existence of numerous studies dedicated to the development of NLP hate speech detection approaches, the accuracy is still poor. The central problem is that social media posts are short and noisy, and most existing hate speech detection solutions take each post as an isolated input instance, which is likely to yield high false positive and negative rates."}, {"paper_id": "406026", "adju_relevance": 0, "title": "Are You a Racist or Am I Seeing Things? Annotator Influence on Hate Speech Detection on Twitter", "background_label": "AbstractHate speech in the form of racism and sexism is commonplace on the internet (Waseem and Hovy, 2016) . For this reason, there has been both an academic and an industry interest in detection of hate speech.", "abstract": "AbstractHate speech in the form of racism and sexism is commonplace on the internet (Waseem and Hovy, 2016) . AbstractHate speech in the form of racism and sexism is commonplace on the internet (Waseem and Hovy, 2016) . For this reason, there has been both an academic and an industry interest in detection of hate speech."}, {"paper_id": "2880908", "adju_relevance": 0, "title": "Deep Learning for Hate Speech Detection in Tweets", "background_label": "Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging.", "method_label": "We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity.", "result_label": "Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points.", "abstract": "Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points."}, {"paper_id": "199472715", "adju_relevance": 0, "title": "DpgMedia2019: A Dutch News Dataset for Partisanship Detection", "background_label": "We present a new Dutch news dataset with labeled partisanship. The dataset contains more than 100K articles that are labeled on the publisher level and 776 articles that were crowdsourced using an internal survey platform and labeled on the article level.", "abstract": "We present a new Dutch news dataset with labeled partisanship. We present a new Dutch news dataset with labeled partisanship. The dataset contains more than 100K articles that are labeled on the publisher level and 776 articles that were crowdsourced using an internal survey platform and labeled on the article level."}, {"paper_id": "51777592", "adju_relevance": 0, "title": "The nature of hate", "background_label": "1. The problem: the role of hate in the world 2. Definitions and theories of hate 3. The duplex theory of hate I: the triangular theory of the structure of hate 4.", "abstract": "1. 1. The problem: the role of hate in the world 2. 1. The problem: the role of hate in the world 2. Definitions and theories of hate 3. 1. The problem: the role of hate in the world 2. Definitions and theories of hate 3. The duplex theory of hate I: the triangular theory of the structure of hate 4."}, {"paper_id": "59842973", "adju_relevance": 0, "title": "How is Your Mood When Writing Sexist tweets? Detecting the Emotion Type and Intensity of Emotion Using Natural Language Processing Techniques", "background_label": "Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Categorizing sexism as either benevolent or hostile sexism is so broad that it easily ignores the other categories of sexism on social media.", "method_label": "Sharifirad S and Matwin S 2018 proposed a well-defined category of sexism including indirect harassment, information threat, sexual harassment and physical harassment, inspired from social science for the purpose of natural language processing techniques.", "abstract": "Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Online social platforms have been the battlefield of users with different emotions and attitudes toward each other in recent years. While sexism has been considered as a category of hateful speech in the literature, there is no comprehensive definition and category of sexism attracting natural language processing techniques. Categorizing sexism as either benevolent or hostile sexism is so broad that it easily ignores the other categories of sexism on social media. Sharifirad S and Matwin S 2018 proposed a well-defined category of sexism including indirect harassment, information threat, sexual harassment and physical harassment, inspired from social science for the purpose of natural language processing techniques."}, {"paper_id": "17104678", "adju_relevance": 0, "title": "Part-of-Speech Tagging for Code-mixed Indian Social Media Text at ICON 2015", "background_label": "This paper discusses the experiments carried out by us at Jadavpur University as part of the participation in ICON 2015 task: POS Tagging for Code-mixed Indian Social Media Text.", "method_label": "The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information from dictionary as well as some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. We submitted runs for Bengali-English, Hindi-English and Tamil-English Language pairs. Our system has been trained and tested on the datasets released for ICON 2015 shared task: POS Tagging For Code-mixed Indian Social Media Text.", "result_label": "In constrained mode, our system obtains average overall accuracy (averaged over all three language pairs) of 75.60% which is very close to other participating two systems (76.79% for IIITH and 75.79% for AMRITA_CEN) ranked higher than our system. In unconstrained mode, our system obtains average overall accuracy of 70.65% which is also close to the system (72.85% for AMRITA_CEN) which obtains the highest average overall accuracy.", "abstract": "This paper discusses the experiments carried out by us at Jadavpur University as part of the participation in ICON 2015 task: POS Tagging for Code-mixed Indian Social Media Text. The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information from dictionary as well as some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information from dictionary as well as some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. We submitted runs for Bengali-English, Hindi-English and Tamil-English Language pairs. The tool that we have developed for the task is based on Trigram Hidden Markov Model that utilizes information from dictionary as well as some other word level features to enhance the observation probabilities of the known tokens as well as unknown tokens. We submitted runs for Bengali-English, Hindi-English and Tamil-English Language pairs. Our system has been trained and tested on the datasets released for ICON 2015 shared task: POS Tagging For Code-mixed Indian Social Media Text. In constrained mode, our system obtains average overall accuracy (averaged over all three language pairs) of 75.60% which is very close to other participating two systems (76.79% for IIITH and 75.79% for AMRITA_CEN) ranked higher than our system. In constrained mode, our system obtains average overall accuracy (averaged over all three language pairs) of 75.60% which is very close to other participating two systems (76.79% for IIITH and 75.79% for AMRITA_CEN) ranked higher than our system. In unconstrained mode, our system obtains average overall accuracy of 70.65% which is also close to the system (72.85% for AMRITA_CEN) which obtains the highest average overall accuracy."}, {"paper_id": "4737415", "adju_relevance": 0, "title": "Hate Speech Detection: A Solved Problem? The Challenging Case of Long Tail on Twitter", "background_label": "In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and researchers. A large number of methods have been developed for automated hate speech detection online.", "method_label": "This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech. However, we notice significant difference between the performance of the two (i.e., non-hate v.s. hate).", "abstract": "In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and researchers. In recent years, the increasing propagation of hate speech on social media and the urgent need for effective counter-measures have drawn significant investment from governments, companies, and researchers. A large number of methods have been developed for automated hate speech detection online. This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech. This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech. However, we notice significant difference between the performance of the two (i.e., non-hate v.s. This aims to classify textual content into non-hate or hate speech, in which case the method may also identify the targeting characteristics (i.e., types of hate, such as race, and religion) in the hate speech. However, we notice significant difference between the performance of the two (i.e., non-hate v.s. hate)."}, {"paper_id": "20335790", "adju_relevance": 0, "title": "Using Convolutional Neural Networks to Classify Hate-Speech", "background_label": "AbstractThe paper introduces a deep learningbased Twitter hate-speech text classification system.", "method_label": "The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. Four Convolutional Neural Network models were trained on resp. character 4-grams, word vectors based on semantic information built using word2vec, randomly generated word vectors, and word vectors combined with character n-grams. The feature set was down-sized in the networks by maxpooling, and a softmax function used to classify tweets.", "result_label": "Tested by 10-fold crossvalidation, the model based on word2vec embeddings performed best, with higher precision than recall, and a 78.3% F-score.", "abstract": "AbstractThe paper introduces a deep learningbased Twitter hate-speech text classification system. The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. Four Convolutional Neural Network models were trained on resp. The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. Four Convolutional Neural Network models were trained on resp. character 4-grams, word vectors based on semantic information built using word2vec, randomly generated word vectors, and word vectors combined with character n-grams. The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. Four Convolutional Neural Network models were trained on resp. character 4-grams, word vectors based on semantic information built using word2vec, randomly generated word vectors, and word vectors combined with character n-grams. The feature set was down-sized in the networks by maxpooling, and a softmax function used to classify tweets. Tested by 10-fold crossvalidation, the model based on word2vec embeddings performed best, with higher precision than recall, and a 78.3% F-score."}, {"paper_id": "13813571", "adju_relevance": 0, "title": "#nowplaying Music Dataset: Extracting Listening Behavior from Twitter", "background_label": "The extraction of information from online social networks has become popular in both industry and academia as these data sources allow for innovative applications. However, in the area of music recommender systems and music information retrieval, respective data is hardly exploited.", "abstract": "The extraction of information from online social networks has become popular in both industry and academia as these data sources allow for innovative applications. The extraction of information from online social networks has become popular in both industry and academia as these data sources allow for innovative applications. However, in the area of music recommender systems and music information retrieval, respective data is hardly exploited."}, {"paper_id": "154049112", "adju_relevance": 0, "title": "Hate in Cyberspace: Regulating Hate Speech on the Internet", "background_label": "The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The worldwide potentials for the Internet offer a mechanism for spreading democracy and commercial entrepreneurialship throughout the world. However, the Internet is also a breeding ground for hate groups who use it to expand their membership and to solidify their forces. The packages of information about how to instigate a racial war or to limit the opportunities for identifiable groups do not exist in a virtual world, absent from reality. They strengthen the purveyors of racism, anti-Semitism, sexism, and gay-bashers. They also intimidate traditional scapegoats and limit their ability to exercise the full extent of their fundamental right to autonomy.", "result_label": "False messages which are intended to stifle and exploit existing negative stereotypes impact individuals' lives and the societies where they reside.", "abstract": "The Internet is a global network providing connections for many forms of speech. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The worldwide potentials for the Internet offer a mechanism for spreading democracy and commercial entrepreneurialship throughout the world. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The worldwide potentials for the Internet offer a mechanism for spreading democracy and commercial entrepreneurialship throughout the world. However, the Internet is also a breeding ground for hate groups who use it to expand their membership and to solidify their forces. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The worldwide potentials for the Internet offer a mechanism for spreading democracy and commercial entrepreneurialship throughout the world. However, the Internet is also a breeding ground for hate groups who use it to expand their membership and to solidify their forces. The packages of information about how to instigate a racial war or to limit the opportunities for identifiable groups do not exist in a virtual world, absent from reality. False messages which are intended to stifle and exploit existing negative stereotypes impact individuals' lives and the societies where they reside. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The worldwide potentials for the Internet offer a mechanism for spreading democracy and commercial entrepreneurialship throughout the world. However, the Internet is also a breeding ground for hate groups who use it to expand their membership and to solidify their forces. The packages of information about how to instigate a racial war or to limit the opportunities for identifiable groups do not exist in a virtual world, absent from reality. They strengthen the purveyors of racism, anti-Semitism, sexism, and gay-bashers. The Internet is a global network providing connections for many forms of speech. All the processes of message transmission occur in real space through a system of identifiable algorithms. The information is posted on the Web by individuals or groups intending it to be read by and to affect a limited or expansive audience. The worldwide potentials for the Internet offer a mechanism for spreading democracy and commercial entrepreneurialship throughout the world. However, the Internet is also a breeding ground for hate groups who use it to expand their membership and to solidify their forces. The packages of information about how to instigate a racial war or to limit the opportunities for identifiable groups do not exist in a virtual world, absent from reality. They strengthen the purveyors of racism, anti-Semitism, sexism, and gay-bashers. They also intimidate traditional scapegoats and limit their ability to exercise the full extent of their fundamental right to autonomy."}, {"paper_id": "3356463", "adju_relevance": 0, "title": "LSTM: A Search Space Odyssey", "background_label": "Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants.", "method_label": "In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful fANOVA framework.", "result_label": "In total, we summarize the results of 5400 experimental runs ($\\approx 15$ years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.", "abstract": "Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. Several variants of the Long Short-Term Memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful fANOVA framework. In total, we summarize the results of 5400 experimental runs ($\\approx 15$ years of CPU time), which makes our study the largest of its kind on LSTM networks. In total, we summarize the results of 5400 experimental runs ($\\approx 15$ years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. In total, we summarize the results of 5400 experimental runs ($\\approx 15$ years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment."}, {"paper_id": "144527647", "adju_relevance": 0, "title": "Hate Speech or \u201cReasonable Racism?\u201d The Other in Stormfront", "background_label": "We use the construct of the \u201cother\u201d to explore how hate operates rhetorically within the virtual conclave of Stormfront, credited as the first hate Web site. Through the Internet, white supremacists create a rhetorical vision that resonates with those who feel marginalized by contemporary political, social, and economic forces.", "result_label": "However, as compared to previous studies of on-line white supremacist rhetoric, we show that Stormfront discourse appears less virulent and more palatable to the naive reader. We suggest that Stormfront provides a \u201ccyber transition\u201d between traditional hate speech and \u201creasonable racism,\u201d a tempered discourse that emphasizes pseudo-rational discussions of race, and subsequently may cast a wider net in attracting audiences.", "abstract": "We use the construct of the \u201cother\u201d to explore how hate operates rhetorically within the virtual conclave of Stormfront, credited as the first hate Web site. We use the construct of the \u201cother\u201d to explore how hate operates rhetorically within the virtual conclave of Stormfront, credited as the first hate Web site. Through the Internet, white supremacists create a rhetorical vision that resonates with those who feel marginalized by contemporary political, social, and economic forces. However, as compared to previous studies of on-line white supremacist rhetoric, we show that Stormfront discourse appears less virulent and more palatable to the naive reader. However, as compared to previous studies of on-line white supremacist rhetoric, we show that Stormfront discourse appears less virulent and more palatable to the naive reader. We suggest that Stormfront provides a \u201ccyber transition\u201d between traditional hate speech and \u201creasonable racism,\u201d a tempered discourse that emphasizes pseudo-rational discussions of race, and subsequently may cast a wider net in attracting audiences."}, {"paper_id": "2514901", "adju_relevance": 0, "title": "Quantum Computational Supremacy", "background_label": "A key milestone in this field will be when a universal quantum computer performs a computational task that is beyond the capability of any classical computer, an event known as quantum supremacy. This would be easier to achieve experimentally than full-scale quantum computing, but involves new theoretical challenges.", "result_label": "Here we present the leading proposals to achieve quantum supremacy, and discuss how we can reliably compare the power of a classical computer to the power of a quantum computer.", "abstract": " A key milestone in this field will be when a universal quantum computer performs a computational task that is beyond the capability of any classical computer, an event known as quantum supremacy. A key milestone in this field will be when a universal quantum computer performs a computational task that is beyond the capability of any classical computer, an event known as quantum supremacy. This would be easier to achieve experimentally than full-scale quantum computing, but involves new theoretical challenges. Here we present the leading proposals to achieve quantum supremacy, and discuss how we can reliably compare the power of a classical computer to the power of a quantum computer."}, {"paper_id": "119425731", "adju_relevance": 0, "title": "Unzerlegbare Darstellungen I", "background_label": "LetK be the structure got by forgetting the composition law of morphisms in a given category. A linear representation ofK is given by a map V associating with any morphism \u03d5: a\u2192e ofK a linear vector space map V(\u03d5): V(a)\u2192V(e).", "method_label": "We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations.", "abstract": "LetK be the structure got by forgetting the composition law of morphisms in a given category. LetK be the structure got by forgetting the composition law of morphisms in a given category. A linear representation ofK is given by a map V associating with any morphism \u03d5: a\u2192e ofK a linear vector space map V(\u03d5): V(a)\u2192V(e). We classify thoseK having only finitely many isomorphy classes of indecomposable linear representations."}, {"paper_id": "44102273", "adju_relevance": 0, "title": "Examining a hate speech corpus for hate speech detection and popularity prediction", "background_label": "As research on hate speech becomes more and more relevant every day, most of it is still focused on hate speech detection.", "abstract": "As research on hate speech becomes more and more relevant every day, most of it is still focused on hate speech detection."}, {"paper_id": "49207827", "adju_relevance": 0, "title": "Gender Prediction in English-Hindi Code-Mixed Social Media Content : Corpus and Baseline System", "background_label": "The rapid expansion in the usage of social media networking sites leads to a huge amount of unprocessed user generated data which can be used for text mining. Author profiling is the problem of automatically determining profiling aspects like the author's gender and age group through a text is gaining much popularity in computational linguistics. Most of the past research in author profiling is concentrated on English texts \\cite{1,2}. However many users often change the language while posting on social media which is called code-mixing, and it develops some challenges in the field of text classification and author profiling like variations in spelling, non-grammatical structure and transliteration \\cite{3}. There are very few English-Hindi code-mixed annotated datasets of social media content present online \\cite{4}.", "abstract": "The rapid expansion in the usage of social media networking sites leads to a huge amount of unprocessed user generated data which can be used for text mining. The rapid expansion in the usage of social media networking sites leads to a huge amount of unprocessed user generated data which can be used for text mining. Author profiling is the problem of automatically determining profiling aspects like the author's gender and age group through a text is gaining much popularity in computational linguistics. The rapid expansion in the usage of social media networking sites leads to a huge amount of unprocessed user generated data which can be used for text mining. Author profiling is the problem of automatically determining profiling aspects like the author's gender and age group through a text is gaining much popularity in computational linguistics. Most of the past research in author profiling is concentrated on English texts \\cite{1,2}. The rapid expansion in the usage of social media networking sites leads to a huge amount of unprocessed user generated data which can be used for text mining. Author profiling is the problem of automatically determining profiling aspects like the author's gender and age group through a text is gaining much popularity in computational linguistics. Most of the past research in author profiling is concentrated on English texts \\cite{1,2}. However many users often change the language while posting on social media which is called code-mixing, and it develops some challenges in the field of text classification and author profiling like variations in spelling, non-grammatical structure and transliteration \\cite{3}. The rapid expansion in the usage of social media networking sites leads to a huge amount of unprocessed user generated data which can be used for text mining. Author profiling is the problem of automatically determining profiling aspects like the author's gender and age group through a text is gaining much popularity in computational linguistics. Most of the past research in author profiling is concentrated on English texts \\cite{1,2}. However many users often change the language while posting on social media which is called code-mixing, and it develops some challenges in the field of text classification and author profiling like variations in spelling, non-grammatical structure and transliteration \\cite{3}. There are very few English-Hindi code-mixed annotated datasets of social media content present online \\cite{4}."}, {"paper_id": "153326830", "adju_relevance": 0, "title": "White Supremacy and Racism in the Post-Civil Rights Era", "abstract": ""}, {"paper_id": "34009405", "adju_relevance": 0, "title": "Active learning in annotating micro-blogs dealing with e-reputation", "background_label": "Elections unleash strong political views on Twitter, but what do people really think about politics? Opinion and trend mining on micro blogs dealing with politics has recently attracted researchers in several fields including Information Retrieval and Machine Learning (ML). Since the performance of ML and Natural Language Processing (NLP) approaches are limited by the amount and quality of data available, one promising alternative for some tasks is the automatic propagation of expert annotations.", "abstract": "Elections unleash strong political views on Twitter, but what do people really think about politics? Elections unleash strong political views on Twitter, but what do people really think about politics? Opinion and trend mining on micro blogs dealing with politics has recently attracted researchers in several fields including Information Retrieval and Machine Learning (ML). Elections unleash strong political views on Twitter, but what do people really think about politics? Opinion and trend mining on micro blogs dealing with politics has recently attracted researchers in several fields including Information Retrieval and Machine Learning (ML). Since the performance of ML and Natural Language Processing (NLP) approaches are limited by the amount and quality of data available, one promising alternative for some tasks is the automatic propagation of expert annotations."}, {"paper_id": "4809781", "adju_relevance": 0, "title": "Hate Lingo: A Target-based Linguistic Analysis of Hate Speech in Social Media", "background_label": "While social media empowers freedom of expression and individual voices, it also enables anti-social behavior, online harassment, cyberbullying, and hate speech. In this paper, we deepen our understanding of online hate speech by focusing on a largely neglected but crucial aspect of hate speech -- its target: either\"directed\"towards a specific person or entity, or\"generalized\"towards a group of people sharing a common protected characteristic.", "method_label": "We perform the first linguistic and psycholinguistic analysis of these two forms of hate speech and reveal the presence of interesting markers that distinguish these types of hate speech.", "result_label": "Our analysis reveals that Directed hate speech, in addition to being more personal and directed, is more informal, angrier, and often explicitly attacks the target (via name calling) with fewer analytic words and more words suggesting authority and influence. Generalized hate speech, on the other hand, is dominated by religious hate, is characterized by the use of lethal words such as murder, exterminate, and kill; and quantity words such as million and many. Altogether, our work provides a data-driven analysis of the nuances of online-hate speech that enables not only a deepened understanding of hate speech and its social implications but also its detection.", "abstract": "While social media empowers freedom of expression and individual voices, it also enables anti-social behavior, online harassment, cyberbullying, and hate speech. While social media empowers freedom of expression and individual voices, it also enables anti-social behavior, online harassment, cyberbullying, and hate speech. In this paper, we deepen our understanding of online hate speech by focusing on a largely neglected but crucial aspect of hate speech -- its target: either\"directed\"towards a specific person or entity, or\"generalized\"towards a group of people sharing a common protected characteristic. We perform the first linguistic and psycholinguistic analysis of these two forms of hate speech and reveal the presence of interesting markers that distinguish these types of hate speech. Our analysis reveals that Directed hate speech, in addition to being more personal and directed, is more informal, angrier, and often explicitly attacks the target (via name calling) with fewer analytic words and more words suggesting authority and influence. Our analysis reveals that Directed hate speech, in addition to being more personal and directed, is more informal, angrier, and often explicitly attacks the target (via name calling) with fewer analytic words and more words suggesting authority and influence. Generalized hate speech, on the other hand, is dominated by religious hate, is characterized by the use of lethal words such as murder, exterminate, and kill; and quantity words such as million and many. Our analysis reveals that Directed hate speech, in addition to being more personal and directed, is more informal, angrier, and often explicitly attacks the target (via name calling) with fewer analytic words and more words suggesting authority and influence. Generalized hate speech, on the other hand, is dominated by religious hate, is characterized by the use of lethal words such as murder, exterminate, and kill; and quantity words such as million and many. Altogether, our work provides a data-driven analysis of the nuances of online-hate speech that enables not only a deepened understanding of hate speech and its social implications but also its detection."}, {"paper_id": "16011169", "adju_relevance": 0, "title": "A Lexicon-based Approach for Hate Speech Detection", "background_label": "We explore the idea of creating a classifier that can be used to detect presence of hate speech in web discourses such as web forums and blogs. In this work, hate speech problem is abstracted into three main thematic areas of race, nationality and religion.", "abstract": "We explore the idea of creating a classifier that can be used to detect presence of hate speech in web discourses such as web forums and blogs. We explore the idea of creating a classifier that can be used to detect presence of hate speech in web discourses such as web forums and blogs. In this work, hate speech problem is abstracted into three main thematic areas of race, nationality and religion."}, {"paper_id": "61094808", "adju_relevance": 0, "title": "Regulating hate speech online", "background_label": "The exponential growth in the Internet as a means of communication has been emulated by an increase in far-right and extremist web sites and hate based activity in cyberspace. The anonymity and mobility afforded by the Internet has made harassment and expressions of hate effortless in a landscape that is abstract and beyond the realms of traditional law enforcement.", "abstract": "The exponential growth in the Internet as a means of communication has been emulated by an increase in far-right and extremist web sites and hate based activity in cyberspace. The exponential growth in the Internet as a means of communication has been emulated by an increase in far-right and extremist web sites and hate based activity in cyberspace. The anonymity and mobility afforded by the Internet has made harassment and expressions of hate effortless in a landscape that is abstract and beyond the realms of traditional law enforcement."}, {"paper_id": "12981628", "adju_relevance": 0, "title": "WITP Classifying Party Affiliation from Political Speech", "method_label": "We then examine these party classifiers' person-dependency and time-dependency.", "result_label": "We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. The classifiers trained on 2005 House speeches performed better on Senate speeches from recent years than on older ones, which indicates the classifiers' time-dependency. This dependency may be caused by changes in the issue agenda or the ideological composition of Congress.", "abstract": " We then examine these party classifiers' person-dependency and time-dependency. We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. The classifiers trained on 2005 House speeches performed better on Senate speeches from recent years than on older ones, which indicates the classifiers' time-dependency. We found that party classifiers trained on 2005 House speeches can be generalized to the Senate speeches of the same year, but not vice versa. The classifiers trained on 2005 House speeches performed better on Senate speeches from recent years than on older ones, which indicates the classifiers' time-dependency. This dependency may be caused by changes in the issue agenda or the ideological composition of Congress."}, {"paper_id": "5491258", "adju_relevance": 0, "title": "CASME database: A dataset of spontaneous micro-expressions collected from neutralized faces", "background_label": "Micro-expressions are facial expressions which are fleeting and reveal genuine emotions that people try to conceal. These are important clues for detecting lies and dangerous behaviors and therefore have potential applications in various fields such as the clinical field and national security. However, recognition through the naked eye is very difficult. Therefore, researchers in the field of computer vision have tried to develop micro-expression detection and recognition algorithms but lack spontaneous micro-expression databases.", "abstract": "Micro-expressions are facial expressions which are fleeting and reveal genuine emotions that people try to conceal. Micro-expressions are facial expressions which are fleeting and reveal genuine emotions that people try to conceal. These are important clues for detecting lies and dangerous behaviors and therefore have potential applications in various fields such as the clinical field and national security. Micro-expressions are facial expressions which are fleeting and reveal genuine emotions that people try to conceal. These are important clues for detecting lies and dangerous behaviors and therefore have potential applications in various fields such as the clinical field and national security. However, recognition through the naked eye is very difficult. Micro-expressions are facial expressions which are fleeting and reveal genuine emotions that people try to conceal. These are important clues for detecting lies and dangerous behaviors and therefore have potential applications in various fields such as the clinical field and national security. However, recognition through the naked eye is very difficult. Therefore, researchers in the field of computer vision have tried to develop micro-expression detection and recognition algorithms but lack spontaneous micro-expression databases."}, {"paper_id": "152136830", "adju_relevance": 0, "title": "Defining Hate Speech", "background_label": "There is no shortage of opinions about what should be done about hate speech, but if there is one point of agreement, it is that the topic is ripe for rigorous study. But just what is hate speech, and how will we know it when we see it online? For all of the extensive literature about the causes, harms, and responses to hate speech, few scholars have endeavored to systematically define the term. Where other areas of content analysis have developed rich methodologies to account for influences like context or bias, the present scholarship around hate speech rarely extends beyond identification of particular words or phrases that are likely to cause harm targeted toward immutable characteristics.", "abstract": "There is no shortage of opinions about what should be done about hate speech, but if there is one point of agreement, it is that the topic is ripe for rigorous study. There is no shortage of opinions about what should be done about hate speech, but if there is one point of agreement, it is that the topic is ripe for rigorous study. But just what is hate speech, and how will we know it when we see it online? There is no shortage of opinions about what should be done about hate speech, but if there is one point of agreement, it is that the topic is ripe for rigorous study. But just what is hate speech, and how will we know it when we see it online? For all of the extensive literature about the causes, harms, and responses to hate speech, few scholars have endeavored to systematically define the term. There is no shortage of opinions about what should be done about hate speech, but if there is one point of agreement, it is that the topic is ripe for rigorous study. But just what is hate speech, and how will we know it when we see it online? For all of the extensive literature about the causes, harms, and responses to hate speech, few scholars have endeavored to systematically define the term. Where other areas of content analysis have developed rich methodologies to account for influences like context or bias, the present scholarship around hate speech rarely extends beyond identification of particular words or phrases that are likely to cause harm targeted toward immutable characteristics."}, {"paper_id": "37028011", "adju_relevance": 0, "title": "Automatic Speech Recognition of English-isiZulu Code-switched Speech from South African Soap Operas", "background_label": "Abstract We introduce a new English-isiZulu code-switched speech corpus compiled from South African soap opera broadcasts. isiZulu itself is currently under-resourced, and automatic speech recognition is made even more challenging by the high prevalence of code-switching in spontaneous speech. Analysis of the corpus reflects effects common in conversational isiZulu, such as vowel deletion and cross-language prefixes and suffixes.", "method_label": "Baseline monolingual and code-switched automatic speech recognition systems are developed, including a new language model configuration that explicitly includes switching transitions.", "result_label": "For code-switched speech, a system with language-dependent acoustic models and language-dependent language models linked by switching transitions leads to best performance, although word error rates overall remain very high.", "abstract": "Abstract We introduce a new English-isiZulu code-switched speech corpus compiled from South African soap opera broadcasts. Abstract We introduce a new English-isiZulu code-switched speech corpus compiled from South African soap opera broadcasts. isiZulu itself is currently under-resourced, and automatic speech recognition is made even more challenging by the high prevalence of code-switching in spontaneous speech. Abstract We introduce a new English-isiZulu code-switched speech corpus compiled from South African soap opera broadcasts. isiZulu itself is currently under-resourced, and automatic speech recognition is made even more challenging by the high prevalence of code-switching in spontaneous speech. Analysis of the corpus reflects effects common in conversational isiZulu, such as vowel deletion and cross-language prefixes and suffixes. Baseline monolingual and code-switched automatic speech recognition systems are developed, including a new language model configuration that explicitly includes switching transitions. For code-switched speech, a system with language-dependent acoustic models and language-dependent language models linked by switching transitions leads to best performance, although word error rates overall remain very high."}, {"paper_id": "69775383", "adju_relevance": 0, "title": "Bridging the Gaps: Multi Task Learning for Domain Transfer of Hate Speech Detection", "background_label": "Accurately detecting hate speech using supervised classification is dependent on data that is annotated by humans. Attaining high agreement amongst annotators though is difficult due to the subjective nature of the task, and different cultural, geographic and social backgrounds of the annotators. Furthermore, existing datasets capture only single types of hate speech such as sexism or racism; or single demographics such as people living in the United States, which negatively affects the recall when classifying data that are not captured in the training examples. End users of websites where hate speech may occur are exposed to risk of being exposed to explicit content due to the shortcomings in the training of automatic hate speech detection systems where unseen forms of hate speech or hate speech towards unseen groups are not captured.", "abstract": "Accurately detecting hate speech using supervised classification is dependent on data that is annotated by humans. Accurately detecting hate speech using supervised classification is dependent on data that is annotated by humans. Attaining high agreement amongst annotators though is difficult due to the subjective nature of the task, and different cultural, geographic and social backgrounds of the annotators. Accurately detecting hate speech using supervised classification is dependent on data that is annotated by humans. Attaining high agreement amongst annotators though is difficult due to the subjective nature of the task, and different cultural, geographic and social backgrounds of the annotators. Furthermore, existing datasets capture only single types of hate speech such as sexism or racism; or single demographics such as people living in the United States, which negatively affects the recall when classifying data that are not captured in the training examples. Accurately detecting hate speech using supervised classification is dependent on data that is annotated by humans. Attaining high agreement amongst annotators though is difficult due to the subjective nature of the task, and different cultural, geographic and social backgrounds of the annotators. Furthermore, existing datasets capture only single types of hate speech such as sexism or racism; or single demographics such as people living in the United States, which negatively affects the recall when classifying data that are not captured in the training examples. End users of websites where hate speech may occur are exposed to risk of being exposed to explicit content due to the shortcomings in the training of automatic hate speech detection systems where unseen forms of hate speech or hate speech towards unseen groups are not captured."}, {"paper_id": "56459439", "adju_relevance": 0, "title": "Hateminers : Detecting Hate speech against Women", "background_label": "With the online proliferation of hate speech, there is an urgent need for systems that can detect such harmful content.", "abstract": "With the online proliferation of hate speech, there is an urgent need for systems that can detect such harmful content."}, {"paper_id": "53603447", "adju_relevance": 0, "title": "Interpreting Neural Network Hate Speech Classifiers", "background_label": "AbstractDeep neural networks have been applied to hate speech detection with apparent success, but they have limited practical applicability without transparency into the predictions they make.", "abstract": "AbstractDeep neural networks have been applied to hate speech detection with apparent success, but they have limited practical applicability without transparency into the predictions they make."}, {"paper_id": "202578110", "adju_relevance": 0, "title": "Prediction Uncertainty Estimation for Hate Speech Classification", "background_label": "As a result of social network popularity, in recent years, hate speech phenomenon has significantly increased. Due to its harmful effect on minority groups as well as on large communities, there is a pressing need for hate speech detection and filtering. However, automatic approaches shall not jeopardize free speech, so they shall accompany their decisions with explanations and assessment of uncertainty. Thus, there is a need for predictive machine learning models that not only detect hate speech but also help users understand when texts cross the line and become unacceptable. The reliability of predictions is usually not addressed in text classification.", "method_label": "We fill this gap by proposing the adaptation of deep neural networks that can efficiently estimate prediction uncertainty. To reliably detect hate speech, we use Monte Carlo dropout regularization, which mimics Bayesian inference within neural networks. We evaluate our approach using different text embedding methods.", "result_label": "We visualize the reliability of results with a novel technique that aids in understanding the classification reliability and errors.", "abstract": "As a result of social network popularity, in recent years, hate speech phenomenon has significantly increased. As a result of social network popularity, in recent years, hate speech phenomenon has significantly increased. Due to its harmful effect on minority groups as well as on large communities, there is a pressing need for hate speech detection and filtering. As a result of social network popularity, in recent years, hate speech phenomenon has significantly increased. Due to its harmful effect on minority groups as well as on large communities, there is a pressing need for hate speech detection and filtering. However, automatic approaches shall not jeopardize free speech, so they shall accompany their decisions with explanations and assessment of uncertainty. As a result of social network popularity, in recent years, hate speech phenomenon has significantly increased. Due to its harmful effect on minority groups as well as on large communities, there is a pressing need for hate speech detection and filtering. However, automatic approaches shall not jeopardize free speech, so they shall accompany their decisions with explanations and assessment of uncertainty. Thus, there is a need for predictive machine learning models that not only detect hate speech but also help users understand when texts cross the line and become unacceptable. As a result of social network popularity, in recent years, hate speech phenomenon has significantly increased. Due to its harmful effect on minority groups as well as on large communities, there is a pressing need for hate speech detection and filtering. However, automatic approaches shall not jeopardize free speech, so they shall accompany their decisions with explanations and assessment of uncertainty. Thus, there is a need for predictive machine learning models that not only detect hate speech but also help users understand when texts cross the line and become unacceptable. The reliability of predictions is usually not addressed in text classification. We fill this gap by proposing the adaptation of deep neural networks that can efficiently estimate prediction uncertainty. We fill this gap by proposing the adaptation of deep neural networks that can efficiently estimate prediction uncertainty. To reliably detect hate speech, we use Monte Carlo dropout regularization, which mimics Bayesian inference within neural networks. We fill this gap by proposing the adaptation of deep neural networks that can efficiently estimate prediction uncertainty. To reliably detect hate speech, we use Monte Carlo dropout regularization, which mimics Bayesian inference within neural networks. We evaluate our approach using different text embedding methods. We visualize the reliability of results with a novel technique that aids in understanding the classification reliability and errors."}, {"paper_id": "47019287", "adju_relevance": 0, "title": "The PMEmo Dataset for Music Emotion Recognition", "background_label": "Music Emotion Recognition (MER) has recently received considerable attention. To support the MER research which requires large music content libraries, we present the PMEmo dataset containing emotion annotations of 794 songs as well as the simultaneous electrodermal activity (EDA) signals.", "method_label": "A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. In addition to that, manually selected chorus excerpts (compressed in MP3) of songs are provided to facilitate the development of chorus-related research. In this article, We describe in detail the resource acquisition, subject selection, experiment design and annotation collection procedures, as well as the dataset content and data reliability analysis. We also illustrate its usage in some simple music emotion recognition tasks which testified the PMEmo dataset's competence for the MER work.", "result_label": "Compared to other homogeneous datasets, PMEmo is novel in the organization and management of the recruited annotators, and it is also characterized by its large amount of music with simultaneous physiological signals.", "abstract": "Music Emotion Recognition (MER) has recently received considerable attention. Music Emotion Recognition (MER) has recently received considerable attention. To support the MER research which requires large music content libraries, we present the PMEmo dataset containing emotion annotations of 794 songs as well as the simultaneous electrodermal activity (EDA) signals. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. In addition to that, manually selected chorus excerpts (compressed in MP3) of songs are provided to facilitate the development of chorus-related research. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. In addition to that, manually selected chorus excerpts (compressed in MP3) of songs are provided to facilitate the development of chorus-related research. In this article, We describe in detail the resource acquisition, subject selection, experiment design and annotation collection procedures, as well as the dataset content and data reliability analysis. A Music Emotion Experiment was well-designed for collecting the affective-annotated music corpus of high quality, which recruited 457 subjects. The dataset is publically available to the research community, which is foremost intended for benchmarking in music emotion retrieval and recognition. To straightforwardly evaluate the methodologies for music affective analysis, it also involves pre-computed audio feature sets. In addition to that, manually selected chorus excerpts (compressed in MP3) of songs are provided to facilitate the development of chorus-related research. In this article, We describe in detail the resource acquisition, subject selection, experiment design and annotation collection procedures, as well as the dataset content and data reliability analysis. We also illustrate its usage in some simple music emotion recognition tasks which testified the PMEmo dataset's competence for the MER work. Compared to other homogeneous datasets, PMEmo is novel in the organization and management of the recruited annotators, and it is also characterized by its large amount of music with simultaneous physiological signals."}, {"paper_id": "145114365", "adju_relevance": 0, "title": "Intersectionality and the Spectrum of Racist Hate Speech: Proposals to the UN Committee on the Elimination of Racial Discrimination", "abstract": ""}, {"paper_id": "52156557", "adju_relevance": 0, "title": "Hierarchical CVAE for Fine-Grained Hate Speech Classification", "background_label": "Existing work on automated hate speech detection typically focuses on binary classification or on differentiating among a small set of categories.", "abstract": "Existing work on automated hate speech detection typically focuses on binary classification or on differentiating among a small set of categories."}, {"paper_id": "53245037", "adju_relevance": 0, "title": "KT-Speech-Crawler: Automatic Dataset Construction for Speech Recognition from YouTube Videos", "background_label": "In this paper, we describe KT-Speech-Crawler: an approach for automatic dataset construction for speech recognition by crawling YouTube videos.", "method_label": "We outline several filtering and post-processing steps, which extract samples that can be used for training end-to-end neural speech recognition systems. In our experiments, we demonstrate that a single-core version of the crawler can obtain around 150 hours of transcribed speech within a day, containing an estimated 3.5% word error rate in the transcriptions. Automatically collected samples contain reading and spontaneous speech recorded in various conditions including background noise and music, distant microphone recordings, and a variety of accents and reverberation.", "result_label": "When training a deep neural network on speech recognition, we observed around 40\\% word error rate reduction on the Wall Street Journal dataset by integrating 200 hours of the collected samples into the training set.", "abstract": "In this paper, we describe KT-Speech-Crawler: an approach for automatic dataset construction for speech recognition by crawling YouTube videos. We outline several filtering and post-processing steps, which extract samples that can be used for training end-to-end neural speech recognition systems. We outline several filtering and post-processing steps, which extract samples that can be used for training end-to-end neural speech recognition systems. In our experiments, we demonstrate that a single-core version of the crawler can obtain around 150 hours of transcribed speech within a day, containing an estimated 3.5% word error rate in the transcriptions. We outline several filtering and post-processing steps, which extract samples that can be used for training end-to-end neural speech recognition systems. In our experiments, we demonstrate that a single-core version of the crawler can obtain around 150 hours of transcribed speech within a day, containing an estimated 3.5% word error rate in the transcriptions. Automatically collected samples contain reading and spontaneous speech recorded in various conditions including background noise and music, distant microphone recordings, and a variety of accents and reverberation. When training a deep neural network on speech recognition, we observed around 40\\% word error rate reduction on the Wall Street Journal dataset by integrating 200 hours of the collected samples into the training set."}, {"paper_id": "4570064", "adju_relevance": 0, "title": "Hate Speech on Twitter: A Pragmatic Approach to Collect Hateful and Offensive Expressions and Perform Hate Speech Detection", "background_label": "With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more \u201ccyber\u201d conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. Hate speech refers to the use of aggressive, violent or offensive language, targeting a specific group of people sharing a common property, whether this property is their gender (i.e., sexism), their ethnic group or race (i.e., racism) or their believes and religion. While most of the online social networks and microblogging websites forbid the use of hate speech, the size of these networks and websites makes it almost impossible to control all of their content. Therefore, arises the necessity to detect such speech automatically and filter any content that presents hateful language or language inciting to hatred.", "abstract": "With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more \u201ccyber\u201d conflicts between these people. With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more \u201ccyber\u201d conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more \u201ccyber\u201d conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. Hate speech refers to the use of aggressive, violent or offensive language, targeting a specific group of people sharing a common property, whether this property is their gender (i.e., sexism), their ethnic group or race (i.e., racism) or their believes and religion. With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more \u201ccyber\u201d conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. Hate speech refers to the use of aggressive, violent or offensive language, targeting a specific group of people sharing a common property, whether this property is their gender (i.e., sexism), their ethnic group or race (i.e., racism) or their believes and religion. While most of the online social networks and microblogging websites forbid the use of hate speech, the size of these networks and websites makes it almost impossible to control all of their content. With the rapid growth of social networks and microblogging websites, communication between people from different cultural and psychological backgrounds has become more direct, resulting in more and more \u201ccyber\u201d conflicts between these people. Consequently, hate speech is used more and more, to the point where it has become a serious problem invading these open spaces. Hate speech refers to the use of aggressive, violent or offensive language, targeting a specific group of people sharing a common property, whether this property is their gender (i.e., sexism), their ethnic group or race (i.e., racism) or their believes and religion. While most of the online social networks and microblogging websites forbid the use of hate speech, the size of these networks and websites makes it almost impossible to control all of their content. Therefore, arises the necessity to detect such speech automatically and filter any content that presents hateful language or language inciting to hatred."}, {"paper_id": "36117198", "adju_relevance": 0, "title": "DeepMind_Commentary", "background_label": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy.", "abstract": "We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. We agree with Lake and colleagues on their list of key ingredients for building humanlike intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy."}, {"paper_id": "11997218", "adju_relevance": 0, "title": "Cultural factors in the regression of non-verbal communication perception", "background_label": "Recognition of non-verbal communication (NVC) is important for understanding human communication and designing user centric user interfaces. Cultural differences affect the expression and perception of NVC but no previous automatic system considers these cultural differences. Annotation data for the LILiR TwoTalk corpus, containing dyadic (two person) conversations, was gathered using Internet crowdsourcing, with a significant quantity collected from India, Kenya and the United Kingdom (UK). Many studies have investigated cultural differences based on human observations but this has not been addressed in the context of automatic emotion or NVC recognition.", "method_label": "Perhaps not surprisingly, testing an automatic system on data that is not culturally representative of the training data is seen to result in low performance.", "abstract": "Recognition of non-verbal communication (NVC) is important for understanding human communication and designing user centric user interfaces. Recognition of non-verbal communication (NVC) is important for understanding human communication and designing user centric user interfaces. Cultural differences affect the expression and perception of NVC but no previous automatic system considers these cultural differences. Recognition of non-verbal communication (NVC) is important for understanding human communication and designing user centric user interfaces. Cultural differences affect the expression and perception of NVC but no previous automatic system considers these cultural differences. Annotation data for the LILiR TwoTalk corpus, containing dyadic (two person) conversations, was gathered using Internet crowdsourcing, with a significant quantity collected from India, Kenya and the United Kingdom (UK). Recognition of non-verbal communication (NVC) is important for understanding human communication and designing user centric user interfaces. Cultural differences affect the expression and perception of NVC but no previous automatic system considers these cultural differences. Annotation data for the LILiR TwoTalk corpus, containing dyadic (two person) conversations, was gathered using Internet crowdsourcing, with a significant quantity collected from India, Kenya and the United Kingdom (UK). Many studies have investigated cultural differences based on human observations but this has not been addressed in the context of automatic emotion or NVC recognition. Perhaps not surprisingly, testing an automatic system on data that is not culturally representative of the training data is seen to result in low performance."}, {"paper_id": "9626793", "adju_relevance": 0, "title": "A Survey on Hate Speech Detection using Natural Language Processing", "background_label": "AbstractThis paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing.", "method_label": "Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing.", "result_label": "We also discuss limits of those approaches.", "abstract": "AbstractThis paper presents a survey on hate speech detection. AbstractThis paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing. Due to the massive scale of the web, methods that automatically detect hate speech are required. Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing. We also discuss limits of those approaches."}, {"paper_id": "153089281", "adju_relevance": 0, "title": "Hate Crimes: Causes, Controls, and Controversies", "background_label": "Preface Second Edition Preface Acknowledgments 1. Introduction Overview of This book Goals of This book 2.", "abstract": "Preface Second Edition Preface Acknowledgments 1. Preface Second Edition Preface Acknowledgments 1. Introduction Overview of This book Goals of This book 2."}, {"paper_id": "145803626", "adju_relevance": 0, "title": "Laughter Punctuates Speech: Linguistic, Social and Gender Contexts of Laughter", "background_label": "The relation between laughter and speech was investigated by describing the position of naturally occurring laughter in the speech stream of anonymous young adults observed in public places. Laughter of both speaker and audience occurred during pauses at the end of phrases or sentences in over 99 % of the sample of 1200 episodes of laughter, indicating that speech has priority access to the single vocalization channel and that a lawful process governs the placement of laughter in speech. Laughter is not randomly scattered throughout the speech stream. Laughter followed both statements and questions and material that did not seem humorous outside of the conversational context.", "result_label": "Speakers, especially females, laughed more than their audiences, but the relative amount of speaker and audience laughter depended on the gender composition of a group. Audiences of both males and females laughed more to male than female speakers. These baseline data provide insights into gender differences, normal and abnormal emotional behavior and define variables for future studies of neuro-and psychopathology.", "abstract": "The relation between laughter and speech was investigated by describing the position of naturally occurring laughter in the speech stream of anonymous young adults observed in public places. The relation between laughter and speech was investigated by describing the position of naturally occurring laughter in the speech stream of anonymous young adults observed in public places. Laughter of both speaker and audience occurred during pauses at the end of phrases or sentences in over 99 % of the sample of 1200 episodes of laughter, indicating that speech has priority access to the single vocalization channel and that a lawful process governs the placement of laughter in speech. The relation between laughter and speech was investigated by describing the position of naturally occurring laughter in the speech stream of anonymous young adults observed in public places. Laughter of both speaker and audience occurred during pauses at the end of phrases or sentences in over 99 % of the sample of 1200 episodes of laughter, indicating that speech has priority access to the single vocalization channel and that a lawful process governs the placement of laughter in speech. Laughter is not randomly scattered throughout the speech stream. The relation between laughter and speech was investigated by describing the position of naturally occurring laughter in the speech stream of anonymous young adults observed in public places. Laughter of both speaker and audience occurred during pauses at the end of phrases or sentences in over 99 % of the sample of 1200 episodes of laughter, indicating that speech has priority access to the single vocalization channel and that a lawful process governs the placement of laughter in speech. Laughter is not randomly scattered throughout the speech stream. Laughter followed both statements and questions and material that did not seem humorous outside of the conversational context. Speakers, especially females, laughed more than their audiences, but the relative amount of speaker and audience laughter depended on the gender composition of a group. Speakers, especially females, laughed more than their audiences, but the relative amount of speaker and audience laughter depended on the gender composition of a group. Audiences of both males and females laughed more to male than female speakers. Speakers, especially females, laughed more than their audiences, but the relative amount of speaker and audience laughter depended on the gender composition of a group. Audiences of both males and females laughed more to male than female speakers. These baseline data provide insights into gender differences, normal and abnormal emotional behavior and define variables for future studies of neuro-and psychopathology."}, {"paper_id": "7246877", "adju_relevance": 0, "title": "Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words", "background_label": "Common approaches to text categorization  essentially rely either on n-gram  counts or on word embeddings. This  presents important difficulties in highly  dynamic or quickly-interacting environments,  where the appearance of new words  and/or varied misspellings is the norm. A paradigmatic example of this situation  is abusive online behavior, with social  networks and media platforms struggling  to effectively combat uncommon or nonblacklisted  hate words.", "method_label": "To better deal with  these issues in those fast-paced environments,  we propose using the error signal  of class-based language models as input  to text classification algorithms. In particular,  we train a next-character prediction  model for any given class, and then exploit  the error of such class-based models  to inform a neural network classifier. This  way, we shift from the ability to describe  seen documents to the ability to predict  unseen content.", "result_label": "Preliminary studies using  out-of-vocabulary splits from abusive  tweet data show promising results, outperforming  competitive text categorization  strategies by 4\u201311%", "abstract": "Common approaches to text categorization  essentially rely either on n-gram  counts or on word embeddings. Common approaches to text categorization  essentially rely either on n-gram  counts or on word embeddings. This  presents important difficulties in highly  dynamic or quickly-interacting environments,  where the appearance of new words  and/or varied misspellings is the norm. Common approaches to text categorization  essentially rely either on n-gram  counts or on word embeddings. This  presents important difficulties in highly  dynamic or quickly-interacting environments,  where the appearance of new words  and/or varied misspellings is the norm. A paradigmatic example of this situation  is abusive online behavior, with social  networks and media platforms struggling  to effectively combat uncommon or nonblacklisted  hate words. To better deal with  these issues in those fast-paced environments,  we propose using the error signal  of class-based language models as input  to text classification algorithms. To better deal with  these issues in those fast-paced environments,  we propose using the error signal  of class-based language models as input  to text classification algorithms. In particular,  we train a next-character prediction  model for any given class, and then exploit  the error of such class-based models  to inform a neural network classifier. To better deal with  these issues in those fast-paced environments,  we propose using the error signal  of class-based language models as input  to text classification algorithms. In particular,  we train a next-character prediction  model for any given class, and then exploit  the error of such class-based models  to inform a neural network classifier. This  way, we shift from the ability to describe  seen documents to the ability to predict  unseen content. Preliminary studies using  out-of-vocabulary splits from abusive  tweet data show promising results, outperforming  competitive text categorization  strategies by 4\u201311%"}, {"paper_id": "5047299", "adju_relevance": 0, "title": "The Effect of Extremist Violence on Hateful Speech Online", "background_label": "User-generated content online is shaped by many factors, including endogenous elements such as platform affordances and norms, as well as exogenous elements, in particular significant events. These impact what users say, how they say it, and when they say it.", "abstract": "User-generated content online is shaped by many factors, including endogenous elements such as platform affordances and norms, as well as exogenous elements, in particular significant events. User-generated content online is shaped by many factors, including endogenous elements such as platform affordances and norms, as well as exogenous elements, in particular significant events. These impact what users say, how they say it, and when they say it."}, {"paper_id": "54448090", "adju_relevance": 0, "title": "Analyzing the hate and counter speech accounts on Twitter", "background_label": "The online hate speech is proliferating with several organization and countries implementing laws to ban such harmful speech. While these restrictions might reduce the amount of such hateful content, it does so by restricting freedom of speech. Thus, an promising alternative supported by several organizations is to counter such hate speech with more speech.", "abstract": "The online hate speech is proliferating with several organization and countries implementing laws to ban such harmful speech. The online hate speech is proliferating with several organization and countries implementing laws to ban such harmful speech. While these restrictions might reduce the amount of such hateful content, it does so by restricting freedom of speech. The online hate speech is proliferating with several organization and countries implementing laws to ban such harmful speech. While these restrictions might reduce the amount of such hateful content, it does so by restricting freedom of speech. Thus, an promising alternative supported by several organizations is to counter such hate speech with more speech."}, {"paper_id": "8991050", "adju_relevance": 0, "title": "An Annotated Corpus of Relational Strategies in Customer Service", "background_label": "We create and release the first publicly available commercial customer service corpus with annotated relational segments. Human-computer data from three live customer service Intelligent Virtual Agents (IVAs) in the domains of travel and telecommunications were collected, and reviewers marked all text that was deemed unnecessary to the determination of user intention.", "method_label": "After merging the selections of multiple reviewers to create highlighted texts, a second round of annotation was done to determine the classes of language present in the highlighted sections such as the presence of Greetings, Backstory, Justification, Gratitude, Rants, or Emotions. As well as discussing the corpus itself, we compare the usage of such language in human-human interactions on TripAdvisor forums.", "result_label": "This resulting corpus is a valuable resource for improving the quality and relational abilities of IVAs. We show that removal of this language from task-based inputs has a positive effect on IVA understanding by both an increase in confidence and improvement in responses, demonstrating the need for automated methods of its discovery.", "abstract": "We create and release the first publicly available commercial customer service corpus with annotated relational segments. We create and release the first publicly available commercial customer service corpus with annotated relational segments. Human-computer data from three live customer service Intelligent Virtual Agents (IVAs) in the domains of travel and telecommunications were collected, and reviewers marked all text that was deemed unnecessary to the determination of user intention. After merging the selections of multiple reviewers to create highlighted texts, a second round of annotation was done to determine the classes of language present in the highlighted sections such as the presence of Greetings, Backstory, Justification, Gratitude, Rants, or Emotions. This resulting corpus is a valuable resource for improving the quality and relational abilities of IVAs. After merging the selections of multiple reviewers to create highlighted texts, a second round of annotation was done to determine the classes of language present in the highlighted sections such as the presence of Greetings, Backstory, Justification, Gratitude, Rants, or Emotions. As well as discussing the corpus itself, we compare the usage of such language in human-human interactions on TripAdvisor forums. This resulting corpus is a valuable resource for improving the quality and relational abilities of IVAs. We show that removal of this language from task-based inputs has a positive effect on IVA understanding by both an increase in confidence and improvement in responses, demonstrating the need for automated methods of its discovery."}, {"paper_id": "168170119", "adju_relevance": 0, "title": "Racial Bias in Hate Speech and Abusive Language Detection Datasets", "background_label": "Technologies for abusive language detection are being developed and applied with little consideration of their potential biases. We examine racial bias in five different sets of Twitter data annotated for hate speech and abusive language.", "method_label": "We train classifiers on these datasets and compare the predictions of these classifiers on tweets written in African-American English with those written in Standard American English.", "result_label": "The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. If these abusive language detection systems are used in the field they will therefore have a disproportionate negative impact on African-American social media users. Consequently, these systems may discriminate against the groups who are often the targets of the abuse we are trying to detect.", "abstract": "Technologies for abusive language detection are being developed and applied with little consideration of their potential biases. Technologies for abusive language detection are being developed and applied with little consideration of their potential biases. We examine racial bias in five different sets of Twitter data annotated for hate speech and abusive language. We train classifiers on these datasets and compare the predictions of these classifiers on tweets written in African-American English with those written in Standard American English. The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. If these abusive language detection systems are used in the field they will therefore have a disproportionate negative impact on African-American social media users. The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. If these abusive language detection systems are used in the field they will therefore have a disproportionate negative impact on African-American social media users. Consequently, these systems may discriminate against the groups who are often the targets of the abuse we are trying to detect."}, {"paper_id": "52184457", "adju_relevance": 0, "title": "A Survey on Automatic Detection of Hate Speech in Text", "background_label": "The scientific study of hate speech, from a computer science point of view, is recent. This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used.", "abstract": "The scientific study of hate speech, from a computer science point of view, is recent. The scientific study of hate speech, from a computer science point of view, is recent. This survey organizes and describes the current state of the field, providing a structured overview of previous approaches, including core algorithms, methods, and main features used."}, {"paper_id": "13412886", "adju_relevance": 0, "title": "\u2019 The Enemy Among Us \u2019 : Detecting Hate Speech with Threats Based Othering Language Embeddings", "background_label": "Hateful and offensive language (also known as hate speech or cyber hate) posted and widely circulated via the World Wide Web can be considered as a key risk factor for individual and societal tension linked to regional instability. Automated Web-based hate speech detection is important for the observation and understanding trends of societal tension. This problem motivated us to conduct new experiments to identify subtle language use, such as references to immigration or job prosperity in a hateful context.", "method_label": "In this research, we improve on existing research by proposing different data mining feature extraction methods. While previous work has involved using lexicons, bags-of-words or probabilistic parsing approach (e.g. We propose a novel 'Othering Lexicon' to identify these subtleties and we incorporate our lexicon with embedding learning for feature extraction and subsequent classification using a neural network approach. Our method first explores the context around othering terms in a corpus, and identifies context patterns that are relevant to the othering context. These patterns are used along with the othering pronoun and hate speech terms to build our 'Othering Lexicon'. Embedding algorithm has the superior characteristic that the similar words have a closer distance, which is helpful to train our classifier on the negative and positive classes.", "result_label": "using Typed Dependencies), they all suffer from a similar issue which is that hate speech can often be subtle and indirect, and depending on individual words or phrases can lead to a significant number of false negatives. For validation, several experiments were conducted on different types of hate speech, namely religion, disability, race and sexual orientation, with F-measure scores for classifying hateful instances obtained through applying our model of 0.93, 0.95, 0.97 and 0.92 respective.", "abstract": "Hateful and offensive language (also known as hate speech or cyber hate) posted and widely circulated via the World Wide Web can be considered as a key risk factor for individual and societal tension linked to regional instability. Hateful and offensive language (also known as hate speech or cyber hate) posted and widely circulated via the World Wide Web can be considered as a key risk factor for individual and societal tension linked to regional instability. Automated Web-based hate speech detection is important for the observation and understanding trends of societal tension. In this research, we improve on existing research by proposing different data mining feature extraction methods. In this research, we improve on existing research by proposing different data mining feature extraction methods. While previous work has involved using lexicons, bags-of-words or probabilistic parsing approach (e.g. using Typed Dependencies), they all suffer from a similar issue which is that hate speech can often be subtle and indirect, and depending on individual words or phrases can lead to a significant number of false negatives. Hateful and offensive language (also known as hate speech or cyber hate) posted and widely circulated via the World Wide Web can be considered as a key risk factor for individual and societal tension linked to regional instability. Automated Web-based hate speech detection is important for the observation and understanding trends of societal tension. This problem motivated us to conduct new experiments to identify subtle language use, such as references to immigration or job prosperity in a hateful context. In this research, we improve on existing research by proposing different data mining feature extraction methods. While previous work has involved using lexicons, bags-of-words or probabilistic parsing approach (e.g. We propose a novel 'Othering Lexicon' to identify these subtleties and we incorporate our lexicon with embedding learning for feature extraction and subsequent classification using a neural network approach. In this research, we improve on existing research by proposing different data mining feature extraction methods. While previous work has involved using lexicons, bags-of-words or probabilistic parsing approach (e.g. We propose a novel 'Othering Lexicon' to identify these subtleties and we incorporate our lexicon with embedding learning for feature extraction and subsequent classification using a neural network approach. Our method first explores the context around othering terms in a corpus, and identifies context patterns that are relevant to the othering context. In this research, we improve on existing research by proposing different data mining feature extraction methods. While previous work has involved using lexicons, bags-of-words or probabilistic parsing approach (e.g. We propose a novel 'Othering Lexicon' to identify these subtleties and we incorporate our lexicon with embedding learning for feature extraction and subsequent classification using a neural network approach. Our method first explores the context around othering terms in a corpus, and identifies context patterns that are relevant to the othering context. These patterns are used along with the othering pronoun and hate speech terms to build our 'Othering Lexicon'. In this research, we improve on existing research by proposing different data mining feature extraction methods. While previous work has involved using lexicons, bags-of-words or probabilistic parsing approach (e.g. We propose a novel 'Othering Lexicon' to identify these subtleties and we incorporate our lexicon with embedding learning for feature extraction and subsequent classification using a neural network approach. Our method first explores the context around othering terms in a corpus, and identifies context patterns that are relevant to the othering context. These patterns are used along with the othering pronoun and hate speech terms to build our 'Othering Lexicon'. Embedding algorithm has the superior characteristic that the similar words have a closer distance, which is helpful to train our classifier on the negative and positive classes. using Typed Dependencies), they all suffer from a similar issue which is that hate speech can often be subtle and indirect, and depending on individual words or phrases can lead to a significant number of false negatives. For validation, several experiments were conducted on different types of hate speech, namely religion, disability, race and sexual orientation, with F-measure scores for classifying hateful instances obtained through applying our model of 0.93, 0.95, 0.97 and 0.92 respective."}, {"paper_id": "11767903", "adju_relevance": 0, "title": "BEADS: A dataset of Binaural Emotionally Annotated Digital Sounds", "background_label": "Emotion recognition from generalized sounds is an interdisciplinary and emerging field of research. A vital requirement for this kind of investigations is the availability of ground truth datasets. Currently, there are 2 freely available datasets of emotionally annotated sounds, which, however, do not include sound evenets (SEs) with manifestation of the spatial location of the source. The latter is an inherent natural component of SEs, since all sound sources in real-world conditions are physically located and perceived somewhere in the listener's surrounding space.", "method_label": "In this work we present a novel emotionally annotated sounds dataset consisting of 32 SEs that are spatially rendered using appropriate binaural processing. All SEs in the dataset are available in 5 spatial positions corresponding to source/receiver angles equal to 0, 45, 90, 135 and 180 degrees. We have used the IADS dataset as the initial collection of SEs prior to binaural processing.", "result_label": "The annotation measures obtained for the novel binaural dataset demonstrate a significant accordance with the existing IADS dataset, while small ratings declinations illustrate a perceptual adaptation imposed by the more realistic SEs spatial representation.", "abstract": "Emotion recognition from generalized sounds is an interdisciplinary and emerging field of research. Emotion recognition from generalized sounds is an interdisciplinary and emerging field of research. A vital requirement for this kind of investigations is the availability of ground truth datasets. Emotion recognition from generalized sounds is an interdisciplinary and emerging field of research. A vital requirement for this kind of investigations is the availability of ground truth datasets. Currently, there are 2 freely available datasets of emotionally annotated sounds, which, however, do not include sound evenets (SEs) with manifestation of the spatial location of the source. Emotion recognition from generalized sounds is an interdisciplinary and emerging field of research. A vital requirement for this kind of investigations is the availability of ground truth datasets. Currently, there are 2 freely available datasets of emotionally annotated sounds, which, however, do not include sound evenets (SEs) with manifestation of the spatial location of the source. The latter is an inherent natural component of SEs, since all sound sources in real-world conditions are physically located and perceived somewhere in the listener's surrounding space. In this work we present a novel emotionally annotated sounds dataset consisting of 32 SEs that are spatially rendered using appropriate binaural processing. In this work we present a novel emotionally annotated sounds dataset consisting of 32 SEs that are spatially rendered using appropriate binaural processing. All SEs in the dataset are available in 5 spatial positions corresponding to source/receiver angles equal to 0, 45, 90, 135 and 180 degrees. In this work we present a novel emotionally annotated sounds dataset consisting of 32 SEs that are spatially rendered using appropriate binaural processing. All SEs in the dataset are available in 5 spatial positions corresponding to source/receiver angles equal to 0, 45, 90, 135 and 180 degrees. We have used the IADS dataset as the initial collection of SEs prior to binaural processing. The annotation measures obtained for the novel binaural dataset demonstrate a significant accordance with the existing IADS dataset, while small ratings declinations illustrate a perceptual adaptation imposed by the more realistic SEs spatial representation."}, {"paper_id": "5405986", "adju_relevance": 0, "title": "The SENSEI Annotated Corpus: Human Summaries of Reader Comment Conversations in On-line News", "background_label": "Researchers are beginning to explore how  to generate summaries of extended argumentative  conversations in social media,  such as those found in reader comments in  on-line news. To date, however, there has  been little discussion of what these summaries  should be like and a lack of humanauthored  exemplars, quite likely because  writing summaries of this kind of interchange  is so difficult.", "abstract": "Researchers are beginning to explore how  to generate summaries of extended argumentative  conversations in social media,  such as those found in reader comments in  on-line news. Researchers are beginning to explore how  to generate summaries of extended argumentative  conversations in social media,  such as those found in reader comments in  on-line news. To date, however, there has  been little discussion of what these summaries  should be like and a lack of humanauthored  exemplars, quite likely because  writing summaries of this kind of interchange  is so difficult."}, {"paper_id": "2039295", "adju_relevance": 0, "title": "Hate Speech Detection with Comment Embeddings", "background_label": "We address the problem of hate speech detection in online user comments. Hate speech, defined as an \"abusive speech targeting specific group characteristics, such as ethnicity, religion, or gender\", is an important problem plaguing websites that allow users to leave feedback, having a negative impact on their online business and overall user experience.", "method_label": "We propose to learn distributed low-dimensional representations of comments using recently proposed neural language models, that can then be fed as inputs to a classification algorithm. Our approach addresses issues of high-dimensionality and sparsity that impact the current state-of-the-art, resulting in highly efficient and effective hate speech detectors.", "abstract": "We address the problem of hate speech detection in online user comments. We address the problem of hate speech detection in online user comments. Hate speech, defined as an \"abusive speech targeting specific group characteristics, such as ethnicity, religion, or gender\", is an important problem plaguing websites that allow users to leave feedback, having a negative impact on their online business and overall user experience. We propose to learn distributed low-dimensional representations of comments using recently proposed neural language models, that can then be fed as inputs to a classification algorithm. We propose to learn distributed low-dimensional representations of comments using recently proposed neural language models, that can then be fed as inputs to a classification algorithm. Our approach addresses issues of high-dimensionality and sparsity that impact the current state-of-the-art, resulting in highly efficient and effective hate speech detectors."}, {"paper_id": "51873630", "adju_relevance": 0, "title": "SNAG: Spoken Narratives and Gaze Dataset", "background_label": "AbstractHumans rely on multiple sensory modalities when examining and reasoning over images.", "abstract": "AbstractHumans rely on multiple sensory modalities when examining and reasoning over images."}, {"paper_id": "16440727", "adju_relevance": 0, "title": "A Review of Automatic Speaker Age Classification , Recognition and Identifying Speaker Emotion Using Voice Signal", "background_label": "Accurate gender classification is mostly convenient in case of speech and speaker recognition and also in speech emotion classification; since a superior performance has been stated when separate acoustic models are employed for males and females. Gender classification is also specious into face recognition, particular video summarization, human or robot interaction (HCI), etc. In various criminal cases, an evidence either in the form of as phone conversations or in the form of as tape recordings. Thus, act of law enforcement agencies have been concerned which help the identification of a criminal about accurate approaches to profile dissimilar characteristics of a speaker from recorded patterns of voice. The importance of automatically recognizing expressed emotions from human speech has grown with the increasing role of spoken language interfaces in human-computer interaction (HCI) applications.", "abstract": "Accurate gender classification is mostly convenient in case of speech and speaker recognition and also in speech emotion classification; since a superior performance has been stated when separate acoustic models are employed for males and females. Accurate gender classification is mostly convenient in case of speech and speaker recognition and also in speech emotion classification; since a superior performance has been stated when separate acoustic models are employed for males and females. Gender classification is also specious into face recognition, particular video summarization, human or robot interaction (HCI), etc. Accurate gender classification is mostly convenient in case of speech and speaker recognition and also in speech emotion classification; since a superior performance has been stated when separate acoustic models are employed for males and females. Gender classification is also specious into face recognition, particular video summarization, human or robot interaction (HCI), etc. In various criminal cases, an evidence either in the form of as phone conversations or in the form of as tape recordings. Accurate gender classification is mostly convenient in case of speech and speaker recognition and also in speech emotion classification; since a superior performance has been stated when separate acoustic models are employed for males and females. Gender classification is also specious into face recognition, particular video summarization, human or robot interaction (HCI), etc. In various criminal cases, an evidence either in the form of as phone conversations or in the form of as tape recordings. Thus, act of law enforcement agencies have been concerned which help the identification of a criminal about accurate approaches to profile dissimilar characteristics of a speaker from recorded patterns of voice. Accurate gender classification is mostly convenient in case of speech and speaker recognition and also in speech emotion classification; since a superior performance has been stated when separate acoustic models are employed for males and females. Gender classification is also specious into face recognition, particular video summarization, human or robot interaction (HCI), etc. In various criminal cases, an evidence either in the form of as phone conversations or in the form of as tape recordings. Thus, act of law enforcement agencies have been concerned which help the identification of a criminal about accurate approaches to profile dissimilar characteristics of a speaker from recorded patterns of voice. The importance of automatically recognizing expressed emotions from human speech has grown with the increasing role of spoken language interfaces in human-computer interaction (HCI) applications."}, {"paper_id": "52878910", "adju_relevance": 0, "title": "Predictive Embeddings for Hate Speech Detection on Twitter", "method_label": "Using pre-trained word embeddings and max/mean pooling from simple, fully-connected transformations of these embeddings, we are able to predict the occurrence of hate speech on three commonly used publicly available datasets.", "result_label": "Our models match or outperform state of the art F1 performance on all three datasets using significantly fewer parameters and minimal feature preprocessing compared to previous methods.", "abstract": " Using pre-trained word embeddings and max/mean pooling from simple, fully-connected transformations of these embeddings, we are able to predict the occurrence of hate speech on three commonly used publicly available datasets. Our models match or outperform state of the art F1 performance on all three datasets using significantly fewer parameters and minimal feature preprocessing compared to previous methods."}, {"paper_id": "52111461", "adju_relevance": 0, "title": "All You Need is\"Love\": Evading Hate-speech Detection", "background_label": "With the spread of social networks and their unfortunate use for hate speech, automatic detection of the latter has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on.", "method_label": "Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are brittle against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective -- a cutting-edge solution from industry.", "result_label": "Our experiments demonstrate that adversarial training does not completely mitigate the attacks, and using character-level features makes the models systematically more attack-resistant than using word-level features.", "abstract": "With the spread of social networks and their unfortunate use for hate speech, automatic detection of the latter has become a pressing problem. With the spread of social networks and their unfortunate use for hate speech, automatic detection of the latter has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are brittle against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are brittle against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective -- a cutting-edge solution from industry. Our experiments demonstrate that adversarial training does not completely mitigate the attacks, and using character-level features makes the models systematically more attack-resistant than using word-level features."}, {"paper_id": "82456167", "adju_relevance": 0, "title": "Janeway's Immunobiology", "background_label": "Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Dynamics of Adaptive Immunity 11.", "method_label": "The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. Signaling Through Immune System Receptors 7.", "result_label": "The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8.", "abstract": "Part I An Introduction to Immunobiology and Innate Immunity 1. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. The Generation of Lymphocyte Antigen Receptors 5. The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. The Generation of Lymphocyte Antigen Receptors 5. Antigen Presentation to T Lymphocytes Part III The Development of Mature Lymphocyte Receptor Repertoires 6. Signaling Through Immune System Receptors 7. The Development and Survival of Lymphocytes Part IV The Adaptive Immune Response 8. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Part I An Introduction to Immunobiology and Innate Immunity 1. Basic Concepts in Immunology 2. Innate Immunity Part II The Recognition of Antigen 3. Antigen Recognition by B-cell and T-cell Receptors 4. T Cell-Mediated Immunity 9. The Humoral Immune Response 10. Dynamics of Adaptive Immunity 11."}, {"paper_id": "182952952", "adju_relevance": 0, "title": "Transfer Learning for Hate Speech Detection in Social Media", "background_label": "In today's society more and more people are connected to the Internet, and its information and communication technologies have become an essential part of our everyday life. Unfortunately, the flip side of this increased connectivity to social media and other online contents is cyber-bullying and -hatred, among other harmful and anti-social behaviors. Models based on machine learning and natural language processing provide a way to detect this hate speech in web text in order to make discussion forums and other media and platforms safer. The main difficulty, however, is annotating a sufficiently large number of examples to train these models. We train and test our methods on the total of $37,520$ English tweets that have been annotated for differentiating harmless messages from racist or sexists contexts in the first detection task, and hateful or offensive contents in the second detection task.", "method_label": "In this paper, we report on developing automated text analytics methods, capable of jointly learning a single representation of hate from several smaller, unrelated data sets. Our most sophisticated method combines a deep neural network architecture with transfer learning. It is capable of creating word and sentence embeddings that are specific to these tasks while also embedding the meaning of generic hate speech. Its prediction correctness is the macro-averaged F1 of $78\\%$ and $72\\%$ in the first and second task, respectively. This method enables generating an interpretable two-dimensional text visualization --- called the Map of Hate --- that is capable of separating different types of hate speech and explaining what makes text harmful.", "result_label": "These methods and insights hold a potential for not only safer social media, but also reduced need to expose human moderators and annotators to distressing online~messaging.", "abstract": "In today's society more and more people are connected to the Internet, and its information and communication technologies have become an essential part of our everyday life. In today's society more and more people are connected to the Internet, and its information and communication technologies have become an essential part of our everyday life. Unfortunately, the flip side of this increased connectivity to social media and other online contents is cyber-bullying and -hatred, among other harmful and anti-social behaviors. In today's society more and more people are connected to the Internet, and its information and communication technologies have become an essential part of our everyday life. Unfortunately, the flip side of this increased connectivity to social media and other online contents is cyber-bullying and -hatred, among other harmful and anti-social behaviors. Models based on machine learning and natural language processing provide a way to detect this hate speech in web text in order to make discussion forums and other media and platforms safer. In today's society more and more people are connected to the Internet, and its information and communication technologies have become an essential part of our everyday life. Unfortunately, the flip side of this increased connectivity to social media and other online contents is cyber-bullying and -hatred, among other harmful and anti-social behaviors. Models based on machine learning and natural language processing provide a way to detect this hate speech in web text in order to make discussion forums and other media and platforms safer. The main difficulty, however, is annotating a sufficiently large number of examples to train these models. In this paper, we report on developing automated text analytics methods, capable of jointly learning a single representation of hate from several smaller, unrelated data sets. In today's society more and more people are connected to the Internet, and its information and communication technologies have become an essential part of our everyday life. Unfortunately, the flip side of this increased connectivity to social media and other online contents is cyber-bullying and -hatred, among other harmful and anti-social behaviors. Models based on machine learning and natural language processing provide a way to detect this hate speech in web text in order to make discussion forums and other media and platforms safer. The main difficulty, however, is annotating a sufficiently large number of examples to train these models. We train and test our methods on the total of $37,520$ English tweets that have been annotated for differentiating harmless messages from racist or sexists contexts in the first detection task, and hateful or offensive contents in the second detection task. In this paper, we report on developing automated text analytics methods, capable of jointly learning a single representation of hate from several smaller, unrelated data sets. Our most sophisticated method combines a deep neural network architecture with transfer learning. In this paper, we report on developing automated text analytics methods, capable of jointly learning a single representation of hate from several smaller, unrelated data sets. Our most sophisticated method combines a deep neural network architecture with transfer learning. It is capable of creating word and sentence embeddings that are specific to these tasks while also embedding the meaning of generic hate speech. In this paper, we report on developing automated text analytics methods, capable of jointly learning a single representation of hate from several smaller, unrelated data sets. Our most sophisticated method combines a deep neural network architecture with transfer learning. It is capable of creating word and sentence embeddings that are specific to these tasks while also embedding the meaning of generic hate speech. Its prediction correctness is the macro-averaged F1 of $78\\%$ and $72\\%$ in the first and second task, respectively. In this paper, we report on developing automated text analytics methods, capable of jointly learning a single representation of hate from several smaller, unrelated data sets. Our most sophisticated method combines a deep neural network architecture with transfer learning. It is capable of creating word and sentence embeddings that are specific to these tasks while also embedding the meaning of generic hate speech. Its prediction correctness is the macro-averaged F1 of $78\\%$ and $72\\%$ in the first and second task, respectively. This method enables generating an interpretable two-dimensional text visualization --- called the Map of Hate --- that is capable of separating different types of hate speech and explaining what makes text harmful. These methods and insights hold a potential for not only safer social media, but also reduced need to expose human moderators and annotators to distressing online~messaging."}, {"paper_id": "160030976", "adju_relevance": 0, "title": "All You Need is \"Love\": Evading Hate-speech Detection", "background_label": "ABSTRACTWith the spread of social networks and their unfortunate use for hate speech, automatic detection of the la er has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on.", "method_label": "Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are bri le against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective -a cu ingedge solution from industry.", "result_label": "Our experiments demonstrate that adversarial training does not completely mitigate the a acks, and using character-level features makes the models systematically more a ack-resistant than using word-level features.", "abstract": "ABSTRACTWith the spread of social networks and their unfortunate use for hate speech, automatic detection of the la er has become a pressing problem. ABSTRACTWith the spread of social networks and their unfortunate use for hate speech, automatic detection of the la er has become a pressing problem. In this paper, we reproduce seven state-of-the-art hate speech detection models from prior work, and show that they perform well only when tested on the same type of data they were trained on. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are bri le against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. Based on these results, we argue that for successful hate speech detection, model architecture is less important than the type of data and labeling criteria. We further show that all proposed detection techniques are bri le against adversaries who can (automatically) insert typos, change word boundaries or add innocuous words to the original hate speech. A combination of these methods is also effective against Google Perspective -a cu ingedge solution from industry. Our experiments demonstrate that adversarial training does not completely mitigate the a acks, and using character-level features makes the models systematically more a ack-resistant than using word-level features."}]