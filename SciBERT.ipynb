{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport math\nimport json\nimport torch\nimport time\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:17:11.128834Z","iopub.execute_input":"2023-03-08T10:17:11.129565Z","iopub.status.idle":"2023-03-08T10:17:12.384875Z","shell.execute_reply.started":"2023-03-08T10:17:11.129514Z","shell.execute_reply":"2023-03-08T10:17:12.383249Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:17:12.393418Z","iopub.execute_input":"2023-03-08T10:17:12.393933Z","iopub.status.idle":"2023-03-08T10:17:12.402685Z","shell.execute_reply.started":"2023-03-08T10:17:12.393876Z","shell.execute_reply":"2023-03-08T10:17:12.401591Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import *\n\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\nmodel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased', output_attentions=False, output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:17:12.404430Z","iopub.execute_input":"2023-03-08T10:17:12.404873Z","iopub.status.idle":"2023-03-08T10:17:25.616230Z","shell.execute_reply.started":"2023-03-08T10:17:12.404827Z","shell.execute_reply":"2023-03-08T10:17:25.614449Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/generation_utils.py:27: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/transformers/generation_tf_utils.py:27: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n  FutureWarning,\n/opt/conda/lib/python3.7/site-packages/transformers/generation_flax_utils.py:27: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n  FutureWarning,\nCould not locate the tokenizer configuration file, will try to use the model config instead.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading file vocab.txt from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt\nloading file tokenizer.json from cache at None\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at None\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin\nSome weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_rankings(ip_dir, file, max_length):\n    '''\n        function to compute rankings based on ratings using cosine similarity between query facet text and corresponding candidate facet text.\n    '''\n    input_dir = ip_dir\n    filename = file\n    query_facet = filename.split('-')[1]\n    query_dicts = dict()\n    candidate_dicts = list()\n    rankings = dict()\n    max_length = max_length\n\n    with open(input_dir + filename, 'r') as f:\n        annot = json.load(f)\n        query_dict = annot[0]\n        candidate_dicts = annot[1:]\n        del annot                        # delete unnecessary files using del and gc.collect() to save RAM\n        gc.collect()\n        \n        try:       # needed because some files don't have query facet text for the requested query\n            query_text = query_dict[query_facet + '_label']        # query facet text\n            candi_texts = list()                                   # corresponding candidate facet texts\n            candi_ratings = list()\n            candidate_relevances = list()\n            for candi_dict in candidate_dicts:\n                try:\n                    candi_texts.append(candi_dict[query_facet+'_label'])\n                except:\n                    candi_texts.append('')\n                candidate_relevances.append(candi_dict['adju_relevance'])\n\n            del query_dict, candidate_dicts\n            gc.collect()\n\n            # important! grad accumulation not needed because we're doing inference\n            # without it, RAM gets eaten up pretty quickly\n            with torch.no_grad():     \n                query_encoding = tokenizer(query_text, max_length=max_length, padding='max_length', return_tensors='pt')\n                query_dense_output = model(**query_encoding)['pooler_output'].flatten()\n                csim = nn.CosineSimilarity(dim=0)\n\n                for text in candi_texts:\n                    encoding = tokenizer(text, max_length=max_length, padding='max_length', return_tensors='pt')\n                    output = model(**encoding)['pooler_output'].flatten()\n                    rating = csim(query_dense_output, output)        # compute cosine similarity\n#                     print(rating)\n                    candi_ratings.append(rating)\n\n                sorted_indices = torch.argsort(torch.tensor(candi_ratings), descending=True).numpy()\n                assert len(sorted_indices) == len(candidate_relevances)\n                rankings = {i: int(docid) for i, docid in enumerate(sorted_indices)}\n                candi_relevances = [candidate_relevances[int(docid)] for docid in sorted_indices]    # compute ground truth relevance values for the ranked docs\n\n                return rankings, candi_relevances\n        except:\n            print(\"Facet : {}, Dict : {}\".format(query_facet, query_dict.keys()))\n            return None","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:27:54.594921Z","iopub.execute_input":"2023-03-08T10:27:54.595553Z","iopub.status.idle":"2023-03-08T10:27:54.612348Z","shell.execute_reply.started":"2023-03-08T10:27:54.595501Z","shell.execute_reply":"2023-03-08T10:27:54.610578Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"input_dir = '/kaggle/input/parsed-annotations/parsed_annotations/'\nmax_length = 400\nfiles_parsed = 0     # to keep track of files parsed till now; to prevent code from starting over again\n\nall_files  = os.listdir(input_dir)\nfilenames = [file for file in all_files if os.path.isfile(os.path.join(input_dir, file))]\ntry:\n    with open('ranking_relevances.json', 'r') as f:\n        results = json.load(f)\nexcept:\n    results = dict()\nstart = time.time()\n\nfile_names = filenames[files_parsed:]          # added so that when cell restarted, code parses only the files left, not the ones that were parsed earlier\nfor i, filename in enumerate(file_names):\n    paper_id = filename.split('-')[0]\n    facet = filename.split('-')[1]\n    try:\n        rankings, relevances = compute_rankings(input_dir, filename, max_length)\n        results[paper_id+'_'+facet] = {'rankings':rankings, 'relevances':relevances}\n    except KeyboardInterrupt:          # when cell stopped, results dict() in its current state will be saved into file\n        with open('ranking_relevances.json', 'w') as f:\n            json.dump(results, f)\n            break\n    except Exception as e:\n        print(e)\n        results[paper_id+'_'+facet] = None\n        \n    end = time.time()\n    files_parsed+=1\n    print(\"{} papers analyzed, Time : {}\".format(files_parsed, end-start))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:34:18.788269Z","iopub.execute_input":"2023-03-08T10:34:18.788839Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"1 papers analyzed, Time : 94.2567412853241\n2 papers analyzed, Time : 162.69917726516724\n3 papers analyzed, Time : 237.49411964416504\n4 papers analyzed, Time : 416.7727208137512\n5 papers analyzed, Time : 599.7255144119263\n6 papers analyzed, Time : 675.973653793335\nFacet : result, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\ncannot unpack non-iterable NoneType object\n7 papers analyzed, Time : 676.5959901809692\nFacet : result, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\ncannot unpack non-iterable NoneType object\n8 papers analyzed, Time : 677.2151629924774\n9 papers analyzed, Time : 760.2884352207184\n10 papers analyzed, Time : 838.6516993045807\n11 papers analyzed, Time : 913.9706315994263\n12 papers analyzed, Time : 995.2099525928497\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\ncannot unpack non-iterable NoneType object\n13 papers analyzed, Time : 995.8408181667328\n14 papers analyzed, Time : 1067.3644120693207\n15 papers analyzed, Time : 1148.7471761703491\n16 papers analyzed, Time : 1240.526696920395\n17 papers analyzed, Time : 1310.1500918865204\n18 papers analyzed, Time : 1388.0817630290985\n19 papers analyzed, Time : 1457.0961472988129\n20 papers analyzed, Time : 1537.024901151657\n21 papers analyzed, Time : 1729.079071521759\n22 papers analyzed, Time : 1799.6838290691376\n23 papers analyzed, Time : 1999.0305817127228\n24 papers analyzed, Time : 2105.930781364441\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\ncannot unpack non-iterable NoneType object\n25 papers analyzed, Time : 2106.5401537418365\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\ncannot unpack non-iterable NoneType object\n26 papers analyzed, Time : 2107.145694255829\n27 papers analyzed, Time : 2190.561005592346\n28 papers analyzed, Time : 2270.4484372138977\n","output_type":"stream"}]},{"cell_type":"code","source":"print(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm ranking_relevances.json","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:34:10.580847Z","iopub.execute_input":"2023-03-08T10:34:10.581943Z","iopub.status.idle":"2023-03-08T10:34:11.724640Z","shell.execute_reply.started":"2023-03-08T10:34:10.581883Z","shell.execute_reply":"2023-03-08T10:34:11.722657Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"# with open('ranking_relevances.json', 'w') as f:\n#     json.dump(results, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('ranking_relevances.json', 'r') as f:\n    results = json.load(f)\n    print(results)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T10:21:15.272677Z","iopub.execute_input":"2023-03-08T10:21:15.273194Z","iopub.status.idle":"2023-03-08T10:21:15.284093Z","shell.execute_reply.started":"2023-03-08T10:21:15.273153Z","shell.execute_reply":"2023-03-08T10:21:15.282501Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{'11844559': None, '6173686': None, '53082542': None, '11629674': None, '10695055': {'rankings': {'0': 58, '1': 14, '2': 99, '3': 45, '4': 0, '5': 1, '6': 204, '7': 59, '8': 15, '9': 177, '10': 82, '11': 85, '12': 185, '13': 2, '14': 46, '15': 23, '16': 144, '17': 219, '18': 217, '19': 130, '20': 125, '21': 128, '22': 127, '23': 47, '24': 88, '25': 221, '26': 119, '27': 13, '28': 195, '29': 56, '30': 224, '31': 212, '32': 118, '33': 57, '34': 192, '35': 113, '36': 171, '37': 84, '38': 112, '39': 95, '40': 143, '41': 208, '42': 25, '43': 102, '44': 31, '45': 230, '46': 156, '47': 44, '48': 111, '49': 199, '50': 153, '51': 24, '52': 52, '53': 169, '54': 207, '55': 229, '56': 165, '57': 148, '58': 123, '59': 176, '60': 76, '61': 136, '62': 138, '63': 103, '64': 237, '65': 172, '66': 182, '67': 147, '68': 214, '69': 110, '70': 6, '71': 4, '72': 62, '73': 174, '74': 35, '75': 9, '76': 36, '77': 191, '78': 223, '79': 8, '80': 141, '81': 198, '82': 30, '83': 133, '84': 235, '85': 97, '86': 75, '87': 163, '88': 64, '89': 60, '90': 38, '91': 186, '92': 121, '93': 124, '94': 63, '95': 190, '96': 194, '97': 116, '98': 50, '99': 54, '100': 7, '101': 150, '102': 49, '103': 16, '104': 164, '105': 51, '106': 11, '107': 81, '108': 206, '109': 220, '110': 216, '111': 168, '112': 40, '113': 179, '114': 78, '115': 126, '116': 157, '117': 173, '118': 159, '119': 151, '120': 203, '121': 196, '122': 202, '123': 71, '124': 73, '125': 98, '126': 184, '127': 80, '128': 21, '129': 65, '130': 61, '131': 87, '132': 233, '133': 89, '134': 27, '135': 18, '136': 48, '137': 154, '138': 232, '139': 37, '140': 170, '141': 29, '142': 94, '143': 197, '144': 10, '145': 167, '146': 139, '147': 117, '148': 53, '149': 188, '150': 155, '151': 226, '152': 234, '153': 201, '154': 228, '155': 131, '156': 42, '157': 231, '158': 137, '159': 33, '160': 19, '161': 178, '162': 175, '163': 83, '164': 101, '165': 205, '166': 67, '167': 105, '168': 28, '169': 5, '170': 134, '171': 69, '172': 209, '173': 77, '174': 115, '175': 210, '176': 70, '177': 213, '178': 129, '179': 135, '180': 34, '181': 93, '182': 32, '183': 183, '184': 236, '185': 227, '186': 3, '187': 166, '188': 114, '189': 146, '190': 142, '191': 92, '192': 162, '193': 55, '194': 158, '195': 79, '196': 218, '197': 74, '198': 20, '199': 96, '200': 17, '201': 161, '202': 122, '203': 108, '204': 86, '205': 66, '206': 104, '207': 72, '208': 200, '209': 193, '210': 120, '211': 181, '212': 132, '213': 109, '214': 187, '215': 160, '216': 39, '217': 106, '218': 22, '219': 100, '220': 152, '221': 68, '222': 225, '223': 145, '224': 222, '225': 189, '226': 91, '227': 12, '228': 211, '229': 215, '230': 180, '231': 140, '232': 41, '233': 149, '234': 26, '235': 43, '236': 90, '237': 107}, 'relevances': [1, 2, 0, 1, 3, 2, 0, 1, 2, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 1, 2, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0]}, '5052952': {'rankings': {'0': 4, '1': 45, '2': 61, '3': 6, '4': 8, '5': 9, '6': 52, '7': 49, '8': 48, '9': 3, '10': 33, '11': 2, '12': 50, '13': 76, '14': 44, '15': 83, '16': 69, '17': 67, '18': 60, '19': 11, '20': 62, '21': 18, '22': 63, '23': 92, '24': 14, '25': 75, '26': 7, '27': 65, '28': 38, '29': 30, '30': 57, '31': 41, '32': 68, '33': 97, '34': 35, '35': 74, '36': 28, '37': 64, '38': 86, '39': 84, '40': 93, '41': 40, '42': 42, '43': 27, '44': 19, '45': 81, '46': 34, '47': 96, '48': 16, '49': 15, '50': 13, '51': 71, '52': 72, '53': 95, '54': 10, '55': 77, '56': 78, '57': 82, '58': 5, '59': 66, '60': 85, '61': 87, '62': 1, '63': 88, '64': 89, '65': 91, '66': 56, '67': 26, '68': 51, '69': 24, '70': 53, '71': 47, '72': 46, '73': 54, '74': 55, '75': 29, '76': 23, '77': 43, '78': 58, '79': 31, '80': 39, '81': 37, '82': 36, '83': 70, '84': 25, '85': 0, '86': 17, '87': 73, '88': 90, '89': 32, '90': 22, '91': 94, '92': 59, '93': 20, '94': 79, '95': 21, '96': 80, '97': 12}, 'relevances': [1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, '8781666': {'rankings': {'0': 0, '1': 60, '2': 73, '3': 51, '4': 14, '5': 83, '6': 10, '7': 63, '8': 1, '9': 96, '10': 56, '11': 18, '12': 17, '13': 84, '14': 13, '15': 44, '16': 22, '17': 11, '18': 54, '19': 53, '20': 31, '21': 98, '22': 5, '23': 77, '24': 79, '25': 40, '26': 24, '27': 33, '28': 4, '29': 21, '30': 2, '31': 64, '32': 97, '33': 99, '34': 61, '35': 66, '36': 58, '37': 69, '38': 48, '39': 74, '40': 39, '41': 85, '42': 41, '43': 87, '44': 70, '45': 45, '46': 8, '47': 50, '48': 20, '49': 12, '50': 89, '51': 57, '52': 42, '53': 92, '54': 9, '55': 75, '56': 30, '57': 78, '58': 35, '59': 68, '60': 49, '61': 82, '62': 28, '63': 16, '64': 25, '65': 46, '66': 7, '67': 43, '68': 6, '69': 86, '70': 34, '71': 90, '72': 47, '73': 93, '74': 81, '75': 52, '76': 15, '77': 3, '78': 59, '79': 71, '80': 67, '81': 38, '82': 37, '83': 26, '84': 95, '85': 27, '86': 55, '87': 72, '88': 91, '89': 19, '90': 88, '91': 65, '92': 80, '93': 76, '94': 100, '95': 36, '96': 23, '97': 29, '98': 94, '99': 62, '100': 32}, 'relevances': [3, 0, 0, 0, 1, 0, 1, 0, 3, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1]}, '2090262': None, '1587': {'rankings': {'0': 85, '1': 87, '2': 40, '3': 20, '4': 10, '5': 89, '6': 80, '7': 27, '8': 35, '9': 1, '10': 53, '11': 56, '12': 17, '13': 73, '14': 65, '15': 95, '16': 29, '17': 21, '18': 13, '19': 70, '20': 14, '21': 48, '22': 3, '23': 76, '24': 41, '25': 42, '26': 77, '27': 19, '28': 18, '29': 57, '30': 88, '31': 52, '32': 75, '33': 60, '34': 34, '35': 82, '36': 9, '37': 99, '38': 37, '39': 66, '40': 38, '41': 23, '42': 100, '43': 15, '44': 71, '45': 102, '46': 91, '47': 59, '48': 50, '49': 74, '50': 94, '51': 78, '52': 83, '53': 54, '54': 86, '55': 11, '56': 104, '57': 101, '58': 24, '59': 68, '60': 5, '61': 8, '62': 79, '63': 92, '64': 33, '65': 22, '66': 44, '67': 55, '68': 46, '69': 93, '70': 31, '71': 62, '72': 105, '73': 98, '74': 67, '75': 90, '76': 69, '77': 61, '78': 36, '79': 58, '80': 47, '81': 2, '82': 4, '83': 96, '84': 26, '85': 32, '86': 45, '87': 64, '88': 97, '89': 25, '90': 16, '91': 103, '92': 39, '93': 63, '94': 30, '95': 49, '96': 12, '97': 81, '98': 72, '99': 0, '100': 43, '101': 6, '102': 7, '103': 51, '104': 106, '105': 28, '106': 84}, 'relevances': [0, 0, 1, 1, 2, 0, 0, 1, 1, 3, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 2, 0, 3, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 2, 0, 0, 3, 0, 2, 2, 0, 0, 1, 0]}, '52194540': {'rankings': {'0': 68, '1': 86, '2': 15, '3': 66, '4': 99, '5': 73, '6': 12, '7': 3, '8': 84, '9': 33, '10': 82, '11': 10, '12': 97, '13': 77, '14': 92, '15': 96, '16': 75, '17': 80, '18': 4, '19': 51, '20': 64, '21': 56, '22': 62, '23': 32, '24': 14, '25': 24, '26': 17, '27': 26, '28': 41, '29': 35, '30': 36, '31': 22, '32': 21, '33': 19, '34': 95, '35': 94, '36': 61, '37': 98, '38': 69, '39': 2, '40': 81, '41': 31, '42': 11, '43': 65, '44': 7, '45': 58, '46': 59, '47': 79, '48': 89, '49': 23, '50': 18, '51': 47, '52': 8, '53': 57, '54': 60, '55': 20, '56': 9, '57': 28, '58': 70, '59': 55, '60': 91, '61': 27, '62': 46, '63': 50, '64': 88, '65': 53, '66': 43, '67': 87, '68': 67, '69': 85, '70': 40, '71': 42, '72': 0, '73': 78, '74': 54, '75': 1, '76': 29, '77': 90, '78': 83, '79': 76, '80': 30, '81': 52, '82': 100, '83': 38, '84': 72, '85': 13, '86': 34, '87': 93, '88': 44, '89': 39, '90': 71, '91': 63, '92': 49, '93': 37, '94': 16, '95': 48, '96': 45, '97': 25, '98': 6, '99': 74, '100': 5}, 'relevances': [0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 1, 1, 0, 0, 2, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 3, 0, 1, 3, 2, 0, 0, 0, 2, 1, 0, 1, 0, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 2, 2, 0, 2]}, '7898033': {'rankings': {'0': 5, '1': 16, '2': 88, '3': 52, '4': 54, '5': 10, '6': 76, '7': 78, '8': 66, '9': 23, '10': 4, '11': 31, '12': 85, '13': 26, '14': 12, '15': 67, '16': 51, '17': 65, '18': 11, '19': 86, '20': 1, '21': 28, '22': 70, '23': 95, '24': 60, '25': 64, '26': 2, '27': 32, '28': 37, '29': 74, '30': 73, '31': 35, '32': 61, '33': 62, '34': 0, '35': 48, '36': 40, '37': 75, '38': 49, '39': 83, '40': 39, '41': 84, '42': 69, '43': 46, '44': 82, '45': 63, '46': 59, '47': 55, '48': 93, '49': 33, '50': 56, '51': 17, '52': 9, '53': 79, '54': 44, '55': 43, '56': 22, '57': 36, '58': 77, '59': 15, '60': 30, '61': 3, '62': 90, '63': 94, '64': 47, '65': 53, '66': 19, '67': 6, '68': 42, '69': 91, '70': 81, '71': 92, '72': 96, '73': 7, '74': 45, '75': 41, '76': 57, '77': 50, '78': 34, '79': 38, '80': 13, '81': 29, '82': 27, '83': 18, '84': 71, '85': 87, '86': 68, '87': 14, '88': 58, '89': 21, '90': 72, '91': 20, '92': 89, '93': 8, '94': 80, '95': 24, '96': 25}, 'relevances': [2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 0, 3, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1]}, '80628431': {'rankings': {'0': 4, '1': 21, '2': 92, '3': 13, '4': 69, '5': 60, '6': 3, '7': 72, '8': 91, '9': 0, '10': 55, '11': 88, '12': 85, '13': 15, '14': 54, '15': 84, '16': 90, '17': 75, '18': 17, '19': 80, '20': 99, '21': 51, '22': 39, '23': 33, '24': 76, '25': 24, '26': 102, '27': 77, '28': 40, '29': 37, '30': 44, '31': 14, '32': 64, '33': 8, '34': 68, '35': 6, '36': 93, '37': 28, '38': 79, '39': 52, '40': 56, '41': 16, '42': 62, '43': 95, '44': 25, '45': 30, '46': 35, '47': 81, '48': 31, '49': 47, '50': 63, '51': 12, '52': 5, '53': 74, '54': 46, '55': 58, '56': 45, '57': 23, '58': 18, '59': 41, '60': 103, '61': 73, '62': 78, '63': 82, '64': 86, '65': 87, '66': 101, '67': 94, '68': 96, '69': 97, '70': 100, '71': 98, '72': 36, '73': 1, '74': 2, '75': 7, '76': 9, '77': 10, '78': 11, '79': 19, '80': 20, '81': 22, '82': 26, '83': 27, '84': 29, '85': 32, '86': 34, '87': 71, '88': 38, '89': 42, '90': 43, '91': 48, '92': 49, '93': 50, '94': 53, '95': 57, '96': 59, '97': 61, '98': 65, '99': 66, '100': 67, '101': 70, '102': 83, '103': 89}, 'relevances': [2, 0, 0, 1, 0, 0, 2, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, '5270848': None, '1791179': {'rankings': {'0': 0, '1': 26, '2': 60, '3': 91, '4': 2, '5': 11, '6': 65, '7': 5, '8': 80, '9': 33, '10': 86, '11': 75, '12': 36, '13': 57, '14': 56, '15': 82, '16': 55, '17': 15, '18': 84, '19': 45, '20': 4, '21': 25, '22': 28, '23': 62, '24': 14, '25': 17, '26': 29, '27': 58, '28': 13, '29': 48, '30': 37, '31': 69, '32': 88, '33': 89, '34': 40, '35': 30, '36': 81, '37': 19, '38': 21, '39': 85, '40': 20, '41': 12, '42': 66, '43': 71, '44': 54, '45': 10, '46': 44, '47': 41, '48': 59, '49': 73, '50': 18, '51': 87, '52': 34, '53': 8, '54': 7, '55': 90, '56': 31, '57': 27, '58': 23, '59': 50, '60': 52, '61': 72, '62': 64, '63': 47, '64': 46, '65': 74, '66': 51, '67': 78, '68': 67, '69': 32, '70': 1, '71': 22, '72': 83, '73': 43, '74': 6, '75': 63, '76': 38, '77': 42, '78': 76, '79': 35, '80': 53, '81': 79, '82': 16, '83': 9, '84': 24, '85': 39, '86': 49, '87': 77, '88': 68, '89': 61, '90': 70, '91': 3}, 'relevances': [3, 1, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2]}, '929877': {'rankings': {'0': 28, '1': 95, '2': 2, '3': 99, '4': 55, '5': 65, '6': 24, '7': 27, '8': 60, '9': 64, '10': 43, '11': 54, '12': 51, '13': 94, '14': 89, '15': 96, '16': 16, '17': 9, '18': 37, '19': 104, '20': 25, '21': 26, '22': 59, '23': 15, '24': 12, '25': 79, '26': 3, '27': 98, '28': 63, '29': 20, '30': 52, '31': 56, '32': 14, '33': 101, '34': 23, '35': 75, '36': 5, '37': 7, '38': 44, '39': 29, '40': 58, '41': 18, '42': 35, '43': 33, '44': 1, '45': 100, '46': 72, '47': 73, '48': 74, '49': 68, '50': 76, '51': 78, '52': 11, '53': 103, '54': 80, '55': 81, '56': 82, '57': 102, '58': 83, '59': 8, '60': 84, '61': 4, '62': 85, '63': 86, '64': 87, '65': 88, '66': 97, '67': 10, '68': 90, '69': 91, '70': 92, '71': 93, '72': 0, '73': 32, '74': 34, '75': 36, '76': 30, '77': 38, '78': 39, '79': 40, '80': 42, '81': 45, '82': 46, '83': 47, '84': 48, '85': 49, '86': 50, '87': 17, '88': 69, '89': 31, '90': 67, '91': 13, '92': 70, '93': 62, '94': 61, '95': 19, '96': 57, '97': 21, '98': 22, '99': 53, '100': 41, '101': 77, '102': 66, '103': 71, '104': 6}, 'relevances': [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]}, '189897839': {'rankings': {'0': 1, '1': 0, '2': 112, '3': 69, '4': 15, '5': 31, '6': 81, '7': 38, '8': 96, '9': 9, '10': 98, '11': 76, '12': 21, '13': 53, '14': 12, '15': 37, '16': 45, '17': 8, '18': 94, '19': 28, '20': 84, '21': 46, '22': 55, '23': 101, '24': 83, '25': 6, '26': 32, '27': 51, '28': 73, '29': 10, '30': 79, '31': 114, '32': 54, '33': 93, '34': 58, '35': 111, '36': 41, '37': 4, '38': 19, '39': 26, '40': 105, '41': 24, '42': 89, '43': 30, '44': 5, '45': 49, '46': 71, '47': 64, '48': 68, '49': 18, '50': 72, '51': 104, '52': 82, '53': 74, '54': 63, '55': 66, '56': 110, '57': 22, '58': 95, '59': 75, '60': 20, '61': 43, '62': 27, '63': 17, '64': 47, '65': 91, '66': 34, '67': 60, '68': 90, '69': 70, '70': 16, '71': 85, '72': 109, '73': 7, '74': 102, '75': 106, '76': 77, '77': 103, '78': 59, '79': 42, '80': 80, '81': 97, '82': 57, '83': 62, '84': 65, '85': 67, '86': 50, '87': 36, '88': 78, '89': 2, '90': 48, '91': 56, '92': 100, '93': 39, '94': 44, '95': 118, '96': 3, '97': 88, '98': 113, '99': 33, '100': 86, '101': 25, '102': 99, '103': 117, '104': 29, '105': 52, '106': 13, '107': 92, '108': 87, '109': 116, '110': 35, '111': 14, '112': 40, '113': 107, '114': 115, '115': 108, '116': 61, '117': 23, '118': 11}, 'relevances': [3, 3, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 2, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 2]}, '6431039': {'rankings': {'0': 8, '1': 82, '2': 73, '3': 19, '4': 51, '5': 2, '6': 28, '7': 26, '8': 7, '9': 64, '10': 11, '11': 57, '12': 88, '13': 41, '14': 14, '15': 66, '16': 10, '17': 61, '18': 3, '19': 77, '20': 81, '21': 69, '22': 22, '23': 32, '24': 35, '25': 80, '26': 45, '27': 46, '28': 85, '29': 47, '30': 49, '31': 50, '32': 84, '33': 54, '34': 55, '35': 67, '36': 60, '37': 79, '38': 63, '39': 75, '40': 74, '41': 72, '42': 65, '43': 1, '44': 15, '45': 24, '46': 29, '47': 5, '48': 4, '49': 33, '50': 6, '51': 20, '52': 18, '53': 0, '54': 39, '55': 12, '56': 40, '57': 42, '58': 21, '59': 62, '60': 25, '61': 23, '62': 38, '63': 36, '64': 37, '65': 30, '66': 71, '67': 9, '68': 87, '69': 31, '70': 86, '71': 56, '72': 48, '73': 34, '74': 16, '75': 44, '76': 27, '77': 43, '78': 89, '79': 13, '80': 59, '81': 53, '82': 58, '83': 70, '84': 76, '85': 83, '86': 52, '87': 68, '88': 78, '89': 17}, 'relevances': [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, '3264891': {'rankings': {'0': 42, '1': 38, '2': 50, '3': 34, '4': 35, '5': 31, '6': 76, '7': 55, '8': 28, '9': 69, '10': 46, '11': 59, '12': 60, '13': 10, '14': 73, '15': 78, '16': 80, '17': 84, '18': 40, '19': 11, '20': 20, '21': 15, '22': 7, '23': 49, '24': 64, '25': 79, '26': 58, '27': 74, '28': 85, '29': 54, '30': 87, '31': 0, '32': 36, '33': 21, '34': 67, '35': 56, '36': 29, '37': 14, '38': 4, '39': 22, '40': 44, '41': 70, '42': 8, '43': 16, '44': 37, '45': 68, '46': 62, '47': 18, '48': 77, '49': 24, '50': 12, '51': 3, '52': 71, '53': 1, '54': 5, '55': 72, '56': 13, '57': 33, '58': 75, '59': 9, '60': 45, '61': 43, '62': 6, '63': 47, '64': 81, '65': 82, '66': 83, '67': 39, '68': 2, '69': 86, '70': 41, '71': 63, '72': 26, '73': 25, '74': 57, '75': 53, '76': 23, '77': 19, '78': 61, '79': 52, '80': 27, '81': 51, '82': 65, '83': 66, '84': 17, '85': 30, '86': 32, '87': 48}, 'relevances': [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 2, 0, 2, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]}, '5764728': {'rankings': {'0': 10, '1': 38, '2': 1, '3': 18, '4': 13, '5': 63, '6': 86, '7': 44, '8': 77, '9': 84, '10': 39, '11': 26, '12': 50, '13': 47, '14': 6, '15': 53, '16': 14, '17': 35, '18': 93, '19': 61, '20': 59, '21': 54, '22': 83, '23': 7, '24': 16, '25': 48, '26': 21, '27': 23, '28': 92, '29': 49, '30': 27, '31': 42, '32': 55, '33': 85, '34': 28, '35': 20, '36': 11, '37': 29, '38': 89, '39': 4, '40': 81, '41': 12, '42': 0, '43': 30, '44': 72, '45': 46, '46': 88, '47': 33, '48': 96, '49': 40, '50': 98, '51': 66, '52': 19, '53': 37, '54': 71, '55': 75, '56': 17, '57': 87, '58': 2, '59': 82, '60': 41, '61': 73, '62': 25, '63': 52, '64': 51, '65': 32, '66': 68, '67': 22, '68': 45, '69': 56, '70': 57, '71': 69, '72': 15, '73': 97, '74': 91, '75': 70, '76': 90, '77': 79, '78': 65, '79': 64, '80': 24, '81': 78, '82': 36, '83': 31, '84': 95, '85': 9, '86': 34, '87': 76, '88': 62, '89': 58, '90': 94, '91': 60, '92': 80, '93': 5, '94': 74, '95': 67, '96': 8, '97': 3, '98': 43}, 'relevances': [2, 1, 2, 2, 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 2, 1, 0, 0, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 2, 1, 0, 2, 0, 2, 3, 1, 0, 1, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 2, 1]}, '11310392': None, '51977123': None}\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\n\ndel results\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}