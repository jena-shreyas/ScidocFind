{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-06T19:43:24.902740Z","iopub.execute_input":"2023-03-06T19:43:24.903579Z","iopub.status.idle":"2023-03-06T19:43:24.930248Z","shell.execute_reply.started":"2023-03-06T19:43:24.903530Z","shell.execute_reply":"2023-03-06T19:43:24.929150Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/parsed-annotations/parsed_annotations/11844559-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/6173686-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/53082542-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/11629674-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/10695055-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/5052952-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/8781666-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/2090262-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1587-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/52194540-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/7898033-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/80628431-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/5270848-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1791179-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/929877-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/189897839-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/6431039-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/8781666-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/3264891-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/5764728-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/11310392-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/51977123-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/10014168-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/2865563-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1936997-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/52194540-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/2468783-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/2468783-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1587-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/13949438-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1936997-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1198964-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1306065-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/10052042-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/80628431-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/2360770-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/53080736-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/5052952-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/174799296-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/189897839-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1791179-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/53080736-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/174799296-result-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/10010426-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/1198964-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/929877-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/11844559-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/102353905-method-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/6431039-background-adju.json\n/kaggle/input/parsed-annotations/parsed_annotations/3264891-background-adju.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport math\nimport json\nimport torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-03-07T06:30:26.746035Z","iopub.execute_input":"2023-03-07T06:30:26.746740Z","iopub.status.idle":"2023-03-07T06:30:26.752524Z","shell.execute_reply.started":"2023-03-07T06:30:26.746706Z","shell.execute_reply":"2023-03-07T06:30:26.751315Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"from transformers import *\n\ntokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\nmodel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased', output_attentions=False, output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T04:57:12.054640Z","iopub.execute_input":"2023-03-07T04:57:12.055001Z","iopub.status.idle":"2023-03-07T04:57:14.498984Z","shell.execute_reply.started":"2023-03-07T04:57:12.054969Z","shell.execute_reply":"2023-03-07T04:57:14.498045Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"Could not locate the tokenizer configuration file, will try to use the model config instead.\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading file vocab.txt from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/vocab.txt\nloading file tokenizer.json from cache at None\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at None\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.26.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 31090\n}\n\nloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--allenai--scibert_scivocab_uncased/snapshots/24f92d32b1bfb0bcaf9ab193ff3ad01e87732fc1/pytorch_model.bin\nSome weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_rankings(ip_dir, file, max_length):\n    input_dir = ip_dir\n    filename = file\n    query_facet = filename.split('-')[1]\n    rankings = dict()\n    max_length = max_length\n\n    with open(input_dir + filename, 'r') as f:\n        annot = json.load(f)\n        query_dict = annot[0]\n        candidate_dicts = annot[1:]\n        candidate_relevances = [dict_['adju_relevance'] for dict_ in candidate_dicts]\n        try:\n            query_text = query_dict[query_facet + '_label']\n            candi_texts = list()\n            candi_encodings = list()\n            candi_ratings = list()\n            for candi_dict in candidate_dicts:\n                try:\n                    candi_texts.append(candi_dict[query_facet+'_label'])\n                except:\n                    candi_texts.append('')\n\n            query_encoding = tokenizer.encode(query_text, padding='max_length')\n            query_encoding = query_encoding + [tokenizer.pad_token_id] * (max_length - len(query_encoding))\n            query_encoding = torch.tensor(query_encoding, dtype=torch.float32)\n            csim = nn.CosineSimilarity(dim=0)\n\n            for idx, text in enumerate(candi_texts):\n                encoding = tokenizer.encode(text, padding='max_length')\n                encoding = encoding + [tokenizer.pad_token_id] * (max_length - len(encoding))\n                encoding = torch.tensor(encoding, dtype=torch.float32)\n                candi_encodings.append(encoding)\n                candi_ratings.append(csim(query_encoding, candi_encodings[idx]))\n\n            sorted_indices = torch.argsort(torch.tensor(candi_ratings), descending=True)\n            rankings = {i: int(docid) for i, docid in enumerate(sorted_indices)}\n            candi_relevances = [candidate_relevances[i] for i in sorted_indices]\n            return rankings, candi_relevances\n        except:\n            print(\"Facet : {}, Dict : {}\".format(query_facet, query_dict.keys()))\n            return None","metadata":{"execution":{"iopub.status.busy":"2023-03-07T06:41:13.200580Z","iopub.execute_input":"2023-03-07T06:41:13.200960Z","iopub.status.idle":"2023-03-07T06:41:13.214726Z","shell.execute_reply.started":"2023-03-07T06:41:13.200929Z","shell.execute_reply":"2023-03-07T06:41:13.213613Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"input_dir = '/kaggle/input/parsed-annotations/parsed_annotations/'\nmax_length = 400\n\nall_files  = os.listdir(input_dir)\nfilenames = [file for file in all_files if os.path.isfile(os.path.join(input_dir, file))]\nresults = dict()\nfor filename in filenames:\n    paper_id = filename.split('-')[0]\n    try:\n        rankings, relevances = compute_rankings(input_dir, filename, max_length)\n        results[paper_id] = {'rankings':rankings, 'relevances':relevances}\n    except:\n        results[paper_id] = None","metadata":{"execution":{"iopub.status.busy":"2023-03-07T06:46:22.736882Z","iopub.execute_input":"2023-03-07T06:46:22.737344Z","iopub.status.idle":"2023-03-07T06:46:25.204111Z","shell.execute_reply.started":"2023-03-07T06:46:22.737297Z","shell.execute_reply":"2023-03-07T06:46:25.202820Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"Facet : result, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : result, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : background, Dict : dict_keys(['paper_id', 'title', 'background_label', 'method_label', 'result_label', 'abstract'])\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : background, Dict : dict_keys(['paper_id', 'title', 'method_label', 'result_label', 'abstract'])\nFacet : method, Dict : dict_keys(['paper_id', 'title', 'background_label', 'abstract'])\nFacet : background, Dict : dict_keys(['paper_id', 'title', 'method_label', 'result_label', 'abstract'])\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('ranking_relevances.json', 'w') as f:\n    json.dump(results, f)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T06:46:27.176787Z","iopub.execute_input":"2023-03-07T06:46:27.177193Z","iopub.status.idle":"2023-03-07T06:46:27.197180Z","shell.execute_reply.started":"2023-03-07T06:46:27.177155Z","shell.execute_reply":"2023-03-07T06:46:27.196252Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}