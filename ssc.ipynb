{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOB-45lOfJEH",
        "outputId": "d0028fd1-0e21-4ed3-a4f2-3ceed867ca90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-05 05:48:49--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-4.5.4-Li 100%[===================>]  55.76M   185MB/s    in 0.3s    \n",
            "\n",
            "2023-03-05 05:48:49 (185 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n"
          ]
        }
      ],
      "source": [
        "# same\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2ScZJ7wfpGA",
        "outputId": "649b8980-3171-4abc-9710-978dca5fb104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sequential_sentence_classification'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 93 (delta 31), reused 27 (delta 27), pack-reused 48\u001b[K\n",
            "Unpacking objects: 100% (93/93), 829.02 KiB | 2.19 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/allenai/sequential_sentence_classification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78H916a0f13V",
        "outputId": "af3809a7-2886-4fac-e77b-5fc34e05510e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sequential_sentence_classification\n"
          ]
        }
      ],
      "source": [
        "%cd sequential_sentence_classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyrdgJ5pgAqE",
        "outputId": "77820d96-b2a8-4042-9e6c-113078ad83f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaValueError: prefix already exists: /usr/local/envs/allennlp\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.1/663.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pillow>=4.1.1\n",
            "  Downloading Pillow-9.4.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: six, pillow, numpy, torch, torchvision\n",
            "Successfully installed numpy-1.21.6 pillow-9.4.0 six-1.16.0 torch-1.2.0+cu92 torchvision-0.4.0+cu92\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "%%shell\n",
        "conda create -n allennlp python=3.7\n",
        "source activate allennlp\n",
        "pip install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwm0OWjagCBk",
        "outputId": "35bd70de-5feb-43fb-d7e2-fd2dad0b1cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining allennlp from git+git://github.com/ibeltagy/allennlp@fp16_and_others#egg=allennlp (from -r requirements.txt (line 2))\n",
            "  Cloning git://github.com/ibeltagy/allennlp (to revision fp16_and_others) to ./src/allennlp\n",
            "  Running command git clone --filter=blob:none --quiet git://github.com/ibeltagy/allennlp /content/sequential_sentence_classification/src/allennlp\n",
            "  Running command git checkout -b fp16_and_others --track origin/fp16_and_others\n",
            "  Switched to a new branch 'fp16_and_others'\n",
            "  Branch 'fp16_and_others' set up to track remote branch 'fp16_and_others' from 'origin'.\n",
            "  Resolved git://github.com/ibeltagy/allennlp to commit ac2b21da6008d0e41d31192ea596153988c000a4\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting attrs>=19.2.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/envs/allennlp/lib/python3.7/site-packages (from allennlp->-r requirements.txt (line 2)) (1.2.0+cu92)\n",
            "Collecting overrides\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy<2.2,>=2.1.0\n",
            "  Downloading spacy-2.1.9-cp37-cp37m-manylinux1_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/envs/allennlp/lib/python3.7/site-packages (from allennlp->-r requirements.txt (line 2)) (1.21.6)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.26.84-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask>=1.0.2\n",
            "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flask-cors>=3.0.7\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting gevent>=1.3.6\n",
            "  Downloading gevent-22.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.18\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>=4.19\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting editdistance\n",
            "  Downloading editdistance-0.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py\n",
            "  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=2.2.3\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest\n",
            "  Downloading pytest-7.2.2-py3-none-any.whl (317 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.2/317.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting responses>=0.7\n",
            "  Downloading responses-0.22.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=0.8.0\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting conllu==1.3.1\n",
            "  Downloading conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting parsimonious>=0.8.0\n",
            "  Downloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlparse>=0.2.4\n",
            "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting word2number>=1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-transformers==1.1.0\n",
            "  Downloading pytorch_transformers-1.1.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpickle\n",
            "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.19.1.tar.gz (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.6/593.6 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=3.6.0\n",
            "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
            "Collecting Werkzeug>=2.2.2\n",
            "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting click>=8.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Six in /usr/local/envs/allennlp/lib/python3.7/site-packages (from flask-cors>=3.0.7->allennlp->-r requirements.txt (line 2)) (1.16.0)\n",
            "Collecting greenlet>=2.0.0\n",
            "  Downloading greenlet-2.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (566 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/allennlp/lib/python3.7/site-packages (from gevent>=1.3.6->allennlp->-r requirements.txt (line 2)) (65.6.3)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.5.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/envs/allennlp/lib/python3.7/site-packages (from matplotlib>=2.2.3->allennlp->-r requirements.txt (line 2)) (9.4.0)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx>=4.2\n",
            "  Downloading sphinx-5.3.0-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/allennlp/lib/python3.7/site-packages (from requests>=2.18->allennlp->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting types-toml\n",
            "  Downloading types_toml-0.10.8.5-py3-none-any.whl (4.5 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
            "Collecting wasabi<1.1.0,>=0.2.0\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting srsly<1.1.0,>=0.0.6\n",
            "  Downloading srsly-1.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.6/208.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<4,>=3.8.0\n",
            "  Downloading protobuf-3.20.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.84\n",
            "  Downloading botocore-1.29.84-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth>=0.2.5\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pluggy<2.0,>=0.12\n",
            "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting iniconfig\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting tomli>=1.0.0\n",
            "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8\n",
            "  Downloading exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting docutils<0.20,>=0.14\n",
            "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alabaster<0.8,>=0.7\n",
            "  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
            "Collecting snowballstemmer>=2.0\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-qthelp\n",
            "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting babel>=2.9\n",
            "  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-devhelp\n",
            "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp\n",
            "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pygments>=2.12\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp>=2.0.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.5/100.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting imagesize>=1.3\n",
            "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
            "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: jsonnet, word2number\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.19.1-cp37-cp37m-linux_x86_64.whl size=6339840 sha256=c10019cdbe4ee36655c075bea94f58ecebe1db612cdf3c740e247bd21a9b2d88\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/87/45/fa94c0be98e267923bd8536d6595f1b0d5e56403dd41ebd185\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5566 sha256=5011988a2a6a53757b90742a7636e9eac5a4e79f5b88a070d47408107121657f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/e1/0b/575d02bdf2c7ff9c9be5490db69e8d4e2e26b5523e295137eb\n",
            "Successfully built jsonnet word2number\n",
            "Installing collected packages: word2number, wcwidth, wasabi, types-toml, snowballstemmer, sentencepiece, pytz, plac, jsonnet, cymem, conllu, charset-normalizer, zope.interface, zope.event, zipp, urllib3, unidecode, typing-extensions, tqdm, tomli, toml, threadpoolctl, srsly, sqlparse, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, scipy, regex, python-dateutil, pyparsing, Pygments, protobuf, preshed, packaging, overrides, murmurhash, MarkupSafe, joblib, jmespath, itsdangerous, iniconfig, imagesize, idna, h5py, greenlet, ftfy, fonttools, flaky, exceptiongroup, editdistance, docutils, cycler, blis, babel, attrs, alabaster, Werkzeug, thinc, tensorboardX, scikit-learn, requests, parsimonious, kiwisolver, jsonlines, Jinja2, importlib-metadata, gevent, botocore, sphinx, spacy, s3transfer, responses, pluggy, matplotlib, jsonpickle, click, pytest, numpydoc, nltk, flask, boto3, pytorch-transformers, pytorch-pretrained-bert, flask-cors, allennlp\n",
            "  Running setup.py develop for allennlp\n",
            "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.2 Pygments-2.14.0 Werkzeug-2.2.3 alabaster-0.7.13 allennlp-0.9.0-unreleased attrs-22.2.0 babel-2.12.1 blis-0.2.4 boto3-1.26.84 botocore-1.29.84 charset-normalizer-3.0.1 click-8.1.3 conllu-1.3.1 cycler-0.11.0 cymem-2.0.7 docutils-0.19 editdistance-0.6.2 exceptiongroup-1.1.0 flaky-3.7.0 flask-2.2.3 flask-cors-3.0.10 fonttools-4.38.0 ftfy-6.1.1 gevent-22.10.2 greenlet-2.0.2 h5py-3.8.0 idna-3.4 imagesize-1.4.1 importlib-metadata-6.0.0 iniconfig-2.0.0 itsdangerous-2.1.2 jmespath-1.0.1 joblib-1.2.0 jsonlines-3.1.0 jsonnet-0.19.1 jsonpickle-3.0.1 kiwisolver-1.4.4 matplotlib-3.5.3 murmurhash-1.0.9 nltk-3.8.1 numpydoc-1.5.0 overrides-7.3.1 packaging-23.0 parsimonious-0.10.0 plac-0.9.6 pluggy-1.0.0 preshed-2.0.1 protobuf-3.20.3 pyparsing-3.0.9 pytest-7.2.2 python-dateutil-2.8.2 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 pytz-2022.7.1 regex-2022.10.31 requests-2.28.2 responses-0.22.0 s3transfer-0.6.0 scikit-learn-1.0.2 scipy-1.7.3 sentencepiece-0.1.97 snowballstemmer-2.2.0 spacy-2.1.9 sphinx-5.3.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sqlparse-0.4.3 srsly-1.0.6 tensorboardX-2.6 thinc-7.0.8 threadpoolctl-3.1.0 toml-0.10.2 tomli-2.0.1 tqdm-4.65.0 types-toml-0.10.8.5 typing-extensions-4.5.0 unidecode-1.3.6 urllib3-1.26.14 wasabi-0.10.1 wcwidth-0.2.6 word2number-1.1 zipp-3.15.0 zope.event-4.6 zope.interface-5.5.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "%%shell\n",
        "source activate allennlp\n",
        "git config --global url.https://github.com/.insteadOf git://github.com/\n",
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "source activate allennlp\n",
        "pip install overrides==3.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_dZc0gJVgFA",
        "outputId": "8d0d1963-bb64-4118-b3d8-043597330cc8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: overrides\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10173 sha256=397bd4bac989763ebc3a5d792e182112f687742073326da1d69516bf5acc267f\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/13/69/7100f11c8ac18af16359fa07f3469ea79bb65d44fdd37db13f\n",
            "Successfully built overrides\n",
            "Installing collected packages: overrides\n",
            "  Attempting uninstall: overrides\n",
            "    Found existing installation: overrides 7.3.1\n",
            "    Uninstalling overrides-7.3.1:\n",
            "      Successfully uninstalled overrides-7.3.1\n",
            "Successfully installed overrides-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY9_u55TwyS2",
        "outputId": "c7131b55-5120-4d28-b720-3648fcb20535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-05 05:56:36,780 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2023-03-05 05:56:37,313 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2023-03-05 05:56:37,316 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2023-03-05 05:56:37,802 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:56:37,803 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:56:37,804 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:56:37,806 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:56:38,024 - INFO - allennlp.common.params - random_seed = 15270\n",
            "2023-03-05 05:56:38,024 - INFO - allennlp.common.params - numpy_seed = 152\n",
            "2023-03-05 05:56:38,024 - INFO - allennlp.common.params - pytorch_seed = 1527\n",
            "2023-03-05 05:56:38,607 - INFO - allennlp.common.checks - Pytorch version: 1.2.0+cu92\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.params - evaluate_on_test = True\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sent_per_example': '10', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '80', 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'type': 'SeqClassificationReader', 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras set()\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.params - dataset_reader.type = SeqClassificationReader\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.dataset_reader.SeqClassificationReader'> from params {'lazy': False, 'max_sent_per_example': '10', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '80', 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras set()\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2023-03-05 05:56:38,608 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'use_starting_offsets': False} and extras set()\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = True\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512\n",
            "2023-03-05 05:56:38,609 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = True\n",
            "2023-03-05 05:56:39,343 - INFO - pytorch_pretrained_bert.file_utils - https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab not found in cache, downloading to /tmp/tmpk1ri1x64\n",
            "100%|##########| 227845/227845 [00:00<00:00, 442940.29B/s]\n",
            "2023-03-05 05:56:40,605 - INFO - pytorch_pretrained_bert.file_utils - copying /tmp/tmpk1ri1x64 to cache at /root/.pytorch_pretrained_bert/d2fac719b6d663ae040cb698dfbc553ad2ba1796a6cb1acd74a4cd69168a6559.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
            "2023-03-05 05:56:40,606 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for /root/.pytorch_pretrained_bert/d2fac719b6d663ae040cb698dfbc553ad2ba1796a6cb1acd74a4cd69168a6559.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
            "2023-03-05 05:56:40,606 - INFO - pytorch_pretrained_bert.file_utils - removing temp file /tmp/tmpk1ri1x64\n",
            "2023-03-05 05:56:40,606 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab from cache at /root/.pytorch_pretrained_bert/d2fac719b6d663ae040cb698dfbc553ad2ba1796a6cb1acd74a4cd69168a6559.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.params - dataset_reader.word_splitter = bert-basic\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.registrable - instantiating registered subclass bert-basic of <class 'allennlp.data.tokenizers.word_splitter.WordSplitter'>\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.params - dataset_reader.sent_max_len = 80\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.params - dataset_reader.max_sent_per_example = 10\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.params - dataset_reader.use_sep = true\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.params - dataset_reader.sci_sum = False\n",
            "2023-03-05 05:56:40,637 - INFO - allennlp.common.params - dataset_reader.use_abstract_scores = False\n",
            "2023-03-05 05:56:40,638 - INFO - allennlp.common.params - dataset_reader.sci_sum_fake_scores = False\n",
            "2023-03-05 05:56:40,638 - INFO - allennlp.common.params - dataset_reader.predict = False\n",
            "2023-03-05 05:56:40,638 - WARNING - allennlp.common.util - Spacy models 'en_core_web_sm' not found.  Downloading and installing.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: en_core_web_sm\n",
            "  Building wheel for en_core_web_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_web_sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074412 sha256=a209cb7b4596c1f4436b47a89ec3a18927ac1dbe52ec6e1e6082a4dc9a49e670\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y8k0ds65/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en_core_web_sm\n",
            "Installing collected packages: en_core_web_sm\n",
            "Successfully installed en_core_web_sm-2.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "/usr/local/envs/allennlp/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: 0.9.0-unreleased is an invalid version and will not be supported in a future release\n",
            "  PkgResourcesDeprecationWarning,\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/envs/allennlp/lib/python3.7/site-packages/en_core_web_sm -->\n",
            "/usr/local/envs/allennlp/lib/python3.7/site-packages/spacy/data/en_core_web_sm\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "2023-03-05 05:56:49,470 - INFO - allennlp.common.params - train_data_path = data/CSAbstruct/train.jsonl\n",
            "2023-03-05 05:56:49,470 - INFO - allennlp.training.util - Reading training data from data/CSAbstruct/train.jsonl\n",
            "1668it [00:06, 256.37it/s]\n",
            "2023-03-05 05:56:55,977 - INFO - allennlp.common.params - validation_data_path = data/CSAbstruct/dev.jsonl\n",
            "2023-03-05 05:56:55,977 - INFO - allennlp.training.util - Reading validation data from data/CSAbstruct/dev.jsonl\n",
            "295it [00:00, 300.62it/s]\n",
            "2023-03-05 05:56:56,959 - INFO - allennlp.common.params - test_data_path = data/CSAbstruct/test.jsonl\n",
            "2023-03-05 05:56:56,959 - INFO - allennlp.training.util - Reading test data from data/CSAbstruct/test.jsonl\n",
            "226it [00:00, 258.36it/s]\n",
            "2023-03-05 05:56:57,838 - INFO - allennlp.training.trainer_pieces - From dataset instances, test, validation, train will be considered for vocabulary creation.\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.type = None\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.extend = False\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2023-03-05 05:56:57,839 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2023-03-05 05:56:57,840 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "2189it [00:00, 21430.43it/s]\n",
            "2023-03-05 05:56:57,942 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'additional_feature_size': 0, 'bert_dropout': 0.1, 'sci_sum': False, 'self_attn': {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'}}}, 'type': 'SeqClassificationModel', 'use_sep': 'true', 'with_crf': 'false'} and extras {'vocab'}\n",
            "2023-03-05 05:56:57,943 - INFO - allennlp.common.params - model.type = SeqClassificationModel\n",
            "2023-03-05 05:56:57,943 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.model.SeqClassificationModel'> from params {'additional_feature_size': 0, 'bert_dropout': 0.1, 'sci_sum': False, 'self_attn': {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'}}}, 'use_sep': 'true', 'with_crf': 'false'} and extras {'vocab'}\n",
            "2023-03-05 05:56:57,943 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'}}} and extras {'vocab'}\n",
            "2023-03-05 05:56:57,943 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2023-03-05 05:56:57,944 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True\n",
            "2023-03-05 05:56:57,944 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'} and extras {'vocab'}\n",
            "2023-03-05 05:56:57,944 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = bert-pretrained\n",
            "2023-03-05 05:56:57,944 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False} and extras {'vocab'}\n",
            "2023-03-05 05:56:57,944 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz\n",
            "2023-03-05 05:56:57,944 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = all\n",
            "2023-03-05 05:56:57,945 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.top_layer_only = False\n",
            "2023-03-05 05:56:57,945 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.scalar_mix_parameters = None\n",
            "2023-03-05 05:56:58,704 - INFO - pytorch_pretrained_bert.file_utils - https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz not found in cache, downloading to /tmp/tmp2kpll_1_\n",
            "100%|##########| 410360900/410360900 [00:36<00:00, 11354596.69B/s]\n",
            "2023-03-05 05:57:35,656 - INFO - pytorch_pretrained_bert.file_utils - copying /tmp/tmp2kpll_1_ to cache at /root/.pytorch_pretrained_bert/f4bceb9121f485568327eb11277a2e7420852162c4b076db2ace1b3894c79edc.f1a30efcca0295e7993ea2678402b39bf1287d878f42cbc853b53f709e0df78b\n",
            "2023-03-05 05:57:36,749 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for /root/.pytorch_pretrained_bert/f4bceb9121f485568327eb11277a2e7420852162c4b076db2ace1b3894c79edc.f1a30efcca0295e7993ea2678402b39bf1287d878f42cbc853b53f709e0df78b\n",
            "2023-03-05 05:57:36,749 - INFO - pytorch_pretrained_bert.file_utils - removing temp file /tmp/tmp2kpll_1_\n",
            "2023-03-05 05:57:36,866 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/f4bceb9121f485568327eb11277a2e7420852162c4b076db2ace1b3894c79edc.f1a30efcca0295e7993ea2678402b39bf1287d878f42cbc853b53f709e0df78b\n",
            "2023-03-05 05:57:36,867 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /root/.pytorch_pretrained_bert/f4bceb9121f485568327eb11277a2e7420852162c4b076db2ace1b3894c79edc.f1a30efcca0295e7993ea2678402b39bf1287d878f42cbc853b53f709e0df78b to temp dir /tmp/tmpce06dlkv\n",
            "2023-03-05 05:57:41,880 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "2023-03-05 05:57:43,743 - INFO - allennlp.common.params - model.use_sep = true\n",
            "2023-03-05 05:57:43,743 - INFO - allennlp.common.params - model.with_crf = false\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'} and extras {'vocab'}\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.params - model.self_attn.type = stacked_self_attention\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.stacked_self_attention.StackedSelfAttentionEncoder'> from params {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100} and extras {'vocab'}\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.params - model.self_attn.input_dim = 768\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.params - model.self_attn.hidden_dim = 100\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.params - model.self_attn.projection_dim = 100\n",
            "2023-03-05 05:57:43,744 - INFO - allennlp.common.params - model.self_attn.feedforward_hidden_dim = 50\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.params - model.self_attn.num_layers = 2\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.params - model.self_attn.num_attention_heads = 2\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.params - model.self_attn.use_positional_encoding = True\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.params - model.self_attn.dropout_prob = 0.1\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.params - model.self_attn.residual_dropout_prob = 0.2\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.params - model.self_attn.attention_dropout_prob = 0.1\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:57:43,745 - INFO - allennlp.common.registrable - instantiating registered subclass linear of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:57:43,747 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:57:43,747 - INFO - allennlp.common.registrable - instantiating registered subclass linear of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 05:57:43,749 - INFO - allennlp.common.params - model.bert_dropout = 0.1\n",
            "2023-03-05 05:57:43,749 - INFO - allennlp.common.params - model.sci_sum = False\n",
            "2023-03-05 05:57:43,749 - INFO - allennlp.common.params - model.additional_feature_size = 0\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 4, 'biggest_batch_first': True, 'cache_instances': True, 'sorting_keys': [['sentences', 'num_fields']], 'type': 'bucket'} and extras set()\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.type = bucket\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 4, 'biggest_batch_first': True, 'cache_instances': True, 'sorting_keys': [['sentences', 'num_fields']]} and extras set()\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.sorting_keys = [['sentences', 'num_fields']]\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.biggest_batch_first = True\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.batch_size = 4\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2023-03-05 05:57:43,752 - INFO - allennlp.common.params - iterator.cache_instances = True\n",
            "2023-03-05 05:57:43,753 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
            "2023-03-05 05:57:43,753 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
            "2023-03-05 05:57:43,753 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n",
            "2023-03-05 05:57:43,753 - INFO - allennlp.common.params - validation_iterator = None\n",
            "2023-03-05 05:57:43,753 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
            "2023-03-05 05:57:43,754 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n",
            "2023-03-05 05:57:43,754 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n",
            "2023-03-05 05:57:43,754 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight\n",
            "2023-03-05 05:57:43,754 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight\n",
            "2023-03-05 05:57:43,754 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2023-03-05 05:57:43,755 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2023-03-05 05:57:43,756 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,757 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias\n",
            "2023-03-05 05:57:43,758 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,759 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,759 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2023-03-05 05:57:43,759 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2023-03-05 05:57:43,759 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,792 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,793 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,794 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,795 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,796 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,797 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2023-03-05 05:57:43,798 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.gamma\n",
            "2023-03-05 05:57:43,799 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.0\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.1\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.2\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.3\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.4\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.5\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.6\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.7\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.8\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.9\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.10\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.11\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_0._linear_layers.0.weight\n",
            "2023-03-05 05:57:43,800 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_0._linear_layers.0.bias\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_0._linear_layers.1.weight\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_0._linear_layers.1.bias\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_layer_norm_0.gamma\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_layer_norm_0.beta\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_0._combined_projection.weight\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_0._combined_projection.bias\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_0._output_projection.weight\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_0._output_projection.bias\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.layer_norm_0.gamma\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.layer_norm_0.beta\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_1._linear_layers.0.weight\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_1._linear_layers.0.bias\n",
            "2023-03-05 05:57:43,801 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_1._linear_layers.1.weight\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_1._linear_layers.1.bias\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_layer_norm_1.gamma\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.feedforward_layer_norm_1.beta\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_1._combined_projection.weight\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_1._combined_projection.bias\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_1._output_projection.weight\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.self_attention_1._output_projection.bias\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.layer_norm_1.gamma\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - self_attn.layer_norm_1.beta\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - time_distributed_aggregate_feedforward._module.weight\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.training.trainer_pieces - time_distributed_aggregate_feedforward._module.bias\n",
            "2023-03-05 05:57:43,802 - INFO - allennlp.common.params - trainer.patience = 5\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.min_delta = 0.001\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.validation_metric = +acc\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.shuffle = True\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.num_epochs = 2\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.grad_clipping = 1\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.fp16 = False\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.gradient_accumulation_batch_size = 32\n",
            "2023-03-05 05:57:43,803 - INFO - allennlp.common.params - trainer.num_steps_reset_metrics = None\n",
            "2023-03-05 05:57:47,593 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n",
            "2023-03-05 05:57:47,593 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2023-03-05 05:57:47,593 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2023-03-05 05:57:47,593 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups.0.1.weight_decay = 0\n",
            "2023-03-05 05:57:47,594 - INFO - allennlp.training.optimizers - Done constructing parameter groups.\n",
            "2023-03-05 05:57:47,595 - INFO - allennlp.training.optimizers - Group 0: ['text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias', 'self_attn.feedforward_0._linear_layers.1.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias', 'self_attn.feedforward_1._linear_layers.0.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias', 'self_attn.self_attention_0._combined_projection.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias', 'self_attn.self_attention_0._output_projection.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias', 'self_attn.feedforward_1._linear_layers.1.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias', 'self_attn.self_attention_1._output_projection.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias', 'self_attn.feedforward_0._linear_layers.0.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias', 'time_distributed_aggregate_feedforward._module.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias', 'self_attn.self_attention_1._combined_projection.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias'], {'weight_decay': 0}\n",
            "2023-03-05 05:57:47,619 - INFO - allennlp.training.optimizers - Group 1: ['text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight', 'self_attn.feedforward_1._linear_layers.1.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight', 'self_attn.feedforward_layer_norm_0.beta', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.8', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.10', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight', 'self_attn.feedforward_layer_norm_1.beta', 'self_attn.self_attention_1._output_projection.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight', 'self_attn.self_attention_0._output_projection.weight', 'self_attn.feedforward_layer_norm_0.gamma', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.0', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight', 'self_attn.layer_norm_1.gamma', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight', 'self_attn.layer_norm_1.beta', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.6', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.gamma', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.5', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight', 'self_attn.feedforward_0._linear_layers.0.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.7', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.11', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.4', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.3', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight', 'self_attn.layer_norm_0.beta', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight', 'self_attn.self_attention_1._combined_projection.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight', 'self_attn.self_attention_0._combined_projection.weight', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.1', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.9', 'text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.2', 'self_attn.feedforward_1._linear_layers.0.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight', 'time_distributed_aggregate_feedforward._module.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight', 'self_attn.feedforward_layer_norm_1.gamma', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight', 'self_attn.layer_norm_0.gamma', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight', 'self_attn.feedforward_0._linear_layers.1.weight', 'text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight'], {}\n",
            "2023-03-05 05:57:47,620 - WARNING - allennlp.training.optimizers - When constructing parameter groups,  layer_norm.weight not match any parameter name\n",
            "2023-03-05 05:57:47,620 - INFO - allennlp.training.optimizers - Number of trainable parameters: 110057622\n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - trainer.optimizer.lr = 5e-5\n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - trainer.optimizer.max_grad_norm = 1\n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - trainer.optimizer.t_total = -1\n",
            "2023-03-05 05:57:47,621 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.01\n",
            "2023-03-05 05:57:47,622 - INFO - allennlp.common.registrable - instantiating registered subclass bert_adam of <class 'allennlp.training.optimizers.Optimizer'>\n",
            "2023-03-05 05:57:47,622 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n",
            "2023-03-05 05:57:47,622 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = slanted_triangular\n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.registrable - instantiating registered subclass slanted_triangular of <class 'allennlp.training.learning_rate_schedulers.learning_rate_scheduler.LearningRateScheduler'>\n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cut_frac = 0.1\n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.num_epochs = 2\n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.num_steps_per_epoch = 52.125\n",
            "2023-03-05 05:57:47,623 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 20\n",
            "2023-03-05 05:57:47,624 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2023-03-05 05:57:47,624 - INFO - allennlp.common.params - trainer.model_save_interval = 3600\n",
            "2023-03-05 05:57:47,624 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2023-03-05 05:57:47,624 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2023-03-05 05:57:47,624 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
            "2023-03-05 05:57:47,624 - INFO - allennlp.common.params - trainer.should_log_learning_rate = True\n",
            "2023-03-05 05:57:47,625 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n",
            "2023-03-05 05:57:47,629 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2023-03-05 05:57:47,629 - INFO - allennlp.training.trainer - Epoch 0/1\n",
            "2023-03-05 05:57:47,629 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3619.456\n",
            "2023-03-05 05:57:47,722 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1355\n",
            "2023-03-05 05:57:47,724 - INFO - allennlp.training.trainer - Training\n",
            "  0%|          | 0/417 [00:00<?, ?it/s]2023-03-05 05:57:49,268 - WARNING - allennlp.data.token_indexers.wordpiece_indexer - Too many wordpieces, truncating sequence. If you would like a sliding window, set `truncate_long_sequences` to False.The offending input was: ['This', 'paper', 'extends', 'previous', 'work', 'with', 'Dyna', 'a', 'class', 'of', 'architectures', 'for', 'intelligent', 'systems', 'based', 'on', 'approximating', 'dynamic', 'program', 'ming', 'methods', 'Dyna', 'architectures', 'integrate', 'trial', 'and', 'error', 'reinforcement', 'learning', 'and', 'execution', 'time', 'planning', 'into', 'a', 'single', 'process', 'operating', 'alternately', 'on', 'the', 'world', 'and', 'on', 'a', 'learned', 'model', 'of', 'the', 'world', 'In', 'this', 'paper', 'I', 'present', 'and', 'show', 'results', 'for', 'two', 'Dyna', 'archi', 'tectures', 'The', 'Dyna', 'PI', 'architecture', 'is', 'based', 'on', 'dynamic', 'programming', 's', 'policy', 'iteration', 'method', 'and', 'can', 'be', 'related', '[SEP]', 'I', 'brie', 'y', 'introduce', 'Dyna', 'a', 'class', 'of', 'simple', 'architectures', 'integrating', 'and', 'permitting', 'tradeo', 's', 'among', 'these', 'three', 'approaches', '[SEP]', 'Dyna', 'architectures', 'use', 'machine', 'learning', 'algo', 'rithms', 'to', 'approximate', 'the', 'conventional', 'optimal', 'con', 'trol', 'technique', 'known', 'as', 'dynamic', 'programming', 'DP', 'Bellman', 'Ross', 'DP', 'itself', 'is', 'not', 'a', 'learn', 'ing', 'method', 'but', 'rather', 'a', 'computational', 'method', 'for', 'determining', 'optimal', 'behavior', 'given', 'a', 'complete', 'model', 'of', 'the', 'task', 'to', 'be', 'solved', '[SEP]', 'It', 'is', 'very', 'similar', 'to', 'state', 'space', 'search', 'but', 'di', 'ers', 'in', 'that', 'it', 'is', 'more', 'incremental', 'and', 'never', 'considers', 'actual', 'action', 'sequences', 'explicitly', 'only', 'single', 'actions', 'at', 'a', 'time', 'This', 'makes', 'DP', 'more', 'amenable', 'to', 'incremental', 'planning', 'at', 'execution', 'time', 'and', 'also', 'makes', 'it', 'more', 'suitable', 'for', 'stochastic', 'or', 'in', 'completely', 'modeled', 'environments', 'as', 'it', 'need', 'not', 'con', 'sider', 'the', 'extremely', 'large', 'number', 'of', 'sequences', 'possi', 'ble', 'in', 'an', 'uncertain', 'environment', 'Learned', 'world', 'mod', 'els', 'are', 'likely', 'to', 'be', '[SEP]', 'The', 'theory', 'of', 'Dyna', 'is', 'based', 'on', 'the', 'theory', 'of', 'DP', 'e', 'g', 'Ross', 'and', 'on', 'DP', 's', 'relationship', 'to', 'reinforcement', 'learning', 'Watkins', 'Barto', 'Sutton', 'Watkins', 'to', 'temporal', 'di', 'erence', 'learning', 'Sutton', 'and', 'to', 'AI', 'methods', 'for', 'planning', 'and', 'search', 'Korf', 'Werbos', 'has', 'previously', 'argued', 'for', 'the', 'general', 'idea', 'of', 'building', 'AI', 'systems', 'that', 'approx', 'imate', 'dynamic', 'programming', 'and', 'Whitehead', 'and', 'others', 'Sutton', 'Barto', 'Sutton', 'Pinette', 'Rumelhart', 'et', '[SEP]', 'al', 'have', 'presented', 'results', 'for', 'the', 'speci', 'c', 'idea', 'of', 'augmenting', 'a', 'reinforcement', 'learning', 'system', 'with', 'a', 'world', 'model', 'used', 'for', 'planning', 'Dyna', 'PI', 'Dyna', 'by', 'Approximating', 'Policy', 'Iteration', '[SEP]', 'I', 'call', 'the', 'rst', 'Dyna', 'architecture', 'Dyna', 'PI', 'because', 'it', 'is', 'based', 'on', 'approximating', 'a', 'DP', 'method', 'known', 'as', 'pol', 'icy', 'iteration', 'Howard', 'The', 'Dyna', 'PI', 'architec', 'ture', 'consists', 'of', 'four', 'components', 'interacting', 'as', 'shown', 'in', 'Figure', 'The', 'policy', 'is', 'simply', 'the', 'function', 'formed', 'by', 'the', 'current', 'set', 'of', 'reactions', 'it', 'receives', 'as', 'input', 'a', 'description', 'of', 'the', 'current', 'state', 'of', 'the', 'world', 'and', 'pro', 'duces', 'as', 'output', 'an', 'action', 'to', 'be', 'sent', 'to', 'the', 'world', 'The', 'world', 'represents', 'the', '[SEP]', 'The', 'overall', 'task', 'is', 'de', 'ned', 'as', 'maximizing', 'the', 'long', 'term', 'average', 'reward', 'per', 'time', 'step', 'cf', 'Russell', '[SEP]', 'The', 'architecture', 'also', 'includes', 'an', 'explicit', 'world', 'model', 'The', 'world', 'model', 'is', 'intended', 'to', 'mimic', 'the', 'one', 'step', 'input', 'output', 'behavior', 'of', 'the', 'real', 'world', 'Finally', 'the', 'Dyna', 'PI', 'architecture', 'in', 'cludes', 'an', 'evaluation', 'function', 'that', 'rapidly', 'maps', 'states', 'to', 'values', 'much', 'as', 'the', 'policy', 'rapidly', 'maps', 'states', 'to', 'actions', 'The', 'evaluation', 'function', 'the', 'policy', 'and', 'the', 'world', 'model', 'are', 'each', 'updated', 'by', 'separate', 'learning', 'processes', 'WORLD', 'Action', 'Reward', '(', 'scalar', ')', '[SEP]', 'Heuristic', 'Reward', '(', 'scalar', ')', 'State', 'EVALUATION', 'FUNCTION'].To avoid polluting your logs we will not warn about this again.\n",
            "acc: 0.4932, background_labelF: 0.6112, method_labelF: 0.4800, result_labelF: 0.4029, objective_labelF: 0.0720, other_labelF: 0.2857, avgF: 0.3704, loss: 0.7550 ||:  23%|##3       | 96/417 [00:25<01:19,  4.05it/s]2023-03-05 05:58:13,759 - WARNING - sequential_sentence_classification.model - Found 25 labels but 24 sentences\n",
            "acc: 0.6214, background_labelF: 0.7273, method_labelF: 0.6027, result_labelF: 0.6238, objective_labelF: 0.2180, other_labelF: 0.5983, avgF: 0.5540, loss: 0.5474 ||: 100%|##########| 417/417 [01:49<00:00,  3.82it/s]\n",
            "2023-03-05 05:59:36,874 - INFO - allennlp.training.trainer - Validating\n",
            "acc: 0.6634, background_labelF: 0.7871, method_labelF: 0.6169, result_labelF: 0.6864, objective_labelF: 0.2157, other_labelF: 0.5941, avgF: 0.5800, loss: 0.4792 ||: 100%|##########| 74/74 [00:06<00:00, 11.02it/s]\n",
            "2023-03-05 05:59:43,594 - INFO - allennlp.training.tensorboard_writer -                       Training |  Validation\n",
            "2023-03-05 05:59:43,596 - INFO - allennlp.training.tensorboard_writer - objective_labelF  |     0.218  |     0.216\n",
            "2023-03-05 05:59:43,596 - INFO - allennlp.training.tensorboard_writer - avgF              |     0.554  |     0.580\n",
            "2023-03-05 05:59:43,597 - INFO - allennlp.training.tensorboard_writer - background_labelF |     0.727  |     0.787\n",
            "2023-03-05 05:59:43,598 - INFO - allennlp.training.tensorboard_writer - result_labelF     |     0.624  |     0.686\n",
            "2023-03-05 05:59:43,599 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB   |  1355.000  |       N/A\n",
            "2023-03-05 05:59:43,599 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB     |  3619.456  |       N/A\n",
            "2023-03-05 05:59:43,600 - INFO - allennlp.training.tensorboard_writer - method_labelF     |     0.603  |     0.617\n",
            "2023-03-05 05:59:43,601 - INFO - allennlp.training.tensorboard_writer - acc               |     0.621  |     0.663\n",
            "2023-03-05 05:59:43,602 - INFO - allennlp.training.tensorboard_writer - other_labelF      |     0.598  |     0.594\n",
            "2023-03-05 05:59:43,602 - INFO - allennlp.training.tensorboard_writer - loss              |     0.547  |     0.479\n",
            "2023-03-05 05:59:48,312 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'tmp_output_dir/best.th'.\n",
            "2023-03-05 05:59:50,054 - INFO - allennlp.training.trainer - Epoch duration: 0:02:02.425618\n",
            "2023-03-05 05:59:50,134 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:02\n",
            "2023-03-05 05:59:50,134 - INFO - allennlp.training.trainer - Epoch 1/1\n",
            "2023-03-05 05:59:50,135 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3619.456\n",
            "2023-03-05 05:59:50,266 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 8521\n",
            "2023-03-05 05:59:50,270 - INFO - allennlp.training.trainer - Training\n",
            "acc: 0.7229, background_labelF: 0.8134, method_labelF: 0.7091, result_labelF: 0.7301, objective_labelF: 0.4273, other_labelF: 0.7607, avgF: 0.6881, loss: 0.3828 ||:  54%|#####3    | 224/417 [00:58<00:49,  3.88it/s]2023-03-05 06:00:48,826 - WARNING - sequential_sentence_classification.model - Found 25 labels but 24 sentences\n",
            "acc: 0.7375, background_labelF: 0.8262, method_labelF: 0.7223, result_labelF: 0.7422, objective_labelF: 0.4541, other_labelF: 0.7865, avgF: 0.7063, loss: 0.3680 ||: 100%|##########| 417/417 [01:50<00:00,  3.79it/s]\n",
            "2023-03-05 06:01:40,382 - INFO - allennlp.training.trainer - Validating\n",
            "acc: 0.6890, background_labelF: 0.8063, method_labelF: 0.6574, result_labelF: 0.6764, objective_labelF: 0.4450, other_labelF: 0.6094, avgF: 0.6389, loss: 0.4419 ||: 100%|##########| 74/74 [00:06<00:00, 11.69it/s]\n",
            "2023-03-05 06:01:46,716 - INFO - allennlp.training.tensorboard_writer -                       Training |  Validation\n",
            "2023-03-05 06:01:46,716 - INFO - allennlp.training.tensorboard_writer - objective_labelF  |     0.454  |     0.445\n",
            "2023-03-05 06:01:46,718 - INFO - allennlp.training.tensorboard_writer - avgF              |     0.706  |     0.639\n",
            "2023-03-05 06:01:46,719 - INFO - allennlp.training.tensorboard_writer - background_labelF |     0.826  |     0.806\n",
            "2023-03-05 06:01:46,720 - INFO - allennlp.training.tensorboard_writer - result_labelF     |     0.742  |     0.676\n",
            "2023-03-05 06:01:46,720 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB   |  8521.000  |       N/A\n",
            "2023-03-05 06:01:46,721 - INFO - allennlp.training.tensorboard_writer - cpu_memory_MB     |  3619.456  |       N/A\n",
            "2023-03-05 06:01:46,722 - INFO - allennlp.training.tensorboard_writer - method_labelF     |     0.722  |     0.657\n",
            "2023-03-05 06:01:46,722 - INFO - allennlp.training.tensorboard_writer - acc               |     0.737  |     0.689\n",
            "2023-03-05 06:01:46,723 - INFO - allennlp.training.tensorboard_writer - other_labelF      |     0.786  |     0.609\n",
            "2023-03-05 06:01:46,724 - INFO - allennlp.training.tensorboard_writer - loss              |     0.368  |     0.442\n",
            "2023-03-05 06:01:51,485 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'tmp_output_dir/best.th'.\n",
            "2023-03-05 06:01:53,236 - INFO - allennlp.training.trainer - Epoch duration: 0:02:03.101685\n",
            "2023-03-05 06:01:53,238 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2023-03-05 06:01:53,642 - INFO - allennlp.commands.train - The model will be evaluated using the best epoch weights.\n",
            "2023-03-05 06:01:53,643 - INFO - allennlp.training.util - Iterating over dataset\n",
            "acc: 0.83, background_labelF: 0.89, method_labelF: 0.83, result_labelF: 0.83, objective_labelF: 0.62, other_labelF: 0.83, avgF: 0.80, loss: 0.37 ||: 100%|##########| 57/57 [00:04<00:00, 13.08it/s]\n",
            "2023-03-05 06:01:58,004 - INFO - allennlp.models.archival - archiving weights and vocabulary to tmp_output_dir/model.tar.gz\n",
            "2023-03-05 06:02:24,461 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"best_epoch\": 1,\n",
            "  \"peak_cpu_memory_MB\": 3619.456,\n",
            "  \"peak_gpu_0_memory_MB\": 8521,\n",
            "  \"training_duration\": \"0:03:59.095697\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 1,\n",
            "  \"epoch\": 1,\n",
            "  \"training_acc\": 0.7374889478337754,\n",
            "  \"training_background_labelF\": 0.826191782951355,\n",
            "  \"training_method_labelF\": 0.7223393321037292,\n",
            "  \"training_result_labelF\": 0.742164671421051,\n",
            "  \"training_objective_labelF\": 0.4540744125843048,\n",
            "  \"training_other_labelF\": 0.7864822745323181,\n",
            "  \"training_avgF\": 0.7062504947185516,\n",
            "  \"training_loss\": 0.3679678266366514,\n",
            "  \"training_cpu_memory_MB\": 3619.456,\n",
            "  \"training_gpu_0_memory_MB\": 8521,\n",
            "  \"validation_acc\": 0.6890424481737414,\n",
            "  \"validation_background_labelF\": 0.8063127994537354,\n",
            "  \"validation_method_labelF\": 0.6573859453201294,\n",
            "  \"validation_result_labelF\": 0.6764346361160278,\n",
            "  \"validation_objective_labelF\": 0.4449760913848877,\n",
            "  \"validation_other_labelF\": 0.6093749403953552,\n",
            "  \"validation_avgF\": 0.6388968825340271,\n",
            "  \"validation_loss\": 0.4418991492004008,\n",
            "  \"best_validation_acc\": 0.6890424481737414,\n",
            "  \"best_validation_background_labelF\": 0.8063127994537354,\n",
            "  \"best_validation_method_labelF\": 0.6573859453201294,\n",
            "  \"best_validation_result_labelF\": 0.6764346361160278,\n",
            "  \"best_validation_objective_labelF\": 0.4449760913848877,\n",
            "  \"best_validation_other_labelF\": 0.6093749403953552,\n",
            "  \"best_validation_avgF\": 0.6388968825340271,\n",
            "  \"best_validation_loss\": 0.4418991492004008,\n",
            "  \"test_acc\": 0.8295033358042995,\n",
            "  \"test_background_labelF\": 0.8907048106193542,\n",
            "  \"test_method_labelF\": 0.8321512937545776,\n",
            "  \"test_result_labelF\": 0.8284518122673035,\n",
            "  \"test_objective_labelF\": 0.6153846383094788,\n",
            "  \"test_other_labelF\": 0.8256880044937134,\n",
            "  \"test_avgF\": 0.7984761118888855,\n",
            "  \"test_loss\": 0.3702119123517421\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "%%shell\n",
        "source activate allennlp\n",
        "scripts/train.sh tmp_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ny5QPVvBDkeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c82817-c9a9-490b-9e31-cbf8c215c067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-05 06:34:20,048 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2023-03-05 06:34:20,804 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2023-03-05 06:34:20,808 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2023-03-05 06:34:21,147 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:21,148 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:21,149 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:21,150 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:21,327 - INFO - allennlp.models.archival - loading archive file /content/sequential_sentence_classification/tmp_output_dir/model.tar.gz\n",
            "2023-03-05 06:34:21,328 - INFO - allennlp.models.archival - extracting archive file /content/sequential_sentence_classification/tmp_output_dir/model.tar.gz to temp dir /tmp/tmpn672b5bv\n",
            "2023-03-05 06:34:26,445 - INFO - allennlp.common.registrable - instantiating registered subclass SeqClassificationModel of <class 'allennlp.models.model.Model'>\n",
            "2023-03-05 06:34:26,446 - INFO - allennlp.common.params - type = default\n",
            "2023-03-05 06:34:26,446 - INFO - allennlp.common.registrable - instantiating registered subclass default of <class 'allennlp.data.vocabulary.Vocabulary'>\n",
            "2023-03-05 06:34:26,446 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpn672b5bv/vocabulary.\n",
            "2023-03-05 06:34:26,452 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'additional_feature_size': 0, 'bert_dropout': 0.1, 'sci_sum': False, 'self_attn': {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'}}}, 'type': 'SeqClassificationModel', 'use_sep': 'true', 'with_crf': 'false'} and extras {'vocab'}\n",
            "2023-03-05 06:34:26,452 - INFO - allennlp.common.params - model.type = SeqClassificationModel\n",
            "2023-03-05 06:34:26,452 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.model.SeqClassificationModel'> from params {'additional_feature_size': 0, 'bert_dropout': 0.1, 'sci_sum': False, 'self_attn': {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'}, 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'}}}, 'use_sep': 'true', 'with_crf': 'false'} and extras {'vocab'}\n",
            "2023-03-05 06:34:26,453 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert'], 'tokens': ['tokens']}, 'token_embedders': {'bert': {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'}}} and extras {'vocab'}\n",
            "2023-03-05 06:34:26,453 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2023-03-05 06:34:26,453 - INFO - allennlp.common.params - model.text_field_embedder.allow_unmatched_keys = True\n",
            "2023-03-05 06:34:26,453 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False, 'type': 'bert-pretrained'} and extras {'vocab'}\n",
            "2023-03-05 06:34:26,453 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.type = bert-pretrained\n",
            "2023-03-05 06:34:26,454 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz', 'requires_grad': 'all', 'top_layer_only': False} and extras {'vocab'}\n",
            "2023-03-05 06:34:26,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.pretrained_model = https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz\n",
            "2023-03-05 06:34:26,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.requires_grad = all\n",
            "2023-03-05 06:34:26,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.top_layer_only = False\n",
            "2023-03-05 06:34:26,454 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.bert.scalar_mix_parameters = None\n",
            "2023-03-05 06:34:27,174 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scibert_scivocab_uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/f4bceb9121f485568327eb11277a2e7420852162c4b076db2ace1b3894c79edc.f1a30efcca0295e7993ea2678402b39bf1287d878f42cbc853b53f709e0df78b\n",
            "2023-03-05 06:34:27,175 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /root/.pytorch_pretrained_bert/f4bceb9121f485568327eb11277a2e7420852162c4b076db2ace1b3894c79edc.f1a30efcca0295e7993ea2678402b39bf1287d878f42cbc853b53f709e0df78b to temp dir /tmp/tmpgzy61s30\n",
            "2023-03-05 06:34:31,906 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 31090\n",
            "}\n",
            "\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.params - model.use_sep = true\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.params - model.with_crf = false\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100, 'type': 'stacked_self_attention'} and extras {'vocab'}\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.params - model.self_attn.type = stacked_self_attention\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.stacked_self_attention.StackedSelfAttentionEncoder'> from params {'feedforward_hidden_dim': 50, 'hidden_dim': 100, 'input_dim': 768, 'num_attention_heads': 2, 'num_layers': 2, 'projection_dim': 100} and extras {'vocab'}\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.params - model.self_attn.input_dim = 768\n",
            "2023-03-05 06:34:33,639 - INFO - allennlp.common.params - model.self_attn.hidden_dim = 100\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.projection_dim = 100\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.feedforward_hidden_dim = 50\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.num_layers = 2\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.num_attention_heads = 2\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.use_positional_encoding = True\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.dropout_prob = 0.1\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.residual_dropout_prob = 0.2\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.params - model.self_attn.attention_dropout_prob = 0.1\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:33,640 - INFO - allennlp.common.registrable - instantiating registered subclass linear of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:33,641 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:33,641 - INFO - allennlp.common.registrable - instantiating registered subclass linear of <class 'allennlp.nn.activations.Activation'>\n",
            "2023-03-05 06:34:33,642 - INFO - allennlp.common.params - model.bert_dropout = 0.1\n",
            "2023-03-05 06:34:33,642 - INFO - allennlp.common.params - model.sci_sum = False\n",
            "2023-03-05 06:34:33,643 - INFO - allennlp.common.params - model.additional_feature_size = 0\n",
            "2023-03-05 06:34:34,003 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'max_sent_per_example': '10', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '80', 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'type': 'SeqClassificationReader', 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras set()\n",
            "2023-03-05 06:34:34,003 - INFO - allennlp.common.params - dataset_reader.type = SeqClassificationReader\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.from_params - instantiating class <class 'sequential_sentence_classification.dataset_reader.SeqClassificationReader'> from params {'lazy': False, 'max_sent_per_example': '10', 'sci_sum': False, 'sci_sum_fake_scores': False, 'sent_max_len': '80', 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'type': 'bert-pretrained', 'use_starting_offsets': False}}, 'use_abstract_scores': False, 'use_sep': 'true', 'word_splitter': 'bert-basic'} and extras set()\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'type': 'bert-pretrained', 'use_starting_offsets': False} and extras set()\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer'> from params {'do_lowercase': True, 'pretrained_model': 'https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab', 'use_starting_offsets': False} and extras set()\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = True\n",
            "2023-03-05 06:34:34,004 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None\n",
            "2023-03-05 06:34:34,005 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512\n",
            "2023-03-05 06:34:34,005 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = True\n",
            "2023-03-05 06:34:34,715 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://ai2-s2-research.s3-us-west-2.amazonaws.com/scibert/allennlp_files/scivocab_uncased.vocab from cache at /root/.pytorch_pretrained_bert/d2fac719b6d663ae040cb698dfbc553ad2ba1796a6cb1acd74a4cd69168a6559.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
            "2023-03-05 06:34:34,761 - INFO - allennlp.common.params - dataset_reader.word_splitter = bert-basic\n",
            "2023-03-05 06:34:34,761 - INFO - allennlp.common.registrable - instantiating registered subclass bert-basic of <class 'allennlp.data.tokenizers.word_splitter.WordSplitter'>\n",
            "2023-03-05 06:34:34,761 - INFO - allennlp.common.params - dataset_reader.sent_max_len = 80\n",
            "2023-03-05 06:34:34,761 - INFO - allennlp.common.params - dataset_reader.max_sent_per_example = 10\n",
            "2023-03-05 06:34:34,761 - INFO - allennlp.common.params - dataset_reader.use_sep = true\n",
            "2023-03-05 06:34:34,761 - INFO - allennlp.common.params - dataset_reader.sci_sum = False\n",
            "2023-03-05 06:34:34,762 - INFO - allennlp.common.params - dataset_reader.use_abstract_scores = False\n",
            "2023-03-05 06:34:34,762 - INFO - allennlp.common.params - dataset_reader.sci_sum_fake_scores = False\n",
            "2023-03-05 06:34:34,762 - INFO - allennlp.common.params - dataset_reader.predict = True\n",
            "2023-03-05 06:34:34,903 - INFO - allennlp.common.registrable - instantiating registered subclass SeqClassificationPredictor of <class 'allennlp.predictors.predictor.Predictor'>\n",
            "input 0:  {\"abstract_id\": 0, \"sentences\": [\"While deep convolutional neural networks (CNNs) have shown a great success in single-label image classification, it is important to note that real world images generally contain multiple labels, which could correspond to different objects, scenes, actions and attributes in an image.\", \"Traditional approaches to multi-label image classification learn independent classifiers for each category and employ ranking or thresholding on the classification results.\", \"These techniques, although working well, fail to explicitly exploit the label dependencies in an image.\", \"In this paper, we utilize recurrent neural networks (RNNs) to address this problem.\", \"Combined with CNNs, the proposed CNN-RNN framework learns a joint image-label embedding to characterize the semantic label dependency as well as the image-label relevance, and it can be trained end-to-end from scratch to integrate both information in a unified framework.\", \"Experimental results on public benchmark datasets demonstrate that the proposed architecture achieves better performance than the state-of-the-art multi-label classification models.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.7407, 0.7407, 0.7778, 0.7778, 0.7778, 1.0]}\n",
            "prediction:  [0, [[\"While deep convolutional neural networks (CNNs) have shown a great success in single-label image classification, it is important to note that real world images generally contain multiple labels, which could correspond to different objects, scenes, actions and attributes in an image.\", \"background_label\"], [\"Traditional approaches to multi-label image classification learn independent classifiers for each category and employ ranking or thresholding on the classification results.\", \"background_label\"], [\"These techniques, although working well, fail to explicitly exploit the label dependencies in an image.\", \"method_label\"], [\"In this paper, we utilize recurrent neural networks (RNNs) to address this problem.\", \"method_label\"], [\"Combined with CNNs, the proposed CNN-RNN framework learns a joint image-label embedding to characterize the semantic label dependency as well as the image-label relevance, and it can be trained end-to-end from scratch to integrate both information in a unified framework.\", \"method_label\"], [\"Experimental results on public benchmark datasets demonstrate that the proposed architecture achieves better performance than the state-of-the-art multi-label classification models.\", \"result_label\"]]]\n",
            "\n",
            "input 1:  {\"abstract_id\": 0, \"sentences\": [\"Biologists depend on visual representations, and their use of diagrams has drawn the attention of philosophers, historians, and sociologists interested in understanding how these images are involved in biological reasoning.\", \"These studies, however, proceed from identification of diagrams on the basis of their spare visual appearance, and do not draw on a foundational theory of the nature of diagrams as representations.\", \"This approach has limited the extent to which we understand how these diagrams are involved in biological reasoning.\", \"In this paper I characterize three different kinds of figures among those previously identified as diagrams.\", \"The features that make these figures distinctive as representational types, furthermore, illuminate the ways in which they are involved in biological reasoning.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"objective\"], \"confs\": [1.0, 0.7059, 0.7059, 0.7059, 1.0]}\n",
            "prediction:  [0, [[\"Biologists depend on visual representations, and their use of diagrams has drawn the attention of philosophers, historians, and sociologists interested in understanding how these images are involved in biological reasoning.\", \"background_label\"], [\"These studies, however, proceed from identification of diagrams on the basis of their spare visual appearance, and do not draw on a foundational theory of the nature of diagrams as representations.\", \"background_label\"], [\"This approach has limited the extent to which we understand how these diagrams are involved in biological reasoning.\", \"background_label\"], [\"In this paper I characterize three different kinds of figures among those previously identified as diagrams.\", \"objective_label\"], [\"The features that make these figures distinctive as representational types, furthermore, illuminate the ways in which they are involved in biological reasoning.\", \"result_label\"]]]\n",
            "\n",
            "input 2:  {\"abstract_id\": 0, \"sentences\": [\"Mobile robots with reconfigurable chassis are able to traverse unstructured outdoor environments with boulders or rubble, and overcome challenging structures in urban environments, like stairs or steps.\", \"Autonomously traversing rough terrain and such obstacles while ensuring the safety of the robot is a challenging task in mobile robotics.\", \"In this paper we introduce a two-phase motion planning algorithm for actively reconfigurable tracked robots.\", \"We first use the completeness of a graph search on a regular grid to quickly find an initial path in a low dimensional space, considering only the platform's operating limits instead of the complete state.\", \"We then take this initial path to focus the RRT* search in the continuous high-dimensional state space including the actuators of the robot.\", \"We do not rely on a detailed structure/terrain classification or use any predefined motion sequences.\", \"Hence, our planner can be applied to urban structures, like stairs, as well as rough unstructured environments.\", \"Simulation results prove our method to be effective in solving planning queries in such environments.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7619, 1.0, 1.0, 0.7619, 0.7619, 1.0]}\n",
            "prediction:  [0, [[\"Mobile robots with reconfigurable chassis are able to traverse unstructured outdoor environments with boulders or rubble, and overcome challenging structures in urban environments, like stairs or steps.\", \"background_label\"], [\"Autonomously traversing rough terrain and such obstacles while ensuring the safety of the robot is a challenging task in mobile robotics.\", \"background_label\"], [\"In this paper we introduce a two-phase motion planning algorithm for actively reconfigurable tracked robots.\", \"objective_label\"], [\"We first use the completeness of a graph search on a regular grid to quickly find an initial path in a low dimensional space, considering only the platform's operating limits instead of the complete state.\", \"method_label\"], [\"We then take this initial path to focus the RRT* search in the continuous high-dimensional state space including the actuators of the robot.\", \"method_label\"], [\"We do not rely on a detailed structure/terrain classification or use any predefined motion sequences.\", \"method_label\"], [\"Hence, our planner can be applied to urban structures, like stairs, as well as rough unstructured environments.\", \"method_label\"], [\"Simulation results prove our method to be effective in solving planning queries in such environments.\", \"result_label\"]]]\n",
            "\n",
            "input 3:  {\"abstract_id\": 0, \"sentences\": [\"Backtracting is a well-known technique for solving combinatorial problems.\", \"It is of interest to programming methodologists because (1) correctness of backtracking programs may be difficult to ascertain experimentally and (2) efficiency is often of paramount importance.\", \"This paper applies a programming methodology, which we call control structure abstraction, to the backtracking technique.\", \"The value of control structure abstraction in the context of correctness is that proofs of general properties of a class of programs with similar control structures are separated from proofs of specific properties of individual programs of the class.\", \"In the context of efficiency, it provides sufficient conditions for correctness of an initial program which may subsequently be improved for efficiency while preserving correctness.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\"], \"confs\": [0.6, 0.6, 0.6, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"Backtracting is a well-known technique for solving combinatorial problems.\", \"background_label\"], [\"It is of interest to programming methodologists because (1) correctness of backtracking programs may be difficult to ascertain experimentally and (2) efficiency is often of paramount importance.\", \"background_label\"], [\"This paper applies a programming methodology, which we call control structure abstraction, to the backtracking technique.\", \"objective_label\"], [\"The value of control structure abstraction in the context of correctness is that proofs of general properties of a class of programs with similar control structures are separated from proofs of specific properties of individual programs of the class.\", \"method_label\"], [\"In the context of efficiency, it provides sufficient conditions for correctness of an initial program which may subsequently be improved for efficiency while preserving correctness.\", \"result_label\"]]]\n",
            "\n",
            "input 4:  {\"abstract_id\": 0, \"sentences\": [\"In recent years, a plethora of approaches have been proposed to deal with the increasingly challenging task of multi-output regression.\", \"This paper provides a survey on state-of-the-art multi-output regression methods, that are categorized as problem transformation and algorithm adaptation methods.\", \"In addition, we present the mostly used performance evaluation measures, publicly available data sets for multi-output regression real-world problems, as well as open-source software frameworks.\"], \"labels\": [\"background\", \"method\", \"method\"], \"confs\": [1.0, 0.7241, 0.7586]}\n",
            "prediction:  [0, [[\"In recent years, a plethora of approaches have been proposed to deal with the increasingly challenging task of multi-output regression.\", \"background_label\"], [\"This paper provides a survey on state-of-the-art multi-output regression methods, that are categorized as problem transformation and algorithm adaptation methods.\", \"objective_label\"], [\"In addition, we present the mostly used performance evaluation measures, publicly available data sets for multi-output regression real-world problems, as well as open-source software frameworks.\", \"method_label\"]]]\n",
            "\n",
            "input 5:  {\"abstract_id\": 0, \"sentences\": [\"In today\\u2019s fast changing health care sector, decision makers are facing a growing demand for both clinical and administrative information in order to comply with legal and customer-specific requirements.\", \"Performance Management (PM) is thus becoming increasingly important to catch up with the rising informational demands.\", \"However, little is known about the PM usage in health care since the constituent research about PM is primarily focussed on the industrial sector.\", \"For this purpose, an exploratory survey for the health care sector is presented.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\"], \"confs\": [1.0, 1.0, 0.75, 0.75]}\n",
            "prediction:  [0, [[\"In today\\u2019s fast changing health care sector, decision makers are facing a growing demand for both clinical and administrative information in order to comply with legal and customer-specific requirements.\", \"background_label\"], [\"Performance Management (PM) is thus becoming increasingly important to catch up with the rising informational demands.\", \"background_label\"], [\"However, little is known about the PM usage in health care since the constituent research about PM is primarily focussed on the industrial sector.\", \"background_label\"], [\"For this purpose, an exploratory survey for the health care sector is presented.\", \"objective_label\"]]]\n",
            "\n",
            "input 6:  {\"abstract_id\": 0, \"sentences\": [\"This article discusses the issues that arise in the design and implementation of expert systems.\", \"These issues include: task selection; the stages of development of expert system projects; knowledge acquisition; languages and tools; development and run-time environments; and organizational and institutional issues.\", \"The article closes with some speculation about the future development of expert systems.\"], \"labels\": [\"background\", \"background\", \"result\"], \"confs\": [1.0, 0.7143, 1.0]}\n",
            "prediction:  [0, [[\"This article discusses the issues that arise in the design and implementation of expert systems.\", \"background_label\"], [\"These issues include: task selection; the stages of development of expert system projects; knowledge acquisition; languages and tools; development and run-time environments; and organizational and institutional issues.\", \"background_label\"], [\"The article closes with some speculation about the future development of expert systems.\", \"result_label\"]]]\n",
            "\n",
            "input 7:  {\"abstract_id\": 0, \"sentences\": [\"This paper presents a filter-based control scheme for an H-Bridge inverter with output LC filter.\", \"This approach relies only on a single output voltage measurement to reduce the system cost as well as measurement noise and disturbance injected by output current and/or inductor current measurements.\", \"To reduce the controller sensitivity to the system parameters, the proposed controller is developed for unknown system parameters.\", \"A Lyapunov stability analysis is utilized to demonstrate system stability.\", \"Experimental results demonstrate excellent voltage regulation, insensitivity to load variations, and low output voltage distortion as well as the stability of the system under both linear and nonlinear loads.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7273, 0.7273, 1.0]}\n",
            "prediction:  [0, [[\"This paper presents a filter-based control scheme for an H-Bridge inverter with output LC filter.\", \"background_label\"], [\"This approach relies only on a single output voltage measurement to reduce the system cost as well as measurement noise and disturbance injected by output current and/or inductor current measurements.\", \"method_label\"], [\"To reduce the controller sensitivity to the system parameters, the proposed controller is developed for unknown system parameters.\", \"method_label\"], [\"A Lyapunov stability analysis is utilized to demonstrate system stability.\", \"method_label\"], [\"Experimental results demonstrate excellent voltage regulation, insensitivity to load variations, and low output voltage distortion as well as the stability of the system under both linear and nonlinear loads.\", \"result_label\"]]]\n",
            "\n",
            "input 8:  {\"abstract_id\": 0, \"sentences\": [\"In this paper we address the problem of semantic labeling of indoor scenes on RGB-D data.\", \"With the availability of RGB-D cameras, it is expected that additional depth measurement will improve the accuracy.\", \"Here we investigate a solution how to incorporate complementary depth information into a semantic segmentation framework by making use of convolutional neural networks (CNNs).\", \"Recently encoder-decoder type fully convolutional CNN architectures have achieved a great success in the field of semantic segmentation.\", \"Motivated by this observation we propose an encoder-decoder type network, where the encoder part is composed of two branches of networks that simultaneously extract features from RGB and depth images and fuse depth features into the RGB feature maps as the network goes deeper.\", \"Comprehensive experimental evaluations demonstrate that the proposed fusion-based architecture achieves competitive results with the state-of-the-art methods on the challenging SUN RGB-D benchmark obtaining 76.27% global accuracy, 48.30% average class accuracy and 37.29% average intersectionover-union score.\"], \"labels\": [\"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.6111, 0.6111, 0.8333, 0.6111, 0.7778, 0.7778]}\n",
            "prediction:  [0, [[\"In this paper we address the problem of semantic labeling of indoor scenes on RGB-D data.\", \"background_label\"], [\"With the availability of RGB-D cameras, it is expected that additional depth measurement will improve the accuracy.\", \"background_label\"], [\"Here we investigate a solution how to incorporate complementary depth information into a semantic segmentation framework by making use of convolutional neural networks (CNNs).\", \"objective_label\"], [\"Recently encoder-decoder type fully convolutional CNN architectures have achieved a great success in the field of semantic segmentation.\", \"background_label\"], [\"Motivated by this observation we propose an encoder-decoder type network, where the encoder part is composed of two branches of networks that simultaneously extract features from RGB and depth images and fuse depth features into the RGB feature maps as the network goes deeper.\", \"method_label\"], [\"Comprehensive experimental evaluations demonstrate that the proposed fusion-based architecture achieves competitive results with the state-of-the-art methods on the challenging SUN RGB-D benchmark obtaining 76.27% global accuracy, 48.30% average class accuracy and 37.29% average intersectionover-union score.\", \"result_label\"]]]\n",
            "\n",
            "input 9:  {\"abstract_id\": 0, \"sentences\": [\"It is no secret that pornographic material is now a one-clickaway from everyone, including children and minors.\", \"General social media networks are striving to isolate adult images and videos from normal ones.\", \"Intelligent image analysis methods can help to automatically detect and isolate questionable images in media.\", \"Unfortunately, these methods require vast experience to design the classifier including one or more of the popular computer vision feature descriptors.\", \"We propose to build a classifier based on one of the recently flourishing deep learning techniques.\", \"Convolutional neural networks contain many layers for both automatic features extraction and classification.\", \"The benefit is an easier system to build (no need for hand-crafting features and classifiers).\", \"Additionally, our experiments show that it is even more accurate than the state of the art methods on the most recent benchmark dataset.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7742, 0.7742, 0.7419, 0.7742, 0.7419, 0.7742]}\n",
            "prediction:  [0, [[\"It is no secret that pornographic material is now a one-clickaway from everyone, including children and minors.\", \"background_label\"], [\"General social media networks are striving to isolate adult images and videos from normal ones.\", \"background_label\"], [\"Intelligent image analysis methods can help to automatically detect and isolate questionable images in media.\", \"background_label\"], [\"Unfortunately, these methods require vast experience to design the classifier including one or more of the popular computer vision feature descriptors.\", \"background_label\"], [\"We propose to build a classifier based on one of the recently flourishing deep learning techniques.\", \"method_label\"], [\"Convolutional neural networks contain many layers for both automatic features extraction and classification.\", \"method_label\"], [\"The benefit is an easier system to build (no need for hand-crafting features and classifiers).\", \"method_label\"], [\"Additionally, our experiments show that it is even more accurate than the state of the art methods on the most recent benchmark dataset.\", \"result_label\"]]]\n",
            "\n",
            "input 10:  {\"abstract_id\": 0, \"sentences\": [\"Modern charging systems use user, network, and service related information when performing online charging.\", \"Compared, however, to the overall information available and used in network management processes as a whole, charging systems only use a limited subset.\", \"This work is motivated by the challenge to identify which information is used, and how it is used in online charging related processes, and also to explore whether it could be utilized \\u201cbetter\\u201d or \\u201csmarter\\u201d to improve future online charging systems functionality.\", \"We do not attempt to predict which information will be utilized in such systems and for what purpose, but instead we summarize open issues in view of the emerging trend of exploiting the user, network and service related information in service provisioning.\", \"We focus on the latest 3GPP standards and review relevant research papers, and propose three key aspects of online charging, with respect to information utilization: a) signaling aspect, b) inter-domain aspect, and c) serviceand component-based aspect.\", \"We present a state of the art review by grouping the works found in the literature based on the aspects they are associated with, and compare them based on proposed comparison criteria.\", \"The discussion presented at the end of the paper indicates three common open issues, namely: 1) lack of common charging information specification and structure, 2) lack of mechanisms for information sharing between stakeholders in the service delivery process, and 3) lack of a common framework for sharing information while protecting user privacy.\", \"Copyright c \\u00a9 2012 John Wiley & Sons, Ltd.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"method\", \"method\", \"result\", \"other\"], \"confs\": [1.0, 0.8158, 0.8158, 0.8158, 0.6053, 0.6053, 0.6316, 1.0]}\n",
            "prediction:  [0, [[\"Modern charging systems use user, network, and service related information when performing online charging.\", \"background_label\"], [\"Compared, however, to the overall information available and used in network management processes as a whole, charging systems only use a limited subset.\", \"background_label\"], [\"This work is motivated by the challenge to identify which information is used, and how it is used in online charging related processes, and also to explore whether it could be utilized \\u201cbetter\\u201d or \\u201csmarter\\u201d to improve future online charging systems functionality.\", \"objective_label\"], [\"We do not attempt to predict which information will be utilized in such systems and for what purpose, but instead we summarize open issues in view of the emerging trend of exploiting the user, network and service related information in service provisioning.\", \"objective_label\"], [\"We focus on the latest 3GPP standards and review relevant research papers, and propose three key aspects of online charging, with respect to information utilization: a) signaling aspect, b) inter-domain aspect, and c) serviceand component-based aspect.\", \"method_label\"], [\"We present a state of the art review by grouping the works found in the literature based on the aspects they are associated with, and compare them based on proposed comparison criteria.\", \"method_label\"], [\"The discussion presented at the end of the paper indicates three common open issues, namely: 1) lack of common charging information specification and structure, 2) lack of mechanisms for information sharing between stakeholders in the service delivery process, and 3) lack of a common framework for sharing information while protecting user privacy.\", \"result_label\"], [\"Copyright c \\u00a9 2012 John Wiley & Sons, Ltd.\", \"other_label\"]]]\n",
            "\n",
            "input 11:  {\"abstract_id\": 0, \"sentences\": [\"The accurate diagnosis of Alzheimer's disease (AD) plays a significant role in patient care, especially at the early stage, because the consciousness of the severity and the progression risks allows the patients to take prevention measures before irreversible brain damages are shaped.\", \"Although many studies have applied machine learning methods for computer-aided-diagnosis (CAD) of AD recently, a bottleneck of the diagnosis performance was shown in most of the existing researches, mainly due to the congenital limitations of the chosen learning models.\", \"In this study, we design a deep learning architecture, which contains stacked auto-encoders and a softmax output layer, to overcome the bottleneck and aid the diagnosis of AD and its prodromal stage, Mild Cognitive Impairment (MCI).\", \"Compared to the previous workflows, our method is capable of analyzing multiple classes in one setting, and requires less labeled training samples and minimal domain prior knowledge.\", \"A significant performance gain on classification of all diagnosis groups was achieved in our experiments.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.75, 1.0, 0.75, 1.0]}\n",
            "prediction:  [0, [[\"The accurate diagnosis of Alzheimer's disease (AD) plays a significant role in patient care, especially at the early stage, because the consciousness of the severity and the progression risks allows the patients to take prevention measures before irreversible brain damages are shaped.\", \"background_label\"], [\"Although many studies have applied machine learning methods for computer-aided-diagnosis (CAD) of AD recently, a bottleneck of the diagnosis performance was shown in most of the existing researches, mainly due to the congenital limitations of the chosen learning models.\", \"background_label\"], [\"In this study, we design a deep learning architecture, which contains stacked auto-encoders and a softmax output layer, to overcome the bottleneck and aid the diagnosis of AD and its prodromal stage, Mild Cognitive Impairment (MCI).\", \"method_label\"], [\"Compared to the previous workflows, our method is capable of analyzing multiple classes in one setting, and requires less labeled training samples and minimal domain prior knowledge.\", \"method_label\"], [\"A significant performance gain on classification of all diagnosis groups was achieved in our experiments.\", \"result_label\"]]]\n",
            "\n",
            "input 12:  {\"abstract_id\": 0, \"sentences\": [\"Human evaluations of machine translation are extensive but expensive.\", \"Human evaluations can take months to finish and involve human labor that can not be reused.\", \"We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run.\", \"We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.1\"], \"labels\": [\"background\", \"background\", \"method\", \"method\"], \"confs\": [0.7949, 0.7949, 0.8205, 0.6154]}\n",
            "prediction:  [0, [[\"Human evaluations of machine translation are extensive but expensive.\", \"background_label\"], [\"Human evaluations can take months to finish and involve human labor that can not be reused.\", \"background_label\"], [\"We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run.\", \"method_label\"], [\"We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.1\", \"method_label\"]]]\n",
            "\n",
            "input 13:  {\"abstract_id\": 0, \"sentences\": [\"Based on the real data of a Chinese commercial bank\\u2019s credit card, in this paper, we classify the credit card customers into four classifications by K-means.\", \"Then we built forecasting models separately based on four data mining methods such as C5.0, neural network, chi-squared automatic interaction detector, and classification and regression tree according to the background information of the credit cards holders.\", \"Conclusively, we obtain some useful information of decision tree regulation by the best model among the four.\", \"The information is not only helpful for the bank to understand related characteristics of different customers, but also marketing representatives to find potential customers and to implement target marketing.\"], \"labels\": [\"background\", \"method\", \"method\", \"result\"], \"confs\": [0.6, 0.8, 0.6, 0.8]}\n",
            "prediction:  [0, [[\"Based on the real data of a Chinese commercial bank\\u2019s credit card, in this paper, we classify the credit card customers into four classifications by K-means.\", \"method_label\"], [\"Then we built forecasting models separately based on four data mining methods such as C5.0, neural network, chi-squared automatic interaction detector, and classification and regression tree according to the background information of the credit cards holders.\", \"method_label\"], [\"Conclusively, we obtain some useful information of decision tree regulation by the best model among the four.\", \"result_label\"], [\"The information is not only helpful for the bank to understand related characteristics of different customers, but also marketing representatives to find potential customers and to implement target marketing.\", \"result_label\"]]]\n",
            "\n",
            "input 14:  {\"abstract_id\": 0, \"sentences\": [\"Over the last ten years, argumentation has come to be increasingly central as a core study within Artificial Intelligence (AI).\", \"The articles forming this volume reflect a variety of important trends, developments, and applications covering a range of current topics relating to the theory and applications of argumentation.\", \"Our aims in this introduction are, firstly, to place these contributions in the context of the historical foundations of argumentation in AI and, subsequently, to discuss a number of themes that have emerged in recent years resulting in a significant broadening of the areas in which argumentation based methods are used.\", \"We begin by presenting a brief overview of the issues of interest within the classical study of argumentation: in particular, its relationship\\u2014 in terms of both similarities and important differences\\u2014to traditional concepts of logical reasoning and mathematical proof.\", \"We continue by outlining how a number of foundational contributions provided the basis for the formulation of argumentation models and their promotion in AI related settings and then consider a number of new themes that have emerged in recent years, many of which provide the principal topics of the research presented in this volume.\", \"\\u00a9 2007 Elsevier B.V.\", \"All rights reserved.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"other\", \"other\"], \"confs\": [1.0, 0.7419, 1.0, 0.7419, 1.0, 0.7419, 1.0]}\n",
            "prediction:  [0, [[\"Over the last ten years, argumentation has come to be increasingly central as a core study within Artificial Intelligence (AI).\", \"background_label\"], [\"The articles forming this volume reflect a variety of important trends, developments, and applications covering a range of current topics relating to the theory and applications of argumentation.\", \"background_label\"], [\"Our aims in this introduction are, firstly, to place these contributions in the context of the historical foundations of argumentation in AI and, subsequently, to discuss a number of themes that have emerged in recent years resulting in a significant broadening of the areas in which argumentation based methods are used.\", \"objective_label\"], [\"We begin by presenting a brief overview of the issues of interest within the classical study of argumentation: in particular, its relationship\\u2014 in terms of both similarities and important differences\\u2014to traditional concepts of logical reasoning and mathematical proof.\", \"method_label\"], [\"We continue by outlining how a number of foundational contributions provided the basis for the formulation of argumentation models and their promotion in AI related settings and then consider a number of new themes that have emerged in recent years, many of which provide the principal topics of the research presented in this volume.\", \"result_label\"], [\"\\u00a9 2007 Elsevier B.V.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 15:  {\"abstract_id\": 0, \"sentences\": [\"This study investigates self-presentation strategies among online dating participants, exploring how participants manage their online presentation of self in order to accomplish the goal of finding a romantic partner.\", \"Thirty-four individuals active on a large online dating site participated in telephone interviews about their online dating experiences and perceptions.\", \"Qualitative data analysis suggests that participants attended to small cues online, mediated the tension between impression management pressures and the desire to present an authentic sense of self through tactics such as creating a profile that reflected their \\\"ideal self,\\\" and attempted to establish the veracity of their identity claims.\", \"This study provides empirical support for Social Information Processing theory in a naturalistic context while offering insight into the complicated way in which \\\"honesty\\\" is enacted online.\"], \"labels\": [\"objective\", \"background\", \"method\", \"result\"], \"confs\": [0.6, 0.6, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"This study investigates self-presentation strategies among online dating participants, exploring how participants manage their online presentation of self in order to accomplish the goal of finding a romantic partner.\", \"objective_label\"], [\"Thirty-four individuals active on a large online dating site participated in telephone interviews about their online dating experiences and perceptions.\", \"background_label\"], [\"Qualitative data analysis suggests that participants attended to small cues online, mediated the tension between impression management pressures and the desire to present an authentic sense of self through tactics such as creating a profile that reflected their \\\"ideal self,\\\" and attempted to establish the veracity of their identity claims.\", \"method_label\"], [\"This study provides empirical support for Social Information Processing theory in a naturalistic context while offering insight into the complicated way in which \\\"honesty\\\" is enacted online.\", \"result_label\"]]]\n",
            "\n",
            "input 16:  {\"abstract_id\": 0, \"sentences\": [\"The widespread deployment and adoption of the Dynamic Adaptive Streaming over HTTP (DASH) standard is making Internet video-on-demand a `standard' Internet application similar in impact as email and web browsing.\", \"While video streaming has been widely deployed and studied for decades, DASH-based streaming is very different as it involves adaptation both by the application and by TCP.\", \"The dynamics and implications of multiple levels of end-to-end congestion control are not well understood.\", \"The contribution of the research presented in this paper is twofold: first, we characterize the bandwidth consumption of a widely deployed DASH application (i.e., Netflix); second, we provide insight in how different implementations and different access networks can impact bandwidth consumption.\", \"Our results suggest that Netflix adaptation defaults to underlying TCP mechanisms during periods of heavy, sustained network congestion.\", \"However, the application algorithm is clearly intertwined with the underlying TCP mechanisms during periods of volatile network conditions.\", \"In one network scenario, we observed that a backlogged TCP flow achieved a throughput of 6 Mbps while a Netflix session (under similar path conditions) consumed less than 3 Mbps of bandwidth.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 0.6957, 0.6957, 0.6957, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"The widespread deployment and adoption of the Dynamic Adaptive Streaming over HTTP (DASH) standard is making Internet video-on-demand a `standard' Internet application similar in impact as email and web browsing.\", \"background_label\"], [\"While video streaming has been widely deployed and studied for decades, DASH-based streaming is very different as it involves adaptation both by the application and by TCP.\", \"background_label\"], [\"The dynamics and implications of multiple levels of end-to-end congestion control are not well understood.\", \"background_label\"], [\"The contribution of the research presented in this paper is twofold: first, we characterize the bandwidth consumption of a widely deployed DASH application (i.e., Netflix); second, we provide insight in how different implementations and different access networks can impact bandwidth consumption.\", \"method_label\"], [\"Our results suggest that Netflix adaptation defaults to underlying TCP mechanisms during periods of heavy, sustained network congestion.\", \"result_label\"], [\"However, the application algorithm is clearly intertwined with the underlying TCP mechanisms during periods of volatile network conditions.\", \"result_label\"], [\"In one network scenario, we observed that a backlogged TCP flow achieved a throughput of 6 Mbps while a Netflix session (under similar path conditions) consumed less than 3 Mbps of bandwidth.\", \"result_label\"]]]\n",
            "\n",
            "input 17:  {\"abstract_id\": 0, \"sentences\": [\"Applying uses and gratifications theory (UGT), this study examined consumers\\u2019 use of one of four social networking sites (SNSs): Facebook, Twitter, Instagram, or Snapchat, for following brands, and their influence on brand community-related outcomes.\", \"Results (N = 297) indicated Snapchat users scored highest for passing time, sharing problems, and improving social knowledge, while Instagram users scored highest for showing affection, following fashion, and demonstrating sociability.\", \"Twitter users had highest brand community identification and membership intention, while Instagram users had highest brand community engagement and commitment.\", \"Attention to social comparison, SNS trust, tie strength, and homophily also significantly moderated the relationship between frequent use of each SNS to follow brands, and brand community-related outcomes.\", \"Implications for future research on SNS users\\u2019 goal-directed consumption behaviors are discussed.\"], \"labels\": [\"method\", \"result\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 0.7667, 0.7667, 0.7667, 1.0]}\n",
            "prediction:  [0, [[\"Applying uses and gratifications theory (UGT), this study examined consumers\\u2019 use of one of four social networking sites (SNSs): Facebook, Twitter, Instagram, or Snapchat, for following brands, and their influence on brand community-related outcomes.\", \"background_label\"], [\"Results (N = 297) indicated Snapchat users scored highest for passing time, sharing problems, and improving social knowledge, while Instagram users scored highest for showing affection, following fashion, and demonstrating sociability.\", \"result_label\"], [\"Twitter users had highest brand community identification and membership intention, while Instagram users had highest brand community engagement and commitment.\", \"result_label\"], [\"Attention to social comparison, SNS trust, tie strength, and homophily also significantly moderated the relationship between frequent use of each SNS to follow brands, and brand community-related outcomes.\", \"result_label\"], [\"Implications for future research on SNS users\\u2019 goal-directed consumption behaviors are discussed.\", \"result_label\"]]]\n",
            "\n",
            "input 18:  {\"abstract_id\": 0, \"sentences\": [\"The e-commerce literature has rarely addressed the measurement of customer perceptions of website service quality in digital marketing environments.\", \"It is argued that the current SERVQUAL and IS-SERVQUAL instruments need to be refined and validated to fit the digital marketing environment, as they are targeted primarily towards either traditional retailing or information systems contexts.\", \"This article validates and refines a comprehensive model and instrument for measuring customer-perceived service quality of websites that market digital products and services.\", \"After a discussion of the conceptualization and operationalization of the service quality construct, the procedure used in modifying items, collecting data, and validating a multiple-item scale is described.\", \"Subsequently, evidence of reliability and validity on the basis of analyzing data from a quota sample of 260 adult respondents is presented.\", \"Implications for practice and research are then explored.\", \"Finally, this paper concludes by discussing limitations that could be addressed in future studies.\", \"The final EC-SERVQUAL instrument with good reliability and validity will be essential to the development and testing of e-business theories, and provide researchers with a common framework for explaining, justifying, and comparing differences across results.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.6286, 0.8286, 1.0, 0.6, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"The e-commerce literature has rarely addressed the measurement of customer perceptions of website service quality in digital marketing environments.\", \"background_label\"], [\"It is argued that the current SERVQUAL and IS-SERVQUAL instruments need to be refined and validated to fit the digital marketing environment, as they are targeted primarily towards either traditional retailing or information systems contexts.\", \"background_label\"], [\"This article validates and refines a comprehensive model and instrument for measuring customer-perceived service quality of websites that market digital products and services.\", \"objective_label\"], [\"After a discussion of the conceptualization and operationalization of the service quality construct, the procedure used in modifying items, collecting data, and validating a multiple-item scale is described.\", \"method_label\"], [\"Subsequently, evidence of reliability and validity on the basis of analyzing data from a quota sample of 260 adult respondents is presented.\", \"method_label\"], [\"Implications for practice and research are then explored.\", \"method_label\"], [\"Finally, this paper concludes by discussing limitations that could be addressed in future studies.\", \"result_label\"], [\"The final EC-SERVQUAL instrument with good reliability and validity will be essential to the development and testing of e-business theories, and provide researchers with a common framework for explaining, justifying, and comparing differences across results.\", \"result_label\"]]]\n",
            "\n",
            "input 19:  {\"abstract_id\": 0, \"sentences\": [\"Big data is big news, and large companies in all sectors are making significant advances in their customer relations, product selection and development and consequent profitability through using this valuable commodity.\", \"Small and medium enterprises (SMEs) have proved themselves to be slow adopters of the new technology of big data analytics and are in danger of being left behind.\", \"In Europe, SMEs are a vital part of the economy, and the challenges they encounter need to be addressed as a matter of urgency.\", \"This paper identifies barriers to SME uptake of big data analytics and recognises their complex challenge to all stakeholders, including national and international policy makers, IT, business management and data science communities.\", \"The paper proposes a big data maturity model for SMEs as a first step towards an SME roadmap to data analytics.\", \"It considers the \\u2018state-of-the-art\\u2019 of IT with respect to usability and usefulness for SMEs and discusses how SMEs can overcome the barriers preventing them from adopting existing solutions.\", \"The paper then considers management perspectives and the role of maturity models in enhancing and structuring the adoption of data analytics in an organisation.\", \"The history of total quality management is reviewed to inform the core aspects of implanting a new paradigm.\", \"The paper concludes with recommendations to help SMEs develop their big data capability and enable them to continue as the engines of European industrial and business success.\", \"Copyright \\u00a9 2016 John Wiley & Sons, Ltd.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"other\"], \"confs\": [1.0, 0.8333, 0.8333, 0.6111, 0.6111, 0.6111, 0.6667, 0.6111, 1.0, 0.7778]}\n",
            "prediction:  [0, [[\"Big data is big news, and large companies in all sectors are making significant advances in their customer relations, product selection and development and consequent profitability through using this valuable commodity.\", \"background_label\"], [\"Small and medium enterprises (SMEs) have proved themselves to be slow adopters of the new technology of big data analytics and are in danger of being left behind.\", \"background_label\"], [\"In Europe, SMEs are a vital part of the economy, and the challenges they encounter need to be addressed as a matter of urgency.\", \"background_label\"], [\"This paper identifies barriers to SME uptake of big data analytics and recognises their complex challenge to all stakeholders, including national and international policy makers, IT, business management and data science communities.\", \"objective_label\"], [\"The paper proposes a big data maturity model for SMEs as a first step towards an SME roadmap to data analytics.\", \"objective_label\"], [\"It considers the \\u2018state-of-the-art\\u2019 of IT with respect to usability and usefulness for SMEs and discusses how SMEs can overcome the barriers preventing them from adopting existing solutions.\", \"method_label\"], [\"The paper then considers management perspectives and the role of maturity models in enhancing and structuring the adoption of data analytics in an organisation.\", \"method_label\"], [\"The history of total quality management is reviewed to inform the core aspects of implanting a new paradigm.\", \"method_label\"], [\"The paper concludes with recommendations to help SMEs develop their big data capability and enable them to continue as the engines of European industrial and business success.\", \"result_label\"], [\"Copyright \\u00a9 2016 John Wiley & Sons, Ltd.\", \"other_label\"]]]\n",
            "\n",
            "input 20:  {\"abstract_id\": 0, \"sentences\": [\"We propose a sensor-driver integrated muscle module by integrating necessarily components for tendon-driven robot which is likely to complicate.\", \"The module has abilities of high-tension measurability and flexible tension control.\", \"In order to achieve flexible tension control, we developed the new tension measurement mechanism with high-tension measurability and the new motor driver which enables current based motor control.\", \"We demonstrate the tension control ability of the module by several experiments.\", \"Furthermore, utilizing the module advantage of design facilitation, we made two types of tendon-driven robots and confirmed effectiveness of the module.\"], \"labels\": [\"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.6053, 0.6053, 1.0, 0.6053, 0.8158]}\n",
            "prediction:  [0, [[\"We propose a sensor-driver integrated muscle module by integrating necessarily components for tendon-driven robot which is likely to complicate.\", \"background_label\"], [\"The module has abilities of high-tension measurability and flexible tension control.\", \"background_label\"], [\"In order to achieve flexible tension control, we developed the new tension measurement mechanism with high-tension measurability and the new motor driver which enables current based motor control.\", \"method_label\"], [\"We demonstrate the tension control ability of the module by several experiments.\", \"result_label\"], [\"Furthermore, utilizing the module advantage of design facilitation, we made two types of tendon-driven robots and confirmed effectiveness of the module.\", \"result_label\"]]]\n",
            "\n",
            "input 21:  {\"abstract_id\": 0, \"sentences\": [\"This study examines the agenda-setting power of fake news and fact-checkers who fight them through a computational look at the online mediascape from 2014 to 2016.\", \"Although our study confirms that content from fake news websites is increasing, these sites do not exert excessive power.\", \"Instead, fake news has an intricately entwined relationship with online partisan media, both responding and setting its issue agenda.\", \"In 2016, partisan media appeared to be especially susceptible to the agendas of fake news, perhaps due to the election.\", \"Emerging news media are also responsive to the agendas of fake news, but to a lesser degree.\", \"Fake news coverage itself is diverging and becoming more autonomous topically.\", \"While fact-checkers are autonomous in their selection of issues to cover, they were not influential in determining the agenda of news media overall, and their influence appears to be declining, illustrating the difficulties factcheckers face in disseminating their corrections.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"background\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7273]}\n",
            "prediction:  [0, [[\"This study examines the agenda-setting power of fake news and fact-checkers who fight them through a computational look at the online mediascape from 2014 to 2016.\", \"background_label\"], [\"Although our study confirms that content from fake news websites is increasing, these sites do not exert excessive power.\", \"background_label\"], [\"Instead, fake news has an intricately entwined relationship with online partisan media, both responding and setting its issue agenda.\", \"background_label\"], [\"In 2016, partisan media appeared to be especially susceptible to the agendas of fake news, perhaps due to the election.\", \"background_label\"], [\"Emerging news media are also responsive to the agendas of fake news, but to a lesser degree.\", \"result_label\"], [\"Fake news coverage itself is diverging and becoming more autonomous topically.\", \"background_label\"], [\"While fact-checkers are autonomous in their selection of issues to cover, they were not influential in determining the agenda of news media overall, and their influence appears to be declining, illustrating the difficulties factcheckers face in disseminating their corrections.\", \"result_label\"]]]\n",
            "\n",
            "input 22:  {\"abstract_id\": 0, \"sentences\": [\"Virtual Reality (VR) is starting to be used in psychological therapy around the world.\", \"However, a thorough understanding of the reason why VR is effective and what effect it has on the human psyche is still missing.\", \"Most research on this subject is related to the concept of presence.\", \"This paper gives an up-to-date overview of research in this diverse field.\", \"It starts with the most prevailing definitions and theories on presence, most of which attribute special roles for the mental process of attention and for mental models of the virtual space.\", \"A review of the phenomena thought to be effected by presence shows that there is still a strong need for research on this subject because little conclusive evidence exists regarding the relationship between presence and phenoma such as emotional responses to virtual stimuli.\", \"An investigation shows there has been substantial research for developing methods for measuring presence and research regarding factors that contribute to presence.\", \"Knowledge of these contributing factors can play a vital role in development of new VR applications, but key knowledge elements in this area are still missing.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.8333, 0.7778, 1.0, 1.0, 0.6389, 0.6111]}\n",
            "prediction:  [0, [[\"Virtual Reality (VR) is starting to be used in psychological therapy around the world.\", \"background_label\"], [\"However, a thorough understanding of the reason why VR is effective and what effect it has on the human psyche is still missing.\", \"background_label\"], [\"Most research on this subject is related to the concept of presence.\", \"background_label\"], [\"This paper gives an up-to-date overview of research in this diverse field.\", \"objective_label\"], [\"It starts with the most prevailing definitions and theories on presence, most of which attribute special roles for the mental process of attention and for mental models of the virtual space.\", \"method_label\"], [\"A review of the phenomena thought to be effected by presence shows that there is still a strong need for research on this subject because little conclusive evidence exists regarding the relationship between presence and phenoma such as emotional responses to virtual stimuli.\", \"method_label\"], [\"An investigation shows there has been substantial research for developing methods for measuring presence and research regarding factors that contribute to presence.\", \"result_label\"], [\"Knowledge of these contributing factors can play a vital role in development of new VR applications, but key knowledge elements in this area are still missing.\", \"result_label\"]]]\n",
            "\n",
            "input 23:  {\"abstract_id\": 0, \"sentences\": [\"Clustering is often an essential first step in data mining intended to reduce redundancy, or define data categories.\", \"Hierarchical clustering, a widely used clustering technique, can offer a richer representation by suggesting the potential group structures.\", \"However, parallelization of such an algorithm is challenging as it exhibits inherent data dependency during the hierarchical tree construction.\", \"In this paper, we design a parallel implementation of Single-linkage Hierarchical Clustering by formulating it as a Minimum Spanning Tree problem.\", \"We further show that Spark is a natural fit for the parallelization of single-linkage clustering algorithm due to its natural expression of iterative process.\", \"Our algorithm can be deployed easily in Amazon's cloud environment.\", \"And a thorough performance evaluation in Amazon's EC2 verifies that the scalability of our algorithm sustains when the datasets scale up.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.8056, 0.7778, 0.8056, 1.0, 0.8056, 0.6111]}\n",
            "prediction:  [0, [[\"Clustering is often an essential first step in data mining intended to reduce redundancy, or define data categories.\", \"background_label\"], [\"Hierarchical clustering, a widely used clustering technique, can offer a richer representation by suggesting the potential group structures.\", \"background_label\"], [\"However, parallelization of such an algorithm is challenging as it exhibits inherent data dependency during the hierarchical tree construction.\", \"background_label\"], [\"In this paper, we design a parallel implementation of Single-linkage Hierarchical Clustering by formulating it as a Minimum Spanning Tree problem.\", \"objective_label\"], [\"We further show that Spark is a natural fit for the parallelization of single-linkage clustering algorithm due to its natural expression of iterative process.\", \"method_label\"], [\"Our algorithm can be deployed easily in Amazon's cloud environment.\", \"method_label\"], [\"And a thorough performance evaluation in Amazon's EC2 verifies that the scalability of our algorithm sustains when the datasets scale up.\", \"result_label\"]]]\n",
            "\n",
            "input 24:  {\"abstract_id\": 0, \"sentences\": [\"We have entered the era of social media networks represented by Facebook, Twitter, YouTube and Flickr.\", \"Internet users now spend more time on social networks than search engines.\", \"Business entities or public figures set up social networking pages to enhance direct interactions with online users.\", \"Social media systems heavily depend on users for content contribution and sharing.\", \"Information is spread across social networks quickly and effectively.\", \"However, at the same time social media networks become susceptible to different types of unwanted and malicious spammer or hacker actions.\", \"There is a crucial need in the society and industry for security solution in social media.\", \"In this demo, we propose SocialSpamGuard, a scalable and online social media spam detection system based on data mining for social network security.\", \"We employ our GAD clustering algorithm for large scale clustering and integrate it with the designed active learning algorithm to deal with the scalability and real-time detection challenges.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"objective\", \"method\"], \"confs\": [0.8387, 1.0, 1.0, 1.0, 0.8065, 1.0, 0.6774, 0.6774, 1.0]}\n",
            "prediction:  [0, [[\"We have entered the era of social media networks represented by Facebook, Twitter, YouTube and Flickr.\", \"background_label\"], [\"Internet users now spend more time on social networks than search engines.\", \"background_label\"], [\"Business entities or public figures set up social networking pages to enhance direct interactions with online users.\", \"background_label\"], [\"Social media systems heavily depend on users for content contribution and sharing.\", \"background_label\"], [\"Information is spread across social networks quickly and effectively.\", \"background_label\"], [\"However, at the same time social media networks become susceptible to different types of unwanted and malicious spammer or hacker actions.\", \"background_label\"], [\"There is a crucial need in the society and industry for security solution in social media.\", \"background_label\"], [\"In this demo, we propose SocialSpamGuard, a scalable and online social media spam detection system based on data mining for social network security.\", \"objective_label\"], [\"We employ our GAD clustering algorithm for large scale clustering and integrate it with the designed active learning algorithm to deal with the scalability and real-time detection challenges.\", \"method_label\"]]]\n",
            "\n",
            "input 25:  {\"abstract_id\": 0, \"sentences\": [\"A 12-bit low-power successive approximation register analog-to-digital converter (SAR ADC) is presented using dynamic latch comparator to realize power consumption of 47.86\\u03bcW under 1.8V supply voltage.\", \"Fully differential structure and hybrid 9-bit charge-redistribution capacitive and 3-bit resistor string DAC techniques are adopted to achieve balance between high precision and small area.\", \"Fabricated in SMIC 0.18-\\u03bcm 1P6M mixed-signal CMOS technology, the ADC only occupies 0.39mm active area and the DNL/INL achieve 0.6LSB and 0.8LSB respectively.\"], \"labels\": [\"background\", \"background\", \"background\"], \"confs\": [0.75, 0.75, 1.0]}\n",
            "prediction:  [0, [[\"A 12-bit low-power successive approximation register analog-to-digital converter (SAR ADC) is presented using dynamic latch comparator to realize power consumption of 47.86\\u03bcW under 1.8V supply voltage.\", \"background_label\"], [\"Fully differential structure and hybrid 9-bit charge-redistribution capacitive and 3-bit resistor string DAC techniques are adopted to achieve balance between high precision and small area.\", \"method_label\"], [\"Fabricated in SMIC 0.18-\\u03bcm 1P6M mixed-signal CMOS technology, the ADC only occupies 0.39mm active area and the DNL/INL achieve 0.6LSB and 0.8LSB respectively.\", \"result_label\"]]]\n",
            "\n",
            "input 26:  {\"abstract_id\": 0, \"sentences\": [\"In this paper, a power density analysis is presented for 7nm FinFET technology node based on both shorted-gate (SG) and independent-gate (IG) standard cells operating in multiple supply voltage regimes.\", \"A Liberty-formatted standard cell library is established by selecting the appropriate number of fins for the pull-up and pull-down networks of each logic cell.\", \"The layout of both shorted-gate and independent-gate standard cells are then characterized according to lambda-based layout design rules for FinFET devices.\", \"Finally, the power density of 7nm FinFET technology node is analyzed and compared with the 45 nm CMOS technology node for different circuits.\", \"Experimental result shows that the power density of each 7nm FinFET circuit is 3-20 times larger than that of 45nm CMOS circuit under the spacer-defined technology.\", \"Experimental result also shows that the back-gate signal enables a better control of power consumption for independent-gate FinFETs.\"], \"labels\": [\"background\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.8, 0.6, 0.6, 0.6, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"In this paper, a power density analysis is presented for 7nm FinFET technology node based on both shorted-gate (SG) and independent-gate (IG) standard cells operating in multiple supply voltage regimes.\", \"background_label\"], [\"A Liberty-formatted standard cell library is established by selecting the appropriate number of fins for the pull-up and pull-down networks of each logic cell.\", \"method_label\"], [\"The layout of both shorted-gate and independent-gate standard cells are then characterized according to lambda-based layout design rules for FinFET devices.\", \"method_label\"], [\"Finally, the power density of 7nm FinFET technology node is analyzed and compared with the 45 nm CMOS technology node for different circuits.\", \"method_label\"], [\"Experimental result shows that the power density of each 7nm FinFET circuit is 3-20 times larger than that of 45nm CMOS circuit under the spacer-defined technology.\", \"result_label\"], [\"Experimental result also shows that the back-gate signal enables a better control of power consumption for independent-gate FinFETs.\", \"result_label\"]]]\n",
            "\n",
            "input 27:  {\"abstract_id\": 0, \"sentences\": [\"We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier.\", \"We find that only a few manipulations are needed to greatly decrease the accuracy.\", \"Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the onehot input vectors.\", \"Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time.\", \"With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier as well.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.7667, 0.7667, 1.0, 0.7667, 1.0]}\n",
            "prediction:  [0, [[\"We propose an efficient method to generate white-box adversarial examples to trick a character-level neural classifier.\", \"background_label\"], [\"We find that only a few manipulations are needed to greatly decrease the accuracy.\", \"method_label\"], [\"Our method relies on an atomic flip operation, which swaps one token for another, based on the gradients of the onehot input vectors.\", \"method_label\"], [\"Due to efficiency of our method, we can perform adversarial training which makes the model more robust to attacks at test time.\", \"method_label\"], [\"With the use of a few semantics-preserving constraints, we demonstrate that HotFlip can be adapted to attack a word-level classifier as well.\", \"result_label\"]]]\n",
            "\n",
            "input 28:  {\"abstract_id\": 0, \"sentences\": [\"The standard training regime for transition-based dependency parsers makes use of an oracle, which predicts an optimal transition sequence for a sentence and its gold tree.\", \"We present an improved oracle for the arc-eager transition system, which provides a set of optimal transitions for every valid parser configuration, including configurations from which the gold tree is not reachable.\", \"In such cases, the oracle provides transitions that will lead to the best reachable tree from the given configuration.\", \"The oracle is efficient to implement and provably correct.\", \"We use the oracle to train a deterministic left-to-right dependency parser that is less sensitive to error propagation, using an online training procedure that also explores parser configurations resulting from non-optimal sequences of transitions.\", \"This new parser outperforms greedy parsers trained using conventional oracles on a range of data sets, with an average improvement of over 1.2 LAS points and up to almost 3 LAS points on some data sets.\"], \"labels\": [\"background\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.8056, 0.6111, 0.6111, 0.6111, 0.8056, 0.6111]}\n",
            "prediction:  [0, [[\"The standard training regime for transition-based dependency parsers makes use of an oracle, which predicts an optimal transition sequence for a sentence and its gold tree.\", \"background_label\"], [\"We present an improved oracle for the arc-eager transition system, which provides a set of optimal transitions for every valid parser configuration, including configurations from which the gold tree is not reachable.\", \"method_label\"], [\"In such cases, the oracle provides transitions that will lead to the best reachable tree from the given configuration.\", \"method_label\"], [\"The oracle is efficient to implement and provably correct.\", \"method_label\"], [\"We use the oracle to train a deterministic left-to-right dependency parser that is less sensitive to error propagation, using an online training procedure that also explores parser configurations resulting from non-optimal sequences of transitions.\", \"method_label\"], [\"This new parser outperforms greedy parsers trained using conventional oracles on a range of data sets, with an average improvement of over 1.2 LAS points and up to almost 3 LAS points on some data sets.\", \"result_label\"]]]\n",
            "\n",
            "input 29:  {\"abstract_id\": 0, \"sentences\": [\"The field of privacy has seen rapid advances in recent years because of the increases in the ability to store data.\", \"In particular, recent advances in the data mining field have lead to increased concerns about privacy.\", \"While the topic of privacy has been traditionally studied in the context of cryptography and information-hiding, recent emphasis on data mining has lead to renewed interest in the field.\", \"In this chapter, we will introduce the topic of privacy-preserving data mining and provide an overview of the different topics covered in this book.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\"], \"confs\": [1.0, 0.6286, 0.6286, 0.6]}\n",
            "prediction:  [0, [[\"The field of privacy has seen rapid advances in recent years because of the increases in the ability to store data.\", \"background_label\"], [\"In particular, recent advances in the data mining field have lead to increased concerns about privacy.\", \"background_label\"], [\"While the topic of privacy has been traditionally studied in the context of cryptography and information-hiding, recent emphasis on data mining has lead to renewed interest in the field.\", \"background_label\"], [\"In this chapter, we will introduce the topic of privacy-preserving data mining and provide an overview of the different topics covered in this book.\", \"objective_label\"]]]\n",
            "\n",
            "input 30:  {\"abstract_id\": 0, \"sentences\": [\"Social connectedness, i.e. the experience of belonging and relatedness between people, is a central concept in understanding and evaluating communication media, in particular awareness systems.\", \"A generic measure based on this construct can support the design of such systems.\", \"The current paper describes the construction of two questionnaires for the measurement of this concept.\", \"These questionnaires were subsequently applied in survey studies in order to establish the structure of the concept and to identify the items that are suited for the measurement of its dimensions.\", \"One questionnaire was subjected to an initial validation.\", \"We conclude with some preliminary suggestions regarding (design) approaches to foster social connectedness.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Social connectedness, i.e. the experience of belonging and relatedness between people, is a central concept in understanding and evaluating communication media, in particular awareness systems.\", \"background_label\"], [\"A generic measure based on this construct can support the design of such systems.\", \"background_label\"], [\"The current paper describes the construction of two questionnaires for the measurement of this concept.\", \"objective_label\"], [\"These questionnaires were subsequently applied in survey studies in order to establish the structure of the concept and to identify the items that are suited for the measurement of its dimensions.\", \"method_label\"], [\"One questionnaire was subjected to an initial validation.\", \"method_label\"], [\"We conclude with some preliminary suggestions regarding (design) approaches to foster social connectedness.\", \"result_label\"]]]\n",
            "\n",
            "input 31:  {\"abstract_id\": 0, \"sentences\": [\"In this paper, we proposed a sentence encoding-based model for recognizing text entailment.\", \"In our approach, the encoding of sentence is a two-stage process.\", \"Firstly, average pooling was used over word-level bidirectional LSTM (biLSTM) to generate a firststage sentence representation.\", \"Secondly, attention mechanism was employed to replace average pooling on the same sentence for better representations.\", \"Instead of using target sentence to attend words in source sentence, we utilized the sentence\\u2019s first-stage representation to attend words appeared in itself, which is called \\u201dInner-Attention\\u201d in our paper .\", \"Experiments conducted on Stanford Natural Language Inference (SNLI) Corpus has proved the effectiveness of \\u201dInner-Attention\\u201d mechanism.\", \"With less number of parameters, our model outperformed the existing best sentence encoding-based approach by a large margin.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.7333, 0.7667, 1.0, 1.0, 0.7333, 0.7667, 1.0]}\n",
            "prediction:  [0, [[\"In this paper, we proposed a sentence encoding-based model for recognizing text entailment.\", \"objective_label\"], [\"In our approach, the encoding of sentence is a two-stage process.\", \"objective_label\"], [\"Firstly, average pooling was used over word-level bidirectional LSTM (biLSTM) to generate a firststage sentence representation.\", \"method_label\"], [\"Secondly, attention mechanism was employed to replace average pooling on the same sentence for better representations.\", \"method_label\"], [\"Instead of using target sentence to attend words in source sentence, we utilized the sentence\\u2019s first-stage representation to attend words appeared in itself, which is called \\u201dInner-Attention\\u201d in our paper .\", \"method_label\"], [\"Experiments conducted on Stanford Natural Language Inference (SNLI) Corpus has proved the effectiveness of \\u201dInner-Attention\\u201d mechanism.\", \"result_label\"], [\"With less number of parameters, our model outperformed the existing best sentence encoding-based approach by a large margin.\", \"result_label\"]]]\n",
            "\n",
            "input 32:  {\"abstract_id\": 0, \"sentences\": [\"Nowadays we are living an era which is marked by efforts for originality, innovation, collaboration, accumulation of experience and integration with and through many inventions such as computers, the internet, and technologies that have facilitated knowledge sharing and communication among people.\", \"This research seeks to extend the existing literature on KMS and knowledge sharing by proposing a conceptual framework, namely ECCCT (Evolution, Collaboration, Connection, Codification and Technical) that can be used to study how knowledge management systems (KMS) facilitate knowledge sharing to support decision making processes in multinational corporations (MNC).\", \"In this research, 42 semi-structured interviews have been conducted with participants from 35 MNC in 11 countries.\", \"All participants are KMS professionals, managers and employees in MNC who are using KMS in different sectors and at different levels.\", \"The work will assist managers in MNC in finding new ways of leveraging and sharing knowledge.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.8, 0.8, 0.7333]}\n",
            "prediction:  [0, [[\"Nowadays we are living an era which is marked by efforts for originality, innovation, collaboration, accumulation of experience and integration with and through many inventions such as computers, the internet, and technologies that have facilitated knowledge sharing and communication among people.\", \"background_label\"], [\"This research seeks to extend the existing literature on KMS and knowledge sharing by proposing a conceptual framework, namely ECCCT (Evolution, Collaboration, Connection, Codification and Technical) that can be used to study how knowledge management systems (KMS) facilitate knowledge sharing to support decision making processes in multinational corporations (MNC).\", \"objective_label\"], [\"In this research, 42 semi-structured interviews have been conducted with participants from 35 MNC in 11 countries.\", \"method_label\"], [\"All participants are KMS professionals, managers and employees in MNC who are using KMS in different sectors and at different levels.\", \"method_label\"], [\"The work will assist managers in MNC in finding new ways of leveraging and sharing knowledge.\", \"result_label\"]]]\n",
            "\n",
            "input 33:  {\"abstract_id\": 0, \"sentences\": [\"In this paper we present a Universal Turing Machine build in the Cellular Automaton Conway's Game of Life.\", \"This is an extension of the Turing Machine built previously by the author [10].\", \"It is example of spatio-temporal collision based computation and has infinite tape provided by two stack structures which grow continuously using collision based construction.\", \"Two patterns the fanout and takeout are described which are key in solving the routing and synchronization problems.\", \"The procedure used to find a viable order of synthesis of the parts in the stack construction is described.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"In this paper we present a Universal Turing Machine build in the Cellular Automaton Conway's Game of Life.\", \"background_label\"], [\"This is an extension of the Turing Machine built previously by the author [10].\", \"background_label\"], [\"It is example of spatio-temporal collision based computation and has infinite tape provided by two stack structures which grow continuously using collision based construction.\", \"method_label\"], [\"Two patterns the fanout and takeout are described which are key in solving the routing and synchronization problems.\", \"method_label\"], [\"The procedure used to find a viable order of synthesis of the parts in the stack construction is described.\", \"method_label\"]]]\n",
            "\n",
            "input 34:  {\"abstract_id\": 0, \"sentences\": [\"In recent years, 3D point cloud has gained increasing attention as a new representation for objects.\", \"However, the raw point cloud is often noisy and contains outliers.\", \"Therefore, it is crucial to remove the noise and outliers from the point cloud while preserving the features, in particular, its fine details.\", \"This paper makes an attempt to present a comprehensive analysis of the state-of-the-art methods for filtering point cloud.\", \"The existing methods are categorized into seven classes, which concentrate on their common and obvious traits.\", \"An experimental evaluation is also performed to demonstrate robustness, effectiveness and computational efficiency of several methods used widely in practice.\", \"\\u00a9 2017 Elsevier B.V. All rights reserved.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"result\", \"other\"], \"confs\": [0.8333, 0.8333, 0.7778, 0.7778, 0.6667, 0.6111, 0.6111]}\n",
            "prediction:  [0, [[\"In recent years, 3D point cloud has gained increasing attention as a new representation for objects.\", \"background_label\"], [\"However, the raw point cloud is often noisy and contains outliers.\", \"background_label\"], [\"Therefore, it is crucial to remove the noise and outliers from the point cloud while preserving the features, in particular, its fine details.\", \"background_label\"], [\"This paper makes an attempt to present a comprehensive analysis of the state-of-the-art methods for filtering point cloud.\", \"objective_label\"], [\"The existing methods are categorized into seven classes, which concentrate on their common and obvious traits.\", \"method_label\"], [\"An experimental evaluation is also performed to demonstrate robustness, effectiveness and computational efficiency of several methods used widely in practice.\", \"result_label\"], [\"\\u00a9 2017 Elsevier B.V. All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 35:  {\"abstract_id\": 0, \"sentences\": [\"Social media platforms such as Twitter and Facebook enable the creation of virtual customer environments (VCEs) where online communities of interest form around specific firms, brands, or products.\", \"While these platforms can be used as another means to deliver familiar e-commerce applications, when firms fail to fully engage their customers, they also fail to fully exploit the capabilities of social media platforms.\", \"To gain business value, organizations need to incorporate community building as part of the implementation of social media.\"], \"labels\": [\"background\", \"background\", \"result\"], \"confs\": [0.8, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"Social media platforms such as Twitter and Facebook enable the creation of virtual customer environments (VCEs) where online communities of interest form around specific firms, brands, or products.\", \"background_label\"], [\"While these platforms can be used as another means to deliver familiar e-commerce applications, when firms fail to fully engage their customers, they also fail to fully exploit the capabilities of social media platforms.\", \"background_label\"], [\"To gain business value, organizations need to incorporate community building as part of the implementation of social media.\", \"result_label\"]]]\n",
            "\n",
            "input 36:  {\"abstract_id\": 0, \"sentences\": [\"The Hick-Hyman Law and Fitts\\u2019 Law are two surviving human performance principles based on Shannon and Weaver\\u2019s (1949) Information Theory.\", \"In the early 1980s, Card, Moran, and Newell (1983) presented the laws as design principles for developers to maximize usability in the design of human\\u2013computer interfaces.\", \"A search of the current human\\u2013computer interaction (HCI) literature, however, will reveal that the Hick-Hyman Law failed to gain momentum in the field of HCI, whereas Fitts\\u2019 Law received, and continues to receive, substantial attention.\", \"This article begins with a discussion the common information theoretical concepts of the two laws, and then examines each law with respect to its origins, theoretical formulation, theoretical development, research, and applications and examines the possible contributing factors responsible for the failure of Hick-Hyman Law to gain momentum in the field.\", \"HUMAN\\u2013COMPUTER INTERACTION, 2005, Volume 20, pp.\", \"315\\u2013352 Copyright \\u00a9 2005, Lawrence Erlbaum Associates, Inc. Steven Seow recently earned his Ph.D. in Experimental Psychology at Brown University.\", \"He is currently a Usability Engineer at Microsoft Corporation.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"other\", \"other\"], \"confs\": [1.0, 1.0, 0.8056, 0.7778, 0.6389, 0.6111, 0.6111]}\n",
            "prediction:  [0, [[\"The Hick-Hyman Law and Fitts\\u2019 Law are two surviving human performance principles based on Shannon and Weaver\\u2019s (1949) Information Theory.\", \"background_label\"], [\"In the early 1980s, Card, Moran, and Newell (1983) presented the laws as design principles for developers to maximize usability in the design of human\\u2013computer interfaces.\", \"background_label\"], [\"A search of the current human\\u2013computer interaction (HCI) literature, however, will reveal that the Hick-Hyman Law failed to gain momentum in the field of HCI, whereas Fitts\\u2019 Law received, and continues to receive, substantial attention.\", \"background_label\"], [\"This article begins with a discussion the common information theoretical concepts of the two laws, and then examines each law with respect to its origins, theoretical formulation, theoretical development, research, and applications and examines the possible contributing factors responsible for the failure of Hick-Hyman Law to gain momentum in the field.\", \"method_label\"], [\"HUMAN\\u2013COMPUTER INTERACTION, 2005, Volume 20, pp.\", \"other_label\"], [\"315\\u2013352 Copyright \\u00a9 2005, Lawrence Erlbaum Associates, Inc. Steven Seow recently earned his Ph.D. in Experimental Psychology at Brown University.\", \"result_label\"], [\"He is currently a Usability Engineer at Microsoft Corporation.\", \"result_label\"]]]\n",
            "\n",
            "input 37:  {\"abstract_id\": 0, \"sentences\": [\"Predicting the final state of a running process, the remaining time to completion or the next activity of a running process are important aspects of runtime process management.\", \"Runtime management requires the ability to identify processes that are at risk of not meeting certain criteria in order to offer case managers decision information for timely intervention.\", \"This in turn requires accurate prediction models for process outcomes and for the next process event, based on runtime information available at the prediction and decision point.\", \"In this paper, we describe an initial application of deep learning with recurrent neural networks to the problem of predicting the next process event.\", \"This is both a novel method in process prediction, which has previously relied on explicit process models in the form of Hidden Markov Models (HMM) or annotated transition systems, and also a novel application for deep learning methods.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\"], \"confs\": [1.0, 1.0, 1.0, 0.7931, 0.7241]}\n",
            "prediction:  [0, [[\"Predicting the final state of a running process, the remaining time to completion or the next activity of a running process are important aspects of runtime process management.\", \"background_label\"], [\"Runtime management requires the ability to identify processes that are at risk of not meeting certain criteria in order to offer case managers decision information for timely intervention.\", \"background_label\"], [\"This in turn requires accurate prediction models for process outcomes and for the next process event, based on runtime information available at the prediction and decision point.\", \"background_label\"], [\"In this paper, we describe an initial application of deep learning with recurrent neural networks to the problem of predicting the next process event.\", \"method_label\"], [\"This is both a novel method in process prediction, which has previously relied on explicit process models in the form of Hidden Markov Models (HMM) or annotated transition systems, and also a novel application for deep learning methods.\", \"method_label\"]]]\n",
            "\n",
            "input 38:  {\"abstract_id\": 0, \"sentences\": [\"Nowadays, the development of traditional business models become more and more mature that people use them to guide various kinds of E-business activities.\", \"Internet of things(IoT), being an innovative revolution over the Internet, becomes a new platform for E-business.\", \"However, old business models could hardly fit for the E-business on the IoT. In this article, we 1) propose an IoT E-business model, which is specially designed for the IoT E-business; 2) redesign many elements in traditional E-business models; 3) realize the transaction of smart property and paid data on the IoT with the help of P2P trade based on the Blockchain and smart contract.\", \"We also experiment our design and make a comprehensive discuss.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\"], \"confs\": [1.0, 1.0, 0.8214, 0.7143]}\n",
            "prediction:  [0, [[\"Nowadays, the development of traditional business models become more and more mature that people use them to guide various kinds of E-business activities.\", \"background_label\"], [\"Internet of things(IoT), being an innovative revolution over the Internet, becomes a new platform for E-business.\", \"background_label\"], [\"However, old business models could hardly fit for the E-business on the IoT. In this article, we 1) propose an IoT E-business model, which is specially designed for the IoT E-business; 2) redesign many elements in traditional E-business models; 3) realize the transaction of smart property and paid data on the IoT with the help of P2P trade based on the Blockchain and smart contract.\", \"method_label\"], [\"We also experiment our design and make a comprehensive discuss.\", \"result_label\"]]]\n",
            "\n",
            "input 39:  {\"abstract_id\": 0, \"sentences\": [\"Recently the cloud computing paradigm has been receiving significant excitement and attention in the media and blogosphere.\", \"To some, cloud computing seems to be little more than a marketing umbrella, encompassing topics such as distributed computing, grid computing, utility computing, and softwareas-a-service, that have already received significant research focus and commercial implementation.\", \"Nonetheless, there exist an increasing number of large companies that are offering cloud computing infrastructure products and services that do not entirely resemble the visions of these individual compo-\"], \"labels\": [\"background\", \"background\", \"background\"], \"confs\": [0.7, 0.7, 1.0]}\n",
            "prediction:  [0, [[\"Recently the cloud computing paradigm has been receiving significant excitement and attention in the media and blogosphere.\", \"background_label\"], [\"To some, cloud computing seems to be little more than a marketing umbrella, encompassing topics such as distributed computing, grid computing, utility computing, and softwareas-a-service, that have already received significant research focus and commercial implementation.\", \"background_label\"], [\"Nonetheless, there exist an increasing number of large companies that are offering cloud computing infrastructure products and services that do not entirely resemble the visions of these individual compo-\", \"background_label\"]]]\n",
            "\n",
            "input 40:  {\"abstract_id\": 0, \"sentences\": [\"Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures.\", \"The construction of such systems involves many distributed design choices.\", \"The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters.\", \"These parameters are often specified and hard-coded into the software by various developers or teams.\", \"If optimized jointly, these parameters can result in significant improvements.\", \"Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years.\", \"It promises greater automation so as to increase both product quality and human productivity.\", \"This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"objective\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6957]}\n",
            "prediction:  [0, [[\"Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures.\", \"background_label\"], [\"The construction of such systems involves many distributed design choices.\", \"background_label\"], [\"The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters.\", \"background_label\"], [\"These parameters are often specified and hard-coded into the software by various developers or teams.\", \"background_label\"], [\"If optimized jointly, these parameters can result in significant improvements.\", \"background_label\"], [\"Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years.\", \"method_label\"], [\"It promises greater automation so as to increase both product quality and human productivity.\", \"method_label\"], [\"This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications.\", \"result_label\"]]]\n",
            "\n",
            "input 41:  {\"abstract_id\": 0, \"sentences\": [\"In recent years social media has become more and more popular all around the world.\", \"This study aims to examine the influence of social media in the e-commerce context and to find how it impacts users' visit intention and purchase intention.\", \"Through a questionnaire survey, we test and analyze the research model and its related hypotheses by making use of structural equation modeling.\", \"The results indicate that social media interaction ties and social media commitment positively affect normative social influence and informational social influence.\", \"The last one in turn influences visit intention and purchase intention in e-commerce.\", \"In conclusion, we discuss the research findings and suggest some implications for researchers and practitioners.\"], \"labels\": [\"background\", \"objective\", \"method\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 0.7333, 1.0]}\n",
            "prediction:  [0, [[\"In recent years social media has become more and more popular all around the world.\", \"background_label\"], [\"This study aims to examine the influence of social media in the e-commerce context and to find how it impacts users' visit intention and purchase intention.\", \"objective_label\"], [\"Through a questionnaire survey, we test and analyze the research model and its related hypotheses by making use of structural equation modeling.\", \"method_label\"], [\"The results indicate that social media interaction ties and social media commitment positively affect normative social influence and informational social influence.\", \"result_label\"], [\"The last one in turn influences visit intention and purchase intention in e-commerce.\", \"result_label\"], [\"In conclusion, we discuss the research findings and suggest some implications for researchers and practitioners.\", \"result_label\"]]]\n",
            "\n",
            "input 42:  {\"abstract_id\": 0, \"sentences\": [\"Single carrier frequency division multiple access (SC-FDMA) which utilizes single carrier modulation at the transmitter and frequency domain equalization at the receiver is a technique that has similar performance and essentially the same overall structure as those of an OFDMA system.\", \"One prominent advantage over OFDMA is that the SC-FDMA signal has lower peak-to-average power ratio (PAPR).\", \"SC-FDMA has drawn great attention as an attractive alternative to OFDMA, especially in the uplink communications where lower PAPR greatly benefits the mobile terminal in terms of transmit power efficiency.\", \"SC-FDMA is currently a working assumption for the uplink multiple access scheme in 3GPP Long Term Evolution (LTE).\", \"In this paper, we give an in-depth overview of SC-FDMA with focus on physical layer and resource management aspects.\", \"We also show some research results on PAPR characteristics and channel-dependent resource scheduling of SC-FDMA.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"result\"], \"confs\": [1.0, 0.8158, 1.0, 0.8158, 0.6053, 0.6053]}\n",
            "prediction:  [0, [[\"Single carrier frequency division multiple access (SC-FDMA) which utilizes single carrier modulation at the transmitter and frequency domain equalization at the receiver is a technique that has similar performance and essentially the same overall structure as those of an OFDMA system.\", \"background_label\"], [\"One prominent advantage over OFDMA is that the SC-FDMA signal has lower peak-to-average power ratio (PAPR).\", \"background_label\"], [\"SC-FDMA has drawn great attention as an attractive alternative to OFDMA, especially in the uplink communications where lower PAPR greatly benefits the mobile terminal in terms of transmit power efficiency.\", \"background_label\"], [\"SC-FDMA is currently a working assumption for the uplink multiple access scheme in 3GPP Long Term Evolution (LTE).\", \"background_label\"], [\"In this paper, we give an in-depth overview of SC-FDMA with focus on physical layer and resource management aspects.\", \"objective_label\"], [\"We also show some research results on PAPR characteristics and channel-dependent resource scheduling of SC-FDMA.\", \"result_label\"]]]\n",
            "\n",
            "input 43:  {\"abstract_id\": 0, \"sentences\": [\"Since the publication of the first papers on event-related brain potentials (ERP) and language in the 1980s, the field of electrophysiology of language has evolved a great deal.\", \"This article is a brief overview of ERPs and languageprocessing research.\", \"It discusses how ERPs are derived, provides the pros and cons of using ERPs for language-processing research, and gives a summary of the major ERP components relevant to research on speech perception (mismatch negativity), word and sentence comprehension (N400, left anterior negativity, P600), and word production (lateralized readiness potential, N200).\", \"Additionally, it addresses current controversies concerning the interpretation of these components.\", \"Applications of the ERP technique are illustrated with research on first and second language acquisition, bilingualism, and aphasia.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"method\"], \"confs\": [1.0, 0.7419, 0.7419, 0.7419, 0.7419]}\n",
            "prediction:  [0, [[\"Since the publication of the first papers on event-related brain potentials (ERP) and language in the 1980s, the field of electrophysiology of language has evolved a great deal.\", \"background_label\"], [\"This article is a brief overview of ERPs and languageprocessing research.\", \"objective_label\"], [\"It discusses how ERPs are derived, provides the pros and cons of using ERPs for language-processing research, and gives a summary of the major ERP components relevant to research on speech perception (mismatch negativity), word and sentence comprehension (N400, left anterior negativity, P600), and word production (lateralized readiness potential, N200).\", \"method_label\"], [\"Additionally, it addresses current controversies concerning the interpretation of these components.\", \"method_label\"], [\"Applications of the ERP technique are illustrated with research on first and second language acquisition, bilingualism, and aphasia.\", \"result_label\"]]]\n",
            "\n",
            "input 44:  {\"abstract_id\": 0, \"sentences\": [\"The core component of most modern trackers is a discriminative classifier, tasked with distinguishing between the target and the surrounding environment.\", \"To cope with natural image changes, this classifier is typically trained with translated and scaled sample patches.\", \"Such sets of samples are riddled with redundancies\\u2014any overlapping pixels are constrained to be the same.\", \"Based on this simple observation, we propose an analytic model for datasets of thousands of translated patches.\", \"By showing that the resulting data matrix is circulant, we can diagonalize it with the discrete Fourier transform, reducing both storage and computation by several orders of magnitude.\", \"Interestingly, for linear regression our formulation is equivalent to a correlation filter, used by some of the fastest competitive trackers.\", \"For kernel regression, however, we derive a new kernelized correlation filter (KCF), that unlike other kernel algorithms has the exact same complexity as its linear counterpart.\", \"Building on it, we also propose a fast multi-channel extension of linear correlation filters, via a linear kernel, which we call dual correlation filter (DCF).\", \"Both KCF and DCF outperform top-ranking trackers such as Struck or TLD on a 50 videos benchmark, despite running at hundreds of frames-per-second, and being implemented in a few lines of code (Algorithm 1).\", \"To encourage further developments, our tracking framework was made open-source.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\"], \"confs\": [0.8158, 0.7895, 0.7895, 0.6053, 0.8158, 0.6053, 0.8158, 1.0, 0.7895, 0.6316]}\n",
            "prediction:  [0, [[\"The core component of most modern trackers is a discriminative classifier, tasked with distinguishing between the target and the surrounding environment.\", \"background_label\"], [\"To cope with natural image changes, this classifier is typically trained with translated and scaled sample patches.\", \"background_label\"], [\"Such sets of samples are riddled with redundancies\\u2014any overlapping pixels are constrained to be the same.\", \"background_label\"], [\"Based on this simple observation, we propose an analytic model for datasets of thousands of translated patches.\", \"objective_label\"], [\"By showing that the resulting data matrix is circulant, we can diagonalize it with the discrete Fourier transform, reducing both storage and computation by several orders of magnitude.\", \"method_label\"], [\"Interestingly, for linear regression our formulation is equivalent to a correlation filter, used by some of the fastest competitive trackers.\", \"method_label\"], [\"For kernel regression, however, we derive a new kernelized correlation filter (KCF), that unlike other kernel algorithms has the exact same complexity as its linear counterpart.\", \"method_label\"], [\"Building on it, we also propose a fast multi-channel extension of linear correlation filters, via a linear kernel, which we call dual correlation filter (DCF).\", \"method_label\"], [\"Both KCF and DCF outperform top-ranking trackers such as Struck or TLD on a 50 videos benchmark, despite running at hundreds of frames-per-second, and being implemented in a few lines of code (Algorithm 1).\", \"result_label\"], [\"To encourage further developments, our tracking framework was made open-source.\", \"result_label\"]]]\n",
            "\n",
            "input 45:  {\"abstract_id\": 0, \"sentences\": [\"This paper identifies 10 essential aspects, which, if not taken into account in an information security governance plan, will surely cause the plan to fail, or at least, cause serious flaws in the plan.\", \"These 10 aspects can be used as a checklist by management to ensure that a comprehensive plan has been defined and introduced.\", \"a 2004 Elsevier Ltd. All rights reserved.\"], \"labels\": [\"objective\", \"method\", \"other\"], \"confs\": [0.7083, 0.75, 1.0]}\n",
            "prediction:  [0, [[\"This paper identifies 10 essential aspects, which, if not taken into account in an information security governance plan, will surely cause the plan to fail, or at least, cause serious flaws in the plan.\", \"background_label\"], [\"These 10 aspects can be used as a checklist by management to ensure that a comprehensive plan has been defined and introduced.\", \"method_label\"], [\"a 2004 Elsevier Ltd. All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 46:  {\"abstract_id\": 0, \"sentences\": [\"Deep learning methods for 3D human pose estimation from RGB images require a huge amount of domain-specific labeled data for good in-the-wild performance.\", \"However, obtaining annotated 3D pose data requires a complex motion capture setup which is generally limited to controlled settings.\", \"We propose a semi-supervised learning method using a structure-aware loss function which is able to utilize abundant 2D data to learn 3D information.\", \"Furthermore, we present a simple temporal network which uses additional context present in pose sequences to improve and temporally harmonize the pose estimates.\", \"Our complete pipeline improves upon the state-of-the-art by 11.8%, and works at 30 FPS on a commodity graphics card.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.7419, 0.7419, 0.7742, 1.0, 0.7419]}\n",
            "prediction:  [0, [[\"Deep learning methods for 3D human pose estimation from RGB images require a huge amount of domain-specific labeled data for good in-the-wild performance.\", \"background_label\"], [\"However, obtaining annotated 3D pose data requires a complex motion capture setup which is generally limited to controlled settings.\", \"background_label\"], [\"We propose a semi-supervised learning method using a structure-aware loss function which is able to utilize abundant 2D data to learn 3D information.\", \"method_label\"], [\"Furthermore, we present a simple temporal network which uses additional context present in pose sequences to improve and temporally harmonize the pose estimates.\", \"method_label\"], [\"Our complete pipeline improves upon the state-of-the-art by 11.8%, and works at 30 FPS on a commodity graphics card.\", \"result_label\"]]]\n",
            "\n",
            "input 47:  {\"abstract_id\": 0, \"sentences\": [\"Attention based neural network models have been successfully applied in answer selection, which is an important subtask of question answering (QA).\", \"These models often represent a question by a single vector and find its corresponding matches by attending to candidate answers.\", \"However, questions and answers might be related to each other in complicated ways which cannot be captured by single-vector representations.\", \"In this paper, we propose Multihop Attention Networks (MAN) which aim to uncover these complex relations for ranking question and answer pairs.\", \"Unlike previous models, we do not collapse the question into a single vector, instead we use multiple vectors which focus on different parts of the question for its overall semantic representation and apply multiple steps of attention to learn representations for the candidate answers.\", \"For each attention step, in addition to common attention mechanisms, we adopt sequential attention which utilizes context information for computing context-aware attention weights.\", \"Via extensive experiments, we show that MAN outperforms state-of-the-art approaches on popular benchmark QA datasets.\", \"Empirical studies confirm the effectiveness of sequential attention over other attention mechanisms.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 0.6818, 1.0, 1.0, 0.6818, 1.0]}\n",
            "prediction:  [0, [[\"Attention based neural network models have been successfully applied in answer selection, which is an important subtask of question answering (QA).\", \"background_label\"], [\"These models often represent a question by a single vector and find its corresponding matches by attending to candidate answers.\", \"background_label\"], [\"However, questions and answers might be related to each other in complicated ways which cannot be captured by single-vector representations.\", \"background_label\"], [\"In this paper, we propose Multihop Attention Networks (MAN) which aim to uncover these complex relations for ranking question and answer pairs.\", \"objective_label\"], [\"Unlike previous models, we do not collapse the question into a single vector, instead we use multiple vectors which focus on different parts of the question for its overall semantic representation and apply multiple steps of attention to learn representations for the candidate answers.\", \"method_label\"], [\"For each attention step, in addition to common attention mechanisms, we adopt sequential attention which utilizes context information for computing context-aware attention weights.\", \"method_label\"], [\"Via extensive experiments, we show that MAN outperforms state-of-the-art approaches on popular benchmark QA datasets.\", \"result_label\"], [\"Empirical studies confirm the effectiveness of sequential attention over other attention mechanisms.\", \"result_label\"]]]\n",
            "\n",
            "input 48:  {\"abstract_id\": 0, \"sentences\": [\"Group data sharing in cloud environments has become a hot topic in recent decades.\", \"With the popularity of cloud computing, how to achieve secure and efficient data sharing in cloud environments is an urgent problem to be solved.\", \"In addition, how to achieve both anonymity and traceability is also a challenge in the cloud for data sharing.\", \"This paper focuses on enabling data sharing and storage for the same group in the cloud with high security and efficiency in an anonymous manner.\", \"By leveraging the key agreement and the group signature, a novel traceable group data sharing scheme is proposed to support anonymous multiple users in public clouds.\", \"On the one hand, group members can communicate anonymously with respect to the group signature, and the real identities of members can be traced if necessary.\", \"On the other hand, a common conference key is derived based on the key agreement to enable group members to share and store their data securely.\", \"Note that a symmetric balanced incomplete block design is utilized for key generation, which substantially reduces the burden on members to derive a common conference key.\", \"Both theoretical and experimental analyses demonstrate that the proposed scheme is secure and efficient for group data sharing in cloud computing.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.7931, 0.8378, 0.7838, 0.7838, 0.6216, 0.6216, 0.8378, 1.0]}\n",
            "prediction:  [0, [[\"Group data sharing in cloud environments has become a hot topic in recent decades.\", \"background_label\"], [\"With the popularity of cloud computing, how to achieve secure and efficient data sharing in cloud environments is an urgent problem to be solved.\", \"background_label\"], [\"In addition, how to achieve both anonymity and traceability is also a challenge in the cloud for data sharing.\", \"background_label\"], [\"This paper focuses on enabling data sharing and storage for the same group in the cloud with high security and efficiency in an anonymous manner.\", \"objective_label\"], [\"By leveraging the key agreement and the group signature, a novel traceable group data sharing scheme is proposed to support anonymous multiple users in public clouds.\", \"method_label\"], [\"On the one hand, group members can communicate anonymously with respect to the group signature, and the real identities of members can be traced if necessary.\", \"method_label\"], [\"On the other hand, a common conference key is derived based on the key agreement to enable group members to share and store their data securely.\", \"method_label\"], [\"Note that a symmetric balanced incomplete block design is utilized for key generation, which substantially reduces the burden on members to derive a common conference key.\", \"method_label\"], [\"Both theoretical and experimental analyses demonstrate that the proposed scheme is secure and efficient for group data sharing in cloud computing.\", \"result_label\"]]]\n",
            "\n",
            "input 49:  {\"abstract_id\": 0, \"sentences\": [\"We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting.\", \"Focusing on logistic regression, we show that using L1 regularization of the parameters, the sample complexity (i.e., the number of training examples required to learn \\\"well,\\\") grows only logarithmically in the number of irrelevant features.\", \"This logarithmic rate matches the best known bounds for feature selection, and indicates that L1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples.\", \"We also give a lower-bound showing that any rotationally invariant algorithm---including logistic regression with L2 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\"], \"confs\": [0.6053, 0.6053, 0.6053, 0.7895]}\n",
            "prediction:  [0, [[\"We consider supervised learning in the presence of very many irrelevant features, and study two different regularization methods for preventing overfitting.\", \"background_label\"], [\"Focusing on logistic regression, we show that using L1 regularization of the parameters, the sample complexity (i.e., the number of training examples required to learn \\\"well,\\\") grows only logarithmically in the number of irrelevant features.\", \"method_label\"], [\"This logarithmic rate matches the best known bounds for feature selection, and indicates that L1 regularized logistic regression can be effective even if there are exponentially many irrelevant features as there are training examples.\", \"method_label\"], [\"We also give a lower-bound showing that any rotationally invariant algorithm---including logistic regression with L2 regularization, SVMs, and neural networks trained by backpropagation---has a worst case sample complexity that grows at least linearly in the number of irrelevant features.\", \"result_label\"]]]\n",
            "\n",
            "input 50:  {\"abstract_id\": 0, \"sentences\": [\"Clustering, in data mining, is useful to discover distribution patterns in the underlying data.\", \"Clustering algorithms usually employ a distance metric based (e.g., euclidean) similarity measure in order to partition the database such that data points in the same partition are more similar than points in different partitions.\", \"In this paper, we study clustering algorithms for data with boolean and categorical attributes.\", \"We show that traditional clustering algorithms that use distances between points for clustering are not appropriate for boolean and categorical attributes.\", \"Instead, we propose a novel concept of links to measure the similarity/proximity between a pair of data points.\", \"We develop a robust hierarchical clustering algorithm ROCK that employs links and not distances when merging clusters.\", \"Our methods naturally extend to non-metric similarity measures that are relevant in situations where a domain expert/similarity table is the only source of knowledge.\", \"In addition to presenting detailed complexity results for ROCK, we also conduct an experimental study with real-life as well as synthetic data sets to demonstrate the effectiveness of our techniques.\", \"For data with categorical attributes, our findings indicate that ROCK not only generates better quality clusters than traditional algorithms, but it also exhibits good scalability properties.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.7895, 0.7895, 0.6053, 0.7895, 0.8158, 0.8158, 0.7895, 1.0]}\n",
            "prediction:  [0, [[\"Clustering, in data mining, is useful to discover distribution patterns in the underlying data.\", \"background_label\"], [\"Clustering algorithms usually employ a distance metric based (e.g., euclidean) similarity measure in order to partition the database such that data points in the same partition are more similar than points in different partitions.\", \"background_label\"], [\"In this paper, we study clustering algorithms for data with boolean and categorical attributes.\", \"objective_label\"], [\"We show that traditional clustering algorithms that use distances between points for clustering are not appropriate for boolean and categorical attributes.\", \"method_label\"], [\"Instead, we propose a novel concept of links to measure the similarity/proximity between a pair of data points.\", \"method_label\"], [\"We develop a robust hierarchical clustering algorithm ROCK that employs links and not distances when merging clusters.\", \"method_label\"], [\"Our methods naturally extend to non-metric similarity measures that are relevant in situations where a domain expert/similarity table is the only source of knowledge.\", \"method_label\"], [\"In addition to presenting detailed complexity results for ROCK, we also conduct an experimental study with real-life as well as synthetic data sets to demonstrate the effectiveness of our techniques.\", \"result_label\"], [\"For data with categorical attributes, our findings indicate that ROCK not only generates better quality clusters than traditional algorithms, but it also exhibits good scalability properties.\", \"result_label\"]]]\n",
            "\n",
            "input 51:  {\"abstract_id\": 0, \"sentences\": [\"Instant messaging (IM) has become one of the most popular forms of computer-mediated communication (CMC) and is especially prevalent on college campuses.\", \"Previous research suggests that IM users often multitask while conversing online.\", \"To date, no one has yet examined the cognitive effect of concurrent IM use.\", \"Participants in the present study (N = 69) completed a reading comprehension task uninterrupted or while concurrently holding an IM conversation.\", \"Participants who IMed while performing the reading task took significantly longer to complete the task, indicating that concurrent IM use negatively affects efficiency.\", \"Concurrent IM use did not affect reading comprehension scores.\", \"Additional analyses revealed that the more time participants reported spending on IM, the lower their reading comprehension scores.\", \"Finally, we found that the more time participants reported spending on IM, the lower their self-reported GPA.\", \"Implications and future directions are discussed.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"method\", \"result\", \"result\", \"other\"], \"confs\": [1.0, 1.0, 1.0, 0.8286, 0.6, 0.7714, 0.8286, 1.0, 0.6]}\n",
            "prediction:  [0, [[\"Instant messaging (IM) has become one of the most popular forms of computer-mediated communication (CMC) and is especially prevalent on college campuses.\", \"background_label\"], [\"Previous research suggests that IM users often multitask while conversing online.\", \"background_label\"], [\"To date, no one has yet examined the cognitive effect of concurrent IM use.\", \"background_label\"], [\"Participants in the present study (N = 69) completed a reading comprehension task uninterrupted or while concurrently holding an IM conversation.\", \"background_label\"], [\"Participants who IMed while performing the reading task took significantly longer to complete the task, indicating that concurrent IM use negatively affects efficiency.\", \"result_label\"], [\"Concurrent IM use did not affect reading comprehension scores.\", \"result_label\"], [\"Additional analyses revealed that the more time participants reported spending on IM, the lower their reading comprehension scores.\", \"result_label\"], [\"Finally, we found that the more time participants reported spending on IM, the lower their self-reported GPA.\", \"result_label\"], [\"Implications and future directions are discussed.\", \"result_label\"]]]\n",
            "\n",
            "input 52:  {\"abstract_id\": 0, \"sentences\": [\"This paper presents the analogue of the time or frequency scaling theorem of continuous time/frequency Fourier Transform (FT) to the realm of Discrete Fourier Transform (DFT).\", \"The scaling property applies to scaling by integers which are relatively prime to the length of the DFT.\", \"The time reversal property of DFT is identified as a special case of this theorem.\"], \"labels\": [\"objective\", \"method\", \"result\"], \"confs\": [0.7419, 0.7419, 1.0]}\n",
            "prediction:  [0, [[\"This paper presents the analogue of the time or frequency scaling theorem of continuous time/frequency Fourier Transform (FT) to the realm of Discrete Fourier Transform (DFT).\", \"background_label\"], [\"The scaling property applies to scaling by integers which are relatively prime to the length of the DFT.\", \"background_label\"], [\"The time reversal property of DFT is identified as a special case of this theorem.\", \"result_label\"]]]\n",
            "\n",
            "input 53:  {\"abstract_id\": 0, \"sentences\": [\"Waterfall development is still a widely used way of working in software development companies.\", \"Many problems have been reported related to the model.\", \"Commonly accepted problems are for example to cope with change and that defects all too often are detected too late in the software development process.\", \"However, many of the problems mentioned in literature are based on beliefs and experiences, and not on empirical evidence.\", \"To address this research gap, we compare the problems in literature with the results of a case study at Ericsson AB in Sweden, investigating issues in the waterfall model.\", \"The case study aims at validating or contradicting the beliefs of what the problems are in waterfall development through empirical research.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"result\"], \"confs\": [0.6, 0.6, 0.8, 0.6, 0.6, 0.8]}\n",
            "prediction:  [0, [[\"Waterfall development is still a widely used way of working in software development companies.\", \"background_label\"], [\"Many problems have been reported related to the model.\", \"background_label\"], [\"Commonly accepted problems are for example to cope with change and that defects all too often are detected too late in the software development process.\", \"background_label\"], [\"However, many of the problems mentioned in literature are based on beliefs and experiences, and not on empirical evidence.\", \"background_label\"], [\"To address this research gap, we compare the problems in literature with the results of a case study at Ericsson AB in Sweden, investigating issues in the waterfall model.\", \"method_label\"], [\"The case study aims at validating or contradicting the beliefs of what the problems are in waterfall development through empirical research.\", \"result_label\"]]]\n",
            "\n",
            "input 54:  {\"abstract_id\": 0, \"sentences\": [\"Soil testing is the basis for nutrient recommendation and formulated fertilization.\", \"This study presented a brief overview of potentiometric electrochemical sensors (ISE and ISFET) for soil NPK detection.\", \"The opportunities and challenges for electrochemical sensors in soil testing were\"], \"labels\": [\"background\", \"objective\", \"result\"], \"confs\": [0.75, 0.75, 0.75]}\n",
            "prediction:  [0, [[\"Soil testing is the basis for nutrient recommendation and formulated fertilization.\", \"background_label\"], [\"This study presented a brief overview of potentiometric electrochemical sensors (ISE and ISFET) for soil NPK detection.\", \"objective_label\"], [\"The opportunities and challenges for electrochemical sensors in soil testing were\", \"result_label\"]]]\n",
            "\n",
            "input 55:  {\"abstract_id\": 0, \"sentences\": [\"The seemingly unshakeable accuracy of Moore's law - which states that the speed of computers; as measured by the number of transistors that can be placed on a single chip, will double every year or two - has been credited with being the engine of the electronics revolution, and is regarded as the premier example of a self-fulfilling prophecy and technological trajectory in both the academic and popular press.\", \"Although many factors have kept Moore's law as an industry benchmark, it is the entry of foreign competition that seems to have played a critical role in maintaining the pace of Moore's law in the early VLSI transition.\", \"Many different kinds of chips used many competing logic families.\", \"DRAMs and microprocessors became critical to the semiconductor industry, yet were unknown during the original formulation of Moore's law\"], \"labels\": [\"background\", \"background\", \"background\", \"background\"], \"confs\": [1.0, 1.0, 1.0, 0.6154]}\n",
            "prediction:  [0, [[\"The seemingly unshakeable accuracy of Moore's law - which states that the speed of computers; as measured by the number of transistors that can be placed on a single chip, will double every year or two - has been credited with being the engine of the electronics revolution, and is regarded as the premier example of a self-fulfilling prophecy and technological trajectory in both the academic and popular press.\", \"background_label\"], [\"Although many factors have kept Moore's law as an industry benchmark, it is the entry of foreign competition that seems to have played a critical role in maintaining the pace of Moore's law in the early VLSI transition.\", \"background_label\"], [\"Many different kinds of chips used many competing logic families.\", \"background_label\"], [\"DRAMs and microprocessors became critical to the semiconductor industry, yet were unknown during the original formulation of Moore's law\", \"result_label\"]]]\n",
            "\n",
            "input 56:  {\"abstract_id\": 0, \"sentences\": [\"ive Text Summarization using Sequence-to-sequence RNNs and Beyond Ramesh Nallapati IBM\", \"Watson nallapati@us.ibm.com Bowen Zhou IBM\", \"Watson zhou@us.ibm.com Cicero dos Santos\", \"IBM Watson\"], \"labels\": [\"background\", \"other\", \"other\", \"other\"], \"confs\": [0.75, 0.75, 0.75, 0.75]}\n",
            "prediction:  [0, [[\"ive Text Summarization using Sequence-to-sequence RNNs and Beyond Ramesh Nallapati IBM\", \"background_label\"], [\"Watson nallapati@us.ibm.com Bowen Zhou IBM\", \"background_label\"], [\"Watson zhou@us.ibm.com Cicero dos Santos\", \"other_label\"], [\"IBM Watson\", \"other_label\"]]]\n",
            "\n",
            "input 57:  {\"abstract_id\": 0, \"sentences\": [\"This paper measures flow in the context of gamification and investigates the psychometric properties of the Dispositional Flow Scale-2 (DFS-2).\", \"We employ data gathered from users of an exercise gamification service (N = 200).\", \"The results show that the original DFS-2 factorial structure does result in a similar model fit as the original work.\", \"However, we also present a factorial respecification that satisfies more recent model fit thresholds.\", \"Beyond validating the original DFS-2 instrument in the context of gamification, the psychometric analysis and the respecifications suggest that the components of flow divide into highly correlated conditions of flow (which were also found to be more salient in the context of gamification: autotelic experience, balance of skill and challenge, control, clear goals, and feedback) and into possible outcomes (merging action-awareness, concentration, loss of sense of time, and loss of selfconsciousness) from achieving flow.\", \"2014 Elsevier Ltd.\", \"All rights reserved.\"], \"labels\": [\"objective\", \"result\", \"result\", \"result\", \"result\", \"other\", \"other\"], \"confs\": [1.0, 0.7368, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"This paper measures flow in the context of gamification and investigates the psychometric properties of the Dispositional Flow Scale-2 (DFS-2).\", \"background_label\"], [\"We employ data gathered from users of an exercise gamification service (N = 200).\", \"method_label\"], [\"The results show that the original DFS-2 factorial structure does result in a similar model fit as the original work.\", \"result_label\"], [\"However, we also present a factorial respecification that satisfies more recent model fit thresholds.\", \"method_label\"], [\"Beyond validating the original DFS-2 instrument in the context of gamification, the psychometric analysis and the respecifications suggest that the components of flow divide into highly correlated conditions of flow (which were also found to be more salient in the context of gamification: autotelic experience, balance of skill and challenge, control, clear goals, and feedback) and into possible outcomes (merging action-awareness, concentration, loss of sense of time, and loss of selfconsciousness) from achieving flow.\", \"result_label\"], [\"2014 Elsevier Ltd.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 58:  {\"abstract_id\": 0, \"sentences\": [\"Many machine learning algorithms require the input to be represented as a fixed-length feature vector.\", \"When it comes to texts, one of the most common fixed-length features is bag-of-words.\", \"Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words.\", \"For example, \\u201cpowerful,\\u201d \\u201cstrong\\u201d and \\u201cParis\\u201d are equally distant.\", \"In this paper, we proposeParagraph Vector , an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.\", \"Our algorithm represents each document by a dense vector which is trained to predict words in the document.\", \"Its construction gives our algorithm the potential to overcome the weaknesses of bag-ofwords models.\", \"Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations.\", \"Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.8108, 0.8108, 0.8108, 0.8108, 0.8108, 0.6216, 0.8108, 0.6216, 0.8108]}\n",
            "prediction:  [0, [[\"Many machine learning algorithms require the input to be represented as a fixed-length feature vector.\", \"background_label\"], [\"When it comes to texts, one of the most common fixed-length features is bag-of-words.\", \"background_label\"], [\"Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words.\", \"background_label\"], [\"For example, \\u201cpowerful,\\u201d \\u201cstrong\\u201d and \\u201cParis\\u201d are equally distant.\", \"background_label\"], [\"In this paper, we proposeParagraph Vector , an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents.\", \"objective_label\"], [\"Our algorithm represents each document by a dense vector which is trained to predict words in the document.\", \"method_label\"], [\"Its construction gives our algorithm the potential to overcome the weaknesses of bag-ofwords models.\", \"method_label\"], [\"Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations.\", \"result_label\"], [\"Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.\", \"result_label\"]]]\n",
            "\n",
            "input 59:  {\"abstract_id\": 0, \"sentences\": [\"The world of telecommunications, especially mobile communications, continues to evolve with innovative technologies and high-speed data services.\", \"In many economies, mobile phones have overtaken fixed lines.\", \"In this dynamic context, we have envisaged to study mobile communication diffusion in Germany and India, from a historical comparative perspective.\", \"The basic standard for comparison has been Global Systems for Mobile Communications (GSM) and its data services, which was adopted by both economies.\", \"Subsequently, critical success factors in each economy is drawn and compared with the other, to elicit future directions.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 0.7419, 0.7419, 0.7419]}\n",
            "prediction:  [0, [[\"The world of telecommunications, especially mobile communications, continues to evolve with innovative technologies and high-speed data services.\", \"background_label\"], [\"In many economies, mobile phones have overtaken fixed lines.\", \"background_label\"], [\"In this dynamic context, we have envisaged to study mobile communication diffusion in Germany and India, from a historical comparative perspective.\", \"objective_label\"], [\"The basic standard for comparison has been Global Systems for Mobile Communications (GSM) and its data services, which was adopted by both economies.\", \"method_label\"], [\"Subsequently, critical success factors in each economy is drawn and compared with the other, to elicit future directions.\", \"result_label\"]]]\n",
            "\n",
            "input 60:  {\"abstract_id\": 0, \"sentences\": [\"Evolutionary algorithms (EAs) have the tendency to converge quickly into a single solution in the search space.\", \"However, many complex search problems require the identification and maintenance of multiple solutions.\", \"Niching methods are the extension of EAs to address this issue.\", \"In our study, we propose an evolution strategy (ES) niching method, based on the covariance matrix adaptation (CMA) mechanism.\", \"We analyze our algorithm, introduce an experimental setup, and compare its performance with a previous ES niching method, known as the ES dynamic niching algorithm.\", \"In our comparison we introduce for the first time a new analytical tool for niching analysis, and in particular the early niching formation process.\", \"Based on successful data fit, we propose the well-known logistic model to describe our experimental results.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.7857, 0.7857, 0.7143, 1.0, 0.7143, 0.7857, 1.0]}\n",
            "prediction:  [0, [[\"Evolutionary algorithms (EAs) have the tendency to converge quickly into a single solution in the search space.\", \"background_label\"], [\"However, many complex search problems require the identification and maintenance of multiple solutions.\", \"background_label\"], [\"Niching methods are the extension of EAs to address this issue.\", \"background_label\"], [\"In our study, we propose an evolution strategy (ES) niching method, based on the covariance matrix adaptation (CMA) mechanism.\", \"method_label\"], [\"We analyze our algorithm, introduce an experimental setup, and compare its performance with a previous ES niching method, known as the ES dynamic niching algorithm.\", \"method_label\"], [\"In our comparison we introduce for the first time a new analytical tool for niching analysis, and in particular the early niching formation process.\", \"method_label\"], [\"Based on successful data fit, we propose the well-known logistic model to describe our experimental results.\", \"result_label\"]]]\n",
            "\n",
            "input 61:  {\"abstract_id\": 0, \"sentences\": [\"0: Typically, COTS undergo frequent upgrades.\", \"1: Organizations while deploying these upgrades ensure the correctness of existing systems by carrying out exhaustive regression tests.\", \"2: This process is typically costly and time-consuming.\", \"3: An efficient approach to regression testing would be to execute a subset of the system test suite that provides sufficient confidence in the system behavior.\", \"4: In that respect, we have developed a test framework that facilitates capturing and modeling of component interactions.\", \"5: These interactions are analyzed to select a subset of test cases to be executed during regression testing.\", \"6: The approach has been applied to a web-based system and the results obtained are quite promising.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.9274, 0.9604, 0.8219, 0.8907, 0.8483, 0.8813]}\n",
            "prediction:  [0, [[\"0: Typically, COTS undergo frequent upgrades.\", \"background_label\"], [\"1: Organizations while deploying these upgrades ensure the correctness of existing systems by carrying out exhaustive regression tests.\", \"background_label\"], [\"2: This process is typically costly and time-consuming.\", \"background_label\"], [\"3: An efficient approach to regression testing would be to execute a subset of the system test suite that provides sufficient confidence in the system behavior.\", \"method_label\"], [\"4: In that respect, we have developed a test framework that facilitates capturing and modeling of component interactions.\", \"method_label\"], [\"5: These interactions are analyzed to select a subset of test cases to be executed during regression testing.\", \"method_label\"], [\"6: The approach has been applied to a web-based system and the results obtained are quite promising.\", \"result_label\"]]]\n",
            "\n",
            "input 62:  {\"abstract_id\": 0, \"sentences\": [\"In this study, modeling and simulation of a speed sensored field-oriented control (FOC) of a permanent magnet synchronous motor (PMSM) drive is developed by using MATLAB Function blocks in MATLAB/Simulink.\", \"This method allows easier algorithm and software development stages for experimental studies compared to the classical block diagram approach.\", \"The superiority of the method over commonly used \\\"Code Generation\\\" tools is also emphasized.\", \"First, a MATLAB/Simulink model of the FOC of PMSM drive is developed by using MATLAB programming in MATLAB Functions similar to C coding techniques.\", \"The results of the simulation are presented.\", \"Then, the MATLAB programming based codes developed in simulation are implemented in a TMS320F28335 floating-point MCU by using C programming language and the experimental results are obtained.\", \"Finally, the results of the simulation and experiments are compared.\"], \"labels\": [\"method\", \"method\", \"method\", \"result\", \"result\", \"result\", \"result\"], \"confs\": [0.6053, 1.0, 0.7895, 0.6053, 1.0, 0.6053, 1.0]}\n",
            "prediction:  [0, [[\"In this study, modeling and simulation of a speed sensored field-oriented control (FOC) of a permanent magnet synchronous motor (PMSM) drive is developed by using MATLAB Function blocks in MATLAB/Simulink.\", \"background_label\"], [\"This method allows easier algorithm and software development stages for experimental studies compared to the classical block diagram approach.\", \"method_label\"], [\"The superiority of the method over commonly used \\\"Code Generation\\\" tools is also emphasized.\", \"method_label\"], [\"First, a MATLAB/Simulink model of the FOC of PMSM drive is developed by using MATLAB programming in MATLAB Functions similar to C coding techniques.\", \"method_label\"], [\"The results of the simulation are presented.\", \"result_label\"], [\"Then, the MATLAB programming based codes developed in simulation are implemented in a TMS320F28335 floating-point MCU by using C programming language and the experimental results are obtained.\", \"result_label\"], [\"Finally, the results of the simulation and experiments are compared.\", \"result_label\"]]]\n",
            "\n",
            "input 63:  {\"abstract_id\": 0, \"sentences\": [\"0: This article deals with a ring\\u2013mesh network design problem arising from the deployment of an optical transport network.\", \"1: The problem seeks to partition the set of demand pairs to a number of rings and a mesh cluster, and to determine the location of the optical cross-connect system (OXC), while minimizing the total cost of optical add-drop multiplexers (OADMs), OXCs, and fiber links.\", \"2: We formulate this problem as a zero-one integer programming problem.\", \"3: In strengthening the formulation, we develop some valid inequalities for the zero-one quadratic (knapsack) polytope and a columngeneration formulation that eliminates the symmetry of ring configurations.\", \"4: Also, we prescribe an effective tabu search procedure for finding a goodquality feasible solution, which is also used as a starting column for the column generation procedure.\", \"5: Computational results show that the proposed solution procedure provides tight lower and upper bounds within a reasonable time bound.\"], \"labels\": [\"objective\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.9609, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"0: This article deals with a ring\\u2013mesh network design problem arising from the deployment of an optical transport network.\", \"background_label\"], [\"1: The problem seeks to partition the set of demand pairs to a number of rings and a mesh cluster, and to determine the location of the optical cross-connect system (OXC), while minimizing the total cost of optical add-drop multiplexers (OADMs), OXCs, and fiber links.\", \"objective_label\"], [\"2: We formulate this problem as a zero-one integer programming problem.\", \"method_label\"], [\"3: In strengthening the formulation, we develop some valid inequalities for the zero-one quadratic (knapsack) polytope and a columngeneration formulation that eliminates the symmetry of ring configurations.\", \"method_label\"], [\"4: Also, we prescribe an effective tabu search procedure for finding a goodquality feasible solution, which is also used as a starting column for the column generation procedure.\", \"method_label\"], [\"5: Computational results show that the proposed solution procedure provides tight lower and upper bounds within a reasonable time bound.\", \"result_label\"]]]\n",
            "\n",
            "input 64:  {\"abstract_id\": 0, \"sentences\": [\"The video game software industry has a reputation for volatile, chaotic projects yet, in spite of dramatic growth in global revenues, surprisingly little academic work has examined these projects.\", \"This study reports a preliminary investigation into this under-researched area.\", \"We interviewed eight video game producers from a range of companies, using a critical incident method to explore risk management practices and risk perceptions.\", \"Our results revealed that in lieu of formal risk management practices, these managers relied on prototyping, pre-production decision points, and agile approaches to contain risk on their projects.\", \"Among the risk factors mentioned, two are specific to the unique context of video game development.\", \"The risk of failing to match the development strategy to the project was identified as a major cause of problems during the development process, and a new risk - the 'fun factor' - was a key element threatening the success of the final game release.\"], \"labels\": [\"background\", \"objective\", \"method\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"The video game software industry has a reputation for volatile, chaotic projects yet, in spite of dramatic growth in global revenues, surprisingly little academic work has examined these projects.\", \"background_label\"], [\"This study reports a preliminary investigation into this under-researched area.\", \"background_label\"], [\"We interviewed eight video game producers from a range of companies, using a critical incident method to explore risk management practices and risk perceptions.\", \"method_label\"], [\"Our results revealed that in lieu of formal risk management practices, these managers relied on prototyping, pre-production decision points, and agile approaches to contain risk on their projects.\", \"result_label\"], [\"Among the risk factors mentioned, two are specific to the unique context of video game development.\", \"method_label\"], [\"The risk of failing to match the development strategy to the project was identified as a major cause of problems during the development process, and a new risk - the 'fun factor' - was a key element threatening the success of the final game release.\", \"result_label\"]]]\n",
            "\n",
            "input 65:  {\"abstract_id\": 0, \"sentences\": [\"Phase noise is a topic of theoretical and practical interest in electronic circuits, as well as in other fields such as optics.\", \"Although progress has been made in understanding the phenomenon, there still remain significant gaps, both in its fundamental theory and in numerical techniques for its characterisation.\", \"In this paper, we develop a solid foundation for phase noise that is valid for any oscillator, regardless of operating mechanism.\", \"We establish novel results about the dynamics of stable nonlinear oscillators in the presence of perturbations, both deterministic and random.\", \"We obtain an exact, nonlinear equation for phase error, which we solve without approximations for random perturbations.\", \"This leads us to a precise characterisation of timing jitter and spectral dispersion, for computing which we develop efficient numerical methods.\", \"We demonstrate our techniques on practical electrical oscillators, and obtain good matches with measurements even at frequencies close to the carrier, where previous techniques break down.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [0.8532, 0.8532, 0.6606, 0.7529, 1.0, 0.633, 0.633]}\n",
            "prediction:  [0, [[\"Phase noise is a topic of theoretical and practical interest in electronic circuits, as well as in other fields such as optics.\", \"background_label\"], [\"Although progress has been made in understanding the phenomenon, there still remain significant gaps, both in its fundamental theory and in numerical techniques for its characterisation.\", \"background_label\"], [\"In this paper, we develop a solid foundation for phase noise that is valid for any oscillator, regardless of operating mechanism.\", \"objective_label\"], [\"We establish novel results about the dynamics of stable nonlinear oscillators in the presence of perturbations, both deterministic and random.\", \"method_label\"], [\"We obtain an exact, nonlinear equation for phase error, which we solve without approximations for random perturbations.\", \"method_label\"], [\"This leads us to a precise characterisation of timing jitter and spectral dispersion, for computing which we develop efficient numerical methods.\", \"method_label\"], [\"We demonstrate our techniques on practical electrical oscillators, and obtain good matches with measurements even at frequencies close to the carrier, where previous techniques break down.\", \"result_label\"]]]\n",
            "\n",
            "input 66:  {\"abstract_id\": 0, \"sentences\": [\"The Self-Organizing Map (SOM) algorithm has attracted an ever increasing amount of interest among researches and practitioners in a wide variety of elds.\", \"The SOM and a variant of it, the LVQ, have been analyzed extensively, a number of variants of them have been developed and, perhaps most notably, they have been applied extensively within elds ranging from engineering sciences to medicine, biology, and economics.\", \"We have collected a comprehensive list of 3343 scienti c papers that use the algorithms, have bene ted from them, or contain analyses of them.\", \"The list is intended to serve as a source for literature surveys.\", \"We have provided both a thematic and a keyword index to help nding articles of interest.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.8, 0.6, 0.8, 0.8]}\n",
            "prediction:  [0, [[\"The Self-Organizing Map (SOM) algorithm has attracted an ever increasing amount of interest among researches and practitioners in a wide variety of elds.\", \"background_label\"], [\"The SOM and a variant of it, the LVQ, have been analyzed extensively, a number of variants of them have been developed and, perhaps most notably, they have been applied extensively within elds ranging from engineering sciences to medicine, biology, and economics.\", \"background_label\"], [\"We have collected a comprehensive list of 3343 scienti c papers that use the algorithms, have bene ted from them, or contain analyses of them.\", \"method_label\"], [\"The list is intended to serve as a source for literature surveys.\", \"method_label\"], [\"We have provided both a thematic and a keyword index to help nding articles of interest.\", \"result_label\"]]]\n",
            "\n",
            "input 67:  {\"abstract_id\": 0, \"sentences\": [\"Recently, there are many approaches proposed for mining roles using automated technologies.\", \"However, it lacks a tool set that can be used to aid the application of role mining approaches and update role states.\", \"In this demonstration, we introduce a tool set, RMiner, which is based on the core of WEKA, an open source data mining tool.\", \"RMiner implements most of the classic and latest role mining algorithms and provides interactive tools for administrator to update role states.\", \"The running examples of RMiner are presented to demonstrate the effectiveness of the tool set.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.7895, 0.6053, 0.6053, 0.7895, 0.7895]}\n",
            "prediction:  [0, [[\"Recently, there are many approaches proposed for mining roles using automated technologies.\", \"background_label\"], [\"However, it lacks a tool set that can be used to aid the application of role mining approaches and update role states.\", \"background_label\"], [\"In this demonstration, we introduce a tool set, RMiner, which is based on the core of WEKA, an open source data mining tool.\", \"method_label\"], [\"RMiner implements most of the classic and latest role mining algorithms and provides interactive tools for administrator to update role states.\", \"method_label\"], [\"The running examples of RMiner are presented to demonstrate the effectiveness of the tool set.\", \"result_label\"]]]\n",
            "\n",
            "input 68:  {\"abstract_id\": 0, \"sentences\": [\"Many Collaborative Filtering (CF) algorithms are item-based in the sense that they analyze item-item relations in order to produce item similarities.\", \"Recently, several works in the field of Natural Language Processing (NLP) suggested to learn a latent representation of words using neural embedding algorithms.\", \"Among them, the Skip-gram with Negative Sampling (SGNS), also known as word2vec, was shown to provide state-of-the-art results on various linguistics tasks.\", \"In this paper, we show that item-based CF can be cast in the same framework of neural word embedding.\", \"Inspired by SGNS, we describe a method we name item2vec for item-based CF that produces embedding for items in a latent space.\", \"The method is capable of inferring item-item relations even when user information is not available.\", \"We present experimental results that demonstrate the effectiveness of the item2vec method and show it is competitive with SVD.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7742, 0.7742, 1.0, 0.7419, 1.0]}\n",
            "prediction:  [0, [[\"Many Collaborative Filtering (CF) algorithms are item-based in the sense that they analyze item-item relations in order to produce item similarities.\", \"background_label\"], [\"Recently, several works in the field of Natural Language Processing (NLP) suggested to learn a latent representation of words using neural embedding algorithms.\", \"background_label\"], [\"Among them, the Skip-gram with Negative Sampling (SGNS), also known as word2vec, was shown to provide state-of-the-art results on various linguistics tasks.\", \"background_label\"], [\"In this paper, we show that item-based CF can be cast in the same framework of neural word embedding.\", \"method_label\"], [\"Inspired by SGNS, we describe a method we name item2vec for item-based CF that produces embedding for items in a latent space.\", \"method_label\"], [\"The method is capable of inferring item-item relations even when user information is not available.\", \"method_label\"], [\"We present experimental results that demonstrate the effectiveness of the item2vec method and show it is competitive with SVD.\", \"result_label\"]]]\n",
            "\n",
            "input 69:  {\"abstract_id\": 0, \"sentences\": [\"This paper systematically investigates the design of single transistor second-order active filters out-lining all possible architectures and possible impedance settings using an exhaustive MAPLE search code for all stable cases with the minimum number of passive elements (two resistors and two energy storage elements).\", \"The search is performed on six general voltage-input voltage-output transfer functions, derived using a small-signal two-port network transistor model.\", \"Selected LC and RC filter designs are verified experimentally.\", \"The results presented here fill both a circuit-theoretic gap and an application-oriented gap related to single transistor filter design which, apart from a few examples in the literature, has not been rigorously addressed.\"], \"labels\": [\"objective\", \"method\", \"method\", \"result\"], \"confs\": [0.7333, 1.0, 0.7667, 1.0]}\n",
            "prediction:  [0, [[\"This paper systematically investigates the design of single transistor second-order active filters out-lining all possible architectures and possible impedance settings using an exhaustive MAPLE search code for all stable cases with the minimum number of passive elements (two resistors and two energy storage elements).\", \"background_label\"], [\"The search is performed on six general voltage-input voltage-output transfer functions, derived using a small-signal two-port network transistor model.\", \"method_label\"], [\"Selected LC and RC filter designs are verified experimentally.\", \"method_label\"], [\"The results presented here fill both a circuit-theoretic gap and an application-oriented gap related to single transistor filter design which, apart from a few examples in the literature, has not been rigorously addressed.\", \"result_label\"]]]\n",
            "\n",
            "input 70:  {\"abstract_id\": 0, \"sentences\": [\"Many industrial applications with real-time demands are composed of mixed sets of tasks with a variety of requirements.\", \"These can be in the form of standard timing constraints, such as period and deadline, or complex, e.g., to express application specific or non temporal constraints, reliability, performance, etc.\", \"Arrival patterns determin e whether tasks will be treated as periodic, sporadic, or aperiodic.\", \"As many algorithms focus on specific sets of task types and constraints only, system design has to focus on those supported by a particular algorithm, at the expense\"], \"labels\": [\"background\", \"background\", \"background\", \"background\"], \"confs\": [1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Many industrial applications with real-time demands are composed of mixed sets of tasks with a variety of requirements.\", \"background_label\"], [\"These can be in the form of standard timing constraints, such as period and deadline, or complex, e.g., to express application specific or non temporal constraints, reliability, performance, etc.\", \"background_label\"], [\"Arrival patterns determin e whether tasks will be treated as periodic, sporadic, or aperiodic.\", \"background_label\"], [\"As many algorithms focus on specific sets of task types and constraints only, system design has to focus on those supported by a particular algorithm, at the expense\", \"result_label\"]]]\n",
            "\n",
            "input 71:  {\"abstract_id\": 0, \"sentences\": [\"Object detection performance, as measured on the canonical PASCAL VOC Challenge datasets, plateaued in the final years of the competition.\", \"The best-performing methods were complex ensemble systems that typically combined multiple low-level image features with high-level context.\", \"In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 50 percent relative to the previous best result on VOC 2012-achieving a mAP of 62.4 percent.\", \"Our approach combines two ideas: (1) one can apply high-capacity convolutional networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data are scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, boosts performance significantly.\", \"Since we combine region proposals with CNNs, we call the resulting model an R-CNN or Region-based Convolutional Network.\", \"Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"result\", \"other\"], \"confs\": [0.75, 0.75, 0.75, 0.75, 0.75, 1.0]}\n",
            "prediction:  [0, [[\"Object detection performance, as measured on the canonical PASCAL VOC Challenge datasets, plateaued in the final years of the competition.\", \"background_label\"], [\"The best-performing methods were complex ensemble systems that typically combined multiple low-level image features with high-level context.\", \"background_label\"], [\"In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 50 percent relative to the previous best result on VOC 2012-achieving a mAP of 62.4 percent.\", \"objective_label\"], [\"Our approach combines two ideas: (1) one can apply high-capacity convolutional networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data are scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, boosts performance significantly.\", \"method_label\"], [\"Since we combine region proposals with CNNs, we call the resulting model an R-CNN or Region-based Convolutional Network.\", \"method_label\"], [\"Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.\", \"other_label\"]]]\n",
            "\n",
            "input 72:  {\"abstract_id\": 0, \"sentences\": [\"Having developed multiobjective optimization algorithms using evolutionary optimization methods and demonstrated their niche on various practical problems involving mostly two and three objectives, there is now a growing need for developing evolutionary multiobjective optimization (EMO) algorithms for handling many-objective (having four or more objectives) optimization problems.\", \"In this paper, we recognize a few recent efforts and discuss a number of viable directions for developing a potential EMO algorithm for solving many-objective optimization problems.\", \"Thereafter, we suggest a reference-point-based many-objective evolutionary algorithm following NSGA-II framework (we call it NSGA-III) that emphasizes population members that are nondominated, yet close to a set of supplied reference points.\", \"The proposed NSGA-III is applied to a number of many-objective test problems with three to 15 objectives and compared with two versions of a recently suggested EMO algorithm (MOEA/D).\", \"While each of the two MOEA/D methods works well on different classes of problems, the proposed NSGA-III is found to produce satisfactory results on all problems considered in this paper.\", \"This paper presents results on unconstrained problems, and the sequel paper considers constrained and other specialties in handling many-objective optimization problems.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.7419, 1.0, 0.7419, 0.7742, 0.7742, 1.0]}\n",
            "prediction:  [0, [[\"Having developed multiobjective optimization algorithms using evolutionary optimization methods and demonstrated their niche on various practical problems involving mostly two and three objectives, there is now a growing need for developing evolutionary multiobjective optimization (EMO) algorithms for handling many-objective (having four or more objectives) optimization problems.\", \"background_label\"], [\"In this paper, we recognize a few recent efforts and discuss a number of viable directions for developing a potential EMO algorithm for solving many-objective optimization problems.\", \"background_label\"], [\"Thereafter, we suggest a reference-point-based many-objective evolutionary algorithm following NSGA-II framework (we call it NSGA-III) that emphasizes population members that are nondominated, yet close to a set of supplied reference points.\", \"method_label\"], [\"The proposed NSGA-III is applied to a number of many-objective test problems with three to 15 objectives and compared with two versions of a recently suggested EMO algorithm (MOEA/D).\", \"method_label\"], [\"While each of the two MOEA/D methods works well on different classes of problems, the proposed NSGA-III is found to produce satisfactory results on all problems considered in this paper.\", \"result_label\"], [\"This paper presents results on unconstrained problems, and the sequel paper considers constrained and other specialties in handling many-objective optimization problems.\", \"result_label\"]]]\n",
            "\n",
            "input 73:  {\"abstract_id\": 0, \"sentences\": [\"The main contribution of this paper is an approach for introducing additional context into state-of-the-art general object detection.\", \"To achieve this we first combine a state-ofthe-art classifier (Residual-101 [14]) with a fast detection framework (SSD [18]).\", \"We then augment SSD+Residual101 with deconvolution layers to introduce additional largescale context in object detection and improve accuracy, especially for small objects, calling our resulting system DSSD for deconvolutional single shot detector.\", \"While these two contributions are easily described at a high-level, a naive implementation does not succeed.\", \"Instead we show that carefully adding additional stages of learned transformations, specifically a module for feed-forward connections in deconvolution and a new output module, enables this new approach and forms a potential way forward for further detection research.\", \"Results are shown on both PASCAL VOC and COCO detection.\", \"Our DSSD with 513 \\u00d7 513 input achieves 81.5% mAP on VOC2007 test, 80.0% mAP on VOC2012 test, and 33.2% mAP on COCO, outperforming a state-of-the-art method R-FCN [3] on each dataset.\"], \"labels\": [\"background\", \"method\", \"method\", \"background\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.7143, 0.7143, 0.75, 0.7143, 0.7143, 0.7143]}\n",
            "prediction:  [0, [[\"The main contribution of this paper is an approach for introducing additional context into state-of-the-art general object detection.\", \"objective_label\"], [\"To achieve this we first combine a state-ofthe-art classifier (Residual-101 [14]) with a fast detection framework (SSD [18]).\", \"method_label\"], [\"We then augment SSD+Residual101 with deconvolution layers to introduce additional largescale context in object detection and improve accuracy, especially for small objects, calling our resulting system DSSD for deconvolutional single shot detector.\", \"method_label\"], [\"While these two contributions are easily described at a high-level, a naive implementation does not succeed.\", \"method_label\"], [\"Instead we show that carefully adding additional stages of learned transformations, specifically a module for feed-forward connections in deconvolution and a new output module, enables this new approach and forms a potential way forward for further detection research.\", \"method_label\"], [\"Results are shown on both PASCAL VOC and COCO detection.\", \"result_label\"], [\"Our DSSD with 513 \\u00d7 513 input achieves 81.5% mAP on VOC2007 test, 80.0% mAP on VOC2012 test, and 33.2% mAP on COCO, outperforming a state-of-the-art method R-FCN [3] on each dataset.\", \"result_label\"]]]\n",
            "\n",
            "input 74:  {\"abstract_id\": 0, \"sentences\": [\"Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data.\", \"The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive.\", \"A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses.\", \"However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on-chip storage of a multi-chip system.\", \"This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost.\", \"In this article, we introduce a custom multi-chip machine-learning architecture along those lines.\", \"We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system.\", \"We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 1.0, 0.75, 0.75, 0.75, 1.0, 0.75]}\n",
            "prediction:  [0, [[\"Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data.\", \"background_label\"], [\"The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive.\", \"background_label\"], [\"A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses.\", \"background_label\"], [\"However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on-chip storage of a multi-chip system.\", \"background_label\"], [\"This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost.\", \"background_label\"], [\"In this article, we introduce a custom multi-chip machine-learning architecture along those lines.\", \"method_label\"], [\"We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system.\", \"method_label\"], [\"We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects.\", \"method_label\"]]]\n",
            "\n",
            "input 75:  {\"abstract_id\": 0, \"sentences\": [\"Large-pose face alignment is a very challenging problem in computer vision, which is used as a prerequisite for many important vision tasks, e.g, face recognition and 3D face reconstruction.\", \"Recently, there have been a few attempts to solve this problem, but still more research is needed to achieve highly accurate results.\", \"In this paper, we propose a face alignment method for large-pose face images, by combining the powerful cascaded CNN regressor method and 3DMM.\", \"We formulate the face alignment as a 3DMM fitting problem, where the camera projection matrix and 3D shape parameters are estimated by a cascade of CNN-based regressors.\", \"The dense 3D shape allows us to design pose-invariant appearance features for effective CNN learning.\", \"Extensive experiments are conducted on the challenging databases (AFLW and AFW), with comparison to the state of the art.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.6, 0.8, 0.8, 0.6571]}\n",
            "prediction:  [0, [[\"Large-pose face alignment is a very challenging problem in computer vision, which is used as a prerequisite for many important vision tasks, e.g, face recognition and 3D face reconstruction.\", \"background_label\"], [\"Recently, there have been a few attempts to solve this problem, but still more research is needed to achieve highly accurate results.\", \"background_label\"], [\"In this paper, we propose a face alignment method for large-pose face images, by combining the powerful cascaded CNN regressor method and 3DMM.\", \"method_label\"], [\"We formulate the face alignment as a 3DMM fitting problem, where the camera projection matrix and 3D shape parameters are estimated by a cascade of CNN-based regressors.\", \"method_label\"], [\"The dense 3D shape allows us to design pose-invariant appearance features for effective CNN learning.\", \"method_label\"], [\"Extensive experiments are conducted on the challenging databases (AFLW and AFW), with comparison to the state of the art.\", \"result_label\"]]]\n",
            "\n",
            "input 76:  {\"abstract_id\": 0, \"sentences\": [\"What will 5G be?\", \"What it will not be is an incremental advance on 4G.\", \"The previous four generations of cellular technology have each been a major paradigm shift that has broken backward compatibility.\", \"Indeed, 5G will need to be a paradigm shift that includes very high carrier frequencies with massive bandwidths, extreme base station and device densities, and unprecedented numbers of antennas.\", \"However, unlike the previous four generations, it will also be highly integrative: tying any new 5G air interface and spectrum together with LTE and WiFi to provide universal high-rate coverage and a seamless user experience.\", \"To support this, the core network will also have to reach unprecedented levels of flexibility and intelligence, spectrum regulation will need to be rethought and improved, and energy and cost efficiencies will become even more critical considerations.\", \"This paper discusses all of these topics, identifying key challenges for future research and preliminary 5G standardization activities, while providing a comprehensive overview of the current literature, and in particular of the papers appearing in this special issue.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"method\"], \"confs\": [0.6111, 0.6111, 1.0, 1.0, 0.8056, 0.6111, 0.6111]}\n",
            "prediction:  [0, [[\"What will 5G be?\", \"background_label\"], [\"What it will not be is an incremental advance on 4G.\", \"background_label\"], [\"The previous four generations of cellular technology have each been a major paradigm shift that has broken backward compatibility.\", \"background_label\"], [\"Indeed, 5G will need to be a paradigm shift that includes very high carrier frequencies with massive bandwidths, extreme base station and device densities, and unprecedented numbers of antennas.\", \"background_label\"], [\"However, unlike the previous four generations, it will also be highly integrative: tying any new 5G air interface and spectrum together with LTE and WiFi to provide universal high-rate coverage and a seamless user experience.\", \"background_label\"], [\"To support this, the core network will also have to reach unprecedented levels of flexibility and intelligence, spectrum regulation will need to be rethought and improved, and energy and cost efficiencies will become even more critical considerations.\", \"background_label\"], [\"This paper discusses all of these topics, identifying key challenges for future research and preliminary 5G standardization activities, while providing a comprehensive overview of the current literature, and in particular of the papers appearing in this special issue.\", \"result_label\"]]]\n",
            "\n",
            "input 77:  {\"abstract_id\": 0, \"sentences\": [\"The success of deep learning has been a catalyst to solving increasingly complex machine-learning problems, which often involve multiple data modalities.\", \"We review recent advances in deep multimodal learning and highlight the state-of the art, as well as gaps and challenges in this active research field.\", \"We first classify deep multimodal learning architectures and then discuss methods to fuse learned multimodal representations in deep-learning architectures.\", \"We highlight two areas of research&#x02013;regularization strategies and methods that learn or optimize multimodal fusion structures&#x02013;as exciting areas for future work.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\"], \"confs\": [1.0, 1.0, 0.76, 0.76]}\n",
            "prediction:  [0, [[\"The success of deep learning has been a catalyst to solving increasingly complex machine-learning problems, which often involve multiple data modalities.\", \"background_label\"], [\"We review recent advances in deep multimodal learning and highlight the state-of the art, as well as gaps and challenges in this active research field.\", \"objective_label\"], [\"We first classify deep multimodal learning architectures and then discuss methods to fuse learned multimodal representations in deep-learning architectures.\", \"method_label\"], [\"We highlight two areas of research&#x02013;regularization strategies and methods that learn or optimize multimodal fusion structures&#x02013;as exciting areas for future work.\", \"result_label\"]]]\n",
            "\n",
            "input 78:  {\"abstract_id\": 0, \"sentences\": [\"Engineers and researchers in the automobile industry have tried to design and build safer automobiles, but traffic accidents are unavoidable.\", \"Patterns involved in dangerous crashes could be detected if we develop accurate prediction models capable of automatic classification of type of injury severity of various traffic accidents.\", \"These behavioral and roadway accident patterns can be useful to develop traffic safety control policies.\", \"We believe that to obtain the greatest possible accident reduction effects with limited budgetary resources, it is important that measures be based on scientific and objective surveys of the causes of accidents and severity of injuries.\", \"This paper summarizes the performance of four machine learning paradigms applied to modeling the severity of injury that occurred during traffic accidents.\", \"We considered neural networks trained using hybrid learning approaches, support vector machines, decision trees and a concurrent hybrid model involving decision trees and neural networks.\", \"Experiment results reveal that among the machine learning paradigms considered the hybrid decision tree-neural network approach outperformed the individual approaches.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.7241, 0.7241, 0.7241, 0.7241, 0.7241, 1.0]}\n",
            "prediction:  [0, [[\"Engineers and researchers in the automobile industry have tried to design and build safer automobiles, but traffic accidents are unavoidable.\", \"background_label\"], [\"Patterns involved in dangerous crashes could be detected if we develop accurate prediction models capable of automatic classification of type of injury severity of various traffic accidents.\", \"background_label\"], [\"These behavioral and roadway accident patterns can be useful to develop traffic safety control policies.\", \"background_label\"], [\"We believe that to obtain the greatest possible accident reduction effects with limited budgetary resources, it is important that measures be based on scientific and objective surveys of the causes of accidents and severity of injuries.\", \"method_label\"], [\"This paper summarizes the performance of four machine learning paradigms applied to modeling the severity of injury that occurred during traffic accidents.\", \"method_label\"], [\"We considered neural networks trained using hybrid learning approaches, support vector machines, decision trees and a concurrent hybrid model involving decision trees and neural networks.\", \"method_label\"], [\"Experiment results reveal that among the machine learning paradigms considered the hybrid decision tree-neural network approach outperformed the individual approaches.\", \"result_label\"]]]\n",
            "\n",
            "input 79:  {\"abstract_id\": 0, \"sentences\": [\"This paper introduces GEOS, the first automated system to solve unaltered SAT geometry questions by combining text understanding and diagram interpretation.\", \"We model the problem of understanding geometry questions as submodular optimization, and identify a formal problem description likely to be compatible with both the question text and diagram.\", \"GEOS then feeds the description to a geometric solver that attempts to determine the correct answer.\", \"In our experiments, GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions.1 Finally, we show that by integrating textual and visual information, GEOS boosts the accuracy of dependency and semantic parsing of the question text.\"], \"labels\": [\"objective\", \"objective\", \"method\", \"result\"], \"confs\": [0.8, 0.6, 0.8, 1.0]}\n",
            "prediction:  [0, [[\"This paper introduces GEOS, the first automated system to solve unaltered SAT geometry questions by combining text understanding and diagram interpretation.\", \"background_label\"], [\"We model the problem of understanding geometry questions as submodular optimization, and identify a formal problem description likely to be compatible with both the question text and diagram.\", \"method_label\"], [\"GEOS then feeds the description to a geometric solver that attempts to determine the correct answer.\", \"method_label\"], [\"In our experiments, GEOS achieves a 49% score on official SAT questions, and a score of 61% on practice questions.1 Finally, we show that by integrating textual and visual information, GEOS boosts the accuracy of dependency and semantic parsing of the question text.\", \"result_label\"]]]\n",
            "\n",
            "input 80:  {\"abstract_id\": 0, \"sentences\": [\"The Internet, World Wide Web, and related ICTs, have rapidly spread to a large number of countries and great variety of cultures.\", \"Many of these technologies facilitate and mediate activities whose modes and means bind closely to culture.\", \"Research has suggested that communication technologies can affect values and norms for behavior.\", \"Therefore, this research aims to explore and describe the impact of IT on culture, using Saudi Arabia as a context for our study.\", \"In particular, we are interested in answering the following question: How does IT impact culture?\", \"We use phenomenological method, and provide an integration of a framework for IT-driven impact on culture.\", \"The resulting framework can serve as a basis for further investigation to understand individuals\\u2019 culturally linked behavior to various IT in diverse contexts The ultimate goal is to lay a foundation for much needed research on the IT role in cultural change.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7895, 0.6053, 0.6053, 0.8158, 0.8158]}\n",
            "prediction:  [0, [[\"The Internet, World Wide Web, and related ICTs, have rapidly spread to a large number of countries and great variety of cultures.\", \"background_label\"], [\"Many of these technologies facilitate and mediate activities whose modes and means bind closely to culture.\", \"background_label\"], [\"Research has suggested that communication technologies can affect values and norms for behavior.\", \"background_label\"], [\"Therefore, this research aims to explore and describe the impact of IT on culture, using Saudi Arabia as a context for our study.\", \"objective_label\"], [\"In particular, we are interested in answering the following question: How does IT impact culture?\", \"objective_label\"], [\"We use phenomenological method, and provide an integration of a framework for IT-driven impact on culture.\", \"method_label\"], [\"The resulting framework can serve as a basis for further investigation to understand individuals\\u2019 culturally linked behavior to various IT in diverse contexts The ultimate goal is to lay a foundation for much needed research on the IT role in cultural change.\", \"result_label\"]]]\n",
            "\n",
            "input 81:  {\"abstract_id\": 0, \"sentences\": [\"The role of frameworks in information systems has recently received a great deal of critical attention.\", \"One prominent indictment, which has been directed at even commonly accepted frameworks, is that they lack empirical support, and in fact are not constructed in operational terminology.\", \"This article reports the results of an experimental ab study using MBA students as subjects to investigate the tenets of the Gorry and Scott Morton framework (Gorry and Scott Morton, 1971).\", \"While firm support is found for the assumption that the level of information attributes varies across system type in the direction postulated, there is evidence that the ability to differentiate the component attributes is affected by such factors as field dependency and mode of presentation.\"], \"labels\": [\"background\", \"background\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7273, 0.7273]}\n",
            "prediction:  [0, [[\"The role of frameworks in information systems has recently received a great deal of critical attention.\", \"background_label\"], [\"One prominent indictment, which has been directed at even commonly accepted frameworks, is that they lack empirical support, and in fact are not constructed in operational terminology.\", \"background_label\"], [\"This article reports the results of an experimental ab study using MBA students as subjects to investigate the tenets of the Gorry and Scott Morton framework (Gorry and Scott Morton, 1971).\", \"method_label\"], [\"While firm support is found for the assumption that the level of information attributes varies across system type in the direction postulated, there is evidence that the ability to differentiate the component attributes is affected by such factors as field dependency and mode of presentation.\", \"result_label\"]]]\n",
            "\n",
            "input 82:  {\"abstract_id\": 0, \"sentences\": [\"With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and the recent success of deep learning techniques in various fields, deep neural networks have increasingly been leveraged to learn discriminative representations for automatic FER.\", \"Recent deep FER systems generally focus on two important issues: overfitting caused by a lack of sufficient training data and expression-unrelated variations, such as illumination, head pose and identity bias.\", \"In this paper, we provide a comprehensive survey on deep FER, including datasets and algorithms that provide insights into these intrinsic problems.\", \"First, we introduce the available datasets that are widely used in the literature and provide accepted data selection and evaluation principles for these datasets.\", \"We then describe the standard pipeline of a deep FER system with the related background knowledge and suggestions of applicable implementations for each stage.\", \"For the state of the art in deep FER, we review existing novel deep neural networks and related training strategies that are designed for FER based on both static images and dynamic image sequences, and discuss their advantages and limitations.\", \"Competitive performances on widely used benchmarks are also summarized in this section.\", \"We then extend our survey to additional related issues and application scenarios.\", \"Finally, we review the remaining challenges and corresponding opportunities in this field as well as future directions for the design of robust deep FER systems.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7308, 1.0, 1.0, 1.0, 0.7308, 0.7308, 0.8077]}\n",
            "prediction:  [0, [[\"With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and the recent success of deep learning techniques in various fields, deep neural networks have increasingly been leveraged to learn discriminative representations for automatic FER.\", \"background_label\"], [\"Recent deep FER systems generally focus on two important issues: overfitting caused by a lack of sufficient training data and expression-unrelated variations, such as illumination, head pose and identity bias.\", \"background_label\"], [\"In this paper, we provide a comprehensive survey on deep FER, including datasets and algorithms that provide insights into these intrinsic problems.\", \"objective_label\"], [\"First, we introduce the available datasets that are widely used in the literature and provide accepted data selection and evaluation principles for these datasets.\", \"method_label\"], [\"We then describe the standard pipeline of a deep FER system with the related background knowledge and suggestions of applicable implementations for each stage.\", \"method_label\"], [\"For the state of the art in deep FER, we review existing novel deep neural networks and related training strategies that are designed for FER based on both static images and dynamic image sequences, and discuss their advantages and limitations.\", \"method_label\"], [\"Competitive performances on widely used benchmarks are also summarized in this section.\", \"method_label\"], [\"We then extend our survey to additional related issues and application scenarios.\", \"method_label\"], [\"Finally, we review the remaining challenges and corresponding opportunities in this field as well as future directions for the design of robust deep FER systems.\", \"result_label\"]]]\n",
            "\n",
            "input 83:  {\"abstract_id\": 0, \"sentences\": [\"Advertisers are demanding more accurate estimates of the impact of targeted advertisements, yet no study proposes an appropriate methodology to analyze the effectiveness of a targeted advertising campaign, and there is a dearth of empirical evidence on the effectiveness of targeted advertising as a whole.\", \"The targeted population is more likely to convert from advertising so the response lift between the targeted and untargeted group to the advertising is likely an overestimate of the impact of targeted advertising.\", \"We propose a difference-in-differences estimator to account for this selection bias by decomposing the impact of targeting into selection bias and treatment effects components.\", \"Using several large-scale online advertising campaigns, we test the effectiveness of targeted advertising on brand-related searches and clickthrough rates.\", \"We find that the treatment effect on the targeted group is about twice as large for brand-related searches, but naively estimating this effect without taking into account selection bias leads to an overestimation of the lift from targeting on brand-related searches by almost 1,000%.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.8333, 0.6333, 0.8333, 0.7333, 1.0]}\n",
            "prediction:  [0, [[\"Advertisers are demanding more accurate estimates of the impact of targeted advertisements, yet no study proposes an appropriate methodology to analyze the effectiveness of a targeted advertising campaign, and there is a dearth of empirical evidence on the effectiveness of targeted advertising as a whole.\", \"background_label\"], [\"The targeted population is more likely to convert from advertising so the response lift between the targeted and untargeted group to the advertising is likely an overestimate of the impact of targeted advertising.\", \"background_label\"], [\"We propose a difference-in-differences estimator to account for this selection bias by decomposing the impact of targeting into selection bias and treatment effects components.\", \"method_label\"], [\"Using several large-scale online advertising campaigns, we test the effectiveness of targeted advertising on brand-related searches and clickthrough rates.\", \"method_label\"], [\"We find that the treatment effect on the targeted group is about twice as large for brand-related searches, but naively estimating this effect without taking into account selection bias leads to an overestimation of the lift from targeting on brand-related searches by almost 1,000%.\", \"result_label\"]]]\n",
            "\n",
            "input 84:  {\"abstract_id\": 0, \"sentences\": [\"In the course of the More Electric Aircraft program frequently active three-phase rectifiers in the power range of several kilowatts are required.\", \"It is shown that the three-phase -switch rectifier (comprising three -connected bidirectional switches) is well suited for this application.\", \"The system is analyzed using space vector calculus and a novel PWM current controller modulation concept is presented, where all three phases are controlled simultaneously; the analysis shows that the proposed concept yields optimal switching sequences.\", \"Analytical relationships for calculating the power components average and rms current ratings are derived to facilitate the rectifier design.\", \"A laboratory prototype with an output power of 5 kW is built and measurements taken from this prototype confirm the operation of the proposed current controller.\", \"Finally, initial EMI-measurements of the system are also presented.\"], \"labels\": [\"background\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.6154, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"In the course of the More Electric Aircraft program frequently active three-phase rectifiers in the power range of several kilowatts are required.\", \"background_label\"], [\"It is shown that the three-phase -switch rectifier (comprising three -connected bidirectional switches) is well suited for this application.\", \"background_label\"], [\"The system is analyzed using space vector calculus and a novel PWM current controller modulation concept is presented, where all three phases are controlled simultaneously; the analysis shows that the proposed concept yields optimal switching sequences.\", \"method_label\"], [\"Analytical relationships for calculating the power components average and rms current ratings are derived to facilitate the rectifier design.\", \"method_label\"], [\"A laboratory prototype with an output power of 5 kW is built and measurements taken from this prototype confirm the operation of the proposed current controller.\", \"method_label\"], [\"Finally, initial EMI-measurements of the system are also presented.\", \"result_label\"]]]\n",
            "\n",
            "input 85:  {\"abstract_id\": 0, \"sentences\": [\"While significant attention has been recently focused on designing supervised deep semantic segmentation algorithms for vision tasks, there are many domains in which sufficient supervised pixel-level labels are difficult to obtain.\", \"In this paper, we revisit the problem of purely unsupervised image segmentation and propose a novel deep architecture for this problem.\", \"We borrow recent ideas from supervised semantic segmentation methods, in particular by concatenating two fully convolutional networks together into an autoencoder\\u2014one for encoding and one for decoding.\", \"The encoding layer produces a k-way pixelwise prediction, and both the reconstruction error of the autoencoder as well as the normalized cut produced by the encoder are jointly minimized during training.\", \"When combined with suitable postprocessing involving conditional random field smoothing and hierarchical segmentation, our resulting algorithm achieves impressive results on the benchmark Berkeley Segmentation Data Set, outperforming a number of competing methods.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.7419, 0.7742, 0.7742, 0.7742]}\n",
            "prediction:  [0, [[\"While significant attention has been recently focused on designing supervised deep semantic segmentation algorithms for vision tasks, there are many domains in which sufficient supervised pixel-level labels are difficult to obtain.\", \"background_label\"], [\"In this paper, we revisit the problem of purely unsupervised image segmentation and propose a novel deep architecture for this problem.\", \"objective_label\"], [\"We borrow recent ideas from supervised semantic segmentation methods, in particular by concatenating two fully convolutional networks together into an autoencoder\\u2014one for encoding and one for decoding.\", \"method_label\"], [\"The encoding layer produces a k-way pixelwise prediction, and both the reconstruction error of the autoencoder as well as the normalized cut produced by the encoder are jointly minimized during training.\", \"method_label\"], [\"When combined with suitable postprocessing involving conditional random field smoothing and hierarchical segmentation, our resulting algorithm achieves impressive results on the benchmark Berkeley Segmentation Data Set, outperforming a number of competing methods.\", \"result_label\"]]]\n",
            "\n",
            "input 86:  {\"abstract_id\": 0, \"sentences\": [\"Which digital camera should I buy?\", \"What is the best holiday for me and my family?\", \"Which is the best investment for supporting the education of my children?\", \"Which movie should I rent?\", \"Which web sites will I find interesting?\", \"Which book should I buy for my next vacation?\", \"Which degree and university are the best for my future?\"], \"labels\": [\"other\", \"other\", \"other\", \"other\", \"other\", \"other\", \"other\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Which digital camera should I buy?\", \"background_label\"], [\"What is the best holiday for me and my family?\", \"background_label\"], [\"Which is the best investment for supporting the education of my children?\", \"background_label\"], [\"Which movie should I rent?\", \"background_label\"], [\"Which web sites will I find interesting?\", \"background_label\"], [\"Which book should I buy for my next vacation?\", \"background_label\"], [\"Which degree and university are the best for my future?\", \"result_label\"]]]\n",
            "\n",
            "input 87:  {\"abstract_id\": 0, \"sentences\": [\"Host-based security tools such as anti-virus and intrusion detection systems are not adequately protected on today's computers.\", \"Malware is often designed to immediately disable any security tools upon installation, rendering them useless.\", \"While current research has focused on moving these vulnerable security tools into an isolated virtual machine, this approach cripples security tools by preventing them from doing active monitoring.\", \"This paper describes an architecture that takes a hybrid approach, giving security tools the ability to do active monitoring while still benefiting from the increased security of an isolated virtual machine.\", \"We discuss the architecture and a prototype implementation that can process hooks from a virtual machine running Windows XP on Xen.\", \"We conclude with a security analysis and show the performance of a single hook to be 28 musecs in the best case.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.8158, 0.8158, 0.8158, 0.6053, 0.8158]}\n",
            "prediction:  [0, [[\"Host-based security tools such as anti-virus and intrusion detection systems are not adequately protected on today's computers.\", \"background_label\"], [\"Malware is often designed to immediately disable any security tools upon installation, rendering them useless.\", \"background_label\"], [\"While current research has focused on moving these vulnerable security tools into an isolated virtual machine, this approach cripples security tools by preventing them from doing active monitoring.\", \"background_label\"], [\"This paper describes an architecture that takes a hybrid approach, giving security tools the ability to do active monitoring while still benefiting from the increased security of an isolated virtual machine.\", \"method_label\"], [\"We discuss the architecture and a prototype implementation that can process hooks from a virtual machine running Windows XP on Xen.\", \"method_label\"], [\"We conclude with a security analysis and show the performance of a single hook to be 28 musecs in the best case.\", \"result_label\"]]]\n",
            "\n",
            "input 88:  {\"abstract_id\": 0, \"sentences\": [\"Recently, Convolutional neural network (CNN) architectures in deep learning have achieved significant results in the field of computer vision.\", \"To transform this performance toward the task of intrusion detection (ID) in cyber security, this paper models network traffic as time-series, particularly transmission control protocol / internet protocol (TCP/IP) packets in a predefined time range with supervised learning methods such as multi-layer perceptron (MLP), CNN, CNN-recurrent neural network (CNN-RNN), CNN-long short-term memory (CNN-LSTM) and CNN-gated recurrent unit (GRU), using millions of known good and bad network connections.\", \"To measure the efficacy of these approaches we evaluate on the most important synthetic ID data set such as KDDCup 99.\", \"To select the optimal network architecture, comprehensive analysis of various MLP, CNN, CNN-RNN, CNN-LSTM and CNN-GRU with its topologies, network parameters and network structures is used.\", \"The models in each experiment are run up to 1000 epochs with learning rate in the range [0.01-05].\", \"CNN and its variant architectures have significantly performed well in comparison to the classical machine learning classifiers.\", \"This is mainly due to the reason that CNN have capability to extract high level feature representations that represents the abstract form of low level feature sets of network traffic connections.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.7949, 0.7949, 0.7949, 0.7949, 0.6154, 0.7949]}\n",
            "prediction:  [0, [[\"Recently, Convolutional neural network (CNN) architectures in deep learning have achieved significant results in the field of computer vision.\", \"background_label\"], [\"To transform this performance toward the task of intrusion detection (ID) in cyber security, this paper models network traffic as time-series, particularly transmission control protocol / internet protocol (TCP/IP) packets in a predefined time range with supervised learning methods such as multi-layer perceptron (MLP), CNN, CNN-recurrent neural network (CNN-RNN), CNN-long short-term memory (CNN-LSTM) and CNN-gated recurrent unit (GRU), using millions of known good and bad network connections.\", \"method_label\"], [\"To measure the efficacy of these approaches we evaluate on the most important synthetic ID data set such as KDDCup 99.\", \"method_label\"], [\"To select the optimal network architecture, comprehensive analysis of various MLP, CNN, CNN-RNN, CNN-LSTM and CNN-GRU with its topologies, network parameters and network structures is used.\", \"method_label\"], [\"The models in each experiment are run up to 1000 epochs with learning rate in the range [0.01-05].\", \"method_label\"], [\"CNN and its variant architectures have significantly performed well in comparison to the classical machine learning classifiers.\", \"result_label\"], [\"This is mainly due to the reason that CNN have capability to extract high level feature representations that represents the abstract form of low level feature sets of network traffic connections.\", \"result_label\"]]]\n",
            "\n",
            "input 89:  {\"abstract_id\": 0, \"sentences\": [\"The human forearm is composed of two long, thin bones called the radius and the ulna, and rotates using two axle joints.\", \"We aimed to develop a forearm based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body in order to bring out its benefits.\", \"For this, we need to miniaturize the muscle modules.\", \"To approach this task, we arranged two muscle motors inside one muscle module, and used the space effectively by utilizing common parts.\", \"In addition, we enabled the muscle module to also be used as the bone structure.\", \"Moreover, we used miniature motors and developed a way to dissipate the motor heat to the bone structure.\", \"Through these approaches, we succeeded in developing a forearm with a radioulnar joint based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body, while keeping maintainability and reliability.\", \"Also, we performed some motions such as soldering, opening a book, turning a screw, and badminton swinging using the benefits of the radioulnar structure, which have not been discussed before, and verified that Kengoro can realize skillful motions using the radioulnar joint like a human.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.8, 0.6, 0.6, 0.8, 0.8, 0.8286, 0.8286]}\n",
            "prediction:  [0, [[\"The human forearm is composed of two long, thin bones called the radius and the ulna, and rotates using two axle joints.\", \"background_label\"], [\"We aimed to develop a forearm based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body in order to bring out its benefits.\", \"objective_label\"], [\"For this, we need to miniaturize the muscle modules.\", \"objective_label\"], [\"To approach this task, we arranged two muscle motors inside one muscle module, and used the space effectively by utilizing common parts.\", \"method_label\"], [\"In addition, we enabled the muscle module to also be used as the bone structure.\", \"method_label\"], [\"Moreover, we used miniature motors and developed a way to dissipate the motor heat to the bone structure.\", \"method_label\"], [\"Through these approaches, we succeeded in developing a forearm with a radioulnar joint based on the body proportion, weight ratio, muscle arrangement, and joint performance of the human body, while keeping maintainability and reliability.\", \"method_label\"], [\"Also, we performed some motions such as soldering, opening a book, turning a screw, and badminton swinging using the benefits of the radioulnar structure, which have not been discussed before, and verified that Kengoro can realize skillful motions using the radioulnar joint like a human.\", \"result_label\"]]]\n",
            "\n",
            "input 90:  {\"abstract_id\": 0, \"sentences\": [\"1 This paper describes a decentralized peer-to-peer model for building a Web crawler.\", \"Most of the current systems use a centralized client-server model, in which the crawl is done by one or more tightly coupled machines, but the distribution of the crawling jobs and the collection of crawled results are managed in a centralized system using a centralized URL repository.\", \"Centralized solutions are known to have problems like link congestion, being a single point of failure, and expensive administration.\", \"It requires both horizontal and vertical scalability solutions to manage Network File Systems (NFS) and load balancing DNS and HTTP requests.\", \"In this paper, we present an architecture of a completely distributed and decentralized Peer-to-Peer (P2P) crawler called Apoidea, which is self-managing and uses geographical proximity of the web resources to the peers for a better and faster crawl.\", \"We use Distributed Hash Table (DHT) based protocols to perform the critical URL-duplicate and content-duplicate tests.\"], \"labels\": [\"objective\", \"background\", \"background\", \"background\", \"method\", \"method\"], \"confs\": [1.0, 0.7143, 0.7143, 0.7143, 0.7619, 1.0]}\n",
            "prediction:  [0, [[\"1 This paper describes a decentralized peer-to-peer model for building a Web crawler.\", \"background_label\"], [\"Most of the current systems use a centralized client-server model, in which the crawl is done by one or more tightly coupled machines, but the distribution of the crawling jobs and the collection of crawled results are managed in a centralized system using a centralized URL repository.\", \"background_label\"], [\"Centralized solutions are known to have problems like link congestion, being a single point of failure, and expensive administration.\", \"background_label\"], [\"It requires both horizontal and vertical scalability solutions to manage Network File Systems (NFS) and load balancing DNS and HTTP requests.\", \"background_label\"], [\"In this paper, we present an architecture of a completely distributed and decentralized Peer-to-Peer (P2P) crawler called Apoidea, which is self-managing and uses geographical proximity of the web resources to the peers for a better and faster crawl.\", \"method_label\"], [\"We use Distributed Hash Table (DHT) based protocols to perform the critical URL-duplicate and content-duplicate tests.\", \"method_label\"]]]\n",
            "\n",
            "input 91:  {\"abstract_id\": 0, \"sentences\": [\"Apache Cassandra is a leading distributed database of choice when it comes to big data management with zero downtime, linear scalability, and seamless multiple data center deployment.\", \"With increasingly wider adoption of Cassandra for online transaction processing by hundreds of Web-scale companies, there is a growing need for a rigorous and practical data modeling approach that ensures sound and efficient schema design.\", \"This work i) proposes the first query-driven big data modeling methodology for Apache Cassandra, ii) defines important data modeling principles, mapping rules, and mapping patterns to guide logical data modeling, iii) presents visual diagrams for Cassandra logical and physical data models, and iv) demonstrates a data modeling tool that automates the entire data modeling process.\"], \"labels\": [\"background\", \"background\", \"objective\"], \"confs\": [1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Apache Cassandra is a leading distributed database of choice when it comes to big data management with zero downtime, linear scalability, and seamless multiple data center deployment.\", \"background_label\"], [\"With increasingly wider adoption of Cassandra for online transaction processing by hundreds of Web-scale companies, there is a growing need for a rigorous and practical data modeling approach that ensures sound and efficient schema design.\", \"background_label\"], [\"This work i) proposes the first query-driven big data modeling methodology for Apache Cassandra, ii) defines important data modeling principles, mapping rules, and mapping patterns to guide logical data modeling, iii) presents visual diagrams for Cassandra logical and physical data models, and iv) demonstrates a data modeling tool that automates the entire data modeling process.\", \"method_label\"]]]\n",
            "\n",
            "input 92:  {\"abstract_id\": 0, \"sentences\": [\"With the increasingly ubiquitous nature of Social networks and Cloud computing, users are starting to explore new ways to interact with, and exploit these developing paradigms.\", \"Social networks are used to reflect real world relationships that allow users to share information and form connections between one another, essentially creating dynamic Virtual Organizations.\", \"We propose leveraging the pre-established trust formed through friend relationships within a Social network to form a dynamic\\u201cSocial Cloud\\u201d, enabling friends to share resources within the context of a Social network.\", \"We believe that combining trust relationships with suitable incentive mechanisms (through financial payments or bartering) could provide much more sustainable resource sharing mechanisms.\", \"This paper outlines our vision of, and experiences with, creating a Social Storage Cloud, looking specifically at possible market mechanisms that could be used to create a dynamic Cloud infrastructure in a Social network environment.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7241, 0.7586, 0.7586]}\n",
            "prediction:  [0, [[\"With the increasingly ubiquitous nature of Social networks and Cloud computing, users are starting to explore new ways to interact with, and exploit these developing paradigms.\", \"background_label\"], [\"Social networks are used to reflect real world relationships that allow users to share information and form connections between one another, essentially creating dynamic Virtual Organizations.\", \"background_label\"], [\"We propose leveraging the pre-established trust formed through friend relationships within a Social network to form a dynamic\\u201cSocial Cloud\\u201d, enabling friends to share resources within the context of a Social network.\", \"objective_label\"], [\"We believe that combining trust relationships with suitable incentive mechanisms (through financial payments or bartering) could provide much more sustainable resource sharing mechanisms.\", \"method_label\"], [\"This paper outlines our vision of, and experiences with, creating a Social Storage Cloud, looking specifically at possible market mechanisms that could be used to create a dynamic Cloud infrastructure in a Social network environment.\", \"result_label\"]]]\n",
            "\n",
            "input 93:  {\"abstract_id\": 0, \"sentences\": [\"Data clustering is a frequently used technique in finance, computer science, and engineering.\", \"In most of the applications, cluster sizes are either constrained to particular values or available as prior knowledge.\", \"Unfortunately, traditional clustering methods cannot impose constrains on cluster sizes.\", \"In this paper, we propose some vital modifications to the standard k-means algorithm such that it can incorporate size constraints for each cluster separately.\", \"The modified k-means algorithm can be used to obtain clusters in preferred sizes.\", \"A potential application would be obtaining clusters with equal cluster size.\", \"Moreover, the modified algorithm makes use of prior knowledge of the given data set for selectively initializing the cluster centroids which helps escaping from local minima.\", \"Simulation results on multidimensional data demonstrate that the k-means algorithm with the proposed modifications can fulfill cluster size constraints and lead to more accurate and robust results.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.7887, 0.6075, 0.6075, 0.6038, 0.8189, 0.6075, 0.6075, 1.0]}\n",
            "prediction:  [0, [[\"Data clustering is a frequently used technique in finance, computer science, and engineering.\", \"background_label\"], [\"In most of the applications, cluster sizes are either constrained to particular values or available as prior knowledge.\", \"background_label\"], [\"Unfortunately, traditional clustering methods cannot impose constrains on cluster sizes.\", \"background_label\"], [\"In this paper, we propose some vital modifications to the standard k-means algorithm such that it can incorporate size constraints for each cluster separately.\", \"objective_label\"], [\"The modified k-means algorithm can be used to obtain clusters in preferred sizes.\", \"method_label\"], [\"A potential application would be obtaining clusters with equal cluster size.\", \"method_label\"], [\"Moreover, the modified algorithm makes use of prior knowledge of the given data set for selectively initializing the cluster centroids which helps escaping from local minima.\", \"method_label\"], [\"Simulation results on multidimensional data demonstrate that the k-means algorithm with the proposed modifications can fulfill cluster size constraints and lead to more accurate and robust results.\", \"result_label\"]]]\n",
            "\n",
            "input 94:  {\"abstract_id\": 0, \"sentences\": [\"Recently, the Bitcoin-underlying blockchain technology gained prominence as a solution that offers the realization of distributed trust-free systems, where economic transactions are guaranteed by the underlying blockchain.\", \"We are still at an early stage and thus require a deeper understanding of how the blockchain potentials can be realized, and what are the opportunities and challenges in so doing.\", \"Following a design science approach, we developed a proof of concept prototype that has the potential to replace a trust-based coffee shop payment solution that is based on an analogue, pre-paid punch card solution.\", \"The demonstrator provides a starting point to evaluate the strengths and weaknesses of the blockchain technology when replacing a trust-based by a trust-free transaction system.\", \"We conclude that the secure and trust-free blockchain-based transaction has the potential to change many existing trust-based transaction systems, but that scalability issues, costs, and volatility in the transaction currency are hindrances.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7333, 0.7333, 0.7333]}\n",
            "prediction:  [0, [[\"Recently, the Bitcoin-underlying blockchain technology gained prominence as a solution that offers the realization of distributed trust-free systems, where economic transactions are guaranteed by the underlying blockchain.\", \"background_label\"], [\"We are still at an early stage and thus require a deeper understanding of how the blockchain potentials can be realized, and what are the opportunities and challenges in so doing.\", \"background_label\"], [\"Following a design science approach, we developed a proof of concept prototype that has the potential to replace a trust-based coffee shop payment solution that is based on an analogue, pre-paid punch card solution.\", \"method_label\"], [\"The demonstrator provides a starting point to evaluate the strengths and weaknesses of the blockchain technology when replacing a trust-based by a trust-free transaction system.\", \"method_label\"], [\"We conclude that the secure and trust-free blockchain-based transaction has the potential to change many existing trust-based transaction systems, but that scalability issues, costs, and volatility in the transaction currency are hindrances.\", \"result_label\"]]]\n",
            "\n",
            "input 95:  {\"abstract_id\": 0, \"sentences\": [\"Little is known about the effects of successful psychotherapy on brain function in subjects with anxiety disorders.\", \"The present study aimed to identify changes in brain activation following cognitive-behavioral therapy (CBT) in subjects suffering from specific phobia.\", \"Using functional magnetic resonance imaging (fMRI), brain activation to spider videos was measured in 28 spider phobic and 14 healthy control subjects.\", \"Phobics were randomly assigned to a therapy-group (TG) and a waiting-list control group (WG).\", \"Both groups of phobics were scanned twice.\", \"Between scanning sessions, CBT was given to the TG.\", \"Before therapy, brain activation did not differ between both groups of phobics.\", \"As compared to control subjects, phobics showed greater responses to spider vs. control videos in the insula and anterior cingulate cortex (ACC).\", \"CBT strongly reduced phobic symptoms in the TG while the WG remained behaviorally unchanged.\", \"In the second scanning session, a significant reduction of hyperactivity in the insula and ACC was found in the TG compared to the WG.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.75, 1.0, 0.75, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}\n",
            "prediction:  [0, [[\"Little is known about the effects of successful psychotherapy on brain function in subjects with anxiety disorders.\", \"background_label\"], [\"The present study aimed to identify changes in brain activation following cognitive-behavioral therapy (CBT) in subjects suffering from specific phobia.\", \"objective_label\"], [\"Using functional magnetic resonance imaging (fMRI), brain activation to spider videos was measured in 28 spider phobic and 14 healthy control subjects.\", \"method_label\"], [\"Phobics were randomly assigned to a therapy-group (TG) and a waiting-list control group (WG).\", \"method_label\"], [\"Both groups of phobics were scanned twice.\", \"method_label\"], [\"Between scanning sessions, CBT was given to the TG.\", \"method_label\"], [\"Before therapy, brain activation did not differ between both groups of phobics.\", \"method_label\"], [\"As compared to control subjects, phobics showed greater responses to spider vs. control videos in the insula and anterior cingulate cortex (ACC).\", \"result_label\"], [\"CBT strongly reduced phobic symptoms in the TG while the WG remained behaviorally unchanged.\", \"result_label\"], [\"In the second scanning session, a significant reduction of hyperactivity in the insula and ACC was found in the TG compared to the WG.\", \"result_label\"]]]\n",
            "\n",
            "input 96:  {\"abstract_id\": 0, \"sentences\": [\"Image registration finds a variety of applications in computer vision.\", \"Unfortunately, traditional image registration techniques tend to be costly.\", \"We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration.\", \"Our technique is faster because it examines far fewer potential matches between the images than existing techniques.\", \"Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing.\", \"We show show our technique can be adapted for use in a stereo vision system.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.6286, 1.0, 0.8286, 0.6286]}\n",
            "prediction:  [0, [[\"Image registration finds a variety of applications in computer vision.\", \"background_label\"], [\"Unfortunately, traditional image registration techniques tend to be costly.\", \"background_label\"], [\"We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration.\", \"method_label\"], [\"Our technique is faster because it examines far fewer potential matches between the images than existing techniques.\", \"method_label\"], [\"Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing.\", \"method_label\"], [\"We show show our technique can be adapted for use in a stereo vision system.\", \"method_label\"]]]\n",
            "\n",
            "input 97:  {\"abstract_id\": 0, \"sentences\": [\"Backpropagation and contrastive Hebbian learning are two methods of training networks with hidden neurons.\", \"Backpropagation computes an error signal for the output neurons and spreads it over the hidden neurons.\", \"Contrastive Hebbian learning involves clamping the output neurons at desired values and letting the effect spread through feedback connections over the entire network.\", \"To investigate the relationship between these two forms of learning, we consider a special case in which they are identical: a multilayer perceptron with linear output units, to which weak feedback connections have been added.\", \"In this case, the change in network state caused by clamping the output neurons turns out to be the same as the error signal spread by backpropagation, except for a scalar prefactor.\", \"This suggests that the functionality of backpropagation can be realized alternatively by a Hebbian-type learning algorithm, which is suitable for implementation in biological networks.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"result\", \"result\"], \"confs\": [0.7714, 1.0, 0.8286, 0.6, 0.6286, 0.8286]}\n",
            "prediction:  [0, [[\"Backpropagation and contrastive Hebbian learning are two methods of training networks with hidden neurons.\", \"background_label\"], [\"Backpropagation computes an error signal for the output neurons and spreads it over the hidden neurons.\", \"background_label\"], [\"Contrastive Hebbian learning involves clamping the output neurons at desired values and letting the effect spread through feedback connections over the entire network.\", \"background_label\"], [\"To investigate the relationship between these two forms of learning, we consider a special case in which they are identical: a multilayer perceptron with linear output units, to which weak feedback connections have been added.\", \"method_label\"], [\"In this case, the change in network state caused by clamping the output neurons turns out to be the same as the error signal spread by backpropagation, except for a scalar prefactor.\", \"method_label\"], [\"This suggests that the functionality of backpropagation can be realized alternatively by a Hebbian-type learning algorithm, which is suitable for implementation in biological networks.\", \"result_label\"]]]\n",
            "\n",
            "input 98:  {\"abstract_id\": 0, \"sentences\": [\"Understanding gaming motivations is important given the growing trend of incorporating game-based mechanisms in non-gaming applications.\", \"In this paper, we describe the development and validation of an online gaming motivations scale based on a 3-factor model.\", \"Data from 2,071 US participants and 645 Hong Kong and Taiwan participants is used to provide a cross-cultural validation of the developed scale.\", \"Analysis of actual in-game behavioral metrics is also provided to demonstrate predictive validity of the scale.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\"], \"confs\": [1.0, 0.7, 0.7, 0.7]}\n",
            "prediction:  [0, [[\"Understanding gaming motivations is important given the growing trend of incorporating game-based mechanisms in non-gaming applications.\", \"background_label\"], [\"In this paper, we describe the development and validation of an online gaming motivations scale based on a 3-factor model.\", \"objective_label\"], [\"Data from 2,071 US participants and 645 Hong Kong and Taiwan participants is used to provide a cross-cultural validation of the developed scale.\", \"method_label\"], [\"Analysis of actual in-game behavioral metrics is also provided to demonstrate predictive validity of the scale.\", \"result_label\"]]]\n",
            "\n",
            "input 99:  {\"abstract_id\": 0, \"sentences\": [\"We present an end-to-end system for augmented and virtual reality telepresence, called Holoportation.\", \"Our system demonstrates high-quality, real-time 3D reconstructions of an entire space, including people, furniture and objects, using a set of new depth cameras.\", \"These 3D models can also be transmitted in real-time to remote users.\", \"This allows users wearing virtual or augmented reality displays to see, hear and interact with remote participants in 3D, almost as if they were present in the same physical space.\", \"From an audio-visual perspective, communicating and interacting with remote users edges closer to face-to-face communication.\", \"This paper describes the Holoportation technical system in full, its key interactive capabilities, the application scenarios it enables, and an initial qualitative study of using this new communication medium.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.8, 0.8, 0.6, 0.6, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"We present an end-to-end system for augmented and virtual reality telepresence, called Holoportation.\", \"background_label\"], [\"Our system demonstrates high-quality, real-time 3D reconstructions of an entire space, including people, furniture and objects, using a set of new depth cameras.\", \"background_label\"], [\"These 3D models can also be transmitted in real-time to remote users.\", \"background_label\"], [\"This allows users wearing virtual or augmented reality displays to see, hear and interact with remote participants in 3D, almost as if they were present in the same physical space.\", \"method_label\"], [\"From an audio-visual perspective, communicating and interacting with remote users edges closer to face-to-face communication.\", \"method_label\"], [\"This paper describes the Holoportation technical system in full, its key interactive capabilities, the application scenarios it enables, and an initial qualitative study of using this new communication medium.\", \"result_label\"]]]\n",
            "\n",
            "input 100:  {\"abstract_id\": 0, \"sentences\": [\"This research demo describes the implementation of a mobile AR-supported educational course application, AR Circuit, which is designed to promote the effectiveness of remote collaborative learning for physics.\", \"The application employs the TCP/IP protocol enabling multiplayer functionality in a mobile AR environment.\", \"One phone acts as the server and the other acts as the client.\", \"The server phone will capture the video frames, process the video frame, and send the current frame and the markers transformation matrices to the client phone.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\"], \"confs\": [0.6053, 0.6053, 0.6053, 0.6053]}\n",
            "prediction:  [0, [[\"This research demo describes the implementation of a mobile AR-supported educational course application, AR Circuit, which is designed to promote the effectiveness of remote collaborative learning for physics.\", \"objective_label\"], [\"The application employs the TCP/IP protocol enabling multiplayer functionality in a mobile AR environment.\", \"method_label\"], [\"One phone acts as the server and the other acts as the client.\", \"method_label\"], [\"The server phone will capture the video frames, process the video frame, and send the current frame and the markers transformation matrices to the client phone.\", \"method_label\"]]]\n",
            "\n",
            "input 101:  {\"abstract_id\": 0, \"sentences\": [\"Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network.\", \"In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS).\", \"Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model.\", \"We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set.\", \"The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification.\", \"The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.\"], \"labels\": [\"background\", \"objective\", \"objective\", \"method\", \"result\", \"result\"], \"confs\": [0.8158, 0.6053, 0.6053, 1.0, 0.8158, 0.8158]}\n",
            "prediction:  [0, [[\"Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network.\", \"background_label\"], [\"In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS).\", \"objective_label\"], [\"Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model.\", \"method_label\"], [\"We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set.\", \"method_label\"], [\"The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification.\", \"result_label\"], [\"The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.\", \"result_label\"]]]\n",
            "\n",
            "input 102:  {\"abstract_id\": 0, \"sentences\": [\"In this letter, we develop a gaussian process model for clustering.\", \"The variances of predictive values in gaussian processes learned from a training data are shown to comprise an estimate of the support of a probability density function.\", \"The constructed variance function is then applied to construct a set of contours that enclose the data points, which correspond to cluster boundaries.\", \"To perform clustering tasks of the data points, an associated dynamical system is built, and its topological invariant property is investigated.\", \"The experimental results show that the proposed method works successfully for clustering problems with arbitrary shapes.\"], \"labels\": [\"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.6, 0.6286, 0.7714, 0.7714, 0.7714]}\n",
            "prediction:  [0, [[\"In this letter, we develop a gaussian process model for clustering.\", \"background_label\"], [\"The variances of predictive values in gaussian processes learned from a training data are shown to comprise an estimate of the support of a probability density function.\", \"method_label\"], [\"The constructed variance function is then applied to construct a set of contours that enclose the data points, which correspond to cluster boundaries.\", \"method_label\"], [\"To perform clustering tasks of the data points, an associated dynamical system is built, and its topological invariant property is investigated.\", \"method_label\"], [\"The experimental results show that the proposed method works successfully for clustering problems with arbitrary shapes.\", \"result_label\"]]]\n",
            "\n",
            "input 103:  {\"abstract_id\": 0, \"sentences\": [\"Advanced energy storage has been a key enabling technology for the portable electronics explosion.\", \"The lithium and Ni-MeH battery technologies are less than 40 years old and have taken over the electronics industry and are on the same track for the transportation industry and the utility grid.\", \"In this review, energy storage from the gigawatt pumped hydro systems to the smallest watt-hour battery are discussed, and the future directions predicted.\", \"If renewable energy, or even lower cost energy, is to become prevalent energy storage is a critical component in reducing peak power demands and the intermittent nature of solar and wind power.\", \"An electric economy will demand more electrification of the transportation sector and it is likely that all vehicles sold by the end of this decade will have some level of hybridization.\", \"Energy storage capabilities in conjunction with the smart grid are expected to see a massive leap forward over the next 25 years.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"objective\", \"objective\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 0.7419]}\n",
            "prediction:  [0, [[\"Advanced energy storage has been a key enabling technology for the portable electronics explosion.\", \"background_label\"], [\"The lithium and Ni-MeH battery technologies are less than 40 years old and have taken over the electronics industry and are on the same track for the transportation industry and the utility grid.\", \"background_label\"], [\"In this review, energy storage from the gigawatt pumped hydro systems to the smallest watt-hour battery are discussed, and the future directions predicted.\", \"background_label\"], [\"If renewable energy, or even lower cost energy, is to become prevalent energy storage is a critical component in reducing peak power demands and the intermittent nature of solar and wind power.\", \"background_label\"], [\"An electric economy will demand more electrification of the transportation sector and it is likely that all vehicles sold by the end of this decade will have some level of hybridization.\", \"background_label\"], [\"Energy storage capabilities in conjunction with the smart grid are expected to see a massive leap forward over the next 25 years.\", \"result_label\"]]]\n",
            "\n",
            "input 104:  {\"abstract_id\": 0, \"sentences\": [\"Social media is becoming increasingly popular for news consumption due to its easy access, fast dissemination, and low cost.\", \"However, social media also enables the wide propagation of \\u201cfake news\\u201d, i.e., news with intentionally false information.\", \"Fake news on social media can have significant negative societal effects.\", \"Identifying and mitigating fake news also presents unique challenges.\", \"To tackle these challenges, many existing research efforts exploit various features of the data, including network features.\", \"In essence, a news dissemination ecosystem involves three dimensions on social media, i.e., a content dimension, a social dimension, and a temporal dimension.\", \"In this chapter, we will review network properties for studying fake news, introduce popular network types and propose how these networks can be used to detect and mitigate fake news on social media.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"background\", \"objective\"], \"confs\": [1.0, 1.0, 0.8205, 0.6154, 0.6154, 0.6154, 0.6154]}\n",
            "prediction:  [0, [[\"Social media is becoming increasingly popular for news consumption due to its easy access, fast dissemination, and low cost.\", \"background_label\"], [\"However, social media also enables the wide propagation of \\u201cfake news\\u201d, i.e., news with intentionally false information.\", \"background_label\"], [\"Fake news on social media can have significant negative societal effects.\", \"background_label\"], [\"Identifying and mitigating fake news also presents unique challenges.\", \"background_label\"], [\"To tackle these challenges, many existing research efforts exploit various features of the data, including network features.\", \"background_label\"], [\"In essence, a news dissemination ecosystem involves three dimensions on social media, i.e., a content dimension, a social dimension, and a temporal dimension.\", \"method_label\"], [\"In this chapter, we will review network properties for studying fake news, introduce popular network types and propose how these networks can be used to detect and mitigate fake news on social media.\", \"result_label\"]]]\n",
            "\n",
            "input 105:  {\"abstract_id\": 0, \"sentences\": [\"This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding.\", \"It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes.\", \"We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC [6] while being simpler.\", \"We show competitive results in word error rate on the Librispeech corpus [18] with MFCC features, and promising results from raw waveform.\"], \"labels\": [\"objective\", \"objective\", \"method\", \"result\"], \"confs\": [0.6316, 0.6316, 1.0, 0.8421]}\n",
            "prediction:  [0, [[\"This paper presents a simple end-to-end model for speech recognition, combining a convolutional network based acoustic model and a graph decoding.\", \"background_label\"], [\"It is trained to output letters, with transcribed speech, without the need for force alignment of phonemes.\", \"method_label\"], [\"We introduce an automatic segmentation criterion for training from sequence annotation without alignment that is on par with CTC [6] while being simpler.\", \"method_label\"], [\"We show competitive results in word error rate on the Librispeech corpus [18] with MFCC features, and promising results from raw waveform.\", \"result_label\"]]]\n",
            "\n",
            "input 106:  {\"abstract_id\": 0, \"sentences\": [\"We propose a simple method for improving the security of hashed passwords: the maintenance of additional ``honeywords'' (false passwords) associated with each user's account.\", \"An adversary who steals a file of hashed passwords and inverts the hash function cannot tell if he has found the password or a honeyword.\", \"The attempted use of a honeyword for login sets off an alarm.\", \"An auxiliary server (the ``honeychecker'') can distinguish the user password from honeywords for the login routine, and will set off an alarm if a honeyword is submitted.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\"], \"confs\": [0.6, 0.6, 0.6, 1.0]}\n",
            "prediction:  [0, [[\"We propose a simple method for improving the security of hashed passwords: the maintenance of additional ``honeywords'' (false passwords) associated with each user's account.\", \"background_label\"], [\"An adversary who steals a file of hashed passwords and inverts the hash function cannot tell if he has found the password or a honeyword.\", \"background_label\"], [\"The attempted use of a honeyword for login sets off an alarm.\", \"method_label\"], [\"An auxiliary server (the ``honeychecker'') can distinguish the user password from honeywords for the login routine, and will set off an alarm if a honeyword is submitted.\", \"method_label\"]]]\n",
            "\n",
            "input 107:  {\"abstract_id\": 0, \"sentences\": [\"Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains.\", \"The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection.\", \"Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness.\", \"We have grouped state-of-the-art deep anomaly detection research techniques into different categories based on the underlying assumptions and approach adopted.\", \"Within each category, we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior.\", \"Besides, for each category, we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains.\", \"Finally, we outline open issues in research and challenges faced while adopting deep anomaly detection techniques for real-world problems.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7692, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains.\", \"background_label\"], [\"The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection.\", \"objective_label\"], [\"Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness.\", \"method_label\"], [\"We have grouped state-of-the-art deep anomaly detection research techniques into different categories based on the underlying assumptions and approach adopted.\", \"method_label\"], [\"Within each category, we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior.\", \"method_label\"], [\"Besides, for each category, we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains.\", \"method_label\"], [\"Finally, we outline open issues in research and challenges faced while adopting deep anomaly detection techniques for real-world problems.\", \"result_label\"]]]\n",
            "\n",
            "input 108:  {\"abstract_id\": 0, \"sentences\": [\"Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding.\", \"Despite their success, neural networks are still hard to design.\", \"In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set.\", \"On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy.\", \"Our CIFAR-10 model achieves a test error rate of 3.84, which is only 0.1 percent worse and 1.2x faster than the current state-of-the-art model.\", \"On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines.\", \"Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-ofthe-art.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.8148, 0.8148, 0.8148, 0.7778, 1.0, 0.7037]}\n",
            "prediction:  [0, [[\"Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding.\", \"background_label\"], [\"Despite their success, neural networks are still hard to design.\", \"background_label\"], [\"In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set.\", \"method_label\"], [\"On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy.\", \"method_label\"], [\"Our CIFAR-10 model achieves a test error rate of 3.84, which is only 0.1 percent worse and 1.2x faster than the current state-of-the-art model.\", \"method_label\"], [\"On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines.\", \"method_label\"], [\"Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-ofthe-art.\", \"result_label\"]]]\n",
            "\n",
            "input 109:  {\"abstract_id\": 0, \"sentences\": [\"Receiver operating characteristic (ROC) analysis is an established method of measuring diagnostic performance in medical imaging studies.\", \"Traditionally, artificial neural networks (ANN's) have been applied as a classifier to find one \\\"best\\\" detection rate.\", \"Recently researchers have begun to report ROC curve results for ANN classifiers.\", \"The current standard method of generating ROC curves for an ANN is to vary the output node threshold for classification.\", \"Here, the authors propose a different technique for generating ROC curves for a two class ANN classifier.\", \"They show that this new technique generates better ROC curves in the sense of having greater area under the ROC curve (AUC), and in the sense of being composed of a better distribution of operating points.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 0.7059, 0.7059, 0.7059]}\n",
            "prediction:  [0, [[\"Receiver operating characteristic (ROC) analysis is an established method of measuring diagnostic performance in medical imaging studies.\", \"background_label\"], [\"Traditionally, artificial neural networks (ANN's) have been applied as a classifier to find one \\\"best\\\" detection rate.\", \"background_label\"], [\"Recently researchers have begun to report ROC curve results for ANN classifiers.\", \"background_label\"], [\"The current standard method of generating ROC curves for an ANN is to vary the output node threshold for classification.\", \"method_label\"], [\"Here, the authors propose a different technique for generating ROC curves for a two class ANN classifier.\", \"method_label\"], [\"They show that this new technique generates better ROC curves in the sense of having greater area under the ROC curve (AUC), and in the sense of being composed of a better distribution of operating points.\", \"result_label\"]]]\n",
            "\n",
            "input 110:  {\"abstract_id\": 0, \"sentences\": [\"Tables are a common structuring element in many documents, s uch as PDF files.\", \"To reuse such tables, appropriate methods need to b e develop, which capture the structure and the content information.\", \"We have d e loped several heuristics which together recognize and decompose tables i n PDF files and store the extracted data in a structured data format (XML) for easi er reuse.\", \"Additionally, we implemented a prototype, which gives the user the ab ility of making adjustments on the extracted data.\", \"Our work shows that purel y heuristic-based approaches can achieve good results, especially for lucid t ables.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.75, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Tables are a common structuring element in many documents, s uch as PDF files.\", \"background_label\"], [\"To reuse such tables, appropriate methods need to b e develop, which capture the structure and the content information.\", \"background_label\"], [\"We have d e loped several heuristics which together recognize and decompose tables i n PDF files and store the extracted data in a structured data format (XML) for easi er reuse.\", \"method_label\"], [\"Additionally, we implemented a prototype, which gives the user the ab ility of making adjustments on the extracted data.\", \"method_label\"], [\"Our work shows that purel y heuristic-based approaches can achieve good results, especially for lucid t ables.\", \"result_label\"]]]\n",
            "\n",
            "input 111:  {\"abstract_id\": 0, \"sentences\": [\"The Playful Experiences (PLEX) framework is a categorization of playful experiences based on previous theoretical work on pleasurable experiences, game experiences, emotions, elements of play, and reasons why people play.\", \"While the framework has been successfully employed in design-related activities, its potential as an evaluation tool has not yet been studied.\", \"In this paper, we apply the PLEX framework in the evaluation of two game prototypes that explored novel physical interactions between mobile devices using Near-Field Communication, by means of three separate studies.\", \"Our results suggest that the PLEX framework provides anchor points for evaluators to reflect during heuristic evaluations.\", \"More broadly, the framework categories can be used as a checklist to assess different attributes of playfulness of a product or service.\"], \"labels\": [\"background\", \"background\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.7241, 0.7586, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"The Playful Experiences (PLEX) framework is a categorization of playful experiences based on previous theoretical work on pleasurable experiences, game experiences, emotions, elements of play, and reasons why people play.\", \"background_label\"], [\"While the framework has been successfully employed in design-related activities, its potential as an evaluation tool has not yet been studied.\", \"background_label\"], [\"In this paper, we apply the PLEX framework in the evaluation of two game prototypes that explored novel physical interactions between mobile devices using Near-Field Communication, by means of three separate studies.\", \"method_label\"], [\"Our results suggest that the PLEX framework provides anchor points for evaluators to reflect during heuristic evaluations.\", \"result_label\"], [\"More broadly, the framework categories can be used as a checklist to assess different attributes of playfulness of a product or service.\", \"result_label\"]]]\n",
            "\n",
            "input 112:  {\"abstract_id\": 0, \"sentences\": [\"Feature selection aims to find the most important information from a given set of features.\", \"As this task can be seen as an optimization problem, the combinatorial growth of the possible solutions may be in-viable for a exhaustive search.\", \"In this paper we propose a new nature-inspired feature selection technique based on the bats behaviour, which has never been applied to this context so far.\", \"The wrapper approach combines the power of exploration of the bats together with the speed of the Optimum-Path Forest classifier to find the set of features that maximizes the accuracy in a validating set.\", \"Experiments conducted in five public datasets have demonstrated that the proposed approach can outperform some well-known swarm-based techniques.\"], \"labels\": [\"objective\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [0.7407, 0.7407, 1.0, 0.7778, 0.7407]}\n",
            "prediction:  [0, [[\"Feature selection aims to find the most important information from a given set of features.\", \"background_label\"], [\"As this task can be seen as an optimization problem, the combinatorial growth of the possible solutions may be in-viable for a exhaustive search.\", \"background_label\"], [\"In this paper we propose a new nature-inspired feature selection technique based on the bats behaviour, which has never been applied to this context so far.\", \"objective_label\"], [\"The wrapper approach combines the power of exploration of the bats together with the speed of the Optimum-Path Forest classifier to find the set of features that maximizes the accuracy in a validating set.\", \"method_label\"], [\"Experiments conducted in five public datasets have demonstrated that the proposed approach can outperform some well-known swarm-based techniques.\", \"result_label\"]]]\n",
            "\n",
            "input 113:  {\"abstract_id\": 0, \"sentences\": [\"Machine learning is a useful technology for decision support systems and assumes greater importance in research and practice.\", \"Whilst much of the work focuses technical implementations and the adaption of machine learning algorithms to application domains, the factors of machine learning design affecting the usefulness of decision support are still understudied.\", \"To enhance the understanding of machine learning and its use in decision support systems, we report the results of our content analysis of design-oriented research published between 1994 and 2013 in major Information Systems outlets.\", \"The findings suggest that the usefulness of machine learning for supporting decision-makers is dependent on the task, the phase of decision-making, and the applied technologies.\", \"We also report about the advantages and limitations of prior research, the applied evaluation methods and implications for future decision support research.\", \"Our findings suggest that future decision support research should shed more light on organizational and people-related evaluation criteria.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.6, 0.6, 1.0, 0.6, 1.0]}\n",
            "prediction:  [0, [[\"Machine learning is a useful technology for decision support systems and assumes greater importance in research and practice.\", \"background_label\"], [\"Whilst much of the work focuses technical implementations and the adaption of machine learning algorithms to application domains, the factors of machine learning design affecting the usefulness of decision support are still understudied.\", \"background_label\"], [\"To enhance the understanding of machine learning and its use in decision support systems, we report the results of our content analysis of design-oriented research published between 1994 and 2013 in major Information Systems outlets.\", \"method_label\"], [\"The findings suggest that the usefulness of machine learning for supporting decision-makers is dependent on the task, the phase of decision-making, and the applied technologies.\", \"result_label\"], [\"We also report about the advantages and limitations of prior research, the applied evaluation methods and implications for future decision support research.\", \"result_label\"], [\"Our findings suggest that future decision support research should shed more light on organizational and people-related evaluation criteria.\", \"result_label\"]]]\n",
            "\n",
            "input 114:  {\"abstract_id\": 0, \"sentences\": [\"Money laundering has been affecting the global economy for many years.\", \"Large sums of money are laundered every year, posing a threat to the global economy and its security.\", \"Money laundering encompasses illegal activities that are used to make illegally acquired funds appear legal and legitimate.\", \"This paper aims to provide a comprehensive survey of machine learning algorithms and methods applied to detect suspicious transactions.\", \"In particular, solutions of anti-money laundering typologies, link analysis, behavioural modelling, risk scoring, anomaly detection, and geographic capability have been identified and analysed.\", \"Key steps of data preparation, data transformation, and data analytics techniques have been discussed; existing machine learning algorithms and methods described in the literature have been categorised, summarised, and compared.\", \"Finally, what techniques were lacking or under-addressed in the existing research has been elaborated with the purpose of pinpointing future research directions.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 0.7143, 0.7143, 0.7143]}\n",
            "prediction:  [0, [[\"Money laundering has been affecting the global economy for many years.\", \"background_label\"], [\"Large sums of money are laundered every year, posing a threat to the global economy and its security.\", \"background_label\"], [\"Money laundering encompasses illegal activities that are used to make illegally acquired funds appear legal and legitimate.\", \"background_label\"], [\"This paper aims to provide a comprehensive survey of machine learning algorithms and methods applied to detect suspicious transactions.\", \"objective_label\"], [\"In particular, solutions of anti-money laundering typologies, link analysis, behavioural modelling, risk scoring, anomaly detection, and geographic capability have been identified and analysed.\", \"method_label\"], [\"Key steps of data preparation, data transformation, and data analytics techniques have been discussed; existing machine learning algorithms and methods described in the literature have been categorised, summarised, and compared.\", \"method_label\"], [\"Finally, what techniques were lacking or under-addressed in the existing research has been elaborated with the purpose of pinpointing future research directions.\", \"result_label\"]]]\n",
            "\n",
            "input 115:  {\"abstract_id\": 0, \"sentences\": [\"Many Natural Language Processing (NLP) techniques have been used in Information Retrieval.\", \"The results are not encouraging.\", \"Simple methods (stopwording, porter-style stemming, etc.) usually yield significant improvements, while higher-level processing (chunking, parsing, word sense disambiguation, etc.)\", \"only yield very small improvements or even a decrease in accuracy.\", \"At the same time, higher-level methods increase the processing and storage cost dramatically.\", \"This makes them hard to use on large collections.\", \"We review NLP techniques and come to the conclusion that (a) NLP needs to be optimized for IR in order to be effective and (b) document retrieval is not an ideal application for NLP, at least given the current state-of-the-art in NLP.\", \"Other IR-related tasks, e.g., question answering and information extraction, seem to be better suited.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.8, 0.6, 0.6, 0.6, 0.6, 0.8, 0.8]}\n",
            "prediction:  [0, [[\"Many Natural Language Processing (NLP) techniques have been used in Information Retrieval.\", \"background_label\"], [\"The results are not encouraging.\", \"background_label\"], [\"Simple methods (stopwording, porter-style stemming, etc.) usually yield significant improvements, while higher-level processing (chunking, parsing, word sense disambiguation, etc.)\", \"background_label\"], [\"only yield very small improvements or even a decrease in accuracy.\", \"background_label\"], [\"At the same time, higher-level methods increase the processing and storage cost dramatically.\", \"method_label\"], [\"This makes them hard to use on large collections.\", \"method_label\"], [\"We review NLP techniques and come to the conclusion that (a) NLP needs to be optimized for IR in order to be effective and (b) document retrieval is not an ideal application for NLP, at least given the current state-of-the-art in NLP.\", \"result_label\"], [\"Other IR-related tasks, e.g., question answering and information extraction, seem to be better suited.\", \"result_label\"]]]\n",
            "\n",
            "input 116:  {\"abstract_id\": 0, \"sentences\": [\"Fog computing is a promising computing paradigm that extends cloud computing to the edge of networks.\", \"Similar to cloud computing but with distinct characteristics, fog computing faces new security and privacy challenges besides those inherited from cloud computing.\", \"In this paper, we have surveyed these challenges and corresponding solutions in a brief manner.\"], \"labels\": [\"background\", \"background\", \"result\"], \"confs\": [0.7895, 0.6053, 0.6053]}\n",
            "prediction:  [0, [[\"Fog computing is a promising computing paradigm that extends cloud computing to the edge of networks.\", \"background_label\"], [\"Similar to cloud computing but with distinct characteristics, fog computing faces new security and privacy challenges besides those inherited from cloud computing.\", \"background_label\"], [\"In this paper, we have surveyed these challenges and corresponding solutions in a brief manner.\", \"objective_label\"]]]\n",
            "\n",
            "input 117:  {\"abstract_id\": 0, \"sentences\": [\"We present the MULTOVL application suite that detects and statistically analyses multiple overlaps of genomic regions in a fast and efficient manner.\", \"The package supports the detection of multiple region intersections, unions and 'solitary' genomic regions.\", \"The significance of actually observed overlaps is estimated by comparing them with empirical null distributions generated by random shuffling of the input regions.\"], \"labels\": [\"background\", \"background\", \"background\"], \"confs\": [0.6, 0.7714, 0.6]}\n",
            "prediction:  [0, [[\"We present the MULTOVL application suite that detects and statistically analyses multiple overlaps of genomic regions in a fast and efficient manner.\", \"background_label\"], [\"The package supports the detection of multiple region intersections, unions and 'solitary' genomic regions.\", \"background_label\"], [\"The significance of actually observed overlaps is estimated by comparing them with empirical null distributions generated by random shuffling of the input regions.\", \"result_label\"]]]\n",
            "\n",
            "input 118:  {\"abstract_id\": 0, \"sentences\": [\"Selecting views to materialize is one of the most important decisions in designing a data warehouse.\", \"In this paper, we present a framework for analyzing the issues in selecting views to materialize so as to achieve the best combination of good query performance and low view maintenance.\", \"We first develop a heuristic algorithm which can provide a feasible solution based on individual optimal query plans.\", \"We also map the materialized view design problem as O-l integer programming problem, whose solution can guarantee an optimal solution.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\"], \"confs\": [1.0, 0.7143, 1.0, 0.7143]}\n",
            "prediction:  [0, [[\"Selecting views to materialize is one of the most important decisions in designing a data warehouse.\", \"background_label\"], [\"In this paper, we present a framework for analyzing the issues in selecting views to materialize so as to achieve the best combination of good query performance and low view maintenance.\", \"objective_label\"], [\"We first develop a heuristic algorithm which can provide a feasible solution based on individual optimal query plans.\", \"method_label\"], [\"We also map the materialized view design problem as O-l integer programming problem, whose solution can guarantee an optimal solution.\", \"method_label\"]]]\n",
            "\n",
            "input 119:  {\"abstract_id\": 0, \"sentences\": [\"0950-5849/$ see front matter 2009 Elsevier B.V. A doi:10.1016/j.infsof.2009.08.004 * Corresponding author.\", \"Tel.\", \": +49 3\"], \"labels\": [\"other\", \"other\", \"other\"], \"confs\": [0.7586, 1.0, 0.7586]}\n",
            "prediction:  [0, [[\"0950-5849/$ see front matter 2009 Elsevier B.V. A doi:10.1016/j.infsof.2009.08.004 * Corresponding author.\", \"other_label\"], [\"Tel.\", \"other_label\"], [\": +49 3\", \"other_label\"]]]\n",
            "\n",
            "input 120:  {\"abstract_id\": 0, \"sentences\": [\"Graphical interface use involves schemata operations that range from transfer to induction.\", \"The former apply existing knowledge, such as prior schemata, and are effortless, preconscious and intuitive.\", \"The latter, which consist in constructing new schemata, are resource-consuming and thus detrimental to intuitive use (IV).\", \"A quantitative method is proposed to manipulate and screen schemata operations at the level of an interface's states and features.\", \"Relevance for the design cycle of innovative interfaces is critically reviewed, and integration with existing intuitive-use design frameworks is proposed.\", \"These considerations are built upon instructional design studies suggesting that assessment should precede and inform the application of design techniques geared toward IV.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [0.8333, 0.6, 0.6, 1.0, 0.6, 0.7667]}\n",
            "prediction:  [0, [[\"Graphical interface use involves schemata operations that range from transfer to induction.\", \"background_label\"], [\"The former apply existing knowledge, such as prior schemata, and are effortless, preconscious and intuitive.\", \"background_label\"], [\"The latter, which consist in constructing new schemata, are resource-consuming and thus detrimental to intuitive use (IV).\", \"background_label\"], [\"A quantitative method is proposed to manipulate and screen schemata operations at the level of an interface's states and features.\", \"method_label\"], [\"Relevance for the design cycle of innovative interfaces is critically reviewed, and integration with existing intuitive-use design frameworks is proposed.\", \"method_label\"], [\"These considerations are built upon instructional design studies suggesting that assessment should precede and inform the application of design techniques geared toward IV.\", \"result_label\"]]]\n",
            "\n",
            "input 121:  {\"abstract_id\": 0, \"sentences\": [\"Abstract\\u2014 The new information technology is becoming an important factor in the future development of financial services industry, and especially banking industry.\", \"Growing international trading and problems in transferring money have motivated researchers to introduce a new structure.\", \"E-banking is such idea.\", \"Most of banks are using the Internet as a new distribution channel.\", \"This paper presents a through survey of e-banking describing definition, barriers, benefits from the customers\\u2019, economy, and bank point of views, and main issues and challenges such as risk management and factors responsible for e-banking development.\", \"Finally, conclusion and future perspective of e-banking development will be discussed.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7667, 0.7667, 0.7667, 0.7333]}\n",
            "prediction:  [0, [[\"Abstract\\u2014 The new information technology is becoming an important factor in the future development of financial services industry, and especially banking industry.\", \"background_label\"], [\"Growing international trading and problems in transferring money have motivated researchers to introduce a new structure.\", \"background_label\"], [\"E-banking is such idea.\", \"background_label\"], [\"Most of banks are using the Internet as a new distribution channel.\", \"background_label\"], [\"This paper presents a through survey of e-banking describing definition, barriers, benefits from the customers\\u2019, economy, and bank point of views, and main issues and challenges such as risk management and factors responsible for e-banking development.\", \"method_label\"], [\"Finally, conclusion and future perspective of e-banking development will be discussed.\", \"result_label\"]]]\n",
            "\n",
            "input 122:  {\"abstract_id\": 0, \"sentences\": [\"Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data.\", \"They achieve this by deriving backpropagation signals through a competitive process involving a pair of networks.\", \"The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image superresolution, and classification.\", \"The aim of this review article is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible.\", \"In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\"], \"confs\": [1.0, 0.8158, 0.8158, 1.0, 0.6053]}\n",
            "prediction:  [0, [[\"Generative adversarial networks (GANs) provide a way to learn deep representations without extensively annotated training data.\", \"background_label\"], [\"They achieve this by deriving backpropagation signals through a competitive process involving a pair of networks.\", \"background_label\"], [\"The representations that can be learned by GANs may be used in a variety of applications, including image synthesis, semantic image editing, style transfer, image superresolution, and classification.\", \"background_label\"], [\"The aim of this review article is to provide an overview of GANs for the signal processing community, drawing on familiar analogies and concepts where possible.\", \"objective_label\"], [\"In addition to identifying different methods for training and constructing GANs, we also point to remaining challenges in their theory and application.\", \"method_label\"]]]\n",
            "\n",
            "input 123:  {\"abstract_id\": 0, \"sentences\": [\"This article presents an architecture vision to address the challenges placed on 5G mobile networks.\", \"A two-layer architecture is proposed, consisting of a radio network and a network cloud, integrating various enablers such as small cells, massive MIMO, control/user plane split, NFV, and SDN.\", \"Three main concepts are integrated: ultra-dense small cell deployments on licensed and unlicensed spectrum, under control/user plane split architecture, to address capacity and data rate challenges; NFV and SDN to provide flexible network deployment and operation; and intelligent use of network data to facilitate optimal use of network resources for QoE provisioning and planning.\", \"An initial proof of concept evaluation is presented to demonstrate the potential of the proposal.\", \"Finally, other issues that must be addressed to realize a complete 5G architecture vision are discussed.\"], \"labels\": [\"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.9354, 0.9354, 0.9274, 0.8285, 0.7639]}\n",
            "prediction:  [0, [[\"This article presents an architecture vision to address the challenges placed on 5G mobile networks.\", \"objective_label\"], [\"A two-layer architecture is proposed, consisting of a radio network and a network cloud, integrating various enablers such as small cells, massive MIMO, control/user plane split, NFV, and SDN.\", \"objective_label\"], [\"Three main concepts are integrated: ultra-dense small cell deployments on licensed and unlicensed spectrum, under control/user plane split architecture, to address capacity and data rate challenges; NFV and SDN to provide flexible network deployment and operation; and intelligent use of network data to facilitate optimal use of network resources for QoE provisioning and planning.\", \"method_label\"], [\"An initial proof of concept evaluation is presented to demonstrate the potential of the proposal.\", \"result_label\"], [\"Finally, other issues that must be addressed to realize a complete 5G architecture vision are discussed.\", \"result_label\"]]]\n",
            "\n",
            "input 124:  {\"abstract_id\": 0, \"sentences\": [\"The world of science cannot be measured in terms of development and progress.\", \"It shows how far human mind can work and think.\", \"It has now reached to the technology known as \\u201cBlue eyes technology\\u201d that can sense and control human emotions and feelings through gadgets.\", \"The eyes, fingers, speech are the elements which help to sense the emotion level of human body.\", \"This paper implements a new technique known as Emotion Sensory World of Blue eyes technology which identifies human emotions (sad.happy.exclted or surprised) using image processing techniques by extracting eye portion from the captured image which is then compared with stored images of data base.\", \"After identifying mood the songs will be played to make human emotion level normal.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 0.75, 0.75]}\n",
            "prediction:  [0, [[\"The world of science cannot be measured in terms of development and progress.\", \"background_label\"], [\"It shows how far human mind can work and think.\", \"background_label\"], [\"It has now reached to the technology known as \\u201cBlue eyes technology\\u201d that can sense and control human emotions and feelings through gadgets.\", \"background_label\"], [\"The eyes, fingers, speech are the elements which help to sense the emotion level of human body.\", \"background_label\"], [\"This paper implements a new technique known as Emotion Sensory World of Blue eyes technology which identifies human emotions (sad.happy.exclted or surprised) using image processing techniques by extracting eye portion from the captured image which is then compared with stored images of data base.\", \"method_label\"], [\"After identifying mood the songs will be played to make human emotion level normal.\", \"result_label\"]]]\n",
            "\n",
            "input 125:  {\"abstract_id\": 0, \"sentences\": [\"Mobile business is a young promising industry created by the emergence of wireless data networks.\", \"Similar to other emerging industries, it is characterized by a large number of uncertainties at different levels, in particular concerning technology, business strategy and consumer demand.\", \"This paper focuses on the strategic uncertainties, where a large number of actors are trying a number of strategic approaches to position themselves in the most favourable position in the value system.\", \"This paper intends to apply a business model analysis methodology in order to better understand the strategic approaches of these actors.\", \"We argue that successful business models are likely to be the ones that best address the economic peculiarities underlying this industry, like mobility, network effects and natural monopolies.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 0.9348, 0.8336, 0.7217]}\n",
            "prediction:  [0, [[\"Mobile business is a young promising industry created by the emergence of wireless data networks.\", \"background_label\"], [\"Similar to other emerging industries, it is characterized by a large number of uncertainties at different levels, in particular concerning technology, business strategy and consumer demand.\", \"background_label\"], [\"This paper focuses on the strategic uncertainties, where a large number of actors are trying a number of strategic approaches to position themselves in the most favourable position in the value system.\", \"objective_label\"], [\"This paper intends to apply a business model analysis methodology in order to better understand the strategic approaches of these actors.\", \"objective_label\"], [\"We argue that successful business models are likely to be the ones that best address the economic peculiarities underlying this industry, like mobility, network effects and natural monopolies.\", \"result_label\"]]]\n",
            "\n",
            "input 126:  {\"abstract_id\": 0, \"sentences\": [\"For various reasons, the cloud computing paradigm is unable to meet certain requirements (e.g. low latency and jitter, context awareness, mobility support) that are crucial for several applications (e.g. vehicular networks, augmented reality).\", \"To fulfil these requirements, various paradigms, such as fog computing, mobile edge computing, and mobile cloud computing, have emerged in recent years.\", \"While these edge paradigms share several features, most of the existing research is compartmentalised; no synergies have been explored.\", \"This is especially true in the field of security, where most analyses focus only on one edge paradigm, while ignoring the others.\", \"The main goal of this study is to holistically analyse the security threats, challenges, and mechanisms inherent in all edge paradigms, while highlighting potential synergies and venues of collaboration.\", \"In our results, we will show that all edge paradigms should consider the advances in other paradigms.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"objective\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"For various reasons, the cloud computing paradigm is unable to meet certain requirements (e.g. low latency and jitter, context awareness, mobility support) that are crucial for several applications (e.g. vehicular networks, augmented reality).\", \"background_label\"], [\"To fulfil these requirements, various paradigms, such as fog computing, mobile edge computing, and mobile cloud computing, have emerged in recent years.\", \"background_label\"], [\"While these edge paradigms share several features, most of the existing research is compartmentalised; no synergies have been explored.\", \"background_label\"], [\"This is especially true in the field of security, where most analyses focus only on one edge paradigm, while ignoring the others.\", \"background_label\"], [\"The main goal of this study is to holistically analyse the security threats, challenges, and mechanisms inherent in all edge paradigms, while highlighting potential synergies and venues of collaboration.\", \"objective_label\"], [\"In our results, we will show that all edge paradigms should consider the advances in other paradigms.\", \"result_label\"]]]\n",
            "\n",
            "input 127:  {\"abstract_id\": 0, \"sentences\": [\"In any competitive business, success is based on the ability to make an item more appealing to customers than the competition.\", \"A number of questions arise in the context of this task: how do we formalize and quantify the competitiveness between two items?\", \"Who are the main competitors of a given item?\", \"What are the features of an item that most affect its competitiveness?\", \"Despite the impact and relevance of this problem to many domains, only a limited amount of work has been devoted toward an effective solution.\", \"In this paper, we present a formal definition of the competitiveness between two items, based on the market segments that they can both cover.\", \"Our evaluation of competitiveness utilizes customer reviews, an abundant source of information that is available in a wide range of domains.\", \"We present efficient methods for evaluating competitiveness in large review datasets and address the natural problem of finding the top-k competitors of a given item.\", \"Finally, we evaluate the quality of our results and the scalability of our approach using multiple datasets from different domains.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.8286, 0.8286, 0.6, 0.6, 0.7241, 0.6571, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"In any competitive business, success is based on the ability to make an item more appealing to customers than the competition.\", \"background_label\"], [\"A number of questions arise in the context of this task: how do we formalize and quantify the competitiveness between two items?\", \"background_label\"], [\"Who are the main competitors of a given item?\", \"background_label\"], [\"What are the features of an item that most affect its competitiveness?\", \"background_label\"], [\"Despite the impact and relevance of this problem to many domains, only a limited amount of work has been devoted toward an effective solution.\", \"background_label\"], [\"In this paper, we present a formal definition of the competitiveness between two items, based on the market segments that they can both cover.\", \"method_label\"], [\"Our evaluation of competitiveness utilizes customer reviews, an abundant source of information that is available in a wide range of domains.\", \"method_label\"], [\"We present efficient methods for evaluating competitiveness in large review datasets and address the natural problem of finding the top-k competitors of a given item.\", \"method_label\"], [\"Finally, we evaluate the quality of our results and the scalability of our approach using multiple datasets from different domains.\", \"result_label\"]]]\n",
            "\n",
            "input 128:  {\"abstract_id\": 0, \"sentences\": [\"Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences.\", \"For longer documents and summaries however these models often include repetitive and incoherent phrases.\", \"We introduce a neural network model with a novel intraattention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL).\", \"Models trained only with supervised learning often exhibit \\u201cexposure bias\\u201d \\u2013 they assume ground truth is provided at each step during training.\", \"However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable.\", \"We evaluate this model on the CNN/Daily Mail and New York Times datasets.\", \"Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models.\", \"Human evaluation also shows that our model produces higher quality summaries.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 0.7, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences.\", \"background_label\"], [\"For longer documents and summaries however these models often include repetitive and incoherent phrases.\", \"background_label\"], [\"We introduce a neural network model with a novel intraattention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL).\", \"method_label\"], [\"Models trained only with supervised learning often exhibit \\u201cexposure bias\\u201d \\u2013 they assume ground truth is provided at each step during training.\", \"method_label\"], [\"However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable.\", \"method_label\"], [\"We evaluate this model on the CNN/Daily Mail and New York Times datasets.\", \"result_label\"], [\"Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models.\", \"result_label\"], [\"Human evaluation also shows that our model produces higher quality summaries.\", \"result_label\"]]]\n",
            "\n",
            "input 129:  {\"abstract_id\": 0, \"sentences\": [\"In Singapore and Malaysia, people often speak a mixture of Mandarin and English within a single sentence.\", \"We call such sentences intra-sentential code-switch sentences.\", \"In this paper, we report on the development of a Mandarin-English codeswitching spontaneous speech corpus: SEAME.\", \"The corpus is developed as part of a multilingual speech recognition project and will be used to examine how Mandarin-English codeswitch speech occurs in the spoken language in South-East Asia.\", \"Additionally, it can provide insights into the development of large vocabulary continuous speech recognition (LVCSR) for code-switching speech.\", \"The corpus collected consists of intra-sentential code-switching utterances that are recorded under both interview and conversational settings.\", \"This paper describes the corpus design and the analysis of collected corpus.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 0.6842, 1.0, 0.6842, 0.6842, 0.6842]}\n",
            "prediction:  [0, [[\"In Singapore and Malaysia, people often speak a mixture of Mandarin and English within a single sentence.\", \"background_label\"], [\"We call such sentences intra-sentential code-switch sentences.\", \"background_label\"], [\"In this paper, we report on the development of a Mandarin-English codeswitching spontaneous speech corpus: SEAME.\", \"objective_label\"], [\"The corpus is developed as part of a multilingual speech recognition project and will be used to examine how Mandarin-English codeswitch speech occurs in the spoken language in South-East Asia.\", \"method_label\"], [\"Additionally, it can provide insights into the development of large vocabulary continuous speech recognition (LVCSR) for code-switching speech.\", \"objective_label\"], [\"The corpus collected consists of intra-sentential code-switching utterances that are recorded under both interview and conversational settings.\", \"method_label\"], [\"This paper describes the corpus design and the analysis of collected corpus.\", \"result_label\"]]]\n",
            "\n",
            "input 130:  {\"abstract_id\": 0, \"sentences\": [\"Knowledge Portals (KPs) are highly integrative Knowledge Management Systems (KMS) that promise to synthesize widely dispersed knowledge and to interconnect individuals in order to provide a \\u2018one-stop knowledge shop\\u2019.\", \"Yet, KPs face major challenges in practice, as the intricacies of knowledge exchange are subject to varied individual and social factors.\", \"At the same time, growing anecdotal evidence from case studies indicates KPs\\u2019 enormous potential.\", \"In this paper, we take some initial steps towards a theory for KPs that more distinctly conceptualizes KPs and emphasizes a KP\\u2019s role to unify networking and repository KMS features.\", \"We describe three major challenges to successful KP deployment: (1) sufficient contribution, (2) favorable organizational culture, and (3) knowledge integration\\u2014and validate these as applicable to KPs through a review of 42 empirical papers.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\"], \"confs\": [0.8056, 0.8056, 0.8056, 0.6111, 1.0]}\n",
            "prediction:  [0, [[\"Knowledge Portals (KPs) are highly integrative Knowledge Management Systems (KMS) that promise to synthesize widely dispersed knowledge and to interconnect individuals in order to provide a \\u2018one-stop knowledge shop\\u2019.\", \"background_label\"], [\"Yet, KPs face major challenges in practice, as the intricacies of knowledge exchange are subject to varied individual and social factors.\", \"background_label\"], [\"At the same time, growing anecdotal evidence from case studies indicates KPs\\u2019 enormous potential.\", \"background_label\"], [\"In this paper, we take some initial steps towards a theory for KPs that more distinctly conceptualizes KPs and emphasizes a KP\\u2019s role to unify networking and repository KMS features.\", \"objective_label\"], [\"We describe three major challenges to successful KP deployment: (1) sufficient contribution, (2) favorable organizational culture, and (3) knowledge integration\\u2014and validate these as applicable to KPs through a review of 42 empirical papers.\", \"result_label\"]]]\n",
            "\n",
            "input 131:  {\"abstract_id\": 0, \"sentences\": [\"The volume of convolutional neural network (CNN) models proposed for face recognition has been continuously growing larger to better fit the large amount of training data.\", \"When training data are obtained from the Internet, the labels are likely to be ambiguous and inaccurate.\", \"This paper presents a Light CNN framework to learn a compact embedding on the large-scale face data with massive noisy labels.\", \"First, we introduce a variation of maxout activation, called max-feature-map (MFM), into each convolutional layer of CNN.\", \"Different from maxout activation that uses many feature maps to linearly approximate an arbitrary convex activation function, MFM does so via a competitive relationship.\", \"MFM can not only separate noisy and informative signals but also play the role of feature selection between two feature maps.\", \"Second, three networks are carefully designed to obtain better performance, meanwhile, reducing the number of parameters and computational costs.\", \"Finally, a semantic bootstrapping method is proposed to make the prediction of the networks more consistent with noisy labels.\", \"Experimental results show that the proposed framework can utilize large-scale noisy data to learn a Light model that is efficient in computational costs and storage spaces.\", \"The learned single network with a 256-D representation achieves state-of-the-art results on various face benchmarks without fine-tuning.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.7333, 0.7333, 0.7333, 1.0, 1.0, 0.7333, 1.0, 0.7333, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"The volume of convolutional neural network (CNN) models proposed for face recognition has been continuously growing larger to better fit the large amount of training data.\", \"background_label\"], [\"When training data are obtained from the Internet, the labels are likely to be ambiguous and inaccurate.\", \"background_label\"], [\"This paper presents a Light CNN framework to learn a compact embedding on the large-scale face data with massive noisy labels.\", \"objective_label\"], [\"First, we introduce a variation of maxout activation, called max-feature-map (MFM), into each convolutional layer of CNN.\", \"method_label\"], [\"Different from maxout activation that uses many feature maps to linearly approximate an arbitrary convex activation function, MFM does so via a competitive relationship.\", \"method_label\"], [\"MFM can not only separate noisy and informative signals but also play the role of feature selection between two feature maps.\", \"method_label\"], [\"Second, three networks are carefully designed to obtain better performance, meanwhile, reducing the number of parameters and computational costs.\", \"method_label\"], [\"Finally, a semantic bootstrapping method is proposed to make the prediction of the networks more consistent with noisy labels.\", \"method_label\"], [\"Experimental results show that the proposed framework can utilize large-scale noisy data to learn a Light model that is efficient in computational costs and storage spaces.\", \"result_label\"], [\"The learned single network with a 256-D representation achieves state-of-the-art results on various face benchmarks without fine-tuning.\", \"result_label\"]]]\n",
            "\n",
            "input 132:  {\"abstract_id\": 0, \"sentences\": [\"In this brief, a systematic design procedure for a second-order all-digital phase-locked loop (PLL) is proposed.\", \"The design procedure is based on the analogy between a type-II second-order analog PLL and an all-digital PLL.\", \"The all-digital PLL design inherits the frequency response and stability characteristics of the analog prototype PLL\"], \"labels\": [\"objective\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"In this brief, a systematic design procedure for a second-order all-digital phase-locked loop (PLL) is proposed.\", \"objective_label\"], [\"The design procedure is based on the analogy between a type-II second-order analog PLL and an all-digital PLL.\", \"method_label\"], [\"The all-digital PLL design inherits the frequency response and stability characteristics of the analog prototype PLL\", \"method_label\"]]]\n",
            "\n",
            "input 133:  {\"abstract_id\": 0, \"sentences\": [\"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains.\", \"Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information.\", \"The models should not expose private information in these datasets.\", \"Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy.\", \"Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7887, 0.6075, 0.8189]}\n",
            "prediction:  [0, [[\"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains.\", \"background_label\"], [\"Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information.\", \"background_label\"], [\"The models should not expose private information in these datasets.\", \"background_label\"], [\"Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy.\", \"objective_label\"], [\"Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.\", \"result_label\"]]]\n",
            "\n",
            "input 134:  {\"abstract_id\": 0, \"sentences\": [\"Previous studies have presented conflicting claims regarding reasons that people become addicted to the Internet.\", \"In this study, we attempted to identify predictors of Internet addiction based on Sullivan's interpersonal theory and Internet addiction literature.\", \"In our research model, it is hypothesized that good parent-child relationship positively correlates with good interpersonal relationships, which in turn are hypothesized to correlate with undesirable social anxiety.\", \"In addition, both parent-child and interpersonal relationships are hypothesized to negatively correlate with Internet addiction, whereas the level of social anxiety is hypothesized to positively correlate with Internet addiction.\", \"The results of this study confirm the research model hypotheses, indicating that the quality of parent-child relationship is indeed positively correlated to the quality of our participants' interpersonal relationships and that frustrating interpersonal relationships may raise the level of social anxiety.\", \"In addition, interpersonal relationships, the parent-child relationship, and social anxiety all influence Internet addiction, as predicted by the model.\", \"Finally, the more social anxiety and discontent with their peer interactions the participants experienced, the more addicted they were to the Internet.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\", \"result\", \"result\"], \"confs\": [0.8158, 0.7895, 0.6053, 0.6053, 0.6053, 0.7895, 1.0]}\n",
            "prediction:  [0, [[\"Previous studies have presented conflicting claims regarding reasons that people become addicted to the Internet.\", \"background_label\"], [\"In this study, we attempted to identify predictors of Internet addiction based on Sullivan's interpersonal theory and Internet addiction literature.\", \"objective_label\"], [\"In our research model, it is hypothesized that good parent-child relationship positively correlates with good interpersonal relationships, which in turn are hypothesized to correlate with undesirable social anxiety.\", \"objective_label\"], [\"In addition, both parent-child and interpersonal relationships are hypothesized to negatively correlate with Internet addiction, whereas the level of social anxiety is hypothesized to positively correlate with Internet addiction.\", \"method_label\"], [\"The results of this study confirm the research model hypotheses, indicating that the quality of parent-child relationship is indeed positively correlated to the quality of our participants' interpersonal relationships and that frustrating interpersonal relationships may raise the level of social anxiety.\", \"result_label\"], [\"In addition, interpersonal relationships, the parent-child relationship, and social anxiety all influence Internet addiction, as predicted by the model.\", \"result_label\"], [\"Finally, the more social anxiety and discontent with their peer interactions the participants experienced, the more addicted they were to the Internet.\", \"result_label\"]]]\n",
            "\n",
            "input 135:  {\"abstract_id\": 0, \"sentences\": [\"For urban driving, knowledge of ego-vehicle's position is a critical piece of information that enables advanced driver-assistance systems or self-driving cars to execute safety-related, autonomous driving maneuvers.\", \"This is because, without knowing the current location, it is very hard to autonomously execute any driving maneuvers for the future.\", \"The existing solutions for localization rely on a combination of Global Navigation Satellite System (GNSS), an inertial measurement unit, and a digital map.\", \"However, on urban driving environments, due to poor satellite geometry and disruption of radio signal reception, their longitudinal and lateral errors are too significant to be used to guide an autonomous system.\", \"To enhance the existing system's localization capability, this work presents an effort of developing a vision-based lateral localization algorithm.\", \"The algorithm aims at reliably counting, with or without observations of lane-markings, the number road-lanes and identifying the index of the road-lane on the roadway that our vehicle happens to be driving on.\", \"Testings the proposed algorithms against inter-city and inter-state highway videos showed promising results in terms of counting the number of road-lanes and the indices of the current road-lanes.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [0.8, 1.0, 0.6, 0.8, 0.6, 0.8, 0.6]}\n",
            "prediction:  [0, [[\"For urban driving, knowledge of ego-vehicle's position is a critical piece of information that enables advanced driver-assistance systems or self-driving cars to execute safety-related, autonomous driving maneuvers.\", \"background_label\"], [\"This is because, without knowing the current location, it is very hard to autonomously execute any driving maneuvers for the future.\", \"background_label\"], [\"The existing solutions for localization rely on a combination of Global Navigation Satellite System (GNSS), an inertial measurement unit, and a digital map.\", \"background_label\"], [\"However, on urban driving environments, due to poor satellite geometry and disruption of radio signal reception, their longitudinal and lateral errors are too significant to be used to guide an autonomous system.\", \"background_label\"], [\"To enhance the existing system's localization capability, this work presents an effort of developing a vision-based lateral localization algorithm.\", \"objective_label\"], [\"The algorithm aims at reliably counting, with or without observations of lane-markings, the number road-lanes and identifying the index of the road-lane on the roadway that our vehicle happens to be driving on.\", \"method_label\"], [\"Testings the proposed algorithms against inter-city and inter-state highway videos showed promising results in terms of counting the number of road-lanes and the indices of the current road-lanes.\", \"result_label\"]]]\n",
            "\n",
            "input 136:  {\"abstract_id\": 0, \"sentences\": [\"The core capabilities of an organization include critical skills of employees, management systems, and norms and values.\", \"Core capabilities may be transferred fonnally and explicitly.\", \"However, much knowledge, particularly knowledge with rich tacit dimensions, is transferred informally through processes of socialization and intemaiization.\", \"We focus on two transfer mechanisms\\u2014mentoring and storytelling\\u2014that can leverage the knowledge of an organization, particularly its tacit knowledge, to build core capabilities.\", \"We draw on relevant research in leaming and cognitive psychology to clarify the conditions under which mentoring and storytelling can be most effective as carriers of knowledge.\", \"Finally, we present recommendations for specific managerial practices that follow from our analysis.\", \"Journal of Management Information Systems /Summer 200\\\\, Vol.\", \"18, No. 1, pp.\", \"95-114. \\u00a92001 M.E. Sharpe, Inc. 0742-1222 / 2001 $9.50 + 0.00.\", \"96 SWAP, LEONARD, SHIELDS, AND ABRAMS\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"other\", \"other\", \"other\", \"other\"], \"confs\": [1.0, 1.0, 0.8, 1.0, 0.6, 0.6, 0.6, 0.6, 0.8, 1.0]}\n",
            "prediction:  [0, [[\"The core capabilities of an organization include critical skills of employees, management systems, and norms and values.\", \"background_label\"], [\"Core capabilities may be transferred fonnally and explicitly.\", \"background_label\"], [\"However, much knowledge, particularly knowledge with rich tacit dimensions, is transferred informally through processes of socialization and intemaiization.\", \"background_label\"], [\"We focus on two transfer mechanisms\\u2014mentoring and storytelling\\u2014that can leverage the knowledge of an organization, particularly its tacit knowledge, to build core capabilities.\", \"objective_label\"], [\"We draw on relevant research in leaming and cognitive psychology to clarify the conditions under which mentoring and storytelling can be most effective as carriers of knowledge.\", \"method_label\"], [\"Finally, we present recommendations for specific managerial practices that follow from our analysis.\", \"method_label\"], [\"Journal of Management Information Systems /Summer 200\\\\, Vol.\", \"other_label\"], [\"18, No. 1, pp.\", \"other_label\"], [\"95-114. \\u00a92001 M.E. Sharpe, Inc. 0742-1222 / 2001 $9.50 + 0.00.\", \"other_label\"], [\"96 SWAP, LEONARD, SHIELDS, AND ABRAMS\", \"other_label\"]]]\n",
            "\n",
            "input 137:  {\"abstract_id\": 0, \"sentences\": [\"There has been much interest in the Sharing Economy in recent years, accompanied with the hope that it will change and specifically make better use of existing resources.\", \"It intuitively makes sense, from a sustainability point of view, that the sharing of resources is good.\", \"It could even be said that the Sharing Economy ought to align well with Computing within Limits and its underlying premises.\", \"In this paper however, we take a critical stance and will elaborate on the intersection between the Sharing Economy and Limits (including pinpointing potential conflicts) so as to identify and discuss a 'Limits-compliant Sharing Economy'.\", \"We argue that even though there are limits to the Sharing Economy today, it still has potential benefits for a future of scarcity---but only if the practice of sharing is approached with a dual focus on sharing and on limits at the same time.\", \"Finally we conclude that even though we have begun to explore the future of sharing, there is still a need to further develop ideas of how the underlying infrastructure for this movement will look.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.7931, 0.7931, 0.7931, 1.0, 0.7241, 1.0]}\n",
            "prediction:  [0, [[\"There has been much interest in the Sharing Economy in recent years, accompanied with the hope that it will change and specifically make better use of existing resources.\", \"background_label\"], [\"It intuitively makes sense, from a sustainability point of view, that the sharing of resources is good.\", \"background_label\"], [\"It could even be said that the Sharing Economy ought to align well with Computing within Limits and its underlying premises.\", \"background_label\"], [\"In this paper however, we take a critical stance and will elaborate on the intersection between the Sharing Economy and Limits (including pinpointing potential conflicts) so as to identify and discuss a 'Limits-compliant Sharing Economy'.\", \"method_label\"], [\"We argue that even though there are limits to the Sharing Economy today, it still has potential benefits for a future of scarcity---but only if the practice of sharing is approached with a dual focus on sharing and on limits at the same time.\", \"method_label\"], [\"Finally we conclude that even though we have begun to explore the future of sharing, there is still a need to further develop ideas of how the underlying infrastructure for this movement will look.\", \"result_label\"]]]\n",
            "\n",
            "input 138:  {\"abstract_id\": 0, \"sentences\": [\"There are many situations in which it is desirable to be able to distinguish spontaneous speech and speech which is non-spontaneous.\", \"Examples of situations in which this problem may arise include forensic evidence situations, sorting voice-mail responses from voice-mail menus, and automatic segmentation of spontaneous responses from prepared questions.\", \"The later situation can occur if it is desired to create a database of spontaneous data from data which consists of spontaneous discourse responding to prepared prompts.\", \"This paper outlines and compares three methods for automatically classifying spontaneous and non-spontaneous speech and presents the cxperimcntal results comparing the performance of the methods.\", \"All three methods are based on an analysis of the probability distributions of prosodic fcatures extracted from the speech signal.\", \"The first method uses an expansion of the of the probability distribution in terms of the statistical moments.\", \"The second method is an application of a modifed Hellinger\\u2019s method applied to histograms of signal amplitude and other speech features.\", \"The third method is based on a measure of the nonGaussianity of the data.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"method\"], \"confs\": [0.8, 0.8, 0.6, 0.6, 0.8286, 0.8, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"There are many situations in which it is desirable to be able to distinguish spontaneous speech and speech which is non-spontaneous.\", \"background_label\"], [\"Examples of situations in which this problem may arise include forensic evidence situations, sorting voice-mail responses from voice-mail menus, and automatic segmentation of spontaneous responses from prepared questions.\", \"background_label\"], [\"The later situation can occur if it is desired to create a database of spontaneous data from data which consists of spontaneous discourse responding to prepared prompts.\", \"background_label\"], [\"This paper outlines and compares three methods for automatically classifying spontaneous and non-spontaneous speech and presents the cxperimcntal results comparing the performance of the methods.\", \"method_label\"], [\"All three methods are based on an analysis of the probability distributions of prosodic fcatures extracted from the speech signal.\", \"method_label\"], [\"The first method uses an expansion of the of the probability distribution in terms of the statistical moments.\", \"method_label\"], [\"The second method is an application of a modifed Hellinger\\u2019s method applied to histograms of signal amplitude and other speech features.\", \"method_label\"], [\"The third method is based on a measure of the nonGaussianity of the data.\", \"method_label\"]]]\n",
            "\n",
            "input 139:  {\"abstract_id\": 0, \"sentences\": [\"This paper gives an overview of automatic speaker recognition technology, with an emphasis on text-independent recognition.\", \"Speaker recognition has been studied actively for several decades.\", \"We give an overview of both the classical and the state-of-the-art methods.\", \"We start with the fundamentals of automatic speaker recognition, concerning feature extraction and speaker modeling.\", \"We elaborate advanced computational techniques to address robustness and session variability.\", \"The recent progress from vectors towards supervectors opens up a new area of exploration and represents a technology trend.\", \"We also provide an overview of this recent development and discuss the evaluation methodology of speaker recognition systems.\", \"We conclude the paper with discussion on future directions.\", \"2009 Elsevier B.V. All rights reserved.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\", \"other\"], \"confs\": [0.7931, 1.0, 1.0, 1.0, 1.0, 0.7931, 0.7931, 0.7586, 1.0]}\n",
            "prediction:  [0, [[\"This paper gives an overview of automatic speaker recognition technology, with an emphasis on text-independent recognition.\", \"background_label\"], [\"Speaker recognition has been studied actively for several decades.\", \"background_label\"], [\"We give an overview of both the classical and the state-of-the-art methods.\", \"method_label\"], [\"We start with the fundamentals of automatic speaker recognition, concerning feature extraction and speaker modeling.\", \"method_label\"], [\"We elaborate advanced computational techniques to address robustness and session variability.\", \"method_label\"], [\"The recent progress from vectors towards supervectors opens up a new area of exploration and represents a technology trend.\", \"method_label\"], [\"We also provide an overview of this recent development and discuss the evaluation methodology of speaker recognition systems.\", \"method_label\"], [\"We conclude the paper with discussion on future directions.\", \"result_label\"], [\"2009 Elsevier B.V. All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 140:  {\"abstract_id\": 0, \"sentences\": [\"Survival analysis (time-to-event analysis) is widely used in economics and finance, engineering, medicine and many other areas.\", \"A fundamental problem is to understand the relationship between the covariates and the (distribution of) survival times (times-to-event).\", \"Much of the previous work has approached the problem by viewing the survival time as the first hitting time of a stochastic process, assuming a specific form for the underlying stochastic process, using available data to learn the relationship between the covariates and the parameters of the model, and then deducing the relationship between covariates and the distribution of first hitting times (the risk).\", \"However, previous models rely on strong parametric assumptions that are often violated.\", \"This paper proposes a very different approach to survival analysis, DeepHit, that uses a deep neural network to learn the distribution of survival times directly.\", \"DeepHit makes no assumptions about the underlying stochastic process and allows for the possibility that the relationship between covariates and risk(s) changes over time.\", \"Most importantly, DeepHit smoothly handles competing risks; i.e. settings in which there is more than one possible event of interest.\", \"Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves large and statistically significant performance improvements over previous state-of-the-art methods.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [0.7419, 1.0, 0.7419, 1.0, 0.7419, 0.7419, 0.7419, 0.7419]}\n",
            "prediction:  [0, [[\"Survival analysis (time-to-event analysis) is widely used in economics and finance, engineering, medicine and many other areas.\", \"background_label\"], [\"A fundamental problem is to understand the relationship between the covariates and the (distribution of) survival times (times-to-event).\", \"background_label\"], [\"Much of the previous work has approached the problem by viewing the survival time as the first hitting time of a stochastic process, assuming a specific form for the underlying stochastic process, using available data to learn the relationship between the covariates and the parameters of the model, and then deducing the relationship between covariates and the distribution of first hitting times (the risk).\", \"background_label\"], [\"However, previous models rely on strong parametric assumptions that are often violated.\", \"background_label\"], [\"This paper proposes a very different approach to survival analysis, DeepHit, that uses a deep neural network to learn the distribution of survival times directly.\", \"objective_label\"], [\"DeepHit makes no assumptions about the underlying stochastic process and allows for the possibility that the relationship between covariates and risk(s) changes over time.\", \"method_label\"], [\"Most importantly, DeepHit smoothly handles competing risks; i.e. settings in which there is more than one possible event of interest.\", \"method_label\"], [\"Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves large and statistically significant performance improvements over previous state-of-the-art methods.\", \"result_label\"]]]\n",
            "\n",
            "input 141:  {\"abstract_id\": 0, \"sentences\": [\"In this paper we present an implementation of the modified Becke\\u2013Johnson meta-GGA functional (TB09) in the PWSCF program of Quantum ESPRESSO package via the Libxc library.\", \"Using the functionals of TB09 we calculated the band gaps of some semiconductors and compared the resultswith previous calculations and experiments.\", \"We showed that combining GGA pseudo-potential with TB09 functionals would improve greatly the band gaps compared with the GGA calculations.\", \"The details of our implementation and code samples are also given.\", \"\\u00a9 2013 Elsevier B.V.\", \"All rights reserved.\"], \"labels\": [\"method\", \"method\", \"result\", \"result\", \"other\", \"other\"], \"confs\": [0.6176, 1.0, 0.8235, 0.8235, 0.8235, 0.8235]}\n",
            "prediction:  [0, [[\"In this paper we present an implementation of the modified Becke\\u2013Johnson meta-GGA functional (TB09) in the PWSCF program of Quantum ESPRESSO package via the Libxc library.\", \"background_label\"], [\"Using the functionals of TB09 we calculated the band gaps of some semiconductors and compared the resultswith previous calculations and experiments.\", \"method_label\"], [\"We showed that combining GGA pseudo-potential with TB09 functionals would improve greatly the band gaps compared with the GGA calculations.\", \"result_label\"], [\"The details of our implementation and code samples are also given.\", \"result_label\"], [\"\\u00a9 2013 Elsevier B.V.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 142:  {\"abstract_id\": 0, \"sentences\": [\"V-model and its variants have become the most common process models adopted in automotive industry guiding the development of systems on a variety of refinement levels.\", \"Along with the exponentially growing complexity of modern vehicle systems, however, the late verification and validation in the conventional V-model expand in uncontrollable ways that result in higher cost of development and higher risk of failure than ever.\", \"This paper describes an inc-V development process for automotive industry that improves the conventional V-model and variants by introducing and institutionalizing early and continuous integrated verification enabled by simulation-based development.\", \"We developed a continuous simulation model of the inc-V process, and the initial version is used to investigate the characteristics of the inc-V compared to V. The preliminary finding from the simulations of an example project is that the inc-V process is able to improve the traditional V process by saving effort, shortening duration, and increasing product quality.\", \"The finding also show how the advance of development technology impacts the systems engineering processes.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 0.7419, 0.7419, 0.7419, 1.0]}\n",
            "prediction:  [0, [[\"V-model and its variants have become the most common process models adopted in automotive industry guiding the development of systems on a variety of refinement levels.\", \"background_label\"], [\"Along with the exponentially growing complexity of modern vehicle systems, however, the late verification and validation in the conventional V-model expand in uncontrollable ways that result in higher cost of development and higher risk of failure than ever.\", \"background_label\"], [\"This paper describes an inc-V development process for automotive industry that improves the conventional V-model and variants by introducing and institutionalizing early and continuous integrated verification enabled by simulation-based development.\", \"method_label\"], [\"We developed a continuous simulation model of the inc-V process, and the initial version is used to investigate the characteristics of the inc-V compared to V. The preliminary finding from the simulations of an example project is that the inc-V process is able to improve the traditional V process by saving effort, shortening duration, and increasing product quality.\", \"method_label\"], [\"The finding also show how the advance of development technology impacts the systems engineering processes.\", \"result_label\"]]]\n",
            "\n",
            "input 143:  {\"abstract_id\": 0, \"sentences\": [\"Automated medical image analysis has a significant value in diagnosis and treatment of lesions.\", \"Brain tumors segmentation has a special importance and difficulty due to the difference in appearances and shapes of the different tumor regions in magnetic resonance images.\", \"Additionally the data sets are heterogeneous and usually limited in size in comparison with the computer vision problems.\", \"The recently proposed adversarial training has shown promising results in generative image modeling.\", \"In this paper we propose a novel end-to-end trainable architecture for brain tumor semantic segmentation through conditional adversarial training.\", \"We exploit conditional Generative Adversarial Network (cGAN) and train a semantic segmentation Convolution Neural Network (CNN) along with an adversarial network that discriminates segmentation maps coming from the ground truth or from the segmentation network for BraTS 2017 segmentation task[15,4,2,3].\", \"We also propose an end-to-end trainable CNN for survival day prediction based on deep learning techniques for BraTS 2017 prediction task [15,4,2,3].\", \"The experimental results demonstrate the superior ability of the proposed approach for both tasks.\", \"The proposed model achieves on validation data a DICE score, Sensitivity and Specificity respectively 0.68, 0.99 and 0.98 for the whole tumor, regarding online judgment system.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.8158, 1.0, 0.6053, 0.6053, 0.7895, 0.6053, 0.6053, 1.0, 0.7895]}\n",
            "prediction:  [0, [[\"Automated medical image analysis has a significant value in diagnosis and treatment of lesions.\", \"background_label\"], [\"Brain tumors segmentation has a special importance and difficulty due to the difference in appearances and shapes of the different tumor regions in magnetic resonance images.\", \"background_label\"], [\"Additionally the data sets are heterogeneous and usually limited in size in comparison with the computer vision problems.\", \"background_label\"], [\"The recently proposed adversarial training has shown promising results in generative image modeling.\", \"background_label\"], [\"In this paper we propose a novel end-to-end trainable architecture for brain tumor semantic segmentation through conditional adversarial training.\", \"objective_label\"], [\"We exploit conditional Generative Adversarial Network (cGAN) and train a semantic segmentation Convolution Neural Network (CNN) along with an adversarial network that discriminates segmentation maps coming from the ground truth or from the segmentation network for BraTS 2017 segmentation task[15,4,2,3].\", \"method_label\"], [\"We also propose an end-to-end trainable CNN for survival day prediction based on deep learning techniques for BraTS 2017 prediction task [15,4,2,3].\", \"method_label\"], [\"The experimental results demonstrate the superior ability of the proposed approach for both tasks.\", \"result_label\"], [\"The proposed model achieves on validation data a DICE score, Sensitivity and Specificity respectively 0.68, 0.99 and 0.98 for the whole tumor, regarding online judgment system.\", \"result_label\"]]]\n",
            "\n",
            "input 144:  {\"abstract_id\": 0, \"sentences\": [\"T paper shows that corporate social responsibility (CSR) and firm value are positively related for firms with high customer awareness, as proxied by advertising expenditures.\", \"For firms with low customer awareness, the relation is either negative or insignificant.\", \"In addition, we find that the effect of awareness on the CSR\\u2013value relation is reversed for firms with a poor prior reputation as corporate citizens.\", \"This evidence is consistent with the view that CSR activities can add value to the firm but only under certain conditions.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\"], \"confs\": [0.6957, 1.0, 0.6957, 0.6957]}\n",
            "prediction:  [0, [[\"T paper shows that corporate social responsibility (CSR) and firm value are positively related for firms with high customer awareness, as proxied by advertising expenditures.\", \"background_label\"], [\"For firms with low customer awareness, the relation is either negative or insignificant.\", \"background_label\"], [\"In addition, we find that the effect of awareness on the CSR\\u2013value relation is reversed for firms with a poor prior reputation as corporate citizens.\", \"result_label\"], [\"This evidence is consistent with the view that CSR activities can add value to the firm but only under certain conditions.\", \"result_label\"]]]\n",
            "\n",
            "input 145:  {\"abstract_id\": 0, \"sentences\": [\"Monitoring the attentive and emotional status of the driver is critical for the safety and comfort of driving.\", \"In this work a real-time non-intrusive monitoring system is developed, which detects the emotional states of the driver by analyzing facial expressions.\", \"The system considers two negative basic emotions, anger and disgust, as stress related emotions.\", \"We detect an individual emotion in each video frame and the decision on the stress level is made on sequence level.\", \"Experimental results show that the developed system operates very well on simulated data even with generic models.\", \"An additional pose normalization step reduces the impact of pose mismatch due to camera setup and pose variation, and hence improves the detection accuracy further.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.6154, 0.7949, 1.0, 1.0, 0.7949]}\n",
            "prediction:  [0, [[\"Monitoring the attentive and emotional status of the driver is critical for the safety and comfort of driving.\", \"background_label\"], [\"In this work a real-time non-intrusive monitoring system is developed, which detects the emotional states of the driver by analyzing facial expressions.\", \"objective_label\"], [\"The system considers two negative basic emotions, anger and disgust, as stress related emotions.\", \"method_label\"], [\"We detect an individual emotion in each video frame and the decision on the stress level is made on sequence level.\", \"method_label\"], [\"Experimental results show that the developed system operates very well on simulated data even with generic models.\", \"result_label\"], [\"An additional pose normalization step reduces the impact of pose mismatch due to camera setup and pose variation, and hence improves the detection accuracy further.\", \"result_label\"]]]\n",
            "\n",
            "input 146:  {\"abstract_id\": 0, \"sentences\": [\"Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products).\", \"In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases).\", \"There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive knearest-neighbor (kNN).\", \"Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking.\", \"In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem.\", \"We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt.\", \"The learning method is based on stochastic gradient descent with bootstrap sampling.\", \"We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN.\", \"Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN.\", \"The results show the importance of optimizing models for the right criterion.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.6053, 1.0, 0.7895, 0.7895, 0.6053, 0.6053, 1.0, 0.7895, 0.7895, 0.6053]}\n",
            "prediction:  [0, [[\"Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products).\", \"background_label\"], [\"In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases).\", \"background_label\"], [\"There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive knearest-neighbor (kNN).\", \"method_label\"], [\"Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking.\", \"method_label\"], [\"In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem.\", \"method_label\"], [\"We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt.\", \"method_label\"], [\"The learning method is based on stochastic gradient descent with bootstrap sampling.\", \"method_label\"], [\"We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN.\", \"method_label\"], [\"Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN.\", \"result_label\"], [\"The results show the importance of optimizing models for the right criterion.\", \"result_label\"]]]\n",
            "\n",
            "input 147:  {\"abstract_id\": 0, \"sentences\": [\"Addison-Wesley Pub.\", \"Co., 1974, , 470 pages.\", \"With this text, you gain an understanding of the fundamental concepts of algorithms, the very heart of computer science.\", \"It introduces the basic data structures and programming techniques often used in efficient algorithms.\", \"Covers use of lists, push-down stacks, queues, trees, and graphs.\", \"Later chapters go into sorting, searching and graphing algorithms, the string-matching algorithms, and the Schonhage-Strassen integer-multiplication algorithm.\", \"Provides numerous graded exercises at the end of each chapter.\", \"0201000296B04062001.\"], \"labels\": [\"other\", \"other\", \"background\", \"background\", \"background\", \"background\", \"background\", \"other\"], \"confs\": [0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7]}\n",
            "prediction:  [0, [[\"Addison-Wesley Pub.\", \"background_label\"], [\"Co., 1974, , 470 pages.\", \"background_label\"], [\"With this text, you gain an understanding of the fundamental concepts of algorithms, the very heart of computer science.\", \"background_label\"], [\"It introduces the basic data structures and programming techniques often used in efficient algorithms.\", \"objective_label\"], [\"Covers use of lists, push-down stacks, queues, trees, and graphs.\", \"method_label\"], [\"Later chapters go into sorting, searching and graphing algorithms, the string-matching algorithms, and the Schonhage-Strassen integer-multiplication algorithm.\", \"method_label\"], [\"Provides numerous graded exercises at the end of each chapter.\", \"method_label\"], [\"0201000296B04062001.\", \"other_label\"]]]\n",
            "\n",
            "input 148:  {\"abstract_id\": 0, \"sentences\": [\"5G wireless technology is paving the way to revolutionize future ubiquitous and pervasive networking, wireless applications, and user quality of experience.\", \"To realize its potential, 5G must provide considerably higher network capacity, enable massive device connectivity with reduced latency and cost, and achieve considerable energy savings compared to existing wireless technologies.\", \"The main objective of this article is to explore the potential of NFV in enhancing 5G radio access networks' functional, architectural, and commercial viability, including increased automation, operational agility, and reduced capital expenditure.\", \"The ETSI NFV Industry Specification Group has recently published drafts focused on standardization and implementation of NFV.\", \"Harnessing the potential of 5G and network functions virtualization, we discuss how NFV can address critical 5G design challenges through service abstraction and virtualized computing, storage, and network resources.\", \"We describe NFV implementation with network overlay and SDN technologies.\", \"In our discussion, we cover the first steps in understanding the role of NFV in implementing CoMP, D2D communication, and ultra densified networks.\"], \"labels\": [\"background\", \"background\", \"objective\", \"background\", \"method\", \"method\", \"method\"], \"confs\": [0.7241, 0.7241, 0.7586, 0.7241, 0.7241, 0.7241, 0.7586]}\n",
            "prediction:  [0, [[\"5G wireless technology is paving the way to revolutionize future ubiquitous and pervasive networking, wireless applications, and user quality of experience.\", \"background_label\"], [\"To realize its potential, 5G must provide considerably higher network capacity, enable massive device connectivity with reduced latency and cost, and achieve considerable energy savings compared to existing wireless technologies.\", \"background_label\"], [\"The main objective of this article is to explore the potential of NFV in enhancing 5G radio access networks' functional, architectural, and commercial viability, including increased automation, operational agility, and reduced capital expenditure.\", \"objective_label\"], [\"The ETSI NFV Industry Specification Group has recently published drafts focused on standardization and implementation of NFV.\", \"method_label\"], [\"Harnessing the potential of 5G and network functions virtualization, we discuss how NFV can address critical 5G design challenges through service abstraction and virtualized computing, storage, and network resources.\", \"method_label\"], [\"We describe NFV implementation with network overlay and SDN technologies.\", \"method_label\"], [\"In our discussion, we cover the first steps in understanding the role of NFV in implementing CoMP, D2D communication, and ultra densified networks.\", \"result_label\"]]]\n",
            "\n",
            "input 149:  {\"abstract_id\": 0, \"sentences\": [\"Templates are an important asset for question answering over knowledge graphs, simplifying the semantic parsing of input utterances and generating structured queries for interpretable answers.\", \"Stateof-the-art methods rely on hand-crafted templates with limited coverage.\", \"This paper presents QUINT, a system that automatically learns utterance-query templates solely from user questions paired with their answers.\", \"Additionally, QUINT is able to harness language compositionality for answering complex questions without having any templates for the entire question.\", \"Experiments with different benchmarks demonstrate the high quality of QUINT.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [0.7241, 0.7241, 0.7241, 0.7241, 1.0]}\n",
            "prediction:  [0, [[\"Templates are an important asset for question answering over knowledge graphs, simplifying the semantic parsing of input utterances and generating structured queries for interpretable answers.\", \"background_label\"], [\"Stateof-the-art methods rely on hand-crafted templates with limited coverage.\", \"background_label\"], [\"This paper presents QUINT, a system that automatically learns utterance-query templates solely from user questions paired with their answers.\", \"objective_label\"], [\"Additionally, QUINT is able to harness language compositionality for answering complex questions without having any templates for the entire question.\", \"method_label\"], [\"Experiments with different benchmarks demonstrate the high quality of QUINT.\", \"result_label\"]]]\n",
            "\n",
            "input 150:  {\"abstract_id\": 0, \"sentences\": [\"0: Traditional model of association rule mining is adapted to handle weighted association rule mining problems where each item is allowed to have a weight.\", \"1: The goal is to steer the mining focus to those significant relationships involving items with significant weights rather than being flooded in the combinatorial explosion of insignificant relationships.\", \"2: We discuss the use of association rules mining algorithm to push information automatically, and proposed mixed weighted association rules mining algorithm that apply to information push.\", \"3: We identify the related information set and the vertical weight through the analyzing of users\\u2019 behavior, and use the Google\\u2019s PageRank algorithm to define the horizontal weight of information.\", \"4: At last, we evaluate our algorithm against the traditional Apriori algorithm in information push, thereby justifying empirically the strength of our approach.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.967, 0.9339, 0.8811, 0.8785]}\n",
            "prediction:  [0, [[\"0: Traditional model of association rule mining is adapted to handle weighted association rule mining problems where each item is allowed to have a weight.\", \"background_label\"], [\"1: The goal is to steer the mining focus to those significant relationships involving items with significant weights rather than being flooded in the combinatorial explosion of insignificant relationships.\", \"objective_label\"], [\"2: We discuss the use of association rules mining algorithm to push information automatically, and proposed mixed weighted association rules mining algorithm that apply to information push.\", \"method_label\"], [\"3: We identify the related information set and the vertical weight through the analyzing of users\\u2019 behavior, and use the Google\\u2019s PageRank algorithm to define the horizontal weight of information.\", \"method_label\"], [\"4: At last, we evaluate our algorithm against the traditional Apriori algorithm in information push, thereby justifying empirically the strength of our approach.\", \"result_label\"]]]\n",
            "\n",
            "input 151:  {\"abstract_id\": 0, \"sentences\": [\"Ancient Chinese architecture from the Song dynasty is a prominent example of the ancient oriental architectures.\", \"The cai-fen system was a module system used for the carpentry of Song architectures, which was specified by the governmental manual, the Yingzao Fashi (State Building Standards) compiled by Li\", \"Jie [1103].\", \"We present a rule-based approach for generation of ancient Chinese architectures from the Song dynasty.\", \"Based on the special module system and the hierarchical topology of structural patterns in traditional Chinese architectures, the approach parameterizes the wooden elements of buildings and formalizes the construction rules for different architecture styles.\", \"In the approach, XML-based description files are generated for displaying the construction process.\", \"What the approach generates are standard architectures that strictly follow the ancient Chinese governmental manual.\", \"To demonstrate the efficiency of our approach, architectures in different styles have been generated based on their corresponding rules.\", \"The fundamental difference between our approach and previous works is that we apply and implement the module system in digitalization of ancient Chinese architecture.\"], \"labels\": [\"background\", \"background\", \"other\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\"], \"confs\": [1.0, 0.776, 0.804, 0.804, 0.804, 0.776, 0.776, 0.608, 0.644]}\n",
            "prediction:  [0, [[\"Ancient Chinese architecture from the Song dynasty is a prominent example of the ancient oriental architectures.\", \"background_label\"], [\"The cai-fen system was a module system used for the carpentry of Song architectures, which was specified by the governmental manual, the Yingzao Fashi (State Building Standards) compiled by Li\", \"background_label\"], [\"Jie [1103].\", \"background_label\"], [\"We present a rule-based approach for generation of ancient Chinese architectures from the Song dynasty.\", \"objective_label\"], [\"Based on the special module system and the hierarchical topology of structural patterns in traditional Chinese architectures, the approach parameterizes the wooden elements of buildings and formalizes the construction rules for different architecture styles.\", \"method_label\"], [\"In the approach, XML-based description files are generated for displaying the construction process.\", \"method_label\"], [\"What the approach generates are standard architectures that strictly follow the ancient Chinese governmental manual.\", \"method_label\"], [\"To demonstrate the efficiency of our approach, architectures in different styles have been generated based on their corresponding rules.\", \"method_label\"], [\"The fundamental difference between our approach and previous works is that we apply and implement the module system in digitalization of ancient Chinese architecture.\", \"result_label\"]]]\n",
            "\n",
            "input 152:  {\"abstract_id\": 0, \"sentences\": [\"This article presents an architecture vision to address the challenges placed on 5G mobile networks.\", \"A two-layer architecture is proposed, consisting of a radio network and a network cloud, integrating various enablers such as small cells, massive MIMO, control/user plane split, NFV, and SDN.\", \"Three main concepts are integrated: ultra-dense small cell deployments on licensed and unlicensed spectrum, under control/user plane split architecture, to address capacity and data rate challenges; NFV and SDN to provide flexible network deployment and operation; and intelligent use of network data to facilitate optimal use of network resources for QoE provisioning and planning.\", \"An initial proof of concept evaluation is presented to demonstrate the potential of the proposal.\", \"Finally, other issues that must be addressed to realize a complete 5G architecture vision are discussed.\"], \"labels\": [\"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.7674, 0.7674, 0.7674, 0.7558, 0.7674]}\n",
            "prediction:  [0, [[\"This article presents an architecture vision to address the challenges placed on 5G mobile networks.\", \"objective_label\"], [\"A two-layer architecture is proposed, consisting of a radio network and a network cloud, integrating various enablers such as small cells, massive MIMO, control/user plane split, NFV, and SDN.\", \"objective_label\"], [\"Three main concepts are integrated: ultra-dense small cell deployments on licensed and unlicensed spectrum, under control/user plane split architecture, to address capacity and data rate challenges; NFV and SDN to provide flexible network deployment and operation; and intelligent use of network data to facilitate optimal use of network resources for QoE provisioning and planning.\", \"method_label\"], [\"An initial proof of concept evaluation is presented to demonstrate the potential of the proposal.\", \"result_label\"], [\"Finally, other issues that must be addressed to realize a complete 5G architecture vision are discussed.\", \"result_label\"]]]\n",
            "\n",
            "input 153:  {\"abstract_id\": 0, \"sentences\": [\"Traditional syntax models typically leverage part-of-speech (POS) information by constructing features from hand-tuned templates.\", \"We demonstrate that a better approach is to utilize POS tags as a regularizer of learned representations.\", \"We propose a simple method for learning a stacked pipeline of models which we call \\u201cstack-propagation\\u201d.\", \"We apply this to dependency parsing and tagging, where we use the hidden layer of the tagger network as a representation of the input tokens for the parser.\", \"At test time, our parser does not require predicted POS tags.\", \"On 19 languages from the Universal Dependencies, our method is 1.3% (absolute) more accurate than a state-of-the-art graph-based approach and 2.7% more accurate than the most comparable greedy model.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.6923, 0.6923, 1.0, 0.6923, 0.6923, 0.6923]}\n",
            "prediction:  [0, [[\"Traditional syntax models typically leverage part-of-speech (POS) information by constructing features from hand-tuned templates.\", \"background_label\"], [\"We demonstrate that a better approach is to utilize POS tags as a regularizer of learned representations.\", \"objective_label\"], [\"We propose a simple method for learning a stacked pipeline of models which we call \\u201cstack-propagation\\u201d.\", \"method_label\"], [\"We apply this to dependency parsing and tagging, where we use the hidden layer of the tagger network as a representation of the input tokens for the parser.\", \"method_label\"], [\"At test time, our parser does not require predicted POS tags.\", \"method_label\"], [\"On 19 languages from the Universal Dependencies, our method is 1.3% (absolute) more accurate than a state-of-the-art graph-based approach and 2.7% more accurate than the most comparable greedy model.\", \"result_label\"]]]\n",
            "\n",
            "input 154:  {\"abstract_id\": 0, \"sentences\": [\"Although scholars have long studied knowledge sharing drivers within software development teams, our knowledge remains fragmented by the divergent efforts that are based on and contribute to theoretical perspectives.\", \"This study provides a review of the extant literature (1993\\u20132011) on knowledge sharing drivers in software teams and establishes a classification framework using an organizational change perspective.\", \"A synthesis of the literature uncovers diverse themes and gaps in the existing body of knowledge, suggests several paths for advancing theory on knowledge sharing in software development contexts, and discusses implications for practitioners concerned with knowledge sharing in software\"], \"labels\": [\"background\", \"objective\", \"result\"], \"confs\": [0.7308, 0.8077, 0.8077]}\n",
            "prediction:  [0, [[\"Although scholars have long studied knowledge sharing drivers within software development teams, our knowledge remains fragmented by the divergent efforts that are based on and contribute to theoretical perspectives.\", \"background_label\"], [\"This study provides a review of the extant literature (1993\\u20132011) on knowledge sharing drivers in software teams and establishes a classification framework using an organizational change perspective.\", \"objective_label\"], [\"A synthesis of the literature uncovers diverse themes and gaps in the existing body of knowledge, suggests several paths for advancing theory on knowledge sharing in software development contexts, and discusses implications for practitioners concerned with knowledge sharing in software\", \"result_label\"]]]\n",
            "\n",
            "input 155:  {\"abstract_id\": 0, \"sentences\": [\"Automatically generating a natural language description of an image has attracted interests recently both because of its importance in practical applications and because it connects two major artificial intelligence fields: computer vision and natural language processing.\", \"Existing approaches are either top-down, which start from a gist of an image and convert it into words, or bottom-up, which come up with words describing various aspects of an image and then combine them.\", \"In this paper, we propose a new algorithm that combines both approaches through a model of semantic attention.\", \"Our algorithm learns to selectively attend to semantic concept proposals and fuse them into hidden states and outputs of recurrent neural networks.\", \"The selection and fusion form a feedback connecting the top-down and bottom-up computation.\", \"We evaluate our algorithm on two public benchmarks: Microsoft COCO and Flickr30K.\", \"Experimental results show that our algorithm significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.9667, 0.9667, 0.8402, 0.775, 1.0]}\n",
            "prediction:  [0, [[\"Automatically generating a natural language description of an image has attracted interests recently both because of its importance in practical applications and because it connects two major artificial intelligence fields: computer vision and natural language processing.\", \"background_label\"], [\"Existing approaches are either top-down, which start from a gist of an image and convert it into words, or bottom-up, which come up with words describing various aspects of an image and then combine them.\", \"background_label\"], [\"In this paper, we propose a new algorithm that combines both approaches through a model of semantic attention.\", \"method_label\"], [\"Our algorithm learns to selectively attend to semantic concept proposals and fuse them into hidden states and outputs of recurrent neural networks.\", \"method_label\"], [\"The selection and fusion form a feedback connecting the top-down and bottom-up computation.\", \"method_label\"], [\"We evaluate our algorithm on two public benchmarks: Microsoft COCO and Flickr30K.\", \"result_label\"], [\"Experimental results show that our algorithm significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics.\", \"result_label\"]]]\n",
            "\n",
            "input 156:  {\"abstract_id\": 0, \"sentences\": [\"Wireless personal area network (WPAN) is small-ranged network centered at an individual for interconnecting personal devices.\", \"For such a network, the bootstrapping mechanism with which the devices establish a secure group key is of critical importance.\", \"Most existing bootstrapping mechanisms require out-of-band channels and involve human interactions for authentication.\", \"In this paper, we aim to develop a fully automated bootstrapping mechanism with only in-band channels with approvable security.\", \"Toward this end, we designed an integrity-guaranteed message (IGM) structure, a self-authenticated key agreement protocol, and a prescheduling mechanism in allusion to the IEEE 802.15.4 standard for WPANs.\", \"The IGM structure guarantees that an adversary cannot modify the IGM message without being detected, thus protects the message integrity without the requirement of shared secrets between the sender and the receiver devices.\", \"The proposed self-authenticated key agreement protocol utilizes the IGM's integrity guaranteed property, works together with the prescheduling mechanism to achieve message self-authentication, thus protecting the secure bootstrapping process from the node impersonation attack and the man-in-the-middle attack without leveraging any out-of-band channels.\", \"We analyze the security performance of the proposed schemes, and show that they can be seamless interoperative with the existing IEEE 802.15.4 standard.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7895, 1.0, 0.6053, 0.7895, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Wireless personal area network (WPAN) is small-ranged network centered at an individual for interconnecting personal devices.\", \"background_label\"], [\"For such a network, the bootstrapping mechanism with which the devices establish a secure group key is of critical importance.\", \"background_label\"], [\"Most existing bootstrapping mechanisms require out-of-band channels and involve human interactions for authentication.\", \"background_label\"], [\"In this paper, we aim to develop a fully automated bootstrapping mechanism with only in-band channels with approvable security.\", \"objective_label\"], [\"Toward this end, we designed an integrity-guaranteed message (IGM) structure, a self-authenticated key agreement protocol, and a prescheduling mechanism in allusion to the IEEE 802.15.4 standard for WPANs.\", \"method_label\"], [\"The IGM structure guarantees that an adversary cannot modify the IGM message without being detected, thus protects the message integrity without the requirement of shared secrets between the sender and the receiver devices.\", \"method_label\"], [\"The proposed self-authenticated key agreement protocol utilizes the IGM's integrity guaranteed property, works together with the prescheduling mechanism to achieve message self-authentication, thus protecting the secure bootstrapping process from the node impersonation attack and the man-in-the-middle attack without leveraging any out-of-band channels.\", \"method_label\"], [\"We analyze the security performance of the proposed schemes, and show that they can be seamless interoperative with the existing IEEE 802.15.4 standard.\", \"result_label\"]]]\n",
            "\n",
            "input 157:  {\"abstract_id\": 0, \"sentences\": [\"A recent study by Banerjee et al. (1998) proposed and tested an information technology (IT) ethics model.\", \"They found that personal normative beliefs, organizational ethical climate, and organization-scenario were significant indicators of ethical behavioral intention.\", \"Moreover, they found that factors affecting ethical intention are situational and depend upon the ethical dilemma.\", \"Further research was suggested and recommended, among other things, replications with different samples.\", \"The present study furthers the development/validation of the IT ethical model by utilizing a large sample of students in the same organizational climate (a university).\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\"], \"confs\": [0.7377, 0.7377, 0.7377, 0.7377, 1.0]}\n",
            "prediction:  [0, [[\"A recent study by Banerjee et al. (1998) proposed and tested an information technology (IT) ethics model.\", \"background_label\"], [\"They found that personal normative beliefs, organizational ethical climate, and organization-scenario were significant indicators of ethical behavioral intention.\", \"background_label\"], [\"Moreover, they found that factors affecting ethical intention are situational and depend upon the ethical dilemma.\", \"result_label\"], [\"Further research was suggested and recommended, among other things, replications with different samples.\", \"result_label\"], [\"The present study furthers the development/validation of the IT ethical model by utilizing a large sample of students in the same organizational climate (a university).\", \"result_label\"]]]\n",
            "\n",
            "input 158:  {\"abstract_id\": 0, \"sentences\": [\"Traditionally, the normalized cross correlation (NCC) based or shape based template matching methods are utilized in machine vision to locate an object for a robot pick and place or other automatic equipment.\", \"For stability, well-designed LED lighting must be mounted to uniform and stabilize lighting condition.\", \"Even so, these algorithms are not robust to detect the small, blurred, or large deformed target in industrial environment.\", \"In this paper, we propose a convolutional neural network (CNN) based object localization method, called C-CNN: cascaded convolutional neural network, to overcome the disadvantages of the conventional methods.\", \"Our C-CNN method first applies a shallow CNN densely scanning the whole image, most of the background regions are rejected by the network.\", \"Then two CNNs are adopted to further evaluate the passed windows and the windows around.\", \"A relatively deep model net-4 is applied to adjust the passed windows at last and the adjusted windows are regarded as final positions.\", \"The experimental results show that our method can achieve real time detection at the rate of 14FPS and be robust with a small size of training data.\", \"The detection accuracy is much higher than traditional methods and state-of-the-art methods.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [0.6154, 0.6154, 0.6154, 0.6154, 1.0, 0.7949, 0.7949, 0.7949, 0.6154]}\n",
            "prediction:  [0, [[\"Traditionally, the normalized cross correlation (NCC) based or shape based template matching methods are utilized in machine vision to locate an object for a robot pick and place or other automatic equipment.\", \"background_label\"], [\"For stability, well-designed LED lighting must be mounted to uniform and stabilize lighting condition.\", \"background_label\"], [\"Even so, these algorithms are not robust to detect the small, blurred, or large deformed target in industrial environment.\", \"background_label\"], [\"In this paper, we propose a convolutional neural network (CNN) based object localization method, called C-CNN: cascaded convolutional neural network, to overcome the disadvantages of the conventional methods.\", \"method_label\"], [\"Our C-CNN method first applies a shallow CNN densely scanning the whole image, most of the background regions are rejected by the network.\", \"method_label\"], [\"Then two CNNs are adopted to further evaluate the passed windows and the windows around.\", \"method_label\"], [\"A relatively deep model net-4 is applied to adjust the passed windows at last and the adjusted windows are regarded as final positions.\", \"method_label\"], [\"The experimental results show that our method can achieve real time detection at the rate of 14FPS and be robust with a small size of training data.\", \"result_label\"], [\"The detection accuracy is much higher than traditional methods and state-of-the-art methods.\", \"result_label\"]]]\n",
            "\n",
            "input 159:  {\"abstract_id\": 0, \"sentences\": [\"The purpose of this work is to present a study of the thermomechanical behavior of the automotive disc brake during the braking phase.\", \"The first analysis is performed on the disc-pad model without the presence of thermal properties.\", \"Structural performance of the disc-pad model such as deformation and Von-Mises stress is predicted.\", \"The case of thermoelasticity on the same model with the inclusion of convection, adiabatic and heat flux elements were also studied.\", \"The prediction results of temperature distribution, deformation, stress and contact pressure are presented.\", \"Furthermore, the structural performances between the two analyses (mechanical and thermomechanical) were compared as well.\", \"The results of this investigation may assist brake engineers to choose a suitable analysis in order to critically evaluate structural and contact behaviour of the disc brake assembly.\"], \"labels\": [\"objective\", \"method\", \"method\", \"method\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 0.6286, 1.0, 0.6286, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"The purpose of this work is to present a study of the thermomechanical behavior of the automotive disc brake during the braking phase.\", \"objective_label\"], [\"The first analysis is performed on the disc-pad model without the presence of thermal properties.\", \"method_label\"], [\"Structural performance of the disc-pad model such as deformation and Von-Mises stress is predicted.\", \"method_label\"], [\"The case of thermoelasticity on the same model with the inclusion of convection, adiabatic and heat flux elements were also studied.\", \"method_label\"], [\"The prediction results of temperature distribution, deformation, stress and contact pressure are presented.\", \"result_label\"], [\"Furthermore, the structural performances between the two analyses (mechanical and thermomechanical) were compared as well.\", \"result_label\"], [\"The results of this investigation may assist brake engineers to choose a suitable analysis in order to critically evaluate structural and contact behaviour of the disc brake assembly.\", \"result_label\"]]]\n",
            "\n",
            "input 160:  {\"abstract_id\": 0, \"sentences\": [\"Retailers need to monitor products on store shelves in order to maintain adequate stocking and in many cases to comply with a placement arrangement defined by a planogram.\", \"It is possible that such inspections be performed automatically or semi-automatically using computer vision techniques.\", \"Towards this goal, we propose an algorithm to detect shelves from images captured with a handheld digital camera.\", \"First, we identify the vanishing point and the associated line segments corresponding to the shelves.\", \"Second, we divide the image into equal-angle wedges centered at the vanishing point and project the associated line segments into the wedges.\", \"Finally, we identify shelves by analyzing the projections.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Retailers need to monitor products on store shelves in order to maintain adequate stocking and in many cases to comply with a placement arrangement defined by a planogram.\", \"background_label\"], [\"It is possible that such inspections be performed automatically or semi-automatically using computer vision techniques.\", \"background_label\"], [\"Towards this goal, we propose an algorithm to detect shelves from images captured with a handheld digital camera.\", \"objective_label\"], [\"First, we identify the vanishing point and the associated line segments corresponding to the shelves.\", \"method_label\"], [\"Second, we divide the image into equal-angle wedges centered at the vanishing point and project the associated line segments into the wedges.\", \"method_label\"], [\"Finally, we identify shelves by analyzing the projections.\", \"method_label\"]]]\n",
            "\n",
            "input 161:  {\"abstract_id\": 0, \"sentences\": [\"Short text clustering has become an increasingly important task with the popularity of social media like Twitter, Google+, and Facebook.\", \"It is a challenging problem due to its sparse, high-dimensional, and large-volume characteristics.\", \"In this paper, we proposed a collapsed Gibbs Sampling algorithm for the Dirichlet Multinomial Mixture model for short text clustering (abbr.\", \"to GSDMM).\", \"We found that GSDMM can infer the number of clusters automatically with a good balance between the completeness and homogeneity of the clustering results, and is fast to converge.\", \"GSDMM can also cope with the sparse and high-dimensional problem of short texts, and can obtain the representative words of each cluster.\", \"Our extensive experimental study shows that GSDMM can achieve significantly better performance than three other clustering models.\"], \"labels\": [\"background\", \"background\", \"objective\", \"other\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.6452, 0.8387, 0.8065, 0.6452, 1.0]}\n",
            "prediction:  [0, [[\"Short text clustering has become an increasingly important task with the popularity of social media like Twitter, Google+, and Facebook.\", \"background_label\"], [\"It is a challenging problem due to its sparse, high-dimensional, and large-volume characteristics.\", \"background_label\"], [\"In this paper, we proposed a collapsed Gibbs Sampling algorithm for the Dirichlet Multinomial Mixture model for short text clustering (abbr.\", \"method_label\"], [\"to GSDMM).\", \"objective_label\"], [\"We found that GSDMM can infer the number of clusters automatically with a good balance between the completeness and homogeneity of the clustering results, and is fast to converge.\", \"method_label\"], [\"GSDMM can also cope with the sparse and high-dimensional problem of short texts, and can obtain the representative words of each cluster.\", \"method_label\"], [\"Our extensive experimental study shows that GSDMM can achieve significantly better performance than three other clustering models.\", \"result_label\"]]]\n",
            "\n",
            "input 162:  {\"abstract_id\": 0, \"sentences\": [\"When networking researchers meet the task of doing simulations, there is always a need to evaluate the value of such models by measuring a set of well known network performance metrics.\", \"However, simulators in general and NS-3 in particular, require significant programming effort from the researcher in order to collect those metrics.\", \"This paper reports a contribution for NS-3 consisting of a new flow monitoring module that makes it easier to collect and save to persistent storage a common set of network performance metrics.\", \"The module automatically detects all flows passing through the network and stores in a file most of the metrics that a researcher might need to analyze about the flow, such as bitrates, duration, delays, packet sizes, and packet loss ratio.\", \"The value of this module is demonstrated using an easy to follow example.\", \"It is also validated by comparing the measurements of a simple scenario with the expected values.\", \"Finally, the performance of flow monitoring is characterized and shown to introduce small overheads.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.8158, 1.0, 1.0, 0.8158, 1.0, 0.6053, 0.8158]}\n",
            "prediction:  [0, [[\"When networking researchers meet the task of doing simulations, there is always a need to evaluate the value of such models by measuring a set of well known network performance metrics.\", \"background_label\"], [\"However, simulators in general and NS-3 in particular, require significant programming effort from the researcher in order to collect those metrics.\", \"background_label\"], [\"This paper reports a contribution for NS-3 consisting of a new flow monitoring module that makes it easier to collect and save to persistent storage a common set of network performance metrics.\", \"objective_label\"], [\"The module automatically detects all flows passing through the network and stores in a file most of the metrics that a researcher might need to analyze about the flow, such as bitrates, duration, delays, packet sizes, and packet loss ratio.\", \"method_label\"], [\"The value of this module is demonstrated using an easy to follow example.\", \"method_label\"], [\"It is also validated by comparing the measurements of a simple scenario with the expected values.\", \"method_label\"], [\"Finally, the performance of flow monitoring is characterized and shown to introduce small overheads.\", \"result_label\"]]]\n",
            "\n",
            "input 163:  {\"abstract_id\": 0, \"sentences\": [\"Trigger-Action platforms are web-based systems that enable users to create automation rules by stitching together online services representing digital and physical resources using OAuth tokens.\", \"Unfortunately, these platforms introduce a longrange large-scale security risk: If they are compromised, an attacker can misuse the OAuth tokens belonging to a large number of users to arbitrarily manipulate their devices and data.\", \"We introduce Decentralized Action Integrity, a security principle that prevents an untrusted trigger-action platform from misusing compromised OAuth tokens in ways that are inconsistent with any given user\\u2019s set of trigger-action rules.\", \"We present the design and evaluation of Decentralized Trigger-Action Platform (DTAP), a trigger-action platform that implements this principle by overcoming practical challenges.\", \"DTAP splits currently monolithic platform designs into an untrusted cloud service, and a set of user clients (each user only trusts their client).\", \"Our design introduces the concept of Transfer Tokens (XTokens) to practically use finegrained rule-specific tokens without increasing the number of OAuth permission prompts compared to current platforms.\", \"Our evaluation indicates that DTAP poses negligible overhead: it adds less than 15ms of latency to rule execution time, and reduces throughput by 2.5%.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.7949, 0.7949, 0.6154, 0.8205, 0.7949, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Trigger-Action platforms are web-based systems that enable users to create automation rules by stitching together online services representing digital and physical resources using OAuth tokens.\", \"background_label\"], [\"Unfortunately, these platforms introduce a longrange large-scale security risk: If they are compromised, an attacker can misuse the OAuth tokens belonging to a large number of users to arbitrarily manipulate their devices and data.\", \"background_label\"], [\"We introduce Decentralized Action Integrity, a security principle that prevents an untrusted trigger-action platform from misusing compromised OAuth tokens in ways that are inconsistent with any given user\\u2019s set of trigger-action rules.\", \"method_label\"], [\"We present the design and evaluation of Decentralized Trigger-Action Platform (DTAP), a trigger-action platform that implements this principle by overcoming practical challenges.\", \"method_label\"], [\"DTAP splits currently monolithic platform designs into an untrusted cloud service, and a set of user clients (each user only trusts their client).\", \"method_label\"], [\"Our design introduces the concept of Transfer Tokens (XTokens) to practically use finegrained rule-specific tokens without increasing the number of OAuth permission prompts compared to current platforms.\", \"method_label\"], [\"Our evaluation indicates that DTAP poses negligible overhead: it adds less than 15ms of latency to rule execution time, and reduces throughput by 2.5%.\", \"result_label\"]]]\n",
            "\n",
            "input 164:  {\"abstract_id\": 0, \"sentences\": [\"0: The order-preserving pattern matching problem has gained attention in recent years.\", \"1: It consists in finding all substrings in the text, which have the same length and relative order as the input pattern.\", \"2: Typically, the text and the pattern consist of numbers.\", \"3: Since recent times, there has been a tendency to utilize the ability of the word RAM model to increase the efficiency of string matching algorithms.\", \"4: This model works on computer words, reading and processing blocks of characters at once, so that usual arithmetic and logic operations on words can be performed in one unit of time.\", \"5: In this paper, we present a fast order-preserving pattern matching algorithm, which uses specialized word-size packed string matching instructions, grounded on the single instruction multiple data instruction set architecture.\", \"6: We show with experimental results that the new proposed algorithm is more efficient than the previous solutions.\", \"7: \\u00a9 2016\", \"8: The Authors.\", \"9: Software: Practice and Experience Published by John Wiley & Sons Ltd.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"method\", \"result\", \"other\", \"other\", \"other\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8962, 0.8864, 0.9532, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"0: The order-preserving pattern matching problem has gained attention in recent years.\", \"background_label\"], [\"1: It consists in finding all substrings in the text, which have the same length and relative order as the input pattern.\", \"background_label\"], [\"2: Typically, the text and the pattern consist of numbers.\", \"background_label\"], [\"3: Since recent times, there has been a tendency to utilize the ability of the word RAM model to increase the efficiency of string matching algorithms.\", \"background_label\"], [\"4: This model works on computer words, reading and processing blocks of characters at once, so that usual arithmetic and logic operations on words can be performed in one unit of time.\", \"method_label\"], [\"5: In this paper, we present a fast order-preserving pattern matching algorithm, which uses specialized word-size packed string matching instructions, grounded on the single instruction multiple data instruction set architecture.\", \"method_label\"], [\"6: We show with experimental results that the new proposed algorithm is more efficient than the previous solutions.\", \"result_label\"], [\"7: \\u00a9 2016\", \"other_label\"], [\"8: The Authors.\", \"other_label\"], [\"9: Software: Practice and Experience Published by John Wiley & Sons Ltd.\", \"other_label\"]]]\n",
            "\n",
            "input 165:  {\"abstract_id\": 0, \"sentences\": [\"Just recently much Information Systems (IS) research focuses on master data management (MDM) which promises to increase an organization's overall core data quality.\", \"Above any doubt, however, MDM initiatives confront organizations with multi-faceted and complex challenges that call for a more strategic approach to MDM.\", \"In this paper we introduce a framework for approaching MDM projects that has been developed in the course of a design science research study.\", \"The framework distinguishes four major strategies of MDM project initiations all featuring their specific assets and drawbacks.\", \"The usefulness of our artifact is illustrated in a short case narrative.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [0.7419, 1.0, 0.7419, 0.7419, 0.7419]}\n",
            "prediction:  [0, [[\"Just recently much Information Systems (IS) research focuses on master data management (MDM) which promises to increase an organization's overall core data quality.\", \"background_label\"], [\"Above any doubt, however, MDM initiatives confront organizations with multi-faceted and complex challenges that call for a more strategic approach to MDM.\", \"background_label\"], [\"In this paper we introduce a framework for approaching MDM projects that has been developed in the course of a design science research study.\", \"objective_label\"], [\"The framework distinguishes four major strategies of MDM project initiations all featuring their specific assets and drawbacks.\", \"method_label\"], [\"The usefulness of our artifact is illustrated in a short case narrative.\", \"result_label\"]]]\n",
            "\n",
            "input 166:  {\"abstract_id\": 0, \"sentences\": [\"Security and privacy are huge challenges in Internet of Things (IoT) environments, but unfortunately, the harmonization of the IoT-related standards and protocols is hardly and slowly widespread.\", \"In this paper, we propose a new framework for access control in IoT based on the blockchain technology.\", \"Our first contribution consists in providing a reference model for our proposed framework within the Objectives, Models, Architecture and Mechanism specification in IoT. In addition, we introduce FairAccess as a fully decentralized pseudonymous and privacy preserving authorization management framework that enables users to own and control their data.\", \"To implement our model, we use and adapt the blockchain into a decentralized access control manager.\", \"Unlike financial bitcoin transactions, FairAccess introduces new types of transactions that are used to grant, get, delegate, and revoke access.\", \"As a proof of concept, we establish an initial implementation with a Raspberry PI device and local blockchain.\", \"Finally, we discuss some limitations and propose further opportunities.\", \"Copyright \\u00a9 2017 John Wiley & Sons, Ltd.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.6, 0.6, 0.6, 0.8, 0.6, 0.8, 0.6]}\n",
            "prediction:  [0, [[\"Security and privacy are huge challenges in Internet of Things (IoT) environments, but unfortunately, the harmonization of the IoT-related standards and protocols is hardly and slowly widespread.\", \"background_label\"], [\"In this paper, we propose a new framework for access control in IoT based on the blockchain technology.\", \"objective_label\"], [\"Our first contribution consists in providing a reference model for our proposed framework within the Objectives, Models, Architecture and Mechanism specification in IoT. In addition, we introduce FairAccess as a fully decentralized pseudonymous and privacy preserving authorization management framework that enables users to own and control their data.\", \"method_label\"], [\"To implement our model, we use and adapt the blockchain into a decentralized access control manager.\", \"method_label\"], [\"Unlike financial bitcoin transactions, FairAccess introduces new types of transactions that are used to grant, get, delegate, and revoke access.\", \"method_label\"], [\"As a proof of concept, we establish an initial implementation with a Raspberry PI device and local blockchain.\", \"method_label\"], [\"Finally, we discuss some limitations and propose further opportunities.\", \"result_label\"], [\"Copyright \\u00a9 2017 John Wiley & Sons, Ltd.\", \"other_label\"]]]\n",
            "\n",
            "input 167:  {\"abstract_id\": 0, \"sentences\": [\"Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, such as inter-region traffic, events, and weather.\", \"We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast the inflow and outflow of crowds in each and every region of a city.\", \"We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data.\", \"More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic.\", \"For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic.\", \"ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions.\", \"The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region.\", \"Experiments on two types of crowd flows in Beijing and New York City (NYC) demonstrate that the proposed ST-ResNet outperforms six well-known methods.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7586, 1.0, 1.0, 1.0, 0.7931, 1.0]}\n",
            "prediction:  [0, [[\"Forecasting the flow of crowds is of great importance to traffic management and public safety, and very challenging as it is affected by many complex factors, such as inter-region traffic, events, and weather.\", \"background_label\"], [\"We propose a deep-learning-based approach, called ST-ResNet, to collectively forecast the inflow and outflow of crowds in each and every region of a city.\", \"objective_label\"], [\"We design an end-to-end structure of ST-ResNet based on unique properties of spatio-temporal data.\", \"method_label\"], [\"More specifically, we employ the residual neural network framework to model the temporal closeness, period, and trend properties of crowd traffic.\", \"method_label\"], [\"For each property, we design a branch of residual convolutional units, each of which models the spatial properties of crowd traffic.\", \"method_label\"], [\"ST-ResNet learns to dynamically aggregate the output of the three residual neural networks based on data, assigning different weights to different branches and regions.\", \"method_label\"], [\"The aggregation is further combined with external factors, such as weather and day of the week, to predict the final traffic of crowds in each and every region.\", \"method_label\"], [\"Experiments on two types of crowd flows in Beijing and New York City (NYC) demonstrate that the proposed ST-ResNet outperforms six well-known methods.\", \"result_label\"]]]\n",
            "\n",
            "input 168:  {\"abstract_id\": 0, \"sentences\": [\"The field of object detection has seen dramatic performance improvements in the last few years.\", \"Most of these gains are attributed to bottom-up, feedforward ConvNet frameworks.\", \"However, in case of humans, top-down information, context and feedback play an important role in doing object detection.\", \"This paper investigates how we can incorporate top-down information and feedback in the state-of-the-art Faster R-CNN framework.\", \"Specifically, we propose to: (a) augment Faster RCNN with a semantic segmentation network; (b) use segmentation for top-down contextual priming; (c) use segmentation to provide top-down iterative feedback using two stage training.\", \"Our results indicate that all three contributions improve the performance on object detection, semantic segmentation and region proposal generation.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [0.6316, 0.6316, 0.6316, 0.6053, 0.7895, 0.8158]}\n",
            "prediction:  [0, [[\"The field of object detection has seen dramatic performance improvements in the last few years.\", \"background_label\"], [\"Most of these gains are attributed to bottom-up, feedforward ConvNet frameworks.\", \"background_label\"], [\"However, in case of humans, top-down information, context and feedback play an important role in doing object detection.\", \"background_label\"], [\"This paper investigates how we can incorporate top-down information and feedback in the state-of-the-art Faster R-CNN framework.\", \"objective_label\"], [\"Specifically, we propose to: (a) augment Faster RCNN with a semantic segmentation network; (b) use segmentation for top-down contextual priming; (c) use segmentation to provide top-down iterative feedback using two stage training.\", \"method_label\"], [\"Our results indicate that all three contributions improve the performance on object detection, semantic segmentation and region proposal generation.\", \"result_label\"]]]\n",
            "\n",
            "input 169:  {\"abstract_id\": 0, \"sentences\": [\"Industry 4.0 (the fourth industrial revolution) encapsulates future industry development trends to achieve more intelligent manufacturing processes, including reliance on Cyber-Physical Systems (CPS), construction of Cyber-Physical Production Systems (CPPS), and implementation and operation of smart factories.\", \"This paper introduces relevant aspects of Industry 4.0 in relation to strategic planning, key technologies, opportunities, and challenges.\", \"Strategic planning includes construction of a CPS network, discussion of two major themes which are based on the smart factory and intelligent production, achieving three integrations (horizontal integration, vertical integration and end-to-end integration) and achieving eight plans which consist of the formulation of system standardization, efficient management etc.\", \"Finally, it referred to the enlightenment for China's manufacturing industries, to build China's Industry 4.0.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\"], \"confs\": [1.0, 0.6774, 0.8387, 0.6452]}\n",
            "prediction:  [0, [[\"Industry 4.0 (the fourth industrial revolution) encapsulates future industry development trends to achieve more intelligent manufacturing processes, including reliance on Cyber-Physical Systems (CPS), construction of Cyber-Physical Production Systems (CPPS), and implementation and operation of smart factories.\", \"background_label\"], [\"This paper introduces relevant aspects of Industry 4.0 in relation to strategic planning, key technologies, opportunities, and challenges.\", \"objective_label\"], [\"Strategic planning includes construction of a CPS network, discussion of two major themes which are based on the smart factory and intelligent production, achieving three integrations (horizontal integration, vertical integration and end-to-end integration) and achieving eight plans which consist of the formulation of system standardization, efficient management etc.\", \"method_label\"], [\"Finally, it referred to the enlightenment for China's manufacturing industries, to build China's Industry 4.0.\", \"result_label\"]]]\n",
            "\n",
            "input 170:  {\"abstract_id\": 0, \"sentences\": [\"Modern IT systems often produce large volumes of event logs, and event pattern discovery is an important log management task.\", \"For this purpose, data mining methods have been suggested in many previous works.\", \"In this paper, we present the LogCluster algorithm which implements data clustering and line pattern mining for textual event logs.\", \"The paper also describes an open source implementation of LogCluster.\"], \"labels\": [\"background\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.7273, 0.7273]}\n",
            "prediction:  [0, [[\"Modern IT systems often produce large volumes of event logs, and event pattern discovery is an important log management task.\", \"background_label\"], [\"For this purpose, data mining methods have been suggested in many previous works.\", \"background_label\"], [\"In this paper, we present the LogCluster algorithm which implements data clustering and line pattern mining for textual event logs.\", \"method_label\"], [\"The paper also describes an open source implementation of LogCluster.\", \"method_label\"]]]\n",
            "\n",
            "input 171:  {\"abstract_id\": 0, \"sentences\": [\"Protocols that allow operational sites to continue transaction processing even though site failures have occurred are called nonblocking.\", \"Many applications require nonblocking protocols.\", \"This paper investigates the properties of nonblocking protocols.\", \"Necessary and sufficient conditions for a protocol to be nonblocking are presented and from these conditions a method for designing them is derived.\", \"Both a central site nonblocking protocol and a decentralized nonblocking protocol are presented.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\"], \"confs\": [0.8205, 0.8205, 0.6154, 1.0, 0.7949]}\n",
            "prediction:  [0, [[\"Protocols that allow operational sites to continue transaction processing even though site failures have occurred are called nonblocking.\", \"background_label\"], [\"Many applications require nonblocking protocols.\", \"background_label\"], [\"This paper investigates the properties of nonblocking protocols.\", \"objective_label\"], [\"Necessary and sufficient conditions for a protocol to be nonblocking are presented and from these conditions a method for designing them is derived.\", \"method_label\"], [\"Both a central site nonblocking protocol and a decentralized nonblocking protocol are presented.\", \"method_label\"]]]\n",
            "\n",
            "input 172:  {\"abstract_id\": 0, \"sentences\": [\"Information systems development is a high-risk undertaking, and failures remain common despite advances in development tools and technologies.\", \"In this paper, we argue that one reason for this is the collapse of organizational intelligence required to deal with the complexities of systems development.\", \"Organizations fail to learn from their experience in systems development because of limits of organizational intelligence, disincentives for learning, organizational designs and educational barriers.\", \"Not only have many organizations failed to learn, but they have also learned to fail.\", \"Over time they accept and expect poor performance while creating organizational myths that perpetuate short-term optimization.\", \"This paper illustrates learning failure in systems development and recommends tactics for overcoming it.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"objective\"], \"confs\": [1.0, 0.7419, 1.0, 1.0, 1.0, 0.7419]}\n",
            "prediction:  [0, [[\"Information systems development is a high-risk undertaking, and failures remain common despite advances in development tools and technologies.\", \"background_label\"], [\"In this paper, we argue that one reason for this is the collapse of organizational intelligence required to deal with the complexities of systems development.\", \"objective_label\"], [\"Organizations fail to learn from their experience in systems development because of limits of organizational intelligence, disincentives for learning, organizational designs and educational barriers.\", \"background_label\"], [\"Not only have many organizations failed to learn, but they have also learned to fail.\", \"background_label\"], [\"Over time they accept and expect poor performance while creating organizational myths that perpetuate short-term optimization.\", \"result_label\"], [\"This paper illustrates learning failure in systems development and recommends tactics for overcoming it.\", \"result_label\"]]]\n",
            "\n",
            "input 173:  {\"abstract_id\": 0, \"sentences\": [\"Retaining users and facilitating continuance usage are crucial to the success of mobile social network services (SNS).\", \"This research examines the continuance usage of mobile SNS in China by integrating both the perspectives of social influence and privacy concern.\", \"Social influence includes three processes: compliance, identification and internalization, which are respectively represented by subjective norm, social identity, and group norm.\", \"The results indicate that these three factors and privacy concern have significant effects on continuance usage.\", \"The results suggest that service providers should address the issues of social influence and privacy concern to encourage mobile SNS continuance usage.\", \"2014 Elsevier Ltd.\", \"All rights reserved.\"], \"labels\": [\"background\", \"objective\", \"method\", \"result\", \"result\", \"other\", \"other\"], \"confs\": [1.0, 0.7695, 0.7328, 0.6049, 0.8354, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Retaining users and facilitating continuance usage are crucial to the success of mobile social network services (SNS).\", \"background_label\"], [\"This research examines the continuance usage of mobile SNS in China by integrating both the perspectives of social influence and privacy concern.\", \"objective_label\"], [\"Social influence includes three processes: compliance, identification and internalization, which are respectively represented by subjective norm, social identity, and group norm.\", \"method_label\"], [\"The results indicate that these three factors and privacy concern have significant effects on continuance usage.\", \"result_label\"], [\"The results suggest that service providers should address the issues of social influence and privacy concern to encourage mobile SNS continuance usage.\", \"result_label\"], [\"2014 Elsevier Ltd.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 174:  {\"abstract_id\": 0, \"sentences\": [\"Similarity is an important and widely used concept.\", \"Previous definitions of similarity are tied to a particular application or a form of knowledge representation.\", \"We present an informationtheoretic definition of similarity that is applicable as long as there is a probabilistic model.\", \"We demonstrate how our definition can be used to measure the similarity in a number of different domains.\"], \"labels\": [\"background\", \"background\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.6154, 0.7949]}\n",
            "prediction:  [0, [[\"Similarity is an important and widely used concept.\", \"background_label\"], [\"Previous definitions of similarity are tied to a particular application or a form of knowledge representation.\", \"background_label\"], [\"We present an informationtheoretic definition of similarity that is applicable as long as there is a probabilistic model.\", \"objective_label\"], [\"We demonstrate how our definition can be used to measure the similarity in a number of different domains.\", \"result_label\"]]]\n",
            "\n",
            "input 175:  {\"abstract_id\": 0, \"sentences\": [\"Text in natural images is an important source of information, which can be utilized for many real-world applications.\", \"This work focuses on a new problem: distinguishing images that contain text from a large volume of natural images.\", \"To address this problem, we propose a novel convolutional neural network variant, called Multi-scale Spatial Partition Network (MSP-Net).\", \"The network classifies images that contain text or not, by predicting text existence in all image blocks, which are spatial partitions at multiple scales on an input image.\", \"The whole image is classified as a text image (an image containing text) as long as one of the blocks is predicted to contain text.\", \"The network classifies images very efficiently by predicting all blocks simultaneously in a single forward propagation.\", \"Through experimental evaluations and comparisons on public datasets, we demonstrate the effectiveness and robustness of the proposed method.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.7895, 0.7895, 0.6053, 0.6053, 0.6053, 0.6316, 0.6053]}\n",
            "prediction:  [0, [[\"Text in natural images is an important source of information, which can be utilized for many real-world applications.\", \"background_label\"], [\"This work focuses on a new problem: distinguishing images that contain text from a large volume of natural images.\", \"objective_label\"], [\"To address this problem, we propose a novel convolutional neural network variant, called Multi-scale Spatial Partition Network (MSP-Net).\", \"objective_label\"], [\"The network classifies images that contain text or not, by predicting text existence in all image blocks, which are spatial partitions at multiple scales on an input image.\", \"method_label\"], [\"The whole image is classified as a text image (an image containing text) as long as one of the blocks is predicted to contain text.\", \"method_label\"], [\"The network classifies images very efficiently by predicting all blocks simultaneously in a single forward propagation.\", \"method_label\"], [\"Through experimental evaluations and comparisons on public datasets, we demonstrate the effectiveness and robustness of the proposed method.\", \"result_label\"]]]\n",
            "\n",
            "input 176:  {\"abstract_id\": 0, \"sentences\": [\"The basis of applying deep learning to solve natural language processing tasks is to obtain high-quality distributed representations of words, i.e., word embeddings, from large amounts of text data.\", \"However, text itself usually contains incomplete and ambiguous information, which makes necessity to leverage extra knowledge to understand it.\", \"Fortunately, text itself already contains welldefined morphological and syntactic knowledge; moreover, the large amount of texts on the Web enable the extraction of plenty of semantic knowledge.\", \"Therefore, it makes sense to design novel deep learning algorithms and systems in order to leverage the above knowledge to compute more effective word embeddings.\", \"In this paper, we conduct an empirical study on the capacity of leveraging morphological, syntactic, and semantic knowledge to achieve high-quality word embeddings.\", \"Our study explores these types of knowledge to define new basis for word representation, provide additional input information, and serve as auxiliary supervision in deep learning, respectively.\", \"Experiments on an analogical reasoning task, a word similarity task, and a word completion task have all demonstrated that knowledge-powered deep learning can enhance the effectiveness of word embedding.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [0.7667, 1.0, 1.0, 1.0, 0.7667, 0.7333, 1.0]}\n",
            "prediction:  [0, [[\"The basis of applying deep learning to solve natural language processing tasks is to obtain high-quality distributed representations of words, i.e., word embeddings, from large amounts of text data.\", \"background_label\"], [\"However, text itself usually contains incomplete and ambiguous information, which makes necessity to leverage extra knowledge to understand it.\", \"background_label\"], [\"Fortunately, text itself already contains welldefined morphological and syntactic knowledge; moreover, the large amount of texts on the Web enable the extraction of plenty of semantic knowledge.\", \"background_label\"], [\"Therefore, it makes sense to design novel deep learning algorithms and systems in order to leverage the above knowledge to compute more effective word embeddings.\", \"background_label\"], [\"In this paper, we conduct an empirical study on the capacity of leveraging morphological, syntactic, and semantic knowledge to achieve high-quality word embeddings.\", \"objective_label\"], [\"Our study explores these types of knowledge to define new basis for word representation, provide additional input information, and serve as auxiliary supervision in deep learning, respectively.\", \"method_label\"], [\"Experiments on an analogical reasoning task, a word similarity task, and a word completion task have all demonstrated that knowledge-powered deep learning can enhance the effectiveness of word embedding.\", \"result_label\"]]]\n",
            "\n",
            "input 177:  {\"abstract_id\": 0, \"sentences\": [\"Banking and financial industries are facing severe challenges in the form of fraudulent transactions.\", \"Credit card fraud is one example of them.\", \"In order to detect credit card fraud, we employed one-class classification approach in big data paradigm.\", \"We implemented a hybrid architecture of Particle Swarm Optimization and Auto-Associative Neural Network for one-class classification in Spark computational framework.\", \"In this paper, we implemented parallelization of the auto-associative neural network in the hybrid architecture.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\"], \"confs\": [0.6792, 1.0, 0.7736, 1.0, 0.6226]}\n",
            "prediction:  [0, [[\"Banking and financial industries are facing severe challenges in the form of fraudulent transactions.\", \"background_label\"], [\"Credit card fraud is one example of them.\", \"background_label\"], [\"In order to detect credit card fraud, we employed one-class classification approach in big data paradigm.\", \"background_label\"], [\"We implemented a hybrid architecture of Particle Swarm Optimization and Auto-Associative Neural Network for one-class classification in Spark computational framework.\", \"method_label\"], [\"In this paper, we implemented parallelization of the auto-associative neural network in the hybrid architecture.\", \"method_label\"]]]\n",
            "\n",
            "input 178:  {\"abstract_id\": 0, \"sentences\": [\"Technological advances have made FPGAs an attractive platform for the acceleration of complex scientific applications.\", \"These applications demand high performance and hi ghprecision floating point arithmetic.\", \"In this paper, we present a design for calculating the Lennard-Jones potential and for ce as is done in molecular dynamics simulations.\", \"This architecture employs IEEE 754 double precision floating point units, incl uding a square root unit developed for this kernel.\", \"The design pres ented is a modular, very deeply pipelined architecture that exploits the fine-grained parallelism of the calculations.\", \"With the Xilinx Virtex-II Pro as a target device, an implementation using two pipelines operating in parallel achieves 3.9 GFLOPS.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\"], \"confs\": [1.0, 1.0, 0.8182, 0.6364, 1.0, 0.6364]}\n",
            "prediction:  [0, [[\"Technological advances have made FPGAs an attractive platform for the acceleration of complex scientific applications.\", \"background_label\"], [\"These applications demand high performance and hi ghprecision floating point arithmetic.\", \"background_label\"], [\"In this paper, we present a design for calculating the Lennard-Jones potential and for ce as is done in molecular dynamics simulations.\", \"objective_label\"], [\"This architecture employs IEEE 754 double precision floating point units, incl uding a square root unit developed for this kernel.\", \"method_label\"], [\"The design pres ented is a modular, very deeply pipelined architecture that exploits the fine-grained parallelism of the calculations.\", \"method_label\"], [\"With the Xilinx Virtex-II Pro as a target device, an implementation using two pipelines operating in parallel achieves 3.9 GFLOPS.\", \"method_label\"]]]\n",
            "\n",
            "input 179:  {\"abstract_id\": 0, \"sentences\": [\"Agent-based modeling and simulation (ABMS) is a new approach to modeling systems comprised of autonomous, interacting agents.\", \"ABMS promises to have far-reaching effects on the way that businesses use computers to support decision-making and researchers use electronic laboratories to support their research.\", \"Some have gone so far as to contend that ABMS \\\"is a third way of doing science,\\\" in addition to traditional deductive and inductive reasoning (Axelrod 1997).\", \"Computational advances have made possible a growing number of agent-based models across a variety of application domains.\", \"Applications range from modeling agent behavior in the stock market, supply chains, and consumer markets, to predicting the spread of epidemics, the threat of bio-warfare, and the factors responsible for the fall of ancient civilizations.\", \"This tutorial describes the theoretical and practical foundations of ABMS, identifies toolkits and methods for developing agent models, and illustrates the development of a simple agent-based model.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"objective\"], \"confs\": [0.7742, 0.7742, 0.7742, 1.0, 0.7742, 0.7742]}\n",
            "prediction:  [0, [[\"Agent-based modeling and simulation (ABMS) is a new approach to modeling systems comprised of autonomous, interacting agents.\", \"background_label\"], [\"ABMS promises to have far-reaching effects on the way that businesses use computers to support decision-making and researchers use electronic laboratories to support their research.\", \"background_label\"], [\"Some have gone so far as to contend that ABMS \\\"is a third way of doing science,\\\" in addition to traditional deductive and inductive reasoning (Axelrod 1997).\", \"background_label\"], [\"Computational advances have made possible a growing number of agent-based models across a variety of application domains.\", \"background_label\"], [\"Applications range from modeling agent behavior in the stock market, supply chains, and consumer markets, to predicting the spread of epidemics, the threat of bio-warfare, and the factors responsible for the fall of ancient civilizations.\", \"method_label\"], [\"This tutorial describes the theoretical and practical foundations of ABMS, identifies toolkits and methods for developing agent models, and illustrates the development of a simple agent-based model.\", \"result_label\"]]]\n",
            "\n",
            "input 180:  {\"abstract_id\": 0, \"sentences\": [\"The health and wellness sector is critical to human society and as such should be one of the first to receive the benefits of upcoming technologies like IoT. Some of the Internet of Medical Things (IoMT) are connected to IoT networks to monitor the day-to-day activities of the patients.\", \"Recently there has been attempts to design new medical devices which monitor the medications and help aged people for a better assisted living.\", \"In this paper, one such attempt is made to design a multipurpose portable intelligent device named MEDIBOX which helps the patients take their medications at the right time.\", \"This box is a proficient system which maintains the parameters like temperature and humidity in a controlled range recommended by the drug manufacturer and thus maintains the potency of the medicines even if the patient is travelling.\", \"Related to this, we have developed a Host Management System (HMS) which is capable of cloud-based installation and monitoring that stores and controls the MEDIBOX functionality for further analysis and future modification in design aspects.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"method\"], \"confs\": [0.7, 0.7, 0.7, 0.7, 0.7]}\n",
            "prediction:  [0, [[\"The health and wellness sector is critical to human society and as such should be one of the first to receive the benefits of upcoming technologies like IoT. Some of the Internet of Medical Things (IoMT) are connected to IoT networks to monitor the day-to-day activities of the patients.\", \"background_label\"], [\"Recently there has been attempts to design new medical devices which monitor the medications and help aged people for a better assisted living.\", \"background_label\"], [\"In this paper, one such attempt is made to design a multipurpose portable intelligent device named MEDIBOX which helps the patients take their medications at the right time.\", \"objective_label\"], [\"This box is a proficient system which maintains the parameters like temperature and humidity in a controlled range recommended by the drug manufacturer and thus maintains the potency of the medicines even if the patient is travelling.\", \"method_label\"], [\"Related to this, we have developed a Host Management System (HMS) which is capable of cloud-based installation and monitoring that stores and controls the MEDIBOX functionality for further analysis and future modification in design aspects.\", \"result_label\"]]]\n",
            "\n",
            "input 181:  {\"abstract_id\": 0, \"sentences\": [\"We describe ITS4, a tool for statically scanning security-critical C source code for vulnerabilities.\", \"Compared to other approaches, our scanning technique stakes out a new middle ground between accuracy and eficiency.\", \"This method is eficient enough to offer real-time feedback to developers during coding while producing few false negatives.\", \"Unlike other techniques, our method is also simple enough to scan C + + code despite the complexities inherent in the language.\", \"Using ITS4 we found new remotelyexploitable vulnerabilities in a widely distributed software package as well as in a major piece of e-commerce software.\", \"The ITS4 source distribution is available at h t tp : //www.rstcorp.\", \"com/its4.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\", \"other\", \"other\"], \"confs\": [1.0, 0.6286, 0.6, 0.6, 0.6, 0.6, 0.6]}\n",
            "prediction:  [0, [[\"We describe ITS4, a tool for statically scanning security-critical C source code for vulnerabilities.\", \"background_label\"], [\"Compared to other approaches, our scanning technique stakes out a new middle ground between accuracy and eficiency.\", \"background_label\"], [\"This method is eficient enough to offer real-time feedback to developers during coding while producing few false negatives.\", \"method_label\"], [\"Unlike other techniques, our method is also simple enough to scan C + + code despite the complexities inherent in the language.\", \"method_label\"], [\"Using ITS4 we found new remotelyexploitable vulnerabilities in a widely distributed software package as well as in a major piece of e-commerce software.\", \"result_label\"], [\"The ITS4 source distribution is available at h t tp : //www.rstcorp.\", \"other_label\"], [\"com/its4.\", \"other_label\"]]]\n",
            "\n",
            "input 182:  {\"abstract_id\": 0, \"sentences\": [\"Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner.\", \"In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network.\", \"This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process.\", \"We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.\"], \"labels\": [\"background\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 0.7333, 0.7333, 0.7333]}\n",
            "prediction:  [0, [[\"Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner.\", \"background_label\"], [\"In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network.\", \"objective_label\"], [\"This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process.\", \"method_label\"], [\"We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.\", \"result_label\"]]]\n",
            "\n",
            "input 183:  {\"abstract_id\": 0, \"sentences\": [\"Knowing individuals' relational orientation is imperative for effective offline, as well as online, interactions and collaborations.\", \"We use attachment theory to examine the link between Facebook users' relational orientation (in terms of attachment styles: anxiety and avoidance) and their relational activities.\", \"Our research examines whether and how the two key relational processes identified in offline social relationships (self-expression and responsiveness) are manifested on online social networks and related to attachment styles.\", \"We describe our dataset of 640 Facebook users, their attachment scale survey results, and their 525,334 posts.\", \"We define four features that map onto relational activities on Facebook: status updates and status updates with emotional words (self-expression); comments and likes (responsiveness).\", \"We find significant relationships between the users' attachment styles and their self-expression and responsiveness activities on Facebook.\", \"A key takeaway of our research is that without relying on self-reported surveys, a computational analysis of a Facebook user's self-expressing and responding activities alone can reveal the user's underlying relational orientation (i.e., attachment style).\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.7222, 0.7222, 1.0, 1.0, 0.7222, 1.0]}\n",
            "prediction:  [0, [[\"Knowing individuals' relational orientation is imperative for effective offline, as well as online, interactions and collaborations.\", \"background_label\"], [\"We use attachment theory to examine the link between Facebook users' relational orientation (in terms of attachment styles: anxiety and avoidance) and their relational activities.\", \"background_label\"], [\"Our research examines whether and how the two key relational processes identified in offline social relationships (self-expression and responsiveness) are manifested on online social networks and related to attachment styles.\", \"objective_label\"], [\"We describe our dataset of 640 Facebook users, their attachment scale survey results, and their 525,334 posts.\", \"method_label\"], [\"We define four features that map onto relational activities on Facebook: status updates and status updates with emotional words (self-expression); comments and likes (responsiveness).\", \"method_label\"], [\"We find significant relationships between the users' attachment styles and their self-expression and responsiveness activities on Facebook.\", \"result_label\"], [\"A key takeaway of our research is that without relying on self-reported surveys, a computational analysis of a Facebook user's self-expressing and responding activities alone can reveal the user's underlying relational orientation (i.e., attachment style).\", \"result_label\"]]]\n",
            "\n",
            "input 184:  {\"abstract_id\": 0, \"sentences\": [\"Snakes, or active contours, are used extensively in computer vision and image processing applications, particularly to locate object boundaries.\", \"Problems associated with initialization and poor convergence to concave boundaries, however, have limited their utility.\", \"This paper develops a new external force for active contours, largely solving both problems.\", \"This external force, which we call gradient vector flow (GVF), is computed as a diffusion of the gradient vectors of a gray-level or binary edge map derived from the image.\", \"The resultant field has a large capture range and forces active contours into concave regions.\", \"Examples on simulated images and one real image are presented.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.75, 1.0, 1.0, 0.7857]}\n",
            "prediction:  [0, [[\"Snakes, or active contours, are used extensively in computer vision and image processing applications, particularly to locate object boundaries.\", \"background_label\"], [\"Problems associated with initialization and poor convergence to concave boundaries, however, have limited their utility.\", \"background_label\"], [\"This paper develops a new external force for active contours, largely solving both problems.\", \"objective_label\"], [\"This external force, which we call gradient vector flow (GVF), is computed as a diffusion of the gradient vectors of a gray-level or binary edge map derived from the image.\", \"method_label\"], [\"The resultant field has a large capture range and forces active contours into concave regions.\", \"method_label\"], [\"Examples on simulated images and one real image are presented.\", \"result_label\"]]]\n",
            "\n",
            "input 185:  {\"abstract_id\": 0, \"sentences\": [\"Sentiment analysis over Twitter offer organisations a fast and effective way to monitor the publics\\u2019 feelings towards their brand, business, directors, etc.\", \"A wide range of features and methods for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results.\", \"In this paper, we introduce a novel approach of adding semantics as additional features into the training set for sentiment analysis.\", \"For each extracted entity (e.g. iPhone) from tweets, we add its semantic concept (e.g. \\u201cApple product\\u201d) as an additional feature, and measure the correlation of the representative concept with negative/positive sentiment.\", \"We apply this approach to predict sentiment for three different Twitter datasets.\", \"Our results show an average increase of F harmonic accuracy score for identifying both negative and positive sentiment of around 6.5% and 4.8% over the baselines of unigrams and part-of-speech features respectively.\", \"We also compare against an approach based on sentiment-bearing topic analysis, and find that semantic features produce better Recall and F score when classifying negative sentiment, and better Precision with lower Recall and F score in positive sentiment classification.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 0.6774, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Sentiment analysis over Twitter offer organisations a fast and effective way to monitor the publics\\u2019 feelings towards their brand, business, directors, etc.\", \"background_label\"], [\"A wide range of features and methods for training sentiment classifiers for Twitter datasets have been researched in recent years with varying results.\", \"background_label\"], [\"In this paper, we introduce a novel approach of adding semantics as additional features into the training set for sentiment analysis.\", \"method_label\"], [\"For each extracted entity (e.g. iPhone) from tweets, we add its semantic concept (e.g. \\u201cApple product\\u201d) as an additional feature, and measure the correlation of the representative concept with negative/positive sentiment.\", \"method_label\"], [\"We apply this approach to predict sentiment for three different Twitter datasets.\", \"method_label\"], [\"Our results show an average increase of F harmonic accuracy score for identifying both negative and positive sentiment of around 6.5% and 4.8% over the baselines of unigrams and part-of-speech features respectively.\", \"result_label\"], [\"We also compare against an approach based on sentiment-bearing topic analysis, and find that semantic features produce better Recall and F score when classifying negative sentiment, and better Precision with lower Recall and F score in positive sentiment classification.\", \"result_label\"]]]\n",
            "\n",
            "input 186:  {\"abstract_id\": 0, \"sentences\": [\"The trend toward physically dispersed work groups has necessitated a fresh inquiry into the role and nature of team leadership in virtual settings.\", \"To accomplish this, we assembled thirteen culturally diverse global teams from locations in Europe, Mexico, and the United States, assigning each team a project leader and task to complete.\", \"The findings suggest that effective team leaders demonstrate the capability to deal with paradox and contradiction by performing multiple leadership roles simultaneously (behavioral complexity).\", \"Specifically, we discovered that highly effective virtual team leaders act in a mentoring role and exhibit a high degree of understanding (empathy) toward other team members.\", \"At the same time, effective leaders are also able to assert their authority without being perceived as overbearing or inflexible.\", \"Finally, effective leaders are found to be extremely effective at providing regular, detailed, and prompt communication with their peers and in articulating role relationships (responsibilities) among the virtual team members.\", \"This study provides useful insights for managers interested in developing global virtual teams, as well as for academics interested in pursuing virtual team research.\", \"8 KAYWORTH AND LEIDNER\"], \"labels\": [\"background\", \"method\", \"result\", \"result\", \"result\", \"result\", \"result\", \"other\"], \"confs\": [0.7273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7273, 1.0]}\n",
            "prediction:  [0, [[\"The trend toward physically dispersed work groups has necessitated a fresh inquiry into the role and nature of team leadership in virtual settings.\", \"background_label\"], [\"To accomplish this, we assembled thirteen culturally diverse global teams from locations in Europe, Mexico, and the United States, assigning each team a project leader and task to complete.\", \"background_label\"], [\"The findings suggest that effective team leaders demonstrate the capability to deal with paradox and contradiction by performing multiple leadership roles simultaneously (behavioral complexity).\", \"result_label\"], [\"Specifically, we discovered that highly effective virtual team leaders act in a mentoring role and exhibit a high degree of understanding (empathy) toward other team members.\", \"result_label\"], [\"At the same time, effective leaders are also able to assert their authority without being perceived as overbearing or inflexible.\", \"result_label\"], [\"Finally, effective leaders are found to be extremely effective at providing regular, detailed, and prompt communication with their peers and in articulating role relationships (responsibilities) among the virtual team members.\", \"result_label\"], [\"This study provides useful insights for managers interested in developing global virtual teams, as well as for academics interested in pursuing virtual team research.\", \"result_label\"], [\"8 KAYWORTH AND LEIDNER\", \"other_label\"]]]\n",
            "\n",
            "input 187:  {\"abstract_id\": 0, \"sentences\": [\"This chapter aims to provide an overview of the class of multi-criteria recommender systems.\", \"First, it defines the recommendation problem as a multi-criteria decision making (MCDM) problem, and reviews MCDM methods and techniques that can support the implementation of multi-criteria recommenders.\", \"Then, it focuses on the category of multi-criteria rating recommenders \\u2013 techniques that provide recommendations by modelling a user\\u2019s utility for an item as a vector of ratings along several criteria.\", \"A review of current algorithms that use multicriteria ratings for calculating predictions and generating recommendations is provided.\", \"Finally, the chapter concludes with a discussion on open issues and future challenges for the class of multi-criteria rating recommenders.\"], \"labels\": [\"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.6863, 0.6863, 1.0, 0.6863]}\n",
            "prediction:  [0, [[\"This chapter aims to provide an overview of the class of multi-criteria recommender systems.\", \"objective_label\"], [\"First, it defines the recommendation problem as a multi-criteria decision making (MCDM) problem, and reviews MCDM methods and techniques that can support the implementation of multi-criteria recommenders.\", \"method_label\"], [\"Then, it focuses on the category of multi-criteria rating recommenders \\u2013 techniques that provide recommendations by modelling a user\\u2019s utility for an item as a vector of ratings along several criteria.\", \"method_label\"], [\"A review of current algorithms that use multicriteria ratings for calculating predictions and generating recommendations is provided.\", \"method_label\"], [\"Finally, the chapter concludes with a discussion on open issues and future challenges for the class of multi-criteria rating recommenders.\", \"result_label\"]]]\n",
            "\n",
            "input 188:  {\"abstract_id\": 0, \"sentences\": [\"Probabilistic forecasting, i.e. estimating the probability distribution of a time series\\u2019 future given its past, is a key enabler for optimizing business processes.\", \"In retail businesses, for example, forecasting demand is crucial for having the right inventory available at the right time at the right place.\", \"In this paper we propose DeepAR, a methodology for producing accurate probabilistic forecasts, based on training an auto-regressive recurrent network model on a large number of related time series.\", \"We demonstrate how by applying deep learning techniques to forecasting, one can overcome many of the challenges faced by widely-used classical approaches to the problem.\", \"We show through extensive empirical evaluation on several real-world forecasting data sets that our methodology produces more accurate forecasts than other state-of-the-art methods, while requiring minimal manual work.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [0.7419, 0.7419, 0.7419, 1.0, 0.7742]}\n",
            "prediction:  [0, [[\"Probabilistic forecasting, i.e. estimating the probability distribution of a time series\\u2019 future given its past, is a key enabler for optimizing business processes.\", \"background_label\"], [\"In retail businesses, for example, forecasting demand is crucial for having the right inventory available at the right time at the right place.\", \"background_label\"], [\"In this paper we propose DeepAR, a methodology for producing accurate probabilistic forecasts, based on training an auto-regressive recurrent network model on a large number of related time series.\", \"objective_label\"], [\"We demonstrate how by applying deep learning techniques to forecasting, one can overcome many of the challenges faced by widely-used classical approaches to the problem.\", \"method_label\"], [\"We show through extensive empirical evaluation on several real-world forecasting data sets that our methodology produces more accurate forecasts than other state-of-the-art methods, while requiring minimal manual work.\", \"result_label\"]]]\n",
            "\n",
            "input 189:  {\"abstract_id\": 0, \"sentences\": [\"Unlike a univariate decision tree, a multivariate decision tree is not restricted to splits of the instance space that are orthogonal to the features' axes.\", \"This article addresses several issues for constructing multivariate decision trees: representing a multivariate test, including symbolic and numeric features, learning the coefficients of a multivariate test, selecting the features to include in a test, and pruning of multivariate decision trees.\", \"We present several new methods for forming multivariate decision trees and compare them with several well-known methods.\", \"We compare the different methods across a variety of learning tasks, in order to assess each method's ability to find concise, accurate decision trees.\", \"The results demonstrate that some multivariate methods are in general more effective than others (in the context of our experimental assumptions).\", \"In addition, the experiments confirm that allowing multivariate tests generally improves the accuracy of the resulting decision tree over a univariate tree.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.6111, 1.0, 0.7778, 0.6111, 1.0]}\n",
            "prediction:  [0, [[\"Unlike a univariate decision tree, a multivariate decision tree is not restricted to splits of the instance space that are orthogonal to the features' axes.\", \"background_label\"], [\"This article addresses several issues for constructing multivariate decision trees: representing a multivariate test, including symbolic and numeric features, learning the coefficients of a multivariate test, selecting the features to include in a test, and pruning of multivariate decision trees.\", \"objective_label\"], [\"We present several new methods for forming multivariate decision trees and compare them with several well-known methods.\", \"method_label\"], [\"We compare the different methods across a variety of learning tasks, in order to assess each method's ability to find concise, accurate decision trees.\", \"method_label\"], [\"The results demonstrate that some multivariate methods are in general more effective than others (in the context of our experimental assumptions).\", \"result_label\"], [\"In addition, the experiments confirm that allowing multivariate tests generally improves the accuracy of the resulting decision tree over a univariate tree.\", \"result_label\"]]]\n",
            "\n",
            "input 190:  {\"abstract_id\": 0, \"sentences\": [\"A competitive implementation of customer relationship management (CRM) in retail banking requires business processes aligned to the value contribution.\", \"The objective of this paper is to derive a reference process on macro-level from industry best practice and validate its applicability in a survey.\", \"Furthermore, we introduce a new method for evaluating existing business process implementations with respect to the business value, as measured by the value of the customer base as relevant overall key performance measure.\", \"Comparing the individual company process and the reference process, in-house and external experts can evaluate the gaps by using the decision calculus method.\", \"This allows a clear recommendation on the prioritization of potential process modifications and quantifies their effect in terms of business value.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 0.75, 0.75]}\n",
            "prediction:  [0, [[\"A competitive implementation of customer relationship management (CRM) in retail banking requires business processes aligned to the value contribution.\", \"background_label\"], [\"The objective of this paper is to derive a reference process on macro-level from industry best practice and validate its applicability in a survey.\", \"objective_label\"], [\"Furthermore, we introduce a new method for evaluating existing business process implementations with respect to the business value, as measured by the value of the customer base as relevant overall key performance measure.\", \"method_label\"], [\"Comparing the individual company process and the reference process, in-house and external experts can evaluate the gaps by using the decision calculus method.\", \"method_label\"], [\"This allows a clear recommendation on the prioritization of potential process modifications and quantifies their effect in terms of business value.\", \"result_label\"]]]\n",
            "\n",
            "input 191:  {\"abstract_id\": 0, \"sentences\": [\"The problem of concept learning, or forming a general description of a class of objects given a set of examples and non-examples, is viewed here as a search problem.\", \"Existing programs that generalize from examples are characterized in terms of the classes of search strategies that they employ.\", \"Several classes of search strategies are then analyzed and compared in terms of their relative capabilities and computational complexities.\"], \"labels\": [\"background\", \"background\", \"method\"], \"confs\": [1.0, 0.7692, 0.7308]}\n",
            "prediction:  [0, [[\"The problem of concept learning, or forming a general description of a class of objects given a set of examples and non-examples, is viewed here as a search problem.\", \"background_label\"], [\"Existing programs that generalize from examples are characterized in terms of the classes of search strategies that they employ.\", \"background_label\"], [\"Several classes of search strategies are then analyzed and compared in terms of their relative capabilities and computational complexities.\", \"method_label\"]]]\n",
            "\n",
            "input 192:  {\"abstract_id\": 0, \"sentences\": [\"We study the task of image inpainting, which is to fill in the missing region of an incomplete image with plausible contents.\", \"To this end, we propose a learning-based approach to generate visually coherent completion given a high-resolution image with missing components.\", \"In order to overcome the difficulty to directly learn the distribution of high-dimensional image data, we divide the task into initialization and texture-refinement as two separate steps and model each step with a deep neural network.\", \"We also use simple heuristics to guide transferring of textures from boundary to the hole.\", \"We show that, by using such techniques, inpainting reduces to the problem of learning two image-feature translation functions of much smaller dimensionality.\", \"We evaluate our method on several public datasets and show that we not only generate results of comparable or better visual quality, but are orders of magnitude faster than previous state-of-the-art methods.\"], \"labels\": [\"background\", \"objective\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [0.8056, 1.0, 0.6389, 1.0, 0.6667, 0.7778]}\n",
            "prediction:  [0, [[\"We study the task of image inpainting, which is to fill in the missing region of an incomplete image with plausible contents.\", \"background_label\"], [\"To this end, we propose a learning-based approach to generate visually coherent completion given a high-resolution image with missing components.\", \"objective_label\"], [\"In order to overcome the difficulty to directly learn the distribution of high-dimensional image data, we divide the task into initialization and texture-refinement as two separate steps and model each step with a deep neural network.\", \"method_label\"], [\"We also use simple heuristics to guide transferring of textures from boundary to the hole.\", \"method_label\"], [\"We show that, by using such techniques, inpainting reduces to the problem of learning two image-feature translation functions of much smaller dimensionality.\", \"method_label\"], [\"We evaluate our method on several public datasets and show that we not only generate results of comparable or better visual quality, but are orders of magnitude faster than previous state-of-the-art methods.\", \"result_label\"]]]\n",
            "\n",
            "input 193:  {\"abstract_id\": 0, \"sentences\": [\"We consider the effect of imperfect separability in the received signals on the detection performance of multi-input multi-output (MIMO) radar with widely separated antennas.\", \"The mutual orthogonality among the received signals is often assumed but cannot be achieved in practice for all Doppler and delay pairs.\", \"We introduce a data model considering the correlation among the data from different transmitter-receiver pairs as unknown parameters.\", \"Based on the expectation maximization algorithm, we propose a method to estimate the target, correlation, and noise parameters.\", \"We then use the estimates of these parameters to develop a statistical decision test.\", \"Employing the asymptotic statistical characteristics and the numerical performance of the test, we analyze the sensitivity of the MIMO radar with respect to changes in the cross-correlation levels of the measurements.\", \"We demonstrate the effect of the increase in the correlation among the received signals from different transmitters on the detection performance.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"objective\"], \"confs\": [0.8, 1.0, 0.6, 0.8, 1.0, 0.8, 0.6]}\n",
            "prediction:  [0, [[\"We consider the effect of imperfect separability in the received signals on the detection performance of multi-input multi-output (MIMO) radar with widely separated antennas.\", \"background_label\"], [\"The mutual orthogonality among the received signals is often assumed but cannot be achieved in practice for all Doppler and delay pairs.\", \"background_label\"], [\"We introduce a data model considering the correlation among the data from different transmitter-receiver pairs as unknown parameters.\", \"method_label\"], [\"Based on the expectation maximization algorithm, we propose a method to estimate the target, correlation, and noise parameters.\", \"method_label\"], [\"We then use the estimates of these parameters to develop a statistical decision test.\", \"method_label\"], [\"Employing the asymptotic statistical characteristics and the numerical performance of the test, we analyze the sensitivity of the MIMO radar with respect to changes in the cross-correlation levels of the measurements.\", \"method_label\"], [\"We demonstrate the effect of the increase in the correlation among the received signals from different transmitters on the detection performance.\", \"result_label\"]]]\n",
            "\n",
            "input 194:  {\"abstract_id\": 0, \"sentences\": [\"Plant diseases are important factors as they result in serious reduction in quality and quantity of agriculture products.\", \"Therefore, early detection and diagnosis of these diseases are important.\", \"To this end, we propose a deep learning-based approach that automates the process of classifying banana leaves diseases.\", \"In particular, we make use of the LeNet architecture as a convolutional neural network to classify image data sets.\", \"The preliminary results demonstrate the effectiveness of the proposed approach even under challenging conditions such as illumination, complex background, different resolution, size, pose, and orientation of real scene images.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 0.7895, 0.6053, 0.6053, 1.0]}\n",
            "prediction:  [0, [[\"Plant diseases are important factors as they result in serious reduction in quality and quantity of agriculture products.\", \"background_label\"], [\"Therefore, early detection and diagnosis of these diseases are important.\", \"background_label\"], [\"To this end, we propose a deep learning-based approach that automates the process of classifying banana leaves diseases.\", \"objective_label\"], [\"In particular, we make use of the LeNet architecture as a convolutional neural network to classify image data sets.\", \"method_label\"], [\"The preliminary results demonstrate the effectiveness of the proposed approach even under challenging conditions such as illumination, complex background, different resolution, size, pose, and orientation of real scene images.\", \"result_label\"]]]\n",
            "\n",
            "input 195:  {\"abstract_id\": 0, \"sentences\": [\"While favouring communications and easing information sharing, Social Network Sites are also used to launch harmful campaigns against specific groups and individuals.\", \"Cyberbullism, incitement to self-harm practices, sexual predation are just some of the severe effects of massive online offensives.\", \"Moreover, attacks can be carried out against groups of victims and can degenerate in physical violence.\", \"In this work, we aim at containing and preventing the alarming diffusion of such hate campaigns.\", \"Using Facebook as a benchmark, we consider the textual content of comments appeared on a set of public Italian pages.\", \"We first propose a variety of hate categories to distinguish the kind of hate.\", \"Crawled comments are then annotated by up to five distinct human annotators, according to the defined taxonomy.\", \"Leveraging morpho-syntactical features, sentiment polarity and word embedding lexicons, we design and implement two classifiers for the Italian language, based on different learning algorithms: the first based on Support Vector Machines (SVM) and the second on a particular Recurrent Neural Network named Long Short Term Memory (LSTM).\", \"We test these two learning algorithms in order to verify their classification performances on the task of hate speech recognition.\", \"The results show the effectiveness of the two classification approaches tested over the first manually annotated Italian Hate Speech Corpus of social media text.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.8, 0.8, 0.6, 0.6, 0.6, 0.8, 0.6, 1.0]}\n",
            "prediction:  [0, [[\"While favouring communications and easing information sharing, Social Network Sites are also used to launch harmful campaigns against specific groups and individuals.\", \"background_label\"], [\"Cyberbullism, incitement to self-harm practices, sexual predation are just some of the severe effects of massive online offensives.\", \"background_label\"], [\"Moreover, attacks can be carried out against groups of victims and can degenerate in physical violence.\", \"background_label\"], [\"In this work, we aim at containing and preventing the alarming diffusion of such hate campaigns.\", \"objective_label\"], [\"Using Facebook as a benchmark, we consider the textual content of comments appeared on a set of public Italian pages.\", \"method_label\"], [\"We first propose a variety of hate categories to distinguish the kind of hate.\", \"method_label\"], [\"Crawled comments are then annotated by up to five distinct human annotators, according to the defined taxonomy.\", \"method_label\"], [\"Leveraging morpho-syntactical features, sentiment polarity and word embedding lexicons, we design and implement two classifiers for the Italian language, based on different learning algorithms: the first based on Support Vector Machines (SVM) and the second on a particular Recurrent Neural Network named Long Short Term Memory (LSTM).\", \"method_label\"], [\"We test these two learning algorithms in order to verify their classification performances on the task of hate speech recognition.\", \"method_label\"], [\"The results show the effectiveness of the two classification approaches tested over the first manually annotated Italian Hate Speech Corpus of social media text.\", \"result_label\"]]]\n",
            "\n",
            "input 196:  {\"abstract_id\": 0, \"sentences\": [\"0957-4174/$ see front matter 2008 Elsevier Ltd. A doi:10.1016/j.eswa.2008.07.006\", \"* Corresponding author.\", \"Tel.\", \": +3\"], \"labels\": [\"other\", \"other\", \"other\", \"other\"], \"confs\": [0.7586, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"0957-4174/$ see front matter 2008 Elsevier Ltd. A doi:10.1016/j.eswa.2008.07.006\", \"other_label\"], [\"* Corresponding author.\", \"other_label\"], [\"Tel.\", \"other_label\"], [\": +3\", \"other_label\"]]]\n",
            "\n",
            "input 197:  {\"abstract_id\": 0, \"sentences\": [\"We consider the problem of learning a sparse multi-task regression, where the structure in the outputs can be represented as a tree with leaf nodes as outputs and internal nodes as clusters of the outputs at multiple granularity.\", \"Our goal is to recover the common set of relevant inputs for each output cluster.\", \"Assuming that the tree structure is available as prior knowledge, we formulate this problem as a new multi-task regularized regression called tree-guided group lasso.\", \"Our structured regularization is based on a grouplasso penalty, where groups are defined with respect to the tree structure.\", \"We describe a systematic weighting scheme for the groups in the penalty such that each output variable is penalized in a balanced manner even if the groups overlap.\", \"We present an efficient optimization method that can handle a largescale problem.\", \"Using simulated and yeast datasets, we demonstrate that our method shows a superior performance in terms of both prediction errors and recovery of true sparsity patterns compared to other methods for multi-task learning.\"], \"labels\": [\"background\", \"objective\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.8, 0.8, 0.6, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"We consider the problem of learning a sparse multi-task regression, where the structure in the outputs can be represented as a tree with leaf nodes as outputs and internal nodes as clusters of the outputs at multiple granularity.\", \"background_label\"], [\"Our goal is to recover the common set of relevant inputs for each output cluster.\", \"objective_label\"], [\"Assuming that the tree structure is available as prior knowledge, we formulate this problem as a new multi-task regularized regression called tree-guided group lasso.\", \"objective_label\"], [\"Our structured regularization is based on a grouplasso penalty, where groups are defined with respect to the tree structure.\", \"method_label\"], [\"We describe a systematic weighting scheme for the groups in the penalty such that each output variable is penalized in a balanced manner even if the groups overlap.\", \"method_label\"], [\"We present an efficient optimization method that can handle a largescale problem.\", \"method_label\"], [\"Using simulated and yeast datasets, we demonstrate that our method shows a superior performance in terms of both prediction errors and recovery of true sparsity patterns compared to other methods for multi-task learning.\", \"result_label\"]]]\n",
            "\n",
            "input 198:  {\"abstract_id\": 0, \"sentences\": [\"This paper considers real world UK number plates and relates these to ANPR.\", \"It considers aspects of the relevant legislation and standards when applying them to real world number plates.\", \"The varied manufacturing techniques and varied specifications of component parts are also noted.\", \"The varied fixing methodologies and fixing locations are discussed as well as the impact on image capture.\"], \"labels\": [\"background\", \"background\", \"method\", \"method\"], \"confs\": [0.7, 0.7, 0.7, 0.7]}\n",
            "prediction:  [0, [[\"This paper considers real world UK number plates and relates these to ANPR.\", \"background_label\"], [\"It considers aspects of the relevant legislation and standards when applying them to real world number plates.\", \"objective_label\"], [\"The varied manufacturing techniques and varied specifications of component parts are also noted.\", \"method_label\"], [\"The varied fixing methodologies and fixing locations are discussed as well as the impact on image capture.\", \"result_label\"]]]\n",
            "\n",
            "input 199:  {\"abstract_id\": 0, \"sentences\": [\"Multiplayer Online Games (MOGs) like Defense of the Ancients and StarCraft II have attracted hundreds of millions of users who communicate, interact, and socialize with each other through gaming.\", \"In MOGs, rich social relationships emerge and can be used to improve gaming services such as match recommendation and game population retention, which are important for the user experience and the commercial value of the companies who run these MOGs.\", \"In this work, we focus on understanding social relationships in MOGs.\", \"We propose a graph model that is able to capture social relationships of a variety of types and strengths.\", \"We apply our model to real-world data collected from three MOGs that contain in total over ten years of behavioral history for millions of players and matches.\", \"We compare social relationships in MOGs across different game genres and with regular online social networks like Facebook.\", \"Taking match recommendation as an example application of our model, we propose SAMRA, a Socially Aware Match Recommendation Algorithm that takes social relationships into account.\", \"We show that our model not only improves the precision of traditional link prediction approaches, but also potentially helps players enjoy games to a higher extent.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.8056, 1.0, 1.0, 0.8056, 0.6111, 0.7778]}\n",
            "prediction:  [0, [[\"Multiplayer Online Games (MOGs) like Defense of the Ancients and StarCraft II have attracted hundreds of millions of users who communicate, interact, and socialize with each other through gaming.\", \"background_label\"], [\"In MOGs, rich social relationships emerge and can be used to improve gaming services such as match recommendation and game population retention, which are important for the user experience and the commercial value of the companies who run these MOGs.\", \"background_label\"], [\"In this work, we focus on understanding social relationships in MOGs.\", \"objective_label\"], [\"We propose a graph model that is able to capture social relationships of a variety of types and strengths.\", \"method_label\"], [\"We apply our model to real-world data collected from three MOGs that contain in total over ten years of behavioral history for millions of players and matches.\", \"method_label\"], [\"We compare social relationships in MOGs across different game genres and with regular online social networks like Facebook.\", \"method_label\"], [\"Taking match recommendation as an example application of our model, we propose SAMRA, a Socially Aware Match Recommendation Algorithm that takes social relationships into account.\", \"method_label\"], [\"We show that our model not only improves the precision of traditional link prediction approaches, but also potentially helps players enjoy games to a higher extent.\", \"result_label\"]]]\n",
            "\n",
            "input 200:  {\"abstract_id\": 0, \"sentences\": [\"This paper presents a new method for detecting and recognizing text in complex images and video frames.\", \"Text detection is performed in a two-step approach that combines the speed of a text localization step, enabling text size normalization, with the strength of a machine learning text veri3cation step applied on background independent features.\", \"Text recognition, applied on the detected text lines, is addressed by a text segmentation step followed by an traditional OCR algorithm within a multi-hypotheses framework relying on multiple segments, language modeling and OCR statistics.\", \"Experiments conducted on large databases of real broadcast documents demonstrate the validity of our approach.\", \"?\", \"2003 Pattern Recognition Society.\", \"Published by Elsevier Ltd.\", \"All rights reserved.\"], \"labels\": [\"objective\", \"method\", \"method\", \"result\", \"other\", \"other\", \"other\", \"other\"], \"confs\": [0.6111, 1.0, 1.0, 0.6111, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"This paper presents a new method for detecting and recognizing text in complex images and video frames.\", \"background_label\"], [\"Text detection is performed in a two-step approach that combines the speed of a text localization step, enabling text size normalization, with the strength of a machine learning text veri3cation step applied on background independent features.\", \"method_label\"], [\"Text recognition, applied on the detected text lines, is addressed by a text segmentation step followed by an traditional OCR algorithm within a multi-hypotheses framework relying on multiple segments, language modeling and OCR statistics.\", \"method_label\"], [\"Experiments conducted on large databases of real broadcast documents demonstrate the validity of our approach.\", \"result_label\"], [\"?\", \"result_label\"], [\"2003 Pattern Recognition Society.\", \"other_label\"], [\"Published by Elsevier Ltd.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 201:  {\"abstract_id\": 0, \"sentences\": [\"New expressions for one-sided finite-difference approximations are proposed.\", \"In these approximations the odd-order error terms are eliminated while the even-order terms are left to be taken care of by Richardson extrapolation.\", \"The effective local truncation error is shown to be less than for higher-order one-sided finite-difference approximations but the solutions for a test problem are shown to have comparable accuracy for both approximations.\", \"2006 Elsevier Inc. All rights reserved.\"], \"labels\": [\"background\", \"background\", \"background\", \"other\"], \"confs\": [0.7419, 0.7419, 0.7419, 1.0]}\n",
            "prediction:  [0, [[\"New expressions for one-sided finite-difference approximations are proposed.\", \"background_label\"], [\"In these approximations the odd-order error terms are eliminated while the even-order terms are left to be taken care of by Richardson extrapolation.\", \"background_label\"], [\"The effective local truncation error is shown to be less than for higher-order one-sided finite-difference approximations but the solutions for a test problem are shown to have comparable accuracy for both approximations.\", \"result_label\"], [\"2006 Elsevier Inc. All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 202:  {\"abstract_id\": 0, \"sentences\": [\"Little empirical work has directly addressed the sources of competitive advantage of the click and mortar e-commerce approach, despite growing recognition of its importance as a business model.\", \"In this paper, we introduce a framework to describe the areas of physical and virtual synergy in click and mortar enterprises, the management actions for achieving synergies and avoiding channel conflicts, and the types of benefits that may be obtained.\", \"Case studies of ten US companies, including both business to consumer (B2C) and business to business (B2B) cases are used to illustrate the utility of the\"], \"labels\": [\"background\", \"background\", \"background\"], \"confs\": [0.7, 0.7, 0.7]}\n",
            "prediction:  [0, [[\"Little empirical work has directly addressed the sources of competitive advantage of the click and mortar e-commerce approach, despite growing recognition of its importance as a business model.\", \"background_label\"], [\"In this paper, we introduce a framework to describe the areas of physical and virtual synergy in click and mortar enterprises, the management actions for achieving synergies and avoiding channel conflicts, and the types of benefits that may be obtained.\", \"objective_label\"], [\"Case studies of ten US companies, including both business to consumer (B2C) and business to business (B2B) cases are used to illustrate the utility of the\", \"result_label\"]]]\n",
            "\n",
            "input 203:  {\"abstract_id\": 0, \"sentences\": [\"Question Answering (QA) systems over Knowledge Graphs (KG) automatically answer natural language questions using facts contained in a knowledge graph.\", \"Simple questions, which can be answered by the extraction of a single fact, constitute a large part of questions asked on the web but still pose challenges to QA systems, especially when asked against a large knowledge resource.\", \"Existing QA systems usually rely on various components each specialised in solving different sub-tasks of the problem (such as segmentation, entity recognition, disambiguation, and relation classification etc.).\", \"In this work, we follow a quite different approach: We train a neural network for answering simple questions in an end-to-end manner, leaving all decisions to the model.\", \"It learns to rank subject-predicate pairs to enable the retrieval of relevant facts given a question.\", \"The network contains a nested word/character-level question encoder which allows to handle out-of-vocabulary and rare word problems while still being able to exploit word-level semantics.\", \"Our approach achieves results competitive with state-of-the-art end-to-end approaches that rely on an attention mechanism.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.8, 0.8, 0.8, 0.6286, 0.6286, 1.0, 0.6286]}\n",
            "prediction:  [0, [[\"Question Answering (QA) systems over Knowledge Graphs (KG) automatically answer natural language questions using facts contained in a knowledge graph.\", \"background_label\"], [\"Simple questions, which can be answered by the extraction of a single fact, constitute a large part of questions asked on the web but still pose challenges to QA systems, especially when asked against a large knowledge resource.\", \"background_label\"], [\"Existing QA systems usually rely on various components each specialised in solving different sub-tasks of the problem (such as segmentation, entity recognition, disambiguation, and relation classification etc.).\", \"background_label\"], [\"In this work, we follow a quite different approach: We train a neural network for answering simple questions in an end-to-end manner, leaving all decisions to the model.\", \"method_label\"], [\"It learns to rank subject-predicate pairs to enable the retrieval of relevant facts given a question.\", \"method_label\"], [\"The network contains a nested word/character-level question encoder which allows to handle out-of-vocabulary and rare word problems while still being able to exploit word-level semantics.\", \"method_label\"], [\"Our approach achieves results competitive with state-of-the-art end-to-end approaches that rely on an attention mechanism.\", \"result_label\"]]]\n",
            "\n",
            "input 204:  {\"abstract_id\": 0, \"sentences\": [\"https://doi.org/10.1016/j.compag.2018.02.016 Received 14 July 2017; Received in revised form 7 February 2018; Accepted 10 February 2018 \\u204e Corresponding author.\", \"E-mail address: andreas.kamilaris@irta.cat (A. Kamilaris).\", \"Computers and Electronics in Agriculture 147 (2018) 70\\u201390 0168-1699/ \\u00a9 2018 Elsevier B.V.\", \"All rights reserved.\", \"T\"], \"labels\": [\"other\", \"other\", \"other\", \"other\", \"other\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"https://doi.org/10.1016/j.compag.2018.02.016 Received 14 July 2017; Received in revised form 7 February 2018; Accepted 10 February 2018 \\u204e Corresponding author.\", \"other_label\"], [\"E-mail address: andreas.kamilaris@irta.cat (A. Kamilaris).\", \"other_label\"], [\"Computers and Electronics in Agriculture 147 (2018) 70\\u201390 0168-1699/ \\u00a9 2018 Elsevier B.V.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"], [\"T\", \"other_label\"]]]\n",
            "\n",
            "input 205:  {\"abstract_id\": 0, \"sentences\": [\"This paper presents an eficient technique for document page layout structure extraction and classification by analyzing the spatial configuration of the bounding boxes of different entities on the given image.\", \"The algorithm segments an image into a list of homogeneous zones.\", \"The classification algorithm labels each zone as text, table, line-drawing, halftone, ruling, or noise.\", \"The text-lines and words are extracted within text zones and neighboring text-lines are merged to form text-blocks.\", \"The tabular structure is further decomposed into row and column items.\", \"Finally, the document layout hierarchy is produced from these extracted entities.\"], \"labels\": [\"objective\", \"method\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.6286, 0.8, 0.7714, 1.0, 0.8286, 0.8]}\n",
            "prediction:  [0, [[\"This paper presents an eficient technique for document page layout structure extraction and classification by analyzing the spatial configuration of the bounding boxes of different entities on the given image.\", \"background_label\"], [\"The algorithm segments an image into a list of homogeneous zones.\", \"method_label\"], [\"The classification algorithm labels each zone as text, table, line-drawing, halftone, ruling, or noise.\", \"method_label\"], [\"The text-lines and words are extracted within text zones and neighboring text-lines are merged to form text-blocks.\", \"method_label\"], [\"The tabular structure is further decomposed into row and column items.\", \"method_label\"], [\"Finally, the document layout hierarchy is produced from these extracted entities.\", \"result_label\"]]]\n",
            "\n",
            "input 206:  {\"abstract_id\": 0, \"sentences\": [\"Intrusion detection based upon computational intelligence is currently attracting considerable interest from the research community.\", \"Characteristics of computational intelligence (CI) systems, such as adaptation, fault tolerance, high computational speed and error resilience in the face of noisy information fit the requirements of building a good intrusion detection model.\", \"Here we want to provide an overview of the research progress in applying CI methods to the problem of intrusion detection.\", \"The scope of this review will be on core methods of CI, including artificial neural networks, fuzzy systems, evolutionary computation, artificial immune systems, swarm intelligence, and soft computing.\", \"The research contributions in each field are systematically summarized and compared, allowing us to clearly define existing research challenges, and to highlight promising new research directions.\", \"The findings of this review should provide useful insights into the current IDS literature and be a good source for anyone who is interested in the application of CI approaches to IDSs or related fields.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7143, 0.75, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"Intrusion detection based upon computational intelligence is currently attracting considerable interest from the research community.\", \"background_label\"], [\"Characteristics of computational intelligence (CI) systems, such as adaptation, fault tolerance, high computational speed and error resilience in the face of noisy information fit the requirements of building a good intrusion detection model.\", \"background_label\"], [\"Here we want to provide an overview of the research progress in applying CI methods to the problem of intrusion detection.\", \"objective_label\"], [\"The scope of this review will be on core methods of CI, including artificial neural networks, fuzzy systems, evolutionary computation, artificial immune systems, swarm intelligence, and soft computing.\", \"objective_label\"], [\"The research contributions in each field are systematically summarized and compared, allowing us to clearly define existing research challenges, and to highlight promising new research directions.\", \"method_label\"], [\"The findings of this review should provide useful insights into the current IDS literature and be a good source for anyone who is interested in the application of CI approaches to IDSs or related fields.\", \"result_label\"]]]\n",
            "\n",
            "input 207:  {\"abstract_id\": 0, \"sentences\": [\"We present a fast algorithm for computing approximate quantiles in high speed data streams with deterministic error bounds.\", \"For data streams of size N where N is unknown in advance, our algorithm partitions the stream into sub-streams of exponentially increasing size as they arrive.\", \"For each sub-stream which has a fixed size, we compute and maintain a multi-level summary structure using a novel algorithm.\", \"In order to achieve high speed performance, the algorithm uses simple block-wise merge and sample operations.\", \"Overall, our algorithms for fixed-size streams and arbitrary-size streams have a computational cost of O(N log(1/epsivlogepsivN)) and an average per-element update cost of O(log logN) if epsiv is fixed.\"], \"labels\": [\"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [0.7333, 0.7333, 0.7333, 1.0, 0.7333]}\n",
            "prediction:  [0, [[\"We present a fast algorithm for computing approximate quantiles in high speed data streams with deterministic error bounds.\", \"background_label\"], [\"For data streams of size N where N is unknown in advance, our algorithm partitions the stream into sub-streams of exponentially increasing size as they arrive.\", \"method_label\"], [\"For each sub-stream which has a fixed size, we compute and maintain a multi-level summary structure using a novel algorithm.\", \"method_label\"], [\"In order to achieve high speed performance, the algorithm uses simple block-wise merge and sample operations.\", \"method_label\"], [\"Overall, our algorithms for fixed-size streams and arbitrary-size streams have a computational cost of O(N log(1/epsivlogepsivN)) and an average per-element update cost of O(log logN) if epsiv is fixed.\", \"result_label\"]]]\n",
            "\n",
            "input 208:  {\"abstract_id\": 0, \"sentences\": [\"ALIZE is an open-source platform for speaker recognition.\", \"The ALIZE library implements a low-level statistical engine based on the well-known Gaussian mixture modelling.\", \"The toolkit includes a set of high level tools dedicated to speaker recognition based on the latest developments in speaker recognition such as Joint Factor Analysis, Support Vector Machine, i-vector modelling and Probabilistic Linear Discriminant Analysis.\", \"Since 2005, the performance of ALIZE has been demonstrated in series of Speaker Recognition Evaluations (SREs) conducted by NIST and has been used by many participants in the last NISTSRE 2012.\", \"This paper presents the latest version of the corpus and performance on the NIST-SRE 2010 extended task.\"], \"labels\": [\"background\", \"background\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.6053, 0.6053, 0.6053]}\n",
            "prediction:  [0, [[\"ALIZE is an open-source platform for speaker recognition.\", \"background_label\"], [\"The ALIZE library implements a low-level statistical engine based on the well-known Gaussian mixture modelling.\", \"background_label\"], [\"The toolkit includes a set of high level tools dedicated to speaker recognition based on the latest developments in speaker recognition such as Joint Factor Analysis, Support Vector Machine, i-vector modelling and Probabilistic Linear Discriminant Analysis.\", \"method_label\"], [\"Since 2005, the performance of ALIZE has been demonstrated in series of Speaker Recognition Evaluations (SREs) conducted by NIST and has been used by many participants in the last NISTSRE 2012.\", \"result_label\"], [\"This paper presents the latest version of the corpus and performance on the NIST-SRE 2010 extended task.\", \"result_label\"]]]\n",
            "\n",
            "input 209:  {\"abstract_id\": 0, \"sentences\": [\"The logistic regression model is used to predict a binary response variable in terms of a set of explicative ones.\", \"The estimation of the model parameters is not too accurate and their interpretation in terms of odds ratios may be erroneous, when there is multicollinearity (high dependence) among the predictors.\", \"Other important problem is the great number of explicative variables usually needed to explain the response.\", \"In order to improve the estimation of the logistic model parameters under multicollinearity and to reduce the dimension of the problem with continuous covariates, it is proposed to use as covariates of the logistic model a reduced set of optimum principal components of the original predictors.\", \"Finally, the performance of the proposed principal component logistic regression model is analyzed by developing a simulation study where different methods for selecting the optimum principal components are compared.\", \"\\u00a9 2005 Elsevier B.V.\", \"All rights reserved.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"other\", \"other\"], \"confs\": [1.0, 1.0, 1.0, 0.6176, 0.6471, 0.7941, 1.0]}\n",
            "prediction:  [0, [[\"The logistic regression model is used to predict a binary response variable in terms of a set of explicative ones.\", \"background_label\"], [\"The estimation of the model parameters is not too accurate and their interpretation in terms of odds ratios may be erroneous, when there is multicollinearity (high dependence) among the predictors.\", \"background_label\"], [\"Other important problem is the great number of explicative variables usually needed to explain the response.\", \"background_label\"], [\"In order to improve the estimation of the logistic model parameters under multicollinearity and to reduce the dimension of the problem with continuous covariates, it is proposed to use as covariates of the logistic model a reduced set of optimum principal components of the original predictors.\", \"method_label\"], [\"Finally, the performance of the proposed principal component logistic regression model is analyzed by developing a simulation study where different methods for selecting the optimum principal components are compared.\", \"method_label\"], [\"\\u00a9 2005 Elsevier B.V.\", \"other_label\"], [\"All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 210:  {\"abstract_id\": 0, \"sentences\": [\"Given a set of keywords, we find a maximum Web query (containing the most keywords possible) that respects user-defined bounds on the number of returned hits.\", \"We assume a real-world setting where the user is not given direct access to a Web search engine's index, i.e., querying is possible only through an interface.\", \"The goal to be optimized is the overall number of submitted Web queries.\", \"One original contribution of our research is the formalization and theoretical foundation of the problem.\", \"But, in particular, we develop a co-occurrence probability informed search strategy for the problem.\", \"The performance gain achieved with our approach is substantial: compared to the uninformed baseline (without co-occurrence information) the expected savings are up to 20% in the number of submitted queries and runtime.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"objective\", \"result\"], \"confs\": [0.6, 0.8, 0.6, 0.6, 0.6, 0.8]}\n",
            "prediction:  [0, [[\"Given a set of keywords, we find a maximum Web query (containing the most keywords possible) that respects user-defined bounds on the number of returned hits.\", \"background_label\"], [\"We assume a real-world setting where the user is not given direct access to a Web search engine's index, i.e., querying is possible only through an interface.\", \"method_label\"], [\"The goal to be optimized is the overall number of submitted Web queries.\", \"objective_label\"], [\"One original contribution of our research is the formalization and theoretical foundation of the problem.\", \"objective_label\"], [\"But, in particular, we develop a co-occurrence probability informed search strategy for the problem.\", \"method_label\"], [\"The performance gain achieved with our approach is substantial: compared to the uninformed baseline (without co-occurrence information) the expected savings are up to 20% in the number of submitted queries and runtime.\", \"result_label\"]]]\n",
            "\n",
            "input 211:  {\"abstract_id\": 0, \"sentences\": [\"Most current approaches for 3D object tracking rely on distinctive object appearances.\", \"While several such trackers can be instantiated to track multiple objects independently, this not only neglects that objects should not occupy the same space in 3D, but also fails when objects have highly similar or identical appearances.\", \"In this paper we develop a probabilistic graphical model that accounts for similarity and proximity and leads to robust real-time tracking of multiple objects from RGB-D data, without recourse to bolton collision detection.\"], \"labels\": [\"background\", \"background\", \"objective\"], \"confs\": [0.8158, 0.8158, 0.6053]}\n",
            "prediction:  [0, [[\"Most current approaches for 3D object tracking rely on distinctive object appearances.\", \"background_label\"], [\"While several such trackers can be instantiated to track multiple objects independently, this not only neglects that objects should not occupy the same space in 3D, but also fails when objects have highly similar or identical appearances.\", \"background_label\"], [\"In this paper we develop a probabilistic graphical model that accounts for similarity and proximity and leads to robust real-time tracking of multiple objects from RGB-D data, without recourse to bolton collision detection.\", \"method_label\"]]]\n",
            "\n",
            "input 212:  {\"abstract_id\": 0, \"sentences\": [\"The volume of tissue activated (VTA) is a well-established approach to model the direct effects of deep brain stimulation (DBS) on neural tissue and previous studies have pointed to its potential clinical applications.\", \"However, the elevated computational time required to estimate the VTA with standard techniques used in biological neural modeling limits its suitability for practical use.\", \"The goal of this project was to develop a novel methodology to reduce the computation time of VTA estimation.\", \"To that end, we built a Gaussian process emulator.\", \"It combines a field of multi-compartment axon models coupled to the stimulating electric field with a Gaussian process classifier (GPC); following the premise that computing the VTA from a field of axons is in essence a binary classification problem.\", \"We achieved a considerable reduction in the average time required to estimate the VTA, under both ideal isotropic and realistic anisotropic brain tissue conductive conditions, limiting the loss of accuracy and overcoming other drawbacks entailed by alternative methods.\"], \"labels\": [\"background\", \"background\", \"objective\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 0.7143, 0.7143, 1.0]}\n",
            "prediction:  [0, [[\"The volume of tissue activated (VTA) is a well-established approach to model the direct effects of deep brain stimulation (DBS) on neural tissue and previous studies have pointed to its potential clinical applications.\", \"background_label\"], [\"However, the elevated computational time required to estimate the VTA with standard techniques used in biological neural modeling limits its suitability for practical use.\", \"background_label\"], [\"The goal of this project was to develop a novel methodology to reduce the computation time of VTA estimation.\", \"objective_label\"], [\"To that end, we built a Gaussian process emulator.\", \"objective_label\"], [\"It combines a field of multi-compartment axon models coupled to the stimulating electric field with a Gaussian process classifier (GPC); following the premise that computing the VTA from a field of axons is in essence a binary classification problem.\", \"method_label\"], [\"We achieved a considerable reduction in the average time required to estimate the VTA, under both ideal isotropic and realistic anisotropic brain tissue conductive conditions, limiting the loss of accuracy and overcoming other drawbacks entailed by alternative methods.\", \"result_label\"]]]\n",
            "\n",
            "input 213:  {\"abstract_id\": 0, \"sentences\": [\"125 years after Bertha Benz completed the first overland journey in automotive history, the Mercedes Benz S-Class S 500 INTELLIGENT DRIVE followed the same route from Mannheim to Pforzheim, Germany, in fully autonomous manner.\", \"The autonomous vehicle was equipped with close-to-production sensor hardware and relied solely on vision and radar sensors in combination with accurate digital maps to obtain a comprehensive understanding of complex traffic situations.\", \"The historic Bertha Benz Memorial Route is particularly challenging for autonomous driving.\", \"The course taken by the autonomous vehicle had a length of 103 km and covered rural roads, 23 small villages and major cities (e.g. downtown Mannheim and Heidelberg).\", \"The route posed a large variety of difficult traffic scenarios including intersections with and without traffic lights, roundabouts, and narrow passages with oncoming traffic.\", \"This paper gives an overview of the autonomous vehicle and presents details on vision and radar-based perception, digital road maps and video-based self-localization, as well as motion planning in complex urban scenarios.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"background\", \"objective\"], \"confs\": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"125 years after Bertha Benz completed the first overland journey in automotive history, the Mercedes Benz S-Class S 500 INTELLIGENT DRIVE followed the same route from Mannheim to Pforzheim, Germany, in fully autonomous manner.\", \"background_label\"], [\"The autonomous vehicle was equipped with close-to-production sensor hardware and relied solely on vision and radar sensors in combination with accurate digital maps to obtain a comprehensive understanding of complex traffic situations.\", \"background_label\"], [\"The historic Bertha Benz Memorial Route is particularly challenging for autonomous driving.\", \"background_label\"], [\"The course taken by the autonomous vehicle had a length of 103 km and covered rural roads, 23 small villages and major cities (e.g. downtown Mannheim and Heidelberg).\", \"background_label\"], [\"The route posed a large variety of difficult traffic scenarios including intersections with and without traffic lights, roundabouts, and narrow passages with oncoming traffic.\", \"background_label\"], [\"This paper gives an overview of the autonomous vehicle and presents details on vision and radar-based perception, digital road maps and video-based self-localization, as well as motion planning in complex urban scenarios.\", \"result_label\"]]]\n",
            "\n",
            "input 214:  {\"abstract_id\": 0, \"sentences\": [\"We present here a new algorithm for segmentation of intensity images which is robust, rapid, and free of tuning parameters.\", \"The method, however, requires the input of a number of seeds, either individual pixels or regions, which will control the formation of regions into which the image will be segmented.\", \"In this correspondence, we present the algorithm, discuss briefly its properties, and suggest two ways in which it can be employed, namely, by using manual seed selection or by automated procedures.\"], \"labels\": [\"objective\", \"method\", \"method\"], \"confs\": [0.76, 0.76, 0.8]}\n",
            "prediction:  [0, [[\"We present here a new algorithm for segmentation of intensity images which is robust, rapid, and free of tuning parameters.\", \"background_label\"], [\"The method, however, requires the input of a number of seeds, either individual pixels or regions, which will control the formation of regions into which the image will be segmented.\", \"method_label\"], [\"In this correspondence, we present the algorithm, discuss briefly its properties, and suggest two ways in which it can be employed, namely, by using manual seed selection or by automated procedures.\", \"method_label\"]]]\n",
            "\n",
            "input 215:  {\"abstract_id\": 0, \"sentences\": [\"One commonly used framework for developing and evaluating technology intensive information systems is CobiT. This framework was originally a benchmark of best control practices developed and maintained by the Information Technology Governance Institute, the umbrella organization to the Information Systems Audit and Control Association.\", \"We empirically examine the conceptual model that underlies the CobiT internal control framework as it applies to an audit setting (including operational, compliance, and financial audit settings).\", \"We find that superimposing CobiT's conceptual model onto audit relevant assessments made by a panel of highly experienced IT auditors confirms the internal consistency between the underlying constructs of CobiT. Furthermore, we find that CobiT's conceptual model predicts auditor behavior in the field related to their seeking help and giving help as evidenced by their postings to a general IT audit listserv.\", \"Given the results of this study, we propose future research aimed at developing a general theory of internal control applicable to information technology based on CobiT. \\u00a9 2007 Elsevier Inc. All rights reserved.\"], \"labels\": [\"background\", \"background\", \"background\", \"result\"], \"confs\": [0.7377, 0.7377, 0.7377, 0.7377]}\n",
            "prediction:  [0, [[\"One commonly used framework for developing and evaluating technology intensive information systems is CobiT. This framework was originally a benchmark of best control practices developed and maintained by the Information Technology Governance Institute, the umbrella organization to the Information Systems Audit and Control Association.\", \"background_label\"], [\"We empirically examine the conceptual model that underlies the CobiT internal control framework as it applies to an audit setting (including operational, compliance, and financial audit settings).\", \"objective_label\"], [\"We find that superimposing CobiT's conceptual model onto audit relevant assessments made by a panel of highly experienced IT auditors confirms the internal consistency between the underlying constructs of CobiT. Furthermore, we find that CobiT's conceptual model predicts auditor behavior in the field related to their seeking help and giving help as evidenced by their postings to a general IT audit listserv.\", \"result_label\"], [\"Given the results of this study, we propose future research aimed at developing a general theory of internal control applicable to information technology based on CobiT. \\u00a9 2007 Elsevier Inc. All rights reserved.\", \"other_label\"]]]\n",
            "\n",
            "input 216:  {\"abstract_id\": 0, \"sentences\": [\"Automatic classification of fruits via computer vision is still a complicated task due to the various properties of numerous types of fruits.\", \"We propose a novel classification method based on a multi-class kernel support vector machine (kSVM) with the desirable goal of accurate and fast classification of fruits.\", \"First, fruit images were acquired by a digital camera, and then the background of each image was removed by a split-and-merge algorithm; Second, the color histogram, texture and shape features of each fruit image were extracted to compose a feature space; Third, principal component analysis (PCA) was used to reduce the dimensions of feature space; Finally, three kinds of multi-class SVMs were constructed, i.e., Winner-Takes-All SVM, Max-Wins-Voting SVM, and Directed Acyclic Graph SVM.\", \"Meanwhile, three kinds of kernels were chosen, i.e., linear kernel, Homogeneous Polynomial kernel, and Gaussian Radial Basis kernel; finally, the SVMs were trained using 5-fold stratified cross validation with the reduced feature vectors as input.\", \"The experimental results demonstrated that the Max-Wins-Voting SVM with Gaussian Radial Basis kernel achieves the best classification accuracy of 88.2%.\", \"For computation time, the Directed Acyclic Graph SVMs performs swiftest.\"], \"labels\": [\"background\", \"objective\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.7419, 0.7742, 0.7742, 0.7742, 0.7742]}\n",
            "prediction:  [0, [[\"Automatic classification of fruits via computer vision is still a complicated task due to the various properties of numerous types of fruits.\", \"background_label\"], [\"We propose a novel classification method based on a multi-class kernel support vector machine (kSVM) with the desirable goal of accurate and fast classification of fruits.\", \"objective_label\"], [\"First, fruit images were acquired by a digital camera, and then the background of each image was removed by a split-and-merge algorithm; Second, the color histogram, texture and shape features of each fruit image were extracted to compose a feature space; Third, principal component analysis (PCA) was used to reduce the dimensions of feature space; Finally, three kinds of multi-class SVMs were constructed, i.e., Winner-Takes-All SVM, Max-Wins-Voting SVM, and Directed Acyclic Graph SVM.\", \"method_label\"], [\"Meanwhile, three kinds of kernels were chosen, i.e., linear kernel, Homogeneous Polynomial kernel, and Gaussian Radial Basis kernel; finally, the SVMs were trained using 5-fold stratified cross validation with the reduced feature vectors as input.\", \"method_label\"], [\"The experimental results demonstrated that the Max-Wins-Voting SVM with Gaussian Radial Basis kernel achieves the best classification accuracy of 88.2%.\", \"result_label\"], [\"For computation time, the Directed Acyclic Graph SVMs performs swiftest.\", \"result_label\"]]]\n",
            "\n",
            "input 217:  {\"abstract_id\": 0, \"sentences\": [\"As CMOS technologies have shrunk to tens of nanometers, aging problems have emerged as a major challenge.\", \"There has been tremendous progress in developing new methods for modeling and diagnosing reliability at the level of individual transistors, but much less work on propagating these models to higher levels of abstraction to analyze and optimize the reliability of larger circuits.\", \"This talk will provide an introduction to various circuit aging mechanisms and will then discuss research that develops computer-aided design techniques for estimating and enhancing the reliability of large digital circuits, examining solutions that could practically be applied to analyze or improve the lifetime of a design while maintaining consistency to accurate device-level models and the associated physics.\"], \"labels\": [\"background\", \"background\", \"result\"], \"confs\": [0.7838, 0.6216, 0.6216]}\n",
            "prediction:  [0, [[\"As CMOS technologies have shrunk to tens of nanometers, aging problems have emerged as a major challenge.\", \"background_label\"], [\"There has been tremendous progress in developing new methods for modeling and diagnosing reliability at the level of individual transistors, but much less work on propagating these models to higher levels of abstraction to analyze and optimize the reliability of larger circuits.\", \"background_label\"], [\"This talk will provide an introduction to various circuit aging mechanisms and will then discuss research that develops computer-aided design techniques for estimating and enhancing the reliability of large digital circuits, examining solutions that could practically be applied to analyze or improve the lifetime of a design while maintaining consistency to accurate device-level models and the associated physics.\", \"method_label\"]]]\n",
            "\n",
            "input 218:  {\"abstract_id\": 0, \"sentences\": [\"Internet of Things (IoT) security and privacy remain a major challenge, mainly due to the massive scale and distributed nature of IoT networks.\", \"Blockchain-based approaches provide decentralized security and privacy, yet they involve significant energy, delay, and computational overhead that is not suitable for most resource-constrained IoT devices.\", \"In our previous work, we presented a lightweight instantiation of a BC particularly geared for use in IoT by eliminating the Proof of Work (POW) and the concept of coins.\", \"Our approach was exemplified in a smart home setting and consists of three main tiers namely: cloud storage, overlay, and smart home.\", \"In this paper we delve deeper and outline the various core components and functions of the smart home tier.\", \"Each smart home is equipped with an always online, high resource device, known as \\u201cminer\\u201d that is responsible for handling all communication within and external to the home.\", \"The miner also preserves a private and secure BC, used for controlling and auditing communications.\", \"We show that our proposed BC-based smart home framework is secure by thoroughly analysing its security with respect to the fundamental security goals of confidentiality, integrity, and availability.\", \"Finally, we present simulation results to highlight that the overheads (in terms of traffic, processing time and energy consumption) introduced by our approach are insignificant relative to its security and privacy gains.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"method\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 0.7667, 1.0, 1.0, 0.7667, 0.7667, 0.7667, 0.7667]}\n",
            "prediction:  [0, [[\"Internet of Things (IoT) security and privacy remain a major challenge, mainly due to the massive scale and distributed nature of IoT networks.\", \"background_label\"], [\"Blockchain-based approaches provide decentralized security and privacy, yet they involve significant energy, delay, and computational overhead that is not suitable for most resource-constrained IoT devices.\", \"background_label\"], [\"In our previous work, we presented a lightweight instantiation of a BC particularly geared for use in IoT by eliminating the Proof of Work (POW) and the concept of coins.\", \"objective_label\"], [\"Our approach was exemplified in a smart home setting and consists of three main tiers namely: cloud storage, overlay, and smart home.\", \"method_label\"], [\"In this paper we delve deeper and outline the various core components and functions of the smart home tier.\", \"method_label\"], [\"Each smart home is equipped with an always online, high resource device, known as \\u201cminer\\u201d that is responsible for handling all communication within and external to the home.\", \"method_label\"], [\"The miner also preserves a private and secure BC, used for controlling and auditing communications.\", \"method_label\"], [\"We show that our proposed BC-based smart home framework is secure by thoroughly analysing its security with respect to the fundamental security goals of confidentiality, integrity, and availability.\", \"result_label\"], [\"Finally, we present simulation results to highlight that the overheads (in terms of traffic, processing time and energy consumption) introduced by our approach are insignificant relative to its security and privacy gains.\", \"result_label\"]]]\n",
            "\n",
            "input 219:  {\"abstract_id\": 0, \"sentences\": [\"Exaggeration of facial expressions is used in animation and robotics to intensify emotions.\", \"However, modifying a human-like face can lead to an unsettling outcome.\", \"This phenomenon is known as uncanny valley.\", \"The goal of this study was to identify the realism level and magnitude of facial expression that produce the maximum amount of emotional intensity and the minimum amount of perceived strangeness.\", \"We studied the perceived intensity of emotion and perceived strangeness of faces with varying levels of realism (from schematic to photorealistic) and magnitude of facial expressions (from neutral to extremely exaggerated).\", \"We found that less realistic faces required more exaggeration to reach the emotional intensity of a real human face.\", \"While there is a range of emotional intensity that can be expressed by real human faces (from neutral to full intensity), we found that the same range of emotional intensity could be expressed by artificial faces when exaggeration was used.\", \"However, attempts to express emotional intensities outside this range using exaggeration led to strange-looking faces at all levels of realism.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"result\", \"result\", \"result\"], \"confs\": [1.0, 1.0, 0.776, 0.832, 1.0, 0.608, 0.832, 1.0]}\n",
            "prediction:  [0, [[\"Exaggeration of facial expressions is used in animation and robotics to intensify emotions.\", \"background_label\"], [\"However, modifying a human-like face can lead to an unsettling outcome.\", \"background_label\"], [\"This phenomenon is known as uncanny valley.\", \"background_label\"], [\"The goal of this study was to identify the realism level and magnitude of facial expression that produce the maximum amount of emotional intensity and the minimum amount of perceived strangeness.\", \"objective_label\"], [\"We studied the perceived intensity of emotion and perceived strangeness of faces with varying levels of realism (from schematic to photorealistic) and magnitude of facial expressions (from neutral to extremely exaggerated).\", \"method_label\"], [\"We found that less realistic faces required more exaggeration to reach the emotional intensity of a real human face.\", \"method_label\"], [\"While there is a range of emotional intensity that can be expressed by real human faces (from neutral to full intensity), we found that the same range of emotional intensity could be expressed by artificial faces when exaggeration was used.\", \"result_label\"], [\"However, attempts to express emotional intensities outside this range using exaggeration led to strange-looking faces at all levels of realism.\", \"result_label\"]]]\n",
            "\n",
            "input 220:  {\"abstract_id\": 0, \"sentences\": [\"The recent research on the CVRP is being slowed down by the lack of a good set of benchmark instances.\", \"The existing sets suffer from at least one of the following drawbacks: (i) became too easy for current algorithms; (ii) are too artificial; (iii) are too homogeneous, not covering the wide range of characteristics found in real applications.\", \"We propose a new set of instances ranging from 100 to 1000 customers, designed in order to provide a more comprehensive and balanced experimental setting.\", \"We report results with state-of-the-art exact and heuristic methods.\"], \"labels\": [\"background\", \"background\", \"objective\", \"method\"], \"confs\": [0.75, 0.75, 0.75, 1.0]}\n",
            "prediction:  [0, [[\"The recent research on the CVRP is being slowed down by the lack of a good set of benchmark instances.\", \"background_label\"], [\"The existing sets suffer from at least one of the following drawbacks: (i) became too easy for current algorithms; (ii) are too artificial; (iii) are too homogeneous, not covering the wide range of characteristics found in real applications.\", \"background_label\"], [\"We propose a new set of instances ranging from 100 to 1000 customers, designed in order to provide a more comprehensive and balanced experimental setting.\", \"objective_label\"], [\"We report results with state-of-the-art exact and heuristic methods.\", \"result_label\"]]]\n",
            "\n",
            "input 221:  {\"abstract_id\": 0, \"sentences\": [\"Many modern robotics applications require robots to function autonomously in dynamic environments including other decision making agents, such as people or other robots.\", \"This calls for fast and scalable interactive motion planning.\", \"This requires models that take into consideration the other agent's intended actions in one's own planning.\", \"We present a real-time motion planning framework that brings together a few key components including intention inference by reasoning counterfactually about potential motion of the other agents as they work towards different goals.\", \"By using a light-weight motion model, we achieve efficient iterative planning for fluid motion when avoiding pedestrians, in parallel with goal inference for longer range movement prediction.\", \"This inference framework is coupled with a novel distributed visual tracking method that provides reliable and robust models for the current belief-state of the monitored environment.\", \"This combined approach represents a computationally efficient alternative to previously studied policy learning methods that often require significant offline training or calibration and do not yet scale to densely populated environments.\", \"We validate this framework with experiments involving multi-robot and human-robot navigation.\", \"We further validate the tracker component separately on much larger scale unconstrained pedestrian data sets.\"], \"labels\": [\"background\", \"background\", \"background\", \"method\", \"method\", \"method\", \"method\", \"result\", \"result\"], \"confs\": [1.0, 0.9662, 0.9662, 0.8324, 0.9595, 1.0, 0.9662, 0.9662, 0.9324]}\n",
            "prediction:  [0, [[\"Many modern robotics applications require robots to function autonomously in dynamic environments including other decision making agents, such as people or other robots.\", \"background_label\"], [\"This calls for fast and scalable interactive motion planning.\", \"background_label\"], [\"This requires models that take into consideration the other agent's intended actions in one's own planning.\", \"background_label\"], [\"We present a real-time motion planning framework that brings together a few key components including intention inference by reasoning counterfactually about potential motion of the other agents as they work towards different goals.\", \"objective_label\"], [\"By using a light-weight motion model, we achieve efficient iterative planning for fluid motion when avoiding pedestrians, in parallel with goal inference for longer range movement prediction.\", \"method_label\"], [\"This inference framework is coupled with a novel distributed visual tracking method that provides reliable and robust models for the current belief-state of the monitored environment.\", \"method_label\"], [\"This combined approach represents a computationally efficient alternative to previously studied policy learning methods that often require significant offline training or calibration and do not yet scale to densely populated environments.\", \"method_label\"], [\"We validate this framework with experiments involving multi-robot and human-robot navigation.\", \"result_label\"], [\"We further validate the tracker component separately on much larger scale unconstrained pedestrian data sets.\", \"result_label\"]]]\n",
            "\n",
            "input 222:  {\"abstract_id\": 0, \"sentences\": [\"Architectural views are at the foundation of software architecture and are used to describe the system from different perspectives.\", \"However, some architectural concerns crosscut the decomposition of the architecture in views.\", \"The drawbacks of crosscutting with respect to architectural views is similar to the drawbacks with respect to code, i.e. hampering reuse, maintenance and evolution of the architecture.\", \"This paper investigates the relations between architectural concerns, architectural drivers and views to identify why crosscutting manifests itself.\", \"We propose to extend the architectural description with slices and composition mechanisms to prevent this crosscutting and perform an initial exploration of these concepts in an Online Auction system.\", \"Within this limited setting the first results look promising to better separate concerns that otherwise would crosscut the views.\"], \"labels\": [\"background\", \"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 1.0, 1.0, 0.7742, 0.7419, 1.0]}\n",
            "prediction:  [0, [[\"Architectural views are at the foundation of software architecture and are used to describe the system from different perspectives.\", \"background_label\"], [\"However, some architectural concerns crosscut the decomposition of the architecture in views.\", \"background_label\"], [\"The drawbacks of crosscutting with respect to architectural views is similar to the drawbacks with respect to code, i.e. hampering reuse, maintenance and evolution of the architecture.\", \"background_label\"], [\"This paper investigates the relations between architectural concerns, architectural drivers and views to identify why crosscutting manifests itself.\", \"objective_label\"], [\"We propose to extend the architectural description with slices and composition mechanisms to prevent this crosscutting and perform an initial exploration of these concepts in an Online Auction system.\", \"method_label\"], [\"Within this limited setting the first results look promising to better separate concerns that otherwise would crosscut the views.\", \"result_label\"]]]\n",
            "\n",
            "input 223:  {\"abstract_id\": 0, \"sentences\": [\"This paper describes an algorithm to compute the envelope of a set of points in a plane, which generates convex or non-convex hulls that represent the area occupied by the given points.\", \"The proposed algorithm is based on a k-nearest neighbours approach, where the value of k, the only algorithm parameter, is used to control the \\u201csmoothness\\u201d of the final solution.\", \"The obtained results show that this algorithm is able to deal with arbitrary sets of points, and that the time to compute the polygons increases approximately linearly with the number of points.\"], \"labels\": [\"objective\", \"method\", \"result\"], \"confs\": [0.7419, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"This paper describes an algorithm to compute the envelope of a set of points in a plane, which generates convex or non-convex hulls that represent the area occupied by the given points.\", \"background_label\"], [\"The proposed algorithm is based on a k-nearest neighbours approach, where the value of k, the only algorithm parameter, is used to control the \\u201csmoothness\\u201d of the final solution.\", \"method_label\"], [\"The obtained results show that this algorithm is able to deal with arbitrary sets of points, and that the time to compute the polygons increases approximately linearly with the number of points.\", \"result_label\"]]]\n",
            "\n",
            "input 224:  {\"abstract_id\": 0, \"sentences\": [\"Recurrent neural networks are powerful sequence learners.\", \"They are able to incorporate context information in a flexible way, and are robust to localised distortions of the input data.\", \"These properties make them well suited to sequence labelling, where input sequences are transcribed with streams of labels.\", \"Long short-term memory is an especially promising recurrent architecture, able to bridge long time delays between relevant input and output events, and thereby access long range context.\", \"The aim of this thesis is to advance the state-of-the-art in supervised sequence labelling with recurrent networks in general, and long short-term memory in particular.\", \"Its two main contributions are (1) a new type of output layer that allows recurrent networks to be trained directly for sequence labelling tasks where the alignment between the inputs and the labels is unknown, and (2) an extension of long short-term memory to multidimensional data, such as images and video sequences.\", \"Experimental results are presented on speech recognition, online and offline handwriting recognition, keyword spotting, image segmentation and image classification, demonstrating the advantages of advanced recurrent networks over other sequential algorithms, such as hidden Markov Models.\"], \"labels\": [\"background\", \"background\", \"background\", \"background\", \"objective\", \"method\", \"result\"], \"confs\": [1.0, 0.7333, 1.0, 0.7333, 1.0, 0.7333, 1.0]}\n",
            "prediction:  [0, [[\"Recurrent neural networks are powerful sequence learners.\", \"background_label\"], [\"They are able to incorporate context information in a flexible way, and are robust to localised distortions of the input data.\", \"background_label\"], [\"These properties make them well suited to sequence labelling, where input sequences are transcribed with streams of labels.\", \"background_label\"], [\"Long short-term memory is an especially promising recurrent architecture, able to bridge long time delays between relevant input and output events, and thereby access long range context.\", \"background_label\"], [\"The aim of this thesis is to advance the state-of-the-art in supervised sequence labelling with recurrent networks in general, and long short-term memory in particular.\", \"objective_label\"], [\"Its two main contributions are (1) a new type of output layer that allows recurrent networks to be trained directly for sequence labelling tasks where the alignment between the inputs and the labels is unknown, and (2) an extension of long short-term memory to multidimensional data, such as images and video sequences.\", \"method_label\"], [\"Experimental results are presented on speech recognition, online and offline handwriting recognition, keyword spotting, image segmentation and image classification, demonstrating the advantages of advanced recurrent networks over other sequential algorithms, such as hidden Markov Models.\", \"result_label\"]]]\n",
            "\n",
            "input 225:  {\"abstract_id\": 0, \"sentences\": [\"The purposes of this paper are to review the microinstruction sequencing capabilities of several microprogrammed computers; to determine whether these sequencing capabilities permit easy implementation of the control constructs of flowchartable program logic in modular microcode; and to present a set of microinstruction sequencing functions which will support \\\"structured\\\" microprogramming.\", \"Several microprogrammable mini- and microcomputers which provide the user with the means for implementing special purpose instruction sets have been introduced relatively recently.\", \"However, the experiments by Weber and Balzer which demonstrated the possibilities for increasing computation speeds, decreasing main memory space usage, and easing the task of applications programming by means of special purpose instruction sets implemented in microcode were performed some time ago.\"], \"labels\": [\"background\", \"background\", \"background\"], \"confs\": [1.0, 1.0, 1.0]}\n",
            "prediction:  [0, [[\"The purposes of this paper are to review the microinstruction sequencing capabilities of several microprogrammed computers; to determine whether these sequencing capabilities permit easy implementation of the control constructs of flowchartable program logic in modular microcode; and to present a set of microinstruction sequencing functions which will support \\\"structured\\\" microprogramming.\", \"objective_label\"], [\"Several microprogrammable mini- and microcomputers which provide the user with the means for implementing special purpose instruction sets have been introduced relatively recently.\", \"method_label\"], [\"However, the experiments by Weber and Balzer which demonstrated the possibilities for increasing computation speeds, decreasing main memory space usage, and easing the task of applications programming by means of special purpose instruction sets implemented in microcode were performed some time ago.\", \"result_label\"]]]\n",
            "\n",
            "2023-03-05 06:37:15,972 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpn672b5bv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "%%shell\n",
        "chmod +x scripts/predict.sh\n",
        "source activate allennlp\n",
        "sh scripts/predict.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBQblOwFbH3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}